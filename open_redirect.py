"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(path)                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = gettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(path)                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = gettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(path)                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = gettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(path)                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = gettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(path)                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = gettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.translation import gettext as _, gettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(path)                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = gettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

import time
try:
    from urllib.parse import urlencode
except ImportError:
    # Python < 3
    from urllib import urlencode

from django.core.exceptions import SuspiciousOperation
from django.core.urlresolvers import reverse
from django.contrib import auth
from django.http import HttpResponseRedirect
from django.utils.crypto import get_random_string
from django.utils.module_loading import import_string
from django.views.generic import View

from mozilla_django_oidc.utils import (
    absolutify,
    import_from_settings,
    is_authenticated,
)


class OIDCAuthenticationCallbackView(View):
    """OIDC client authentication callback HTTP endpoint"""

    http_method_names = ['get']

    @property
    def failure_url(self):
        return import_from_settings('LOGIN_REDIRECT_URL_FAILURE', '/')

    @property
    def success_url(self):
        next_url = self.request.session.get('oidc_login_next', None)
        return next_url or import_from_settings('LOGIN_REDIRECT_URL', '/')

    def login_failure(self):
        return HttpResponseRedirect(self.failure_url)

    def login_success(self):
        auth.login(self.request, self.user)

        # Figure out when this id_token will expire. This is ignored unless you're
        # using the RenewIDToken middleware.
        expiration_interval = import_from_settings('OIDC_RENEW_ID_TOKEN_EXPIRY_SECONDS', 60 * 15)
        self.request.session['oidc_id_token_expiration'] = time.time() + expiration_interval

        return HttpResponseRedirect(self.success_url)

    def get(self, request):
        """Callback handler for OIDC authorization code flow"""

        nonce = request.session.get('oidc_nonce')
        if nonce:
            # Make sure that nonce is not used twice
            del request.session['oidc_nonce']

        if 'code' in request.GET and 'state' in request.GET:
            kwargs = {
                'request': request,
                'nonce': nonce,
            }

            if 'oidc_state' not in request.session:
                return self.login_failure()

            if request.GET['state'] != request.session['oidc_state']:
                msg = 'Session `oidc_state` does not match the OIDC callback state'
                raise SuspiciousOperation(msg)

            self.user = auth.authenticate(**kwargs)

            if self.user and self.user.is_active:
                return self.login_success()
        return self.login_failure()


class OIDCAuthenticationRequestView(View):
    """OIDC client authentication HTTP endpoint"""

    http_method_names = ['get']

    def __init__(self, *args, **kwargs):
        super(OIDCAuthenticationRequestView, self).__init__(*args, **kwargs)

        self.OIDC_OP_AUTH_ENDPOINT = import_from_settings('OIDC_OP_AUTHORIZATION_ENDPOINT')
        self.OIDC_RP_CLIENT_ID = import_from_settings('OIDC_RP_CLIENT_ID')

    def get(self, request):
        """OIDC client authentication initialization HTTP endpoint"""
        state = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))
        redirect_field_name = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')

        params = {
            'response_type': 'code',
            'scope': 'openid',
            'client_id': self.OIDC_RP_CLIENT_ID,
            'redirect_uri': absolutify(
                request,
                reverse('oidc_authentication_callback')
            ),
            'state': state,
        }

        if import_from_settings('OIDC_USE_NONCE', True):
            nonce = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))
            params.update({
                'nonce': nonce
            })
            request.session['oidc_nonce'] = nonce

        request.session['oidc_state'] = state
        request.session['oidc_login_next'] = request.GET.get(redirect_field_name)                    

        query = urlencode(params)
        redirect_url = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, query=query)
        return HttpResponseRedirect(redirect_url)


class OIDCLogoutView(View):
    """Logout helper view"""

    http_method_names = ['get', 'post']

    @property
    def redirect_url(self):
        """Return the logout url defined in settings."""
        return import_from_settings('LOGOUT_REDIRECT_URL', '/')

    def post(self, request):
        """Log out the user."""
        logout_url = self.redirect_url

        if is_authenticated(request.user):
            # Check if a method exists to build the URL to log out the user
            # from the OP.
            logout_from_op = import_from_settings('OIDC_OP_LOGOUT_URL_METHOD', '')
            if logout_from_op:
                logout_url = import_string(logout_from_op)()

            # Log out the Django user, only if she was actually logged in.
            auth.logout(request)

        return HttpResponseRedirect(logout_url)

import time
try:
    from urllib.parse import urlencode
except ImportError:
    # Python < 3
    from urllib import urlencode

from django.core.exceptions import SuspiciousOperation
from django.core.urlresolvers import reverse
from django.contrib import auth
from django.http import HttpResponseRedirect
from django.utils.crypto import get_random_string
from django.utils.module_loading import import_string
from django.views.generic import View

from mozilla_django_oidc.utils import (
    absolutify,
    import_from_settings,
    is_authenticated,
)


class OIDCAuthenticationCallbackView(View):
    """OIDC client authentication callback HTTP endpoint"""

    http_method_names = ['get']

    @property
    def failure_url(self):
        return import_from_settings('LOGIN_REDIRECT_URL_FAILURE', '/')

    @property
    def success_url(self):
        next_url = self.request.session.get('oidc_login_next', None)
        return next_url or import_from_settings('LOGIN_REDIRECT_URL', '/')

    def login_failure(self):
        return HttpResponseRedirect(self.failure_url)

    def login_success(self):
        auth.login(self.request, self.user)

        # Figure out when this id_token will expire. This is ignored unless you're
        # using the RenewIDToken middleware.
        expiration_interval = import_from_settings('OIDC_RENEW_ID_TOKEN_EXPIRY_SECONDS', 60 * 15)
        self.request.session['oidc_id_token_expiration'] = time.time() + expiration_interval

        return HttpResponseRedirect(self.success_url)

    def get(self, request):
        """Callback handler for OIDC authorization code flow"""

        nonce = request.session.get('oidc_nonce')
        if nonce:
            # Make sure that nonce is not used twice
            del request.session['oidc_nonce']

        if 'code' in request.GET and 'state' in request.GET:
            kwargs = {
                'request': request,
                'nonce': nonce,
            }

            if 'oidc_state' not in request.session:
                return self.login_failure()

            if request.GET['state'] != request.session['oidc_state']:
                msg = 'Session `oidc_state` does not match the OIDC callback state'
                raise SuspiciousOperation(msg)

            self.user = auth.authenticate(**kwargs)

            if self.user and self.user.is_active:
                return self.login_success()
        return self.login_failure()


class OIDCAuthenticationRequestView(View):
    """OIDC client authentication HTTP endpoint"""

    http_method_names = ['get']

    def __init__(self, *args, **kwargs):
        super(OIDCAuthenticationRequestView, self).__init__(*args, **kwargs)

        self.OIDC_OP_AUTH_ENDPOINT = import_from_settings('OIDC_OP_AUTHORIZATION_ENDPOINT')
        self.OIDC_RP_CLIENT_ID = import_from_settings('OIDC_RP_CLIENT_ID')

    def get(self, request):
        """OIDC client authentication initialization HTTP endpoint"""
        state = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))
        redirect_field_name = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')

        params = {
            'response_type': 'code',
            'scope': 'openid',
            'client_id': self.OIDC_RP_CLIENT_ID,
            'redirect_uri': absolutify(
                request,
                reverse('oidc_authentication_callback')
            ),
            'state': state,
        }

        if import_from_settings('OIDC_USE_NONCE', True):
            nonce = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))
            params.update({
                'nonce': nonce
            })
            request.session['oidc_nonce'] = nonce

        request.session['oidc_state'] = state
        request.session['oidc_login_next'] = request.GET.get(redirect_field_name)                    

        query = urlencode(params)
        redirect_url = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, query=query)
        return HttpResponseRedirect(redirect_url)


class OIDCLogoutView(View):
    """Logout helper view"""

    http_method_names = ['get', 'post']

    @property
    def redirect_url(self):
        """Return the logout url defined in settings."""
        return import_from_settings('LOGOUT_REDIRECT_URL', '/')

    def post(self, request):
        """Log out the user."""
        logout_url = self.redirect_url

        if is_authenticated(request.user):
            # Check if a method exists to build the URL to log out the user
            # from the OP.
            logout_from_op = import_from_settings('OIDC_OP_LOGOUT_URL_METHOD', '')
            if logout_from_op:
                logout_url = import_string(logout_from_op)()

            # Log out the Django user, only if she was actually logged in.
            auth.logout(request)

        return HttpResponseRedirect(logout_url)

import time
try:
    from urllib.parse import urlencode
except ImportError:
    # Python < 3
    from urllib import urlencode

from django.core.exceptions import SuspiciousOperation
from django.core.urlresolvers import reverse
from django.contrib import auth
from django.http import HttpResponseRedirect
from django.utils.crypto import get_random_string
from django.utils.module_loading import import_string
from django.views.generic import View

from mozilla_django_oidc.utils import (
    absolutify,
    import_from_settings,
    is_authenticated,
)


class OIDCAuthenticationCallbackView(View):
    """OIDC client authentication callback HTTP endpoint"""

    http_method_names = ['get']

    @property
    def failure_url(self):
        return import_from_settings('LOGIN_REDIRECT_URL_FAILURE', '/')

    @property
    def success_url(self):
        next_url = self.request.session.get('oidc_login_next', None)
        return next_url or import_from_settings('LOGIN_REDIRECT_URL', '/')

    def login_failure(self):
        return HttpResponseRedirect(self.failure_url)

    def login_success(self):
        auth.login(self.request, self.user)

        # Figure out when this id_token will expire. This is ignored unless you're
        # using the RenewIDToken middleware.
        expiration_interval = import_from_settings('OIDC_RENEW_ID_TOKEN_EXPIRY_SECONDS', 60 * 15)
        self.request.session['oidc_id_token_expiration'] = time.time() + expiration_interval

        return HttpResponseRedirect(self.success_url)

    def get(self, request):
        """Callback handler for OIDC authorization code flow"""

        nonce = request.session.get('oidc_nonce')
        if nonce:
            # Make sure that nonce is not used twice
            del request.session['oidc_nonce']

        if 'code' in request.GET and 'state' in request.GET:
            kwargs = {
                'request': request,
                'nonce': nonce,
            }

            if 'oidc_state' not in request.session:
                return self.login_failure()

            if request.GET['state'] != request.session['oidc_state']:
                msg = 'Session `oidc_state` does not match the OIDC callback state'
                raise SuspiciousOperation(msg)

            self.user = auth.authenticate(**kwargs)

            if self.user and self.user.is_active:
                return self.login_success()
        return self.login_failure()


class OIDCAuthenticationRequestView(View):
    """OIDC client authentication HTTP endpoint"""

    http_method_names = ['get']

    def __init__(self, *args, **kwargs):
        super(OIDCAuthenticationRequestView, self).__init__(*args, **kwargs)

        self.OIDC_OP_AUTH_ENDPOINT = import_from_settings('OIDC_OP_AUTHORIZATION_ENDPOINT')
        self.OIDC_RP_CLIENT_ID = import_from_settings('OIDC_RP_CLIENT_ID')

    def get(self, request):
        """OIDC client authentication initialization HTTP endpoint"""
        state = get_random_string(import_from_settings('OIDC_STATE_SIZE', 32))
        redirect_field_name = import_from_settings('OIDC_REDIRECT_FIELD_NAME', 'next')

        params = {
            'response_type': 'code',
            'scope': 'openid',
            'client_id': self.OIDC_RP_CLIENT_ID,
            'redirect_uri': absolutify(
                request,
                reverse('oidc_authentication_callback')
            ),
            'state': state,
        }

        if import_from_settings('OIDC_USE_NONCE', True):
            nonce = get_random_string(import_from_settings('OIDC_NONCE_SIZE', 32))
            params.update({
                'nonce': nonce
            })
            request.session['oidc_nonce'] = nonce

        request.session['oidc_state'] = state
        request.session['oidc_login_next'] = request.GET.get(redirect_field_name)                    

        query = urlencode(params)
        redirect_url = '{url}?{query}'.format(url=self.OIDC_OP_AUTH_ENDPOINT, query=query)
        return HttpResponseRedirect(redirect_url)


class OIDCLogoutView(View):
    """Logout helper view"""

    http_method_names = ['get', 'post']

    @property
    def redirect_url(self):
        """Return the logout url defined in settings."""
        return import_from_settings('LOGOUT_REDIRECT_URL', '/')

    def post(self, request):
        """Log out the user."""
        logout_url = self.redirect_url

        if is_authenticated(request.user):
            # Check if a method exists to build the URL to log out the user
            # from the OP.
            logout_from_op = import_from_settings('OIDC_OP_LOGOUT_URL_METHOD', '')
            if logout_from_op:
                logout_url = import_string(logout_from_op)()

            # Log out the Django user, only if she was actually logged in.
            auth.logout(request)

        return HttpResponseRedirect(logout_url)

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from django.test import Client

from drumbeat.utils import get_partition_id
from users.models import UserProfile

from test_utils import TestCase


class TestLogins(TestCase):

    test_username = 'testuser'
    test_password = 'testpassword'
    test_email = 'test@mozillafoundation.org'

    def setUp(self):
        self.locale = 'en-US'
        self.client = Client()
        self.user = UserProfile(username=self.test_username,
                                email=self.test_email)
        self.user.set_password(self.test_password)
        self.user.save()
        self.user.create_django_user()

    def test_authenticated_redirects(self):
        """Test that authenticated users are redirected in specific views."""
        self.client.login(username=self.test_username,
                          password=self.test_password)
        paths = ('login/', 'register/',
                 'confirm/123456/username/',
                 'confirm/resend/username/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            print response
            self.assertRedirects(response, '/', status_code=302,
                                 target_status_code=301)
        self.client.logout()

    def test_unauthenticated_redirects(self):
        """Test that anonymous users are redirected for specific views."""
        paths = ('logout/', 'profile/edit/', 'profile/edit/image/')
        for path in paths:
            full = "/%s/%s" % (self.locale, path)
            response = self.client.get(full)
            expected = "/%s/" % (self.locale,)
            self.assertRedirects(response, expected, status_code=302,
                                 target_status_code=200)

    def test_login_post(self):
        """Test logging in."""
        path = "/%s/login/" % (self.locale,)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertRedirects(response, '/', status_code=302,
                             target_status_code=301)
        # TODO - Improve this so it doesn't take so many redirects to get a 200
        response2 = self.client.get(response["location"])
        response3 = self.client.get(response2["location"])
        response4 = self.client.get(response3["location"])
        self.assertContains(response4, 'id="dashboard"')
        self.client.logout()

        response5 = self.client.post(path, {
            'username': 'nonexistant',
            'password': 'password',
        })
        self.assertContains(response5, 'id="id_username"')

    def test_login_next_param(self):
        """Test that user is redirected properly after logging in."""
        path = "/%s/login/?next=/%s/profile/edit/" % (self.locale, self.locale)
        response = self.client.post(path, {
            'username': self.test_username,
            'password': self.test_password,
        })
        self.assertEqual(
            "http://testserver/%s/profile/edit/" % (self.locale,),
            response["location"],
        )

    def test_login_next_param_header_injection(self):
        """Test that we can't inject headers into response with next param."""
        path = "/%s/login/" % (self.locale,)
        next_param = "foo\r\nLocation: http://example.com"
        response = self.client.post(path + "?next=%s" % (next_param), {
            'username': self.test_username,
            'password': self.test_password,
        })
        # we expect the header to be urlencoded before being sent.
        self.assertTrue('login/foo%0D%0ALocation' in response['location'])                    
        self.assertNotEqual('http://example.com', response['location'])

    def test_registration_opt_in(self):
        """Test account registration."""
        path = "/%s/register/" % (self.locale,)
        params = {
            'display_name': 'Joe User',
            'username': 'joeuser',
            'password': 'abcdefghijklmno1',
            'password_confirm': 'abcdefghijklmno1',
            'email': 'joe@mozilla.com',
        }
        response = self.client.post(path, params)
        self.assertContains(response, 'You must agree to the licensing terms')
        params['policy_optin'] = 'on'
        response = self.client.post(path, params)
        self.assertEqual(response.status_code, 302)

    def test_profile_image_directories(self):
        """Test that we partition image directories properly."""
        for i in range(1, 1001):
            p_id = get_partition_id(i)
            self.assertEqual(1, p_id)
        for i in range(1001, 2001):
            p_id = get_partition_id(i)
            self.assertEqual(2, p_id)
        for i in range(10001, 11001):
            p_id = get_partition_id(i)
            self.assertEqual(11, p_id)
        self.assertEqual(12, get_partition_id(11002))

from functools import wraps
import os
import json
from base64 import b64encode
import time as time_module
from copy import copy
import logging

from six.moves.urllib.parse import urlencode
from flask import request, session, redirect, url_for, g
from oauth2client.client import flow_from_clientsecrets, OAuth2WebServerFlow,\
    AccessTokenRefreshError
import httplib2
from itsdangerous import TimedJSONWebSignatureSerializer, SignatureExpired                    

__all__ = ['OpenIDConnect', 'MemoryCredentials']

logger = logging.getLogger(__name__)


class MemoryCredentials(dict):
    """
    Non-persistent local credentials store.
    Use this if you only have one app server, and don't mind making everyone
    log in again after a restart.
    """
    pass


class OpenIDConnect(object):
    """
    @see: https://developers.google.com/api-client-library/python/start/get_started
    @see: https://developers.google.com/api-client-library/python/samples/authorized_api_web_server_calendar.py
    """
    def __init__(self, app=None, credentials_store=None, http=None, time=None,
                 urandom=None):
        self.credentials_store = credentials_store\
            if credentials_store is not None\
            else MemoryCredentials()

        # stuff that we might want to override for tests
        self.http = http if http is not None else httplib2.Http()
        self.time = time if time is not None else time_module.time
        self.urandom = urandom if urandom is not None else os.urandom

        # get stuff from the app's config, which may override stuff set above
        if app is not None:
            self.init_app(app)

    def init_app(self, app):
        """
        Do setup that requires a Flask app.
        """
        self.app = app

        # Set some default configuration options
        app.config.setdefault('OIDC_SCOPES', ['openid', 'email'])
        app.config.setdefault('OIDC_GOOGLE_APPS_DOMAIN', None)
        app.config.setdefault('OIDC_ID_TOKEN_COOKIE_NAME', 'oidc_id_token')
        app.config.setdefault('OIDC_ID_TOKEN_COOKIE_TTL', 7 * 86400)  # 7 days
        # should ONLY be turned off for local debugging
        app.config.setdefault('OIDC_ID_TOKEN_COOKIE_SECURE', True)
        app.config.setdefault('OIDC_VALID_ISSUERS',
                              ['accounts.google.com',
                               'https://accounts.google.com'])
        app.config.setdefault('OIDC_CLOCK_SKEW', 60)  # 1 minute
        app.config.setdefault('OIDC_REQUIRE_VERIFIED_EMAIL', True)

        # register callback route and cookie-setting decorator
        app.route('/oidc_callback')(self.oidc_callback)
        app.before_request(self.before_request)
        app.after_request(self.after_request)

        # load client_secrets.json
        self.flow = flow_from_clientsecrets(
            app.config['OIDC_CLIENT_SECRETS'],
            scope=app.config['OIDC_SCOPES'])
        assert isinstance(self.flow, OAuth2WebServerFlow)

        # create a cookie signer using the Flask secret key
        self.cookie_serializer = TimedJSONWebSignatureSerializer(
            app.config['SECRET_KEY'])

        try:
            self.credentials_store = app.config['OIDC_CREDENTIALS_STORE']
        except KeyError:
            pass

    def get_cookie_id_token(self):
        try:
            id_token_cookie = request.cookies[self.app.config['OIDC_ID_TOKEN_COOKIE_NAME']]
            return self.cookie_serializer.loads(id_token_cookie)
        except (KeyError, SignatureExpired):
            logger.debug("Missing or invalid ID token cookie", exc_info=True)
            return None

    def set_cookie_id_token(self, id_token):
        """
        Cooperates with @after_request to set a new ID token cookie.
        """
        g.oidc_id_token = id_token
        g.oidc_id_token_dirty = True

    def after_request(self, response):
        """
        Set a new ID token cookie if the ID token has changed.
        """
        if getattr(g, 'oidc_id_token_dirty', False):
            signed_id_token = self.cookie_serializer.dumps(g.oidc_id_token)
            response.set_cookie(
                self.app.config['OIDC_ID_TOKEN_COOKIE_NAME'], signed_id_token,
                secure=self.app.config['OIDC_ID_TOKEN_COOKIE_SECURE'],
                httponly=True,
                max_age=self.app.config['OIDC_ID_TOKEN_COOKIE_TTL'])
        return response

    def before_request(self):
        g.oidc_id_token = None
        self.authenticate_or_redirect()

    def authenticate_or_redirect(self):
        """
        Helper function suitable for @app.before_request and @check (below).
        Sets g.oidc_id_token to the ID token if the user has successfully
        authenticated, else returns a redirect object so they can go try
        to authenticate.
        :return: A redirect, or None if the user is authenticated.
        """
        # the auth callback and error pages don't need user to be authenticated
        if request.endpoint in frozenset(['oidc_callback', 'oidc_error']):
            return None

        # retrieve signed ID token cookie
        id_token = self.get_cookie_id_token()
        if id_token is None:
            return self.redirect_to_auth_server(request.url)

        # ID token expired
        # when Google is the IdP, this happens after one hour
        if self.time() >= id_token['exp']:
            # get credentials from store
            try:
                credentials = self.credentials_store[id_token['sub']]
            except KeyError:
                logger.debug("Expired ID token, credentials missing",
                             exc_info=True)
                return self.redirect_to_auth_server(request.url)

            # refresh and store credentials
            try:
                credentials.refresh(self.http)
                id_token = credentials.id_token
                self.credentials_store[id_token['sub']] = credentials
                self.set_cookie_id_token(id_token)
            except AccessTokenRefreshError:
                # Can't refresh. Wipe credentials and redirect user to IdP
                # for re-authentication.
                logger.debug("Expired ID token, can't refresh credentials",
                             exc_info=True)
                del self.credentials_store[id_token['sub']]
                return self.redirect_to_auth_server(request.url)

        # make ID token available to views
        g.oidc_id_token = id_token

        return None

    def require_login(self, view_func):
        """
        Use this to decorate view functions if only some of your app's views
        require authentication.
        """
        @wraps(view_func)
        def decorated(*args, **kwargs):
            if g.oidc_id_token is None:
                return self.redirect_to_auth_server(request.url)
            return view_func(*args, **kwargs)
        return decorated
    # Backwards compatibility
    check = require_login

    def flow_for_request(self):
        """
        Build a flow with the correct absolute callback URL for this request.
        :return:
        """
        flow = copy(self.flow)
        flow.redirect_uri = url_for('oidc_callback', _external=True)
        return flow

    def redirect_to_auth_server(self, destination):
        """
        Set a CSRF token in the session, and redirect to the IdP.
        :param destination: the page that the user was going to,
                            before we noticed they weren't logged in
        :return: a redirect response
        """
        csrf_token = b64encode(self.urandom(24)).decode('utf-8')
        session['oidc_csrf_token'] = csrf_token
        state = {
            'csrf_token': csrf_token,
            'destination': destination,
        }
        extra_params = {
            'state': json.dumps(state),
        }
        flow = self.flow_for_request()
        auth_url = '{url}&{extra_params}'.format(
            url=flow.step1_get_authorize_url(),
            extra_params=urlencode(extra_params))
        # if the user has an ID token, it's invalid, or we wouldn't be here
        self.set_cookie_id_token(None)
        return redirect(auth_url)

    def is_id_token_valid(self, id_token):
        """
        Check if `id_token` is a current ID token for this application,
        was issued by the Apps domain we expected,
        and that the email address has been verified.

        @see: http://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation
        """
        if not id_token:
            return False

        # step 2: check issuer
        if id_token['iss'] not in self.app.config['OIDC_VALID_ISSUERS']:
            logger.error('id_token issued by non-trusted issuer: %s'
                         % id_token['iss'])
            return False

        if isinstance(id_token['aud'], list):
            # step 3 for audience list
            if self.flow.client_id not in id_token['aud']:
                logger.error('We are not a valid audience')
                return False
            # step 4
            if 'azp' not in id_token:
                logger.error('Multiple audiences and not authorized party')
                return False
        else:
            # step 3 for single audience
            if id_token['aud'] != self.flow.client_id:
                logger.error('We are not the audience')
                return False

        # step 5
        if 'azp' in id_token and id_token['azp'] != self.flow.client_id:
            logger.error('Authorized Party is not us')
            return False

        # step 6-8: TLS checked

        # step 9: check exp
        if int(self.time()) >= int(id_token['exp']):
            logger.error('Token has expired')
            return False

        # step 10: check iat
        if id_token['iat'] < (self.time() - self.app.config['OIDC_CLOCK_SKEW']):
            logger.error('Token issued in the past')
            return False

        # (not required if using HTTPS?) step 11: check nonce

        # step 12-13: not requested acr or auth_time, so not needed to test

        # additional steps specific to our usage
        if id_token.get('hd') != self.app.config['OIDC_GOOGLE_APPS_DOMAIN']:
            logger.error('Invalid google apps domain')
            return False

        if not id_token.get('email_verified', False) and \
                self.app.config['OIDC_REQUIRE_VERIFIED_EMAIL']:
            logger.error('Email not verified')
            return False

        return True

    WRONG_GOOGLE_APPS_DOMAIN = 'WRONG_GOOGLE_APPS_DOMAIN'

    def oidc_callback(self):
        """
        Exchange the auth code for actual credentials,
        then redirect to the originally requested page.
        """
        # retrieve session and callback variables
        try:
            session_csrf_token = session.pop('oidc_csrf_token')

            state = json.loads(request.args['state'])
            csrf_token = state['csrf_token']
            destination = state['destination']

            code = request.args['code']
        except (KeyError, ValueError):
            logger.debug("Can't retrieve CSRF token, state, or code",
                         exc_info=True)
            return self.oidc_error()

        # check callback CSRF token passed to IdP
        # against session CSRF token held by user
        if csrf_token != session_csrf_token:
            logger.debug("CSRF token mismatch")
            return self.oidc_error()

        # make a request to IdP to exchange the auth code for OAuth credentials
        flow = self.flow_for_request()
        credentials = flow.step2_exchange(code, http=self.http)
        id_token = credentials.id_token
        if not self.is_id_token_valid(id_token):
            logger.debug("Invalid ID token")
            if id_token.get('hd') != self.app.config['OIDC_GOOGLE_APPS_DOMAIN']:
                return self.oidc_error(
                    "You must log in with an account from the {0} domain."
                    .format(self.app.config['OIDC_GOOGLE_APPS_DOMAIN']),
                    self.WRONG_GOOGLE_APPS_DOMAIN)
            return self.oidc_error()

        # store credentials by subject
        # when Google is the IdP, the subject is their G+ account number
        self.credentials_store[id_token['sub']] = credentials

        # set a persistent signed cookie containing the ID token
        # and redirect to the final destination
        # TODO: validate redirect destination
        response = redirect(destination)                    
        self.set_cookie_id_token(id_token)
        return response

    def oidc_error(self, message='Not Authorized', code=None):
        return (message, 401, {
            'Content-Type': 'text/plain',
        })

from flask import render_template, redirect, request, url_for, flash, session
from flask.ext.login import login_user, logout_user, login_required, \
    current_user
from . import auth
from .. import db
from ..models import User
from ..email import send_email
from .forms import LoginForm, RegistrationForm, ChangePasswordForm,\
    PasswordResetRequestForm, PasswordResetForm, ChangeEmailForm


@auth.before_app_request
def before_request():
    if current_user.is_authenticated:
        current_user.ping()
        if not current_user.verify_auth_token(session['auth_token']):
            logout_user()
            flash('Your session has expired.')
            return redirect(url_for('auth.login'))
        if not current_user.confirmed \
                and request.endpoint[:5] != 'auth.' \
                and request.endpoint != 'static':
            return redirect(url_for('auth.unconfirmed'))


@auth.route('/unconfirmed')
def unconfirmed():
    if current_user.is_anonymous or current_user.confirmed:
        return redirect(url_for('main.index'))
    return render_template('auth/unconfirmed.html')


@auth.route('/login', methods=['GET', 'POST'])
def login():
    form = LoginForm()
    if form.validate_on_submit():
        user = User.query.filter_by(email=form.email.data).first()
        if user is not None and user.verify_password(form.password.data):
            login_user(user, form.remember_me.data)
            session['auth_token'] = user.auth_token
            return redirect(request.args.get('next') or url_for('main.index'))                    
        flash('Invalid username or password.')
    return render_template('auth/login.html', form=form)


@auth.route('/logout')
@login_required
def logout():
    logout_user()
    flash('You have logged out.')
    return redirect(url_for('main.index'))


@auth.route('/register', methods=['GET', 'POST'])
def register():
    form = RegistrationForm()
    if form.validate_on_submit():
        user = User(email=form.email.data,
                    username=form.username.data,
                    password=form.password.data)
        db.session.add(user)
        db.session.commit()
        token = user.generate_confirmation_token()
        send_email(user.email, 'Confirm Your Account',
                   'auth/email/confirm', user=user, token=token)
        flash('Check your inbox! A confirmation email has been sent.')
        return redirect(url_for('auth.login'))
    return render_template('auth/register.html', form=form)


@auth.route('/confirm/<token>')
@login_required
def confirm(token):
    if current_user.confirmed:
        return redirect(url_for('main.index'))
    if current_user.confirm(token):
        flash('Your account is confirmed. Thank you!')
    else:
        flash('The confirmation link is invalid or has expired.')
    return redirect(url_for('main.index'))


@auth.route('/confirm')
@login_required
def resend_confirmation():
    token = current_user.generate_confirmation_token()
    send_email(current_user.email, 'Confirm Your Account',
               'auth/email/confirm', user=current_user, token=token)
    flash('A new confirmation email has been sent.')
    return redirect(url_for('main.index'))


@auth.route('/change-password', methods=['GET', 'POST'])
@login_required
def change_password():
    form = ChangePasswordForm()
    if form.validate_on_submit():
        if current_user.verify_password(form.old_password.data):
            current_user.password = form.password.data
            db.session.add(current_user)
            session['auth_token'] = current_user.auth_token
            flash('Your password has been updated.')
            return redirect(url_for('main.index'))
        else:
            flash('Invalid password.')
    return render_template("auth/change_password.html", form=form)


@auth.route('/reset', methods=['GET', 'POST'])
def password_reset_request():
    if not current_user.is_anonymous:
        return redirect(url_for('main.index'))
    form = PasswordResetRequestForm()
    if form.validate_on_submit():
        user = User.query.filter_by(email=form.email.data).first()
        if user:
            token = user.generate_reset_token()
            send_email(user.email, 'Reset Your Password',
                       'auth/email/reset_password',
                       user=user, token=token,
                       next=request.args.get('next'))
        flash('An email with instructions for resetting your password has been '
              'sent.')
        return redirect(url_for('auth.login'))
    return render_template('auth/reset_password.html', form=form)


@auth.route('/reset/<token>', methods=['GET', 'POST'])
def password_reset(token):
    if not current_user.is_anonymous:
        return redirect(url_for('main.index'))
    form = PasswordResetForm()
    if form.validate_on_submit():
        user = User.query.filter_by(email=form.email.data).first()
        if user is None:
            return redirect(url_for('main.index'))
        if user.reset_password(token, form.password.data):
            flash('Your password has been updated.')
            return redirect(url_for('auth.login'))
        else:
            return redirect(url_for('main.index'))
    return render_template('auth/reset_password.html', form=form)


@auth.route('/change-email', methods=['GET', 'POST'])
@login_required
def change_email_request():
    form = ChangeEmailForm()
    if form.validate_on_submit():
        if current_user.verify_password(form.password.data):
            new_email = form.email.data
            token = current_user.generate_email_change_token(new_email)
            send_email(new_email, 'Confirm Your Email Address',
                       'auth/email/change_email',
                       user=current_user, token=token)
            flash('An email with instructions for confirming your new email '
                  'address has been sent.')
            return redirect(url_for('main.index'))
        else:
            flash('Invalid password.')
    return render_template("auth/change_email.html", form=form)


@auth.route('/change-email/<token>')
@login_required
def change_email(token):
    if current_user.change_email(token):
        session['auth_token'] = current_user.auth_token
        flash('Your email address has been updated.')
    else:
        flash('Invalid request.')
    return redirect(url_for('main.index'))

'''Copyright 2018 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.'''

from app.models.bookings import ExamType
from .base import Base
from flask_login import current_user
from qsystem import db


class ExamTypeConfig(Base):
    roles_allowed = ['SUPPORT']

    def is_accessible(self):
        return  current_user.is_authenticated and current_user.role.role_code in self.roles_allowed                    

    def get_query(self):
        return self.session.query(self.model)

    create_modal = False
    edit_modal = False
    column_list = [
        'exam_type_name',                    
        'exam_color',                    
        'number_of_hours',                    
        'method_type',                    
        'ita_ind',                    
        'group_exam_ind'                    
    ]

    column_searchable_list = {'exam_type_name'}

    form_excluded_columns = [
        'exam'
    ]

    form_create_rules = (
        'exam_type_name',                    
        'exam_color',                    
        'number_of_hours',                    
        'method_type',                    
        'ita_ind',                    
        'group_exam_ind'                    
    )

    form_edit_rules = (                    
        'exam_type_name',                    
        'exam_color',                    
        'number_of_hours',                    
        'method_type',                    
        'ita_ind',                    
        'group_exam_ind'                    
    )

    column_sortable_list = [
        'exam_type_name',                    
        'exam_color',                    
        'number_of_hours',                    
        'method_type',                    
        'ita_ind',                    
        'group_exam_ind'                    
    ]

    column_default_sort = 'exam_type_name'


ExamTypeModelView = ExamTypeConfig(ExamType, db.session)


'''Copyright 2018 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.'''


from app.models.theq import Office
from .base import Base
from flask_login import current_user
from qsystem import db


class OfficeConfig(Base):
    roles_allowed = ['SUPPORT']

    def is_accessible(self):
        return current_user.is_authenticated and current_user.role.role_code in self.roles_allowed

    create_modal = False
    edit_modal = False
    can_delete = False
    column_list = ['office_name', 'sb', 'services', 'deleted', 'exams_enabled_ind', 'timezone.timezone_name']                    
    form_excluded_columns = ('citizens', 'csrs', 'exams', 'rooms', 'invigilators')                    
    form_create_rules = ('office_name', 'office_number', 'sb', 'services', 'deleted', 'exams_enabled_ind',
                         'appointments_enabled_ind', 'timezone')
    form_edit_rules = ('office_name', 'office_number', 'sb', 'services', 'deleted', 'exams_enabled_ind',
                       'appointments_enabled_ind', 'timezone')
    column_labels = {'sb': 'Smartboard', 'timezone.timezone_name': 'Timezone Name'}
    column_sortable_list = ['office_name', 'sb', 'deleted', 'exams_enabled_ind']
    column_default_sort = 'office_name'


OfficeModelView = OfficeConfig(Office, db.session)

'''Copyright 2018 Province of British Columbia

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.'''

import logging
from flask import g, request
from flask_restplus import Resource
from sqlalchemy import exc, or_                    
from app.models.bookings import Exam
from app.models.theq import CSR
from app.schemas.bookings import ExamSchema
from qsystem import api, jwt
from datetime import datetime, timedelta


@api.route("/exams/", methods=["GET"])
class ExamList(Resource):

    exam_schema = ExamSchema(many=True)

    @jwt.requires_auth
    def get(self):
        try:
            csr = CSR.find_by_username(g.jwt_oidc_token_info['preferred_username'])

            ninety_day_filter = datetime.now() - timedelta(days=90)

            if csr.liaison_designate == 1:
                exams = Exam.query.filter(Exam.deleted_date.is_(None))\
                                  .filter(or_(Exam.exam_returned_date.is_(None),
                                              Exam.exam_returned_date > ninety_day_filter))                    

            else:
                exams = Exam.query.filter(Exam.deleted_date.is_(None))\
                                  .filter_by(office_id=csr.office_id)\
                                  .filter(or_(Exam.exam_returned_date.is_(None),
                                              Exam.exam_returned_date > ninety_day_filter))                    

            search_kwargs = {}

            if request.args:
                for key in request.args:
                    if hasattr(Exam, key):
                        search_kwargs[key] = request.args.get(key)

                exams = exams.filter_by(**search_kwargs)

            result = self.exam_schema.dump(exams)

            return {'exams': result.data,
                    'errors': result.errors}, 200

        except exc.SQLAlchemyError as error:
            logging.error(error, exc_info=True)
            return {"message": "api is down"}, 500

""" Views for a student's account information. """

import json
import logging
import urlparse
from datetime import datetime

import pytz
from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import resolve, reverse
from django.http import HttpRequest, HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response, render_to_string
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger("audit")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode="login"):
    """Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either "login" or "register".

    """
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    return redirect(
                        pipeline.get_login_url(provider_id, pipeline.AUTH_ENTRY_LOGIN, redirect_url=redirect_to)                    
                    )
                third_party_auth_hint = provider_id
                initial_mode = "hinted_login"
        except (KeyError, ValueError, IndexError):                    
            pass

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == "login":
            return old_login_view(request)
        elif initial_mode == "register":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the "Sign In" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    return render_to_response('student_account/login_and_register.html', context)


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning("Password reset rate limit exceeded")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info("Invalid password reset attempt")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_("No email address provided."))


def update_context_for_enterprise(request, context):
    """
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """
    context = {
        "currentProvider": None,
        "providers": [],
        "secondaryProviders": [],
        "finishAuthUrl": None,
        "errorMessage": None,
    }

    if third_party_auth.is_enabled():
        if not enterprise_customer_for_request(request):
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    "id": enabled.provider_id,
                    "name": enabled.name,
                    "iconClass": enabled.icon_class or None,
                    "iconImage": enabled.icon_image.url if enabled.icon_image else None,
                    "loginUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    "registerUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context["providers" if not enabled.secondary else "secondaryProviders"].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context["currentProvider"] = current_provider.name
                context["finishAuthUrl"] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # As a reliable way of "skipping" the registration form, we just submit it automatically
                    context["autoSubmitRegForm"] = True

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == "social-auth":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """
    return {
        'login': _local_server_get('/user_api/v1/account/login_session/', request.session),
        'registration': _local_server_get('/user_api/v1/account/registration/', request.session),
        'password_reset': _local_server_get('/user_api/v1/account/password_reset/', request.session)
    }


def _local_server_get(url, session):
    """Simulate a server-server GET request for an in-process API.

    Arguments:
        url (str): The URL of the request (excluding the protocol and domain)
        session (SessionStore): The session of the original request,
            used to get past the CSRF checks.

    Returns:
        str: The content of the response

    """
    # Since the user API is currently run in-process,
    # we simulate the server-server API call by constructing
    # our own request object.  We don't need to include much
    # information in the request except for the session
    # (to get past through CSRF validation)
    request = HttpRequest()
    request.method = "GET"
    request.session = session

    # Call the Django view function, simulating
    # the server-server API call
    view, args, kwargs = resolve(url)
    response = view(request, *args, **kwargs)

    # Return the content of the response
    return response.content


def _external_auth_intercept(request, mode):
    """Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either "login" or "register"

    Returns:
        Response or None

    """
    if mode == "login":
        return external_auth_login(request)
    elif mode == "register":
        return external_auth_register(request)


def get_user_orders(user):
    """Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], "%Y-%m-%dT%H:%M:%SZ")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """ Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a "Please wait" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like "course_id" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """ Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse("accounts_api", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context

""" Views for a student's account information. """

import json
import logging
import urlparse
from datetime import datetime

from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.api import (
    RegistrationFormFactory,
    get_login_session_form,
    get_password_reset_form
)
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger("audit")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode="login"):
    """Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either "login" or "register".

    """
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    return redirect(
                        pipeline.get_login_url(provider_id, pipeline.AUTH_ENTRY_LOGIN, redirect_url=redirect_to)                    
                    )
                third_party_auth_hint = provider_id
                initial_mode = "hinted_login"
        except (KeyError, ValueError, IndexError):                    
            pass

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == "login":
            return old_login_view(request)
        elif initial_mode == "register":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the "Sign In" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    response = render_to_response('student_account/login_and_register.html', context)

    # Remove enterprise cookie so that subsequent requests show default login page.
    response.delete_cookie(
        configuration_helpers.get_value("ENTERPRISE_CUSTOMER_COOKIE_NAME", settings.ENTERPRISE_CUSTOMER_COOKIE_NAME),
        domain=configuration_helpers.get_value("BASE_COOKIE_DOMAIN", settings.BASE_COOKIE_DOMAIN),
    )

    return response


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning("Password reset rate limit exceeded")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info("Invalid password reset attempt")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_("No email address provided."))


def update_context_for_enterprise(request, context):
    """
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """
    context = {
        "currentProvider": None,
        "providers": [],
        "secondaryProviders": [],
        "finishAuthUrl": None,
        "errorMessage": None,
        "registerFormSubmitButtonText": _("Create Account"),
    }

    if third_party_auth.is_enabled():
        enterprise_customer = enterprise_customer_for_request(request)
        if not enterprise_customer:
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    "id": enabled.provider_id,
                    "name": enabled.name,
                    "iconClass": enabled.icon_class or None,
                    "iconImage": enabled.icon_image.url if enabled.icon_image else None,
                    "loginUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    "registerUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context["providers" if not enabled.secondary else "secondaryProviders"].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context["currentProvider"] = current_provider.name
                context["finishAuthUrl"] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # For enterprise (and later for everyone), we need to get explicit consent to the
                    # Terms of service instead of auto submitting the registration form outright.
                    if not enterprise_customer:
                        # As a reliable way of "skipping" the registration form, we just submit it automatically
                        context["autoSubmitRegForm"] = True
                    else:
                        context["autoRegisterWelcomeMessage"] = (
                            'Thank you for joining {}. '
                            'Just a couple steps before you start learning!'
                        ).format(
                            configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)
                        )
                        context["registerFormSubmitButtonText"] = _("Continue")

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == "social-auth":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """

    return {
        'password_reset': get_password_reset_form().to_json(),
        'login': get_login_session_form().to_json(),
        'registration': RegistrationFormFactory().get_registration_form(request).to_json()
    }


def _external_auth_intercept(request, mode):
    """Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either "login" or "register"

    Returns:
        Response or None

    """
    if mode == "login":
        return external_auth_login(request)
    elif mode == "register":
        return external_auth_register(request)


def get_user_orders(user):
    """Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], "%Y-%m-%dT%H:%M:%SZ")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """ Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a "Please wait" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like "course_id" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """ Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse("accounts_api", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context

""" Views for a student's account information. """

import json
import logging
import urlparse
from datetime import datetime

from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.api import (
    RegistrationFormFactory,
    get_login_session_form,
    get_password_reset_form
)
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger("audit")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode="login"):
    """Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either "login" or "register".

    """
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    return redirect(
                        pipeline.get_login_url(provider_id, pipeline.AUTH_ENTRY_LOGIN, redirect_url=redirect_to)                    
                    )
                third_party_auth_hint = provider_id
                initial_mode = "hinted_login"
        except (KeyError, ValueError, IndexError):                    
            pass

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == "login":
            return old_login_view(request)
        elif initial_mode == "register":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the "Sign In" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    response = render_to_response('student_account/login_and_register.html', context)

    # Remove enterprise cookie so that subsequent requests show default login page.
    response.delete_cookie(
        configuration_helpers.get_value("ENTERPRISE_CUSTOMER_COOKIE_NAME", settings.ENTERPRISE_CUSTOMER_COOKIE_NAME),
        domain=configuration_helpers.get_value("BASE_COOKIE_DOMAIN", settings.BASE_COOKIE_DOMAIN),
    )

    return response


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning("Password reset rate limit exceeded")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info("Invalid password reset attempt")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_("No email address provided."))


def update_context_for_enterprise(request, context):
    """
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """
    context = {
        "currentProvider": None,
        "providers": [],
        "secondaryProviders": [],
        "finishAuthUrl": None,
        "errorMessage": None,
        "registerFormSubmitButtonText": _("Create Account"),
    }

    if third_party_auth.is_enabled():
        enterprise_customer = enterprise_customer_for_request(request)
        if not enterprise_customer:
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    "id": enabled.provider_id,
                    "name": enabled.name,
                    "iconClass": enabled.icon_class or None,
                    "iconImage": enabled.icon_image.url if enabled.icon_image else None,
                    "loginUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    "registerUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context["providers" if not enabled.secondary else "secondaryProviders"].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context["currentProvider"] = current_provider.name
                context["finishAuthUrl"] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # For enterprise (and later for everyone), we need to get explicit consent to the
                    # Terms of service instead of auto submitting the registration form outright.
                    if not enterprise_customer:
                        # As a reliable way of "skipping" the registration form, we just submit it automatically
                        context["autoSubmitRegForm"] = True
                    else:
                        context["autoRegisterWelcomeMessage"] = (
                            'Thank you for joining {}. '
                            'Just a couple steps before you start learning!'
                        ).format(
                            configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)
                        )
                        context["registerFormSubmitButtonText"] = _("Continue")

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == "social-auth":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """

    return {
        'password_reset': get_password_reset_form().to_json(),
        'login': get_login_session_form().to_json(),
        'registration': RegistrationFormFactory().get_registration_form(request).to_json()
    }


def _external_auth_intercept(request, mode):
    """Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either "login" or "register"

    Returns:
        Response or None

    """
    if mode == "login":
        return external_auth_login(request)
    elif mode == "register":
        return external_auth_register(request)


def get_user_orders(user):
    """Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], "%Y-%m-%dT%H:%M:%SZ")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """ Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a "Please wait" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like "course_id" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """ Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse("accounts_api", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context

""" Views for a student's account information. """

import json
import logging
import urlparse
from datetime import datetime

import pytz
from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import resolve, reverse
from django.http import HttpRequest, HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response, render_to_string
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger("audit")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode="login"):
    """Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either "login" or "register".

    """
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    return redirect(
                        pipeline.get_login_url(provider_id, pipeline.AUTH_ENTRY_LOGIN, redirect_url=redirect_to)                    
                    )
                third_party_auth_hint = provider_id
                initial_mode = "hinted_login"
        except (KeyError, ValueError, IndexError):                    
            pass

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == "login":
            return old_login_view(request)
        elif initial_mode == "register":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the "Sign In" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    return render_to_response('student_account/login_and_register.html', context)


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning("Password reset rate limit exceeded")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info("Invalid password reset attempt")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_("No email address provided."))


def update_context_for_enterprise(request, context):
    """
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """
    context = {
        "currentProvider": None,
        "providers": [],
        "secondaryProviders": [],
        "finishAuthUrl": None,
        "errorMessage": None,
    }

    if third_party_auth.is_enabled():
        if not enterprise_customer_for_request(request):
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    "id": enabled.provider_id,
                    "name": enabled.name,
                    "iconClass": enabled.icon_class or None,
                    "iconImage": enabled.icon_image.url if enabled.icon_image else None,
                    "loginUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    "registerUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context["providers" if not enabled.secondary else "secondaryProviders"].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context["currentProvider"] = current_provider.name
                context["finishAuthUrl"] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # As a reliable way of "skipping" the registration form, we just submit it automatically
                    context["autoSubmitRegForm"] = True

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == "social-auth":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """
    return {
        'login': _local_server_get('/user_api/v1/account/login_session/', request.session),
        'registration': _local_server_get('/user_api/v1/account/registration/', request.session),
        'password_reset': _local_server_get('/user_api/v1/account/password_reset/', request.session)
    }


def _local_server_get(url, session):
    """Simulate a server-server GET request for an in-process API.

    Arguments:
        url (str): The URL of the request (excluding the protocol and domain)
        session (SessionStore): The session of the original request,
            used to get past the CSRF checks.

    Returns:
        str: The content of the response

    """
    # Since the user API is currently run in-process,
    # we simulate the server-server API call by constructing
    # our own request object.  We don't need to include much
    # information in the request except for the session
    # (to get past through CSRF validation)
    request = HttpRequest()
    request.method = "GET"
    request.session = session

    # Call the Django view function, simulating
    # the server-server API call
    view, args, kwargs = resolve(url)
    response = view(request, *args, **kwargs)

    # Return the content of the response
    return response.content


def _external_auth_intercept(request, mode):
    """Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either "login" or "register"

    Returns:
        Response or None

    """
    if mode == "login":
        return external_auth_login(request)
    elif mode == "register":
        return external_auth_register(request)


def get_user_orders(user):
    """Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], "%Y-%m-%dT%H:%M:%SZ")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """ Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a "Please wait" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like "course_id" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """ Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse("accounts_api", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context

""" Views for a student's account information. """

import json
import logging
import urlparse
from datetime import datetime

from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseBadRequest, HttpResponseForbidden
from django.shortcuts import redirect
from django.utils.translation import ugettext as _
from django.views.decorators.csrf import ensure_csrf_cookie
from django.views.decorators.http import require_http_methods
from django_countries import countries

import third_party_auth
from commerce.models import CommerceConfiguration
from edxmako.shortcuts import render_to_response
from lms.djangoapps.commerce.utils import EcommerceService
from openedx.core.djangoapps.commerce.utils import ecommerce_api_client
from openedx.core.djangoapps.external_auth.login_and_register import login as external_auth_login
from openedx.core.djangoapps.external_auth.login_and_register import register as external_auth_register
from openedx.core.djangoapps.lang_pref.api import all_languages, released_languages
from openedx.core.djangoapps.programs.models import ProgramsApiConfig
from openedx.core.djangoapps.site_configuration import helpers as configuration_helpers
from openedx.core.djangoapps.theming.helpers import is_request_in_themed_site
from openedx.core.djangoapps.user_api.accounts.api import request_password_change
from openedx.core.djangoapps.user_api.api import (
    RegistrationFormFactory,
    get_login_session_form,
    get_password_reset_form
)
from openedx.core.djangoapps.user_api.errors import UserNotFound
from openedx.core.lib.edx_api_utils import get_edx_api_data
from openedx.core.lib.time_zone_utils import TIME_ZONE_CHOICES
from openedx.features.enterprise_support.api import enterprise_customer_for_request
from student.helpers import destroy_oauth_tokens, get_next_url_for_login_page
from student.models import UserProfile
from student.views import register_user as old_register_view
from student.views import signin_user as old_login_view
from third_party_auth import pipeline
from third_party_auth.decorators import xframe_allow_whitelisted
from util.bad_request_rate_limiter import BadRequestRateLimiter
from util.date_utils import strftime_localized

AUDIT_LOG = logging.getLogger("audit")
log = logging.getLogger(__name__)
User = get_user_model()  # pylint:disable=invalid-name


@require_http_methods(['GET'])
@ensure_csrf_cookie
@xframe_allow_whitelisted
def login_and_registration_form(request, initial_mode="login"):
    """Render the combined login/registration form, defaulting to login

    This relies on the JS to asynchronously load the actual form from
    the user_api.

    Keyword Args:
        initial_mode (string): Either "login" or "register".

    """
    # Determine the URL to redirect to following login/registration/third_party_auth
    redirect_to = get_next_url_for_login_page(request)
    # If we're already logged in, redirect to the dashboard
    if request.user.is_authenticated():
        return redirect(redirect_to)

    # Retrieve the form descriptions from the user API
    form_descriptions = _get_form_descriptions(request)

    # Our ?next= URL may itself contain a parameter 'tpa_hint=x' that we need to check.
    # If present, we display a login page focused on third-party auth with that provider.
    third_party_auth_hint = None
    if '?' in redirect_to:
        try:
            next_args = urlparse.parse_qs(urlparse.urlparse(redirect_to).query)
            provider_id = next_args['tpa_hint'][0]
            tpa_hint_provider = third_party_auth.provider.Registry.get(provider_id=provider_id)
            if tpa_hint_provider:
                if tpa_hint_provider.skip_hinted_login_dialog:
                    # Forward the user directly to the provider's login URL when the provider is configured
                    # to skip the dialog.
                    return redirect(
                        pipeline.get_login_url(provider_id, pipeline.AUTH_ENTRY_LOGIN, redirect_url=redirect_to)                    
                    )
                third_party_auth_hint = provider_id
                initial_mode = "hinted_login"
        except (KeyError, ValueError, IndexError):                    
            pass

    # If this is a themed site, revert to the old login/registration pages.
    # We need to do this for now to support existing themes.
    # Themed sites can use the new logistration page by setting
    # 'ENABLE_COMBINED_LOGIN_REGISTRATION' in their
    # configuration settings.
    if is_request_in_themed_site() and not configuration_helpers.get_value('ENABLE_COMBINED_LOGIN_REGISTRATION', False):
        if initial_mode == "login":
            return old_login_view(request)
        elif initial_mode == "register":
            return old_register_view(request)

    # Allow external auth to intercept and handle the request
    ext_auth_response = _external_auth_intercept(request, initial_mode)
    if ext_auth_response is not None:
        return ext_auth_response

    # Account activation message
    account_activation_messages = [
        {
            'message': message.message, 'tags': message.tags
        } for message in messages.get_messages(request) if 'account-activation' in message.tags
    ]

    # Otherwise, render the combined login/registration page
    context = {
        'data': {
            'login_redirect_url': redirect_to,
            'initial_mode': initial_mode,
            'third_party_auth': _third_party_auth_context(request, redirect_to, third_party_auth_hint),
            'third_party_auth_hint': third_party_auth_hint or '',
            'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
            'support_link': configuration_helpers.get_value('SUPPORT_SITE_LINK', settings.SUPPORT_SITE_LINK),
            'password_reset_support_link': configuration_helpers.get_value(
                'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
            ) or settings.SUPPORT_SITE_LINK,
            'account_activation_messages': account_activation_messages,

            # Include form descriptions retrieved from the user API.
            # We could have the JS client make these requests directly,
            # but we include them in the initial page load to avoid
            # the additional round-trip to the server.
            'login_form_desc': json.loads(form_descriptions['login']),
            'registration_form_desc': json.loads(form_descriptions['registration']),
            'password_reset_form_desc': json.loads(form_descriptions['password_reset']),
            'account_creation_allowed': configuration_helpers.get_value(
                'ALLOW_PUBLIC_ACCOUNT_CREATION', settings.FEATURES.get('ALLOW_PUBLIC_ACCOUNT_CREATION', True))
        },
        'login_redirect_url': redirect_to,  # This gets added to the query string of the "Sign In" button in header
        'responsive': True,
        'allow_iframing': True,
        'disable_courseware_js': True,
        'combined_login_and_register': True,
        'disable_footer': not configuration_helpers.get_value(
            'ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER',
            settings.FEATURES['ENABLE_COMBINED_LOGIN_REGISTRATION_FOOTER']
        ),
    }

    context = update_context_for_enterprise(request, context)

    response = render_to_response('student_account/login_and_register.html', context)

    # Remove enterprise cookie so that subsequent requests show default login page.
    response.delete_cookie(
        configuration_helpers.get_value("ENTERPRISE_CUSTOMER_COOKIE_NAME", settings.ENTERPRISE_CUSTOMER_COOKIE_NAME),
        domain=configuration_helpers.get_value("BASE_COOKIE_DOMAIN", settings.BASE_COOKIE_DOMAIN),
    )

    return response


@require_http_methods(['POST'])
def password_change_request_handler(request):
    """Handle password change requests originating from the account page.

    Uses the Account API to email the user a link to the password reset page.

    Note:
        The next step in the password reset process (confirmation) is currently handled
        by student.views.password_reset_confirm_wrapper, a custom wrapper around Django's
        password reset confirmation view.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the email was sent successfully
        HttpResponse: 400 if there is no 'email' POST parameter
        HttpResponse: 403 if the client has been rate limited
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        POST /account/password

    """

    limiter = BadRequestRateLimiter()
    if limiter.is_rate_limit_exceeded(request):
        AUDIT_LOG.warning("Password reset rate limit exceeded")
        return HttpResponseForbidden()

    user = request.user
    # Prefer logged-in user's email
    email = user.email if user.is_authenticated() else request.POST.get('email')

    if email:
        try:
            request_password_change(email, request.is_secure())
            user = user if user.is_authenticated() else User.objects.get(email=email)
            destroy_oauth_tokens(user)
        except UserNotFound:
            AUDIT_LOG.info("Invalid password reset attempt")
            # Increment the rate limit counter
            limiter.tick_bad_request_counter(request)

        return HttpResponse(status=200)
    else:
        return HttpResponseBadRequest(_("No email address provided."))


def update_context_for_enterprise(request, context):
    """
    Take the processed context produced by the view, determine if it's relevant
    to a particular Enterprise Customer, and update it to include that customer's
    enterprise metadata.
    """

    context = context.copy()

    sidebar_context = enterprise_sidebar_context(request)

    if sidebar_context:
        context['data']['registration_form_desc']['fields'] = enterprise_fields_only(
            context['data']['registration_form_desc']
        )
        context.update(sidebar_context)
        context['enable_enterprise_sidebar'] = True
        context['data']['hide_auth_warnings'] = True
    else:
        context['enable_enterprise_sidebar'] = False

    return context


def enterprise_fields_only(fields):
    """
    Take the received field definition, and exclude those fields that we don't want
    to require if the user is going to be a member of an Enterprise Customer.
    """
    enterprise_exclusions = configuration_helpers.get_value(
        'ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS',
        settings.ENTERPRISE_EXCLUDED_REGISTRATION_FIELDS
    )
    return [field for field in fields['fields'] if field['name'] not in enterprise_exclusions]


def enterprise_sidebar_context(request):
    """
    Given the current request, render the HTML of a sidebar for the current
    logistration view that depicts Enterprise-related information.
    """
    enterprise_customer = enterprise_customer_for_request(request)

    if not enterprise_customer:
        return {}

    platform_name = configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)

    if enterprise_customer.branding_configuration.logo:
        enterprise_logo_url = enterprise_customer.branding_configuration.logo.url
    else:
        enterprise_logo_url = ''

    if getattr(enterprise_customer.branding_configuration, 'welcome_message', None):
        branded_welcome_template = enterprise_customer.branding_configuration.welcome_message
    else:
        branded_welcome_template = configuration_helpers.get_value(
            'ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE',
            settings.ENTERPRISE_SPECIFIC_BRANDED_WELCOME_TEMPLATE
        )

    branded_welcome_string = branded_welcome_template.format(
        start_bold=u'<b>',
        end_bold=u'</b>',
        enterprise_name=enterprise_customer.name,
        platform_name=platform_name
    )

    platform_welcome_template = configuration_helpers.get_value(
        'ENTERPRISE_PLATFORM_WELCOME_TEMPLATE',
        settings.ENTERPRISE_PLATFORM_WELCOME_TEMPLATE
    )
    platform_welcome_string = platform_welcome_template.format(platform_name=platform_name)

    context = {
        'enterprise_name': enterprise_customer.name,
        'enterprise_logo_url': enterprise_logo_url,
        'enterprise_branded_welcome_string': branded_welcome_string,
        'platform_welcome_string': platform_welcome_string,
    }

    return context


def _third_party_auth_context(request, redirect_to, tpa_hint=None):
    """Context for third party auth providers and the currently running pipeline.

    Arguments:
        request (HttpRequest): The request, used to determine if a pipeline
            is currently running.
        redirect_to: The URL to send the user to following successful
            authentication.
        tpa_hint (string): An override flag that will return a matching provider
            as long as its configuration has been enabled

    Returns:
        dict

    """
    context = {
        "currentProvider": None,
        "providers": [],
        "secondaryProviders": [],
        "finishAuthUrl": None,
        "errorMessage": None,
        "registerFormSubmitButtonText": _("Create Account"),
    }

    if third_party_auth.is_enabled():
        enterprise_customer = enterprise_customer_for_request(request)
        if not enterprise_customer:
            for enabled in third_party_auth.provider.Registry.displayed_for_login(tpa_hint=tpa_hint):
                info = {
                    "id": enabled.provider_id,
                    "name": enabled.name,
                    "iconClass": enabled.icon_class or None,
                    "iconImage": enabled.icon_image.url if enabled.icon_image else None,
                    "loginUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_LOGIN,
                        redirect_url=redirect_to,
                    ),
                    "registerUrl": pipeline.get_login_url(
                        enabled.provider_id,
                        pipeline.AUTH_ENTRY_REGISTER,
                        redirect_url=redirect_to,
                    ),
                }
                context["providers" if not enabled.secondary else "secondaryProviders"].append(info)

        running_pipeline = pipeline.get(request)
        if running_pipeline is not None:
            current_provider = third_party_auth.provider.Registry.get_from_pipeline(running_pipeline)

            if current_provider is not None:
                context["currentProvider"] = current_provider.name
                context["finishAuthUrl"] = pipeline.get_complete_url(current_provider.backend_name)

                if current_provider.skip_registration_form:
                    # For enterprise (and later for everyone), we need to get explicit consent to the
                    # Terms of service instead of auto submitting the registration form outright.
                    if not enterprise_customer:
                        # As a reliable way of "skipping" the registration form, we just submit it automatically
                        context["autoSubmitRegForm"] = True
                    else:
                        context["autoRegisterWelcomeMessage"] = (
                            'Thank you for joining {}. '
                            'Just a couple steps before you start learning!'
                        ).format(
                            configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME)
                        )
                        context["registerFormSubmitButtonText"] = _("Continue")

        # Check for any error messages we may want to display:
        for msg in messages.get_messages(request):
            if msg.extra_tags.split()[0] == "social-auth":
                # msg may or may not be translated. Try translating [again] in case we are able to:
                context['errorMessage'] = _(unicode(msg))  # pylint: disable=translation-of-non-string
                break

    return context


def _get_form_descriptions(request):
    """Retrieve form descriptions from the user API.

    Arguments:
        request (HttpRequest): The original request, used to retrieve session info.

    Returns:
        dict: Keys are 'login', 'registration', and 'password_reset';
            values are the JSON-serialized form descriptions.

    """

    return {
        'password_reset': get_password_reset_form().to_json(),
        'login': get_login_session_form().to_json(),
        'registration': RegistrationFormFactory().get_registration_form(request).to_json()
    }


def _external_auth_intercept(request, mode):
    """Allow external auth to intercept a login/registration request.

    Arguments:
        request (Request): The original request.
        mode (str): Either "login" or "register"

    Returns:
        Response or None

    """
    if mode == "login":
        return external_auth_login(request)
    elif mode == "register":
        return external_auth_register(request)


def get_user_orders(user):
    """Given a user, get the detail of all the orders from the Ecommerce service.

    Args:
        user (User): The user to authenticate as when requesting ecommerce.

    Returns:
        list of dict, representing orders returned by the Ecommerce service.
    """
    no_data = []
    user_orders = []
    commerce_configuration = CommerceConfiguration.current()
    user_query = {'username': user.username}

    use_cache = commerce_configuration.is_cache_enabled
    cache_key = commerce_configuration.CACHE_KEY + '.' + str(user.id) if use_cache else None
    api = ecommerce_api_client(user)
    commerce_user_orders = get_edx_api_data(
        commerce_configuration, 'orders', api=api, querystring=user_query, cache_key=cache_key
    )

    for order in commerce_user_orders:
        if order['status'].lower() == 'complete':
            date_placed = datetime.strptime(order['date_placed'], "%Y-%m-%dT%H:%M:%SZ")
            order_data = {
                'number': order['number'],
                'price': order['total_excl_tax'],
                'order_date': strftime_localized(date_placed, 'SHORT_DATE'),
                'receipt_url': EcommerceService().get_receipt_page_url(order['number']),
                'lines': order['lines'],
            }
            user_orders.append(order_data)

    return user_orders


@login_required
@require_http_methods(['GET'])
def account_settings(request):
    """Render the current user's account settings page.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/settings

    """
    return render_to_response('student_account/account_settings.html', account_settings_context(request))


@login_required
@require_http_methods(['GET'])
def finish_auth(request):  # pylint: disable=unused-argument
    """ Following logistration (1st or 3rd party), handle any special query string params.

    See FinishAuthView.js for details on the query string params.

    e.g. auto-enroll the user in a course, set email opt-in preference.

    This view just displays a "Please wait" message while AJAX calls are made to enroll the
    user in the course etc. This view is only used if a parameter like "course_id" is present
    during login/registration/third_party_auth. Otherwise, there is no need for it.

    Ideally this view will finish and redirect to the next step before the user even sees it.

    Args:
        request (HttpRequest)

    Returns:
        HttpResponse: 200 if the page was sent successfully
        HttpResponse: 302 if not logged in (redirect to login page)
        HttpResponse: 405 if using an unsupported HTTP method

    Example usage:

        GET /account/finish_auth/?course_id=course-v1:blah&enrollment_action=enroll

    """
    return render_to_response('student_account/finish_auth.html', {
        'disable_courseware_js': True,
        'disable_footer': True,
    })


def account_settings_context(request):
    """ Context for the account settings page.

    Args:
        request: The request object.

    Returns:
        dict

    """
    user = request.user

    year_of_birth_options = [(unicode(year), unicode(year)) for year in UserProfile.VALID_YEARS]
    try:
        user_orders = get_user_orders(user)
    except:  # pylint: disable=bare-except
        log.exception('Error fetching order history from Otto.')
        # Return empty order list as account settings page expect a list and
        # it will be broken if exception raised
        user_orders = []

    context = {
        'auth': {},
        'duplicate_provider': None,
        'nav_hidden': True,
        'fields': {
            'country': {
                'options': list(countries),
            }, 'gender': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.GENDER_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'language': {
                'options': released_languages(),
            }, 'level_of_education': {
                'options': [(choice[0], _(choice[1])) for choice in UserProfile.LEVEL_OF_EDUCATION_CHOICES],  # pylint: disable=translation-of-non-string
            }, 'password': {
                'url': reverse('password_reset'),
            }, 'year_of_birth': {
                'options': year_of_birth_options,
            }, 'preferred_language': {
                'options': all_languages(),
            }, 'time_zone': {
                'options': TIME_ZONE_CHOICES,
            }
        },
        'platform_name': configuration_helpers.get_value('PLATFORM_NAME', settings.PLATFORM_NAME),
        'password_reset_support_link': configuration_helpers.get_value(
            'PASSWORD_RESET_SUPPORT_LINK', settings.PASSWORD_RESET_SUPPORT_LINK
        ) or settings.SUPPORT_SITE_LINK,
        'user_accounts_api_url': reverse("accounts_api", kwargs={'username': user.username}),
        'user_preferences_api_url': reverse('preferences_api', kwargs={'username': user.username}),
        'disable_courseware_js': True,
        'show_program_listing': ProgramsApiConfig.is_enabled(),
        'order_history': user_orders
    }

    if third_party_auth.is_enabled():
        # If the account on the third party provider is already connected with another edX account,
        # we display a message to the user.
        context['duplicate_provider'] = pipeline.get_duplicate_provider(messages.get_messages(request))

        auth_states = pipeline.get_provider_user_states(user)

        context['auth']['providers'] = [{
            'id': state.provider.provider_id,
            'name': state.provider.name,  # The name of the provider e.g. Facebook
            'connected': state.has_account,  # Whether the user's edX account is connected with the provider.
            # If the user is not connected, they should be directed to this page to authenticate
            # with the particular provider, as long as the provider supports initiating a login.
            'connect_url': pipeline.get_login_url(
                state.provider.provider_id,
                pipeline.AUTH_ENTRY_ACCOUNT_SETTINGS,
                # The url the user should be directed to after the auth process has completed.
                redirect_url=reverse('account_settings'),
            ),
            'accepts_logins': state.provider.accepts_logins,
            # If the user is connected, sending a POST request to this url removes the connection
            # information for this provider from their edX account.
            'disconnect_url': pipeline.get_disconnect_url(state.provider.provider_id, state.association_id),
            # We only want to include providers if they are either currently available to be logged
            # in with, or if the user is already authenticated with them.
        } for state in auth_states if state.provider.display_for_login or state.has_account]

    return context

#! /usr/bin/env python
# -*- coding:utf-8 -*-

# This file is a part of IoT-LAB gateway_code
# Copyright (C) 2015 INRIA (Contact: admin@iot-lab.info)
# Contributor(s) : see AUTHORS file
#
# This software is governed by the CeCILL license under French law
# and abiding by the rules of distribution of free software.  You can  use,
# modify and/ or redistribute the software under the terms of the CeCILL
# license as circulated by CEA, CNRS and INRIA at the following URL
# http://www.cecill.info.
#
# As a counterpart to the access to the source code and  rights to copy,
# modify and redistribute granted by the license, users are provided only
# with a limited warranty  and the software's author,  the holder of the
# economic rights,  and the successive licensors  have only  limited
# liability.
#
# The fact that you are presently reading this means that you have had
# knowledge of the CeCILL license and that you accept its terms.

""" CLI client for serial_redirection """

import signal
import gateway_code.board_config as board_config
from .. import serial_redirection                    
from . import log_to_stderr


def _get_node(board_cfg):
    if board_cfg.linux_on_class is not None:
        # Linux open node
        return board_cfg.linux_on_class()
    return board_cfg.board_class()


@log_to_stderr
def main():
    """ serial_redirection cli main function """
    board_cfg = board_config.BoardConfig()
    node = _get_node(board_cfg)
    redirect = serial_redirection.SerialRedirection(node.TTY, node.BAUDRATE)                    
    try:
        redirect.start()                    
        print 'Press Ctrl+C to stop'
        signal.pause()
    except KeyboardInterrupt:
        pass
    finally:
        redirect.stop()                    
        print 'Stopped'

from flask import Flask, render_template, request, redirect, url_for, session                    
from flask_bootstrap import Bootstrap
from flask_wtf import FlaskForm
from flask_login import LoginManager, current_user, login_user, logout_user, UserMixin                    
from werkzeug.security import generate_password_hash, check_password_hash
from wtforms import IntegerField, FloatField, DateField, SelectField, \
    SelectMultipleField, FieldList, FormField, StringField, PasswordField, validators
from datetime import datetime
import os.path
import json
import redis
import re
import pprint

pp = pprint.PrettyPrinter(indent=4)

app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret'
app.jinja_env.filters['json_pretty'] = lambda value: json.dumps(value, sort_keys=True, indent=4)
Bootstrap(app)

db = redis.Redis('localhost')


class User(UserMixin):
    user_id = ''
    email = ''
    password_hash = ''

    def get_id(self):
        return self.user_id


def db_init():
    db.flushdb()
    auth_init()
    auth_add_user('gleb.kondratenko@skybonds.com', 'pwd')


def auth_init():
    db.set('user:ids', '0')


def auth_add_user(email, password):
    user_id = db.incr('user:ids')
    db.hset('user:emails', email, user_id)
    db.hmset('user:%s' % user_id, {
        'user_id': user_id,
        'email': email,
        'password_hash': password
    })
    return auth_get_user_by_id(user_id)


def auth_get_user_by_email(email):
    user_id = db.hget('user:emails', email)
    if not user_id:
        return None
    return auth_get_user_by_id(user_id)


def auth_get_user_by_id(user_id):
    key = 'user:%s' % user_id
    if db.hlen(key) == 0:
        return None
    user_data = db.hgetall(key)
    user = User()
    user.user_id = user_data['user_id']
    user.email = user_data['email']
    user.password_hash = generate_password_hash(user_data['password_hash'])
    return user


def auth_check_password(user, password):
    print('auth_check_password', user.password_hash, password)                    
    return check_password_hash(user.password_hash, password)


db_init()

login_manager = LoginManager(app)
login_manager.login_view = 'view_login'


@login_manager.user_loader
def load_user(user_id):
    return auth_get_user_by_id(user_id)


def load_json(name):
    filename = os.path.join(app.static_folder, name)
    return json.load(open(filename))


@app.route('/')
def view_home():
    return render_template('home.html')


@app.route('/models')
def view_models():
    models = load_json('models.json')
    return render_template('models.html', models=models)


@app.route('/results')
def view_results():
    results = load_json('results.json')
    time_series = []
    for name, values in results.items():
        ts = {
            'id': name,
            'values': {
                'x': [],
                'y': []
            }
        }
        dates = [key for key in values]
        dates.sort()
        for date in dates:
            ts['values']['x'].append(date)
            ts['values']['y'].append(values[date])

        # Input time series. Examples:
        # G & A_Exxon_sovcombank: macbook:timeseries
        # oil_Brent: macbook:timeseries
        # Income_tax_rate: macbook:timeseries
        if re.search(':timeseries$', name):
            attrs = name.split(':')
            (ts_name, ts_author), rest = attrs[:2], attrs[2:]
            ts['result_type'] = 'Input time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author

        # Output time series. Examples:
        # incomePerDay_exxon, macbook, (output, Exxon_4)
        # incomePerDay_goodyear, macbook, (output, Goodyear)
        # gasoline_exxon, macbook, (output, Exxon_4)
        if re.search('\(output,.*\)$', name):
            name_wo_braces = re.sub(r'[()]', '', name)
            attrs = name_wo_braces.split(',')
            (ts_name, ts_author, _, model_name), rest = attrs[:4], attrs[4:]
            ts['result_type'] = 'Output time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author
            ts['model_name'] = model_name

        # Intermediate input time series. Examples:
        # gasoline_exxon, Goodyear, macbook, input, source_type: output, Exxon_4, gasoline_exxon, macbook
        # Income_tax_rate, Exxon_4, macbook, input, source_type: timeseries, Income_tax_rate, macbook
        # G & A_Exxon, Exxon_4, macbook, input, source_type: timeseries, G & A_Exxon, macbook
        # oil, Goodyear, macbook, input, source_type: timeseries, oil, macbook
        # oil, Exxon_4, macbook, input, source_type: timeseries, oil, macbook
        if re.search('input,source_type:', name):
            attrs = name.split(',')
            (ts_name, model_name, ts_author, _), source = attrs[:4], attrs[4:]
            ts['result_type'] = 'Intermediate input time series'
            ts['ts_name'] = ts_name
            ts['ts_author'] = ts_author
            ts['model_name'] = model_name
            if re.search('input,source_type:output', name):
                source_model_name, rest = source[1], source[2:]
                ts['source_model_name'] = source_model_name
                ts['source_type'] = 'model'
            else:
                ts['source_type'] = 'timeseries'

        time_series.append(ts)

    time_series.sort(key=lambda ts_item: ts_item['result_type'], reverse=False)

    return render_template('results.html', results=results, time_series=time_series)


# TODO: figure out proper validation
class NoValidationSelectField(SelectField):
    def pre_validate(self, form):
        """per_validation is disabled"""


class ChangeOneModelForm(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeOneModelForm, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    model_system_name = NoValidationSelectField('Model', [validators.required()], choices=[])
    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    input_source_final = NoValidationSelectField('Final input', [validators.required()], choices=[])


class ChangeAllModelsForm(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeAllModelsForm, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    input_source_final = NoValidationSelectField('Final input', [validators.required()], choices=[])


class ChangeInputNewValue(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeInputNewValue, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    new_value = FloatField('Delta', [validators.required()])


class ChangeInputAddDelta(FlaskForm):
    def __init__(self, csrf_enabled=False, *args, **kwargs):
        super(ChangeInputAddDelta, self).__init__(csrf_enabled=csrf_enabled, *args, **kwargs)

    input_source_initial = NoValidationSelectField('Initial input', [validators.required()], choices=[])
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    delta = FloatField('New Value', [validators.required()])


class RunForm(FlaskForm):
    start_day = DateField('Start day', [validators.required()], '%Y-%m-%d', default=datetime.today())
    number_of_days = IntegerField('Number of days', [validators.required()])
    exe_models = SelectMultipleField('Execute models', [validators.required()])
    change_input_series_one_model = FieldList(FormField(ChangeOneModelForm), min_entries=0)
    change_input_series_all_models = FieldList(FormField(ChangeAllModelsForm), min_entries=0)
    change_timeseries_value_several_days = FieldList(FormField(ChangeInputNewValue), min_entries=0)
    change_timeseries_value_several_days_add_delta = FieldList(FormField(ChangeInputAddDelta), min_entries=0)


def get_models_choices():
    models = load_json('models.json')
    return [
        (model['model_system_name'], model['model_name_user'] + ':' + model['author'])
        for model in models
    ]


def get_inputs_choices_by_model(name):
    models = load_json('models.json')
    model = next(item for item in models if item['model_system_name'] == name)
    return [(
        value['series_name_system'],
        value['series_name_system'] + ':' + value['series_name_user']
    ) for key, value in model['inputs'].iteritems()]


def get_inputs_choices():
    models = load_json('models.json')
    inputs_by_models = [get_inputs_choices_by_model(model['model_system_name']) for model in models]
    return [item for inputs in inputs_by_models for item in inputs]


# returns list of commands of form data
def get_commands(form):
    result = []
    for field in form:
        if field.name == 'start_day':
            result.append({'command': field.name, 'start_day': str(field.data)})
        elif field.name == 'number_of_days':
            result.append({'command': field.name, 'number_of_days': field.data})
        elif field.name == 'exe_models':
            result.append({'command': field.name, 'include': field.data})
        elif field.name == 'change_input_series_one_model':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'model_system_name': entry.model_system_name.data,
                    'input_source_initial': entry.input_source_initial.data,
                    'input_source_final': entry.input_source_final.data
                })
        elif field.name == 'change_input_series_all_models':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'input_source_final': entry.input_source_final.data
                })
        elif field.name == 'change_timeseries_value_several_days':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'start_day': str(entry.start_day.data),
                    'number_of_days': entry.number_of_days.data,
                    'new_value': entry.new_value.data
                })
        elif field.name == 'change_timeseries_value_several_days_add_delta':
            for entry in field.entries:
                result.append({
                    'command': field.name,
                    'input_source_initial': entry.input_source_initial.data,
                    'start_day': str(entry.start_day.data),
                    'number_of_days': entry.number_of_days.data,
                    'delta': entry.delta.data
                })

    return result


# creates flask form using data from request.data if any
def get_run_form():
    run_form = RunForm()
    # dynamically fill list or select options for available models
    run_form.exe_models.choices = get_models_choices()
    return run_form


# updates form with defaults from given commands
def set_form_defaults(form, commands):
    def get_command(command_name):
        return [item for item in commands if item['command'] == command_name]

    def str_to_datetime(str):
        if not str or str == 'None':
            str = datetime.today().strftime('%Y-%m-%d')
        str = str[:10]
        return datetime.strptime(str, '%Y-%m-%d')

    # set default values for single fields
    if get_command('start_day'):
        form.start_day.data = str_to_datetime(get_command('start_day')[0]['start_day'])
    if get_command('number_of_days'):
        form.number_of_days.data = get_command('number_of_days')[0]['number_of_days']
    if get_command('exe_models'):
        form.exe_models.data = get_command('exe_models')[0]['include']

    # set default values for compound fields
    # TODO: avoid ifs, use if request.get instead
    if not form.change_input_series_one_model:
        for command in get_command('change_input_series_one_model'):
            form.change_input_series_one_model.append_entry()
    if not form.change_input_series_all_models:
        for command in get_command('change_input_series_all_models'):
            form.change_input_series_all_models.append_entry()
    if not form.change_timeseries_value_several_days:
        for command in get_command('change_timeseries_value_several_days'):
            form.change_timeseries_value_several_days.append_entry()
    if not form.change_timeseries_value_several_days_add_delta:
        for command in get_command('change_timeseries_value_several_days_add_delta'):
            form.change_timeseries_value_several_days_add_delta.append_entry()

    for index, command in enumerate(get_command('change_input_series_one_model')):
        sub_form = form.change_input_series_one_model[index]
        sub_form.model_system_name.choices = get_models_choices()
        sub_form.model_system_name.data = command.get('model_system_name', '')
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.input_source_final.choices = get_inputs_choices()
        sub_form.input_source_final.data = command.get('input_source_final', '')
    for index, command in enumerate(get_command('change_input_series_all_models')):
        sub_form = form.change_input_series_all_models[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.input_source_final.choices = get_inputs_choices()
        sub_form.input_source_final.data = command.get('input_source_final', '')
    for index, command in enumerate(get_command('change_timeseries_value_several_days')):
        sub_form = form.change_timeseries_value_several_days[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.start_day.data = str_to_datetime(command.get('start_day', ''))
        sub_form.number_of_days.data = command.get('number_of_days', '')
        sub_form.new_value.data = command.get('new_value', '')
    for index, command in enumerate(get_command('change_timeseries_value_several_days_add_delta')):
        sub_form = form.change_timeseries_value_several_days_add_delta[index]
        sub_form.input_source_initial.choices = get_inputs_choices()
        sub_form.input_source_initial.data = command.get('input_source_initial', '')
        sub_form.start_day.data = str_to_datetime(command.get('start_day', ''))
        sub_form.number_of_days.data = command.get('number_of_days', '')
        sub_form.delta.data = command.get('delta', '')


@app.route('/run')
def view_run():
    return render_template('run.html')


@app.route('/run/form/init', methods=['POST'])
def view_run_init():
    run_form = get_run_form()
    commands = json.loads(request.data)['commands']
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/submit', methods=['POST'])
def view_run_submit():
    run_form = get_run_form()
    commands = get_commands(run_form)

    # submitted and valid
    if run_form.validate_on_submit():
        # TODO: run modeling with commands
        return json.dumps({
            'commands': commands,
            'html': render_template('run_success.html', commands=commands)
        })

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    }), 400


@app.route('/run/form/add/<field>', methods=['POST'])
def view_run_add(field):
    run_form = get_run_form()
    run_form[field].append_entry()
    commands = get_commands(run_form)
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/remove/<field>', methods=['POST'])
def view_run_remove(field):
    run_form = get_run_form()
    run_form[field].pop_entry()
    commands = get_commands(run_form)
    set_form_defaults(run_form, commands)

    return json.dumps({
        'commands': commands,
        'html': render_template('run_form.html', form=run_form)
    })


@app.route('/run/form/history', methods=['POST'])
def view_run_history():
    history = json.loads(request.data)
    history = [
        {
            'id': item['id'],
            'date': datetime.fromtimestamp(item['date'] / 1000),
            'commands': item['commands']
        } for item in history
    ]
    return render_template('run_history.html', history=history)


class RegisterForm(FlaskForm):
    email = StringField('Email', [validators.required()])
    password = PasswordField('Password', [validators.required()])

    def __init__(self, *args, **kwargs):
        FlaskForm.__init__(self, *args, **kwargs)
        self.user = None

    def validate(self):
        rv = FlaskForm.validate(self)
        if not rv:
            return False

        user = auth_get_user_by_email(self.email.data)
        if user:
            self.password.errors.append('Email already registered')
            return False

        if len(self.password.data) < 8:
            self.password.errors.append('Password should be at least 8 characters long')
            return False

        self.user = auth_add_user(self.email.data, self.password.data)
        return True


class LoginForm(FlaskForm):
    email = StringField('Email', [validators.required()])
    password = PasswordField('Password', [validators.required()])

    def __init__(self, *args, **kwargs):
        FlaskForm.__init__(self, *args, **kwargs)
        self.user = None

    def validate(self):
        rv = FlaskForm.validate(self)
        if not rv:
            return False

        user = auth_get_user_by_email(self.email.data)
        if not user or not auth_check_password(user, self.password.data):
            self.password.errors.append('Invalid email or password')
            return False

        self.user = user
        return True


@app.route('/register', methods=['GET', 'POST'])
def view_register():
    if current_user.is_authenticated:
        return redirect(url_for('view_home'))                    
    register_form = RegisterForm()
    if register_form.validate_on_submit():
        login_user(register_form.user, remember=True)
        return redirect(url_for('view_home'))                    
    return render_template('register.html', form=register_form)


@app.route('/login', methods=['GET', 'POST'])
def view_login():
    if current_user.is_authenticated:
        return redirect(url_for('view_home'))                    
    login_form = LoginForm()
    if login_form.validate_on_submit():
        login_user(login_form.user, remember=True)
        return redirect(url_for('view_home'))                    
    return render_template('login.html', form=login_form)


@app.route('/logout')
def view_logout():
    logout_user()
    return redirect(url_for('view_home'))                    


if __name__ == '__main__':
    app.run()

# Diplomacy Tournament Visualiser
# Copyright (C) 2014, 2016-2019 Chris Brand
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

"""
Round Views for the Diplomacy Tournament Visualiser.
"""

from django.contrib.auth.decorators import permission_required
from django.core.exceptions import ValidationError
from django.forms.formsets import formset_factory
from django.http import Http404, HttpResponseRedirect
from django.shortcuts import render
from django.urls import reverse
from django.utils.translation import ugettext as _

from tournament.forms import BaseGamePlayersFormset
from tournament.forms import BasePlayerRoundFormset
from tournament.forms import BasePowerAssignFormset
from tournament.forms import GamePlayersForm
from tournament.forms import GameScoreForm
from tournament.forms import GetSevenPlayersForm
from tournament.forms import PlayerRoundForm
from tournament.forms import PowerAssignForm

from tournament.tournament_views import get_modifiable_tournament_or_404
from tournament.tournament_views import get_visible_tournament_or_404

from tournament.diplomacy import GreatPower, GameSet
from tournament.email import send_board_call
from tournament.game_seeder import GameSeeder
from tournament.models import Tournament, Round, Game
from tournament.models import TournamentPlayer, RoundPlayer, GamePlayer

# Round views

def get_round_or_404(tournament, round_num):
    """Return the specified numbered round of the specified tournament or raise Http404."""
    try:
        return tournament.round_numbered(round_num)
    except Round.DoesNotExist:
        raise Http404

def round_simple(request, tournament_id, round_num, template):
    """Just render the specified template with the round"""
    t = get_visible_tournament_or_404(tournament_id, request.user)
    r = get_round_or_404(t, round_num)
    context = {'tournament': t, 'round': r}
    return render(request, 'rounds/%s.html' % template, context)

@permission_required('tournament.add_roundplayer')
def roll_call(request, tournament_id, round_num=None):
    """Provide a form to specify which players are playing each round"""
    t = get_modifiable_tournament_or_404(tournament_id, request.user)
    PlayerRoundFormset = formset_factory(PlayerRoundForm,
                                         extra=2,
                                         formset=BasePlayerRoundFormset)
    if round_num:
        r = get_round_or_404(t, round_num)
        round_set = t.round_set.filter(pk=r.pk)
    else:
        round_set = t.round_set.all()
    data = []
    # Go through each player in the Tournament
    for tp in t.tournamentplayer_set.all():
        current = {'player': tp.player}
        rps = tp.roundplayers()
        # And each round of the Tournament
        for r in round_set:
            # Is this player listed as playing this round ?
            played = rps.filter(the_round=r).exists()
            current['round_%d' % r.number()] = played
        data.append(current)
    if round_num:
        formset = PlayerRoundFormset(request.POST or None,
                                     tournament=t,
                                     round_num=int(round_num),
                                     initial=data)
    else:
        formset = PlayerRoundFormset(request.POST or None,
                                     tournament=t,
                                     initial=data)
    if formset.is_valid():
        for form in formset:
            try:
                p = form.cleaned_data['player']
            except KeyError:
                # This must be one of the extra forms, still empty
                continue
            # Ensure that this Player is in the Tournament
            i, created = TournamentPlayer.objects.get_or_create(player=p,
                                                                tournament=t)
            try:
                i.full_clean()
            except ValidationError as e:
                form.add_error(form.fields['player'], e)
                i.delete()
                return render(request,
                              'tournaments/round_players.html',
                              {'title': _('Roll Call'),
                               'tournament': t,
                               'post_url': reverse('roll_call', args=(tournament_id,)),                    
                               'formset' : formset})
            if created:
                i.save()
            for r_name, value in form.cleaned_data.items():
                if r_name == 'player':
                    # This column is just for the user
                    continue
                # Extract the round number from the field name
                i = int(r_name[6:])
                # Find that Round
                r = t.round_numbered(i)
                # Ignore non-bool fields and ones that aren't True
                if value is True:
                    # Ensure that we have a corresponding RoundPlayer
                    i, created = RoundPlayer.objects.get_or_create(player=p,
                                                                   the_round=r)
                    try:
                        i.full_clean()
                    except ValidationError as e:
                        form.add_error(None, e)
                        i.delete()
                        return render(request,
                                      'tournaments/round_players.html',
                                      {'title': _('Roll Call'),
                                       'tournament': t,
                                       'post_url': reverse('roll_call', args=(tournament_id,)),                    
                                       'formset' : formset})
                    if created:
                        i.save()
                else:
                    # delete any corresponding RoundPlayer
                    # This could be a player who was previously checked-off in error
                    RoundPlayer.objects.filter(player=p,
                                               the_round=r).delete()
        r = t.current_round()
        # If we're doing a roll call for a single round,
        # we only want to seed boards if it's the current round
        if not round_num or (r.number() == round_num):
            if t.seed_games:
                if (r.roundplayer_set.count() % 7) == 0:                    
                    # We have an exact multiple of 7 players, so go straight to seeding
                    return HttpResponseRedirect(reverse('seed_games',                    
                                                        args=(tournament_id,                    
                                                              r.number())))                    
                # We need players to sit out or play multiple games
                return HttpResponseRedirect(reverse('get_seven',                    
                                                    args=(tournament_id,                    
                                                          r.number())))                    
            else:
                # Next job is almost certainly to create the actual games
                return HttpResponseRedirect(reverse('create_games',
                                                    args=(tournament_id,                    
                                                          r.number())))                    

    return render(request,
                  'tournaments/round_players.html',
                  {'title': _('Roll Call'),
                   'tournament': t,
                   'post_url': reverse('roll_call', args=(tournament_id,)),                    
                   'formset' : formset})

@permission_required('tournament.add_game')
def get_seven(request, tournament_id, round_num):
    """Provide a form to get a multiple of seven players for a round"""
    t = get_modifiable_tournament_or_404(tournament_id, request.user)
    r = get_round_or_404(t, round_num)
    count = r.roundplayer_set.count()
    sitters = count % 7
    # If we already have an exact multiple of seven players, go straight to creating games
    if sitters == 0:
        return HttpResponseRedirect(reverse('seed_games',                    
                                            args=(tournament_id,                    
                                                  round_num)))

    doubles = 7 - sitters
    context = {'tournament': t,
               'round': r,
               'count' : count,
               'sitters' : sitters,
               'doubles' : doubles}
    form = GetSevenPlayersForm(request.POST or None,
                               the_round=r)
    if form.is_valid():
        # Update RoundPlayers to indicate number of games they're playing
        # First clear any old game_counts
        for rp in r.roundplayer_set.exclude(game_count=1):
            rp.game_count = 1
            rp.save()
        for i in range(sitters):
            rp = form.cleaned_data['sitter_%d' % i]
            if rp:
                rp.game_count = 0
                rp.save()
        for i in range(doubles):
            rp = form.cleaned_data['double_%d' % i]
            if rp:
                rp.game_count = 2
                rp.save()
        return HttpResponseRedirect(reverse('seed_games',                    
                                            args=(tournament_id,                    
                                                  round_num)))
    context['form'] = form
    return render(request,
                  'rounds/get_seven.html',
                  context)

def _sitters_and_two_gamers(tournament, the_round):
    """ Return a (sitters, two_gamers) 2-tuple"""
    tourney_players = tournament.tournamentplayer_set.all()
    round_players = the_round.roundplayer_set.all()
    # Get the set of players that haven't already been assigned to games for this round
    rps = []
    sitters = set()
    two_gamers = set()
    for rp in round_players:
        assert rp.gameplayers().count() == 0, "%d games already exist for %s in this round" % (rp.gameplayers().count(),
                                                                                               str(rp))
        rps.append(rp)
        if rp.game_count == 1:
            continue
        elif rp.game_count == 0:
            # This player is sitting out this round
            sitters.add(rp.tournamentplayer())
        elif rp.game_count == 2:
            # This player is playing two games this round
            two_gamers.add(rp.tournamentplayer())
        else:
            assert 0, 'Unexpected game_count value %d for %s' % (rp.game_count, str(rp))
    assert (not sitters) or (not two_gamers)
    if sitters:
        # Check that we have the right number of players sitting out
        assert (len(rps) - len(sitters)) % 7 == 0
    if two_gamers:
        # Check that we have the right number of players playing two games
        assert (len(rps) + len(two_gamers)) % 7 == 0
    # We also need to flag any players who aren't present for this round as sitting out
    for tp in tourney_players:
        if not round_players.filter(player=tp.player).exists():
            sitters.add(tp)
    return sitters, two_gamers

def _create_game_seeder(tournament, round_number):
    """Return a GameSeeder that knows about the tournament so far"""
    tourney_players = tournament.tournamentplayer_set.all()
    # Create the game seeder
    seeder = GameSeeder(GreatPower.objects.all(),
                        starts=100,
                        iterations=10)
    # Tell the seeder about every player in the tournament
    # (regardless of whether they're playing this round - they may have played already)
    for tp in tourney_players:
        seeder.add_player(tp)
    # Provide details of games already played this tournament
    for n in range(1, round_number):
        rnd = tournament.round_numbered(n)
        for g in rnd.game_set.all():
            game = set()
            for gp in g.gameplayer_set.all():
                game.add((gp.tournamentplayer(), gp.power))
            # TODO This doesn't deal with replacement players
            assert len(game) == 7
            seeder.add_played_game(game)
    # Add in any biases now that all players have been added
    for tp in tourney_players:
        # Just use seederbias_set so we only get each SeederBias once
        # because we only look at their player1
        for sb in tp.seederbias_set.all():
            seeder.add_bias(sb.player1, sb.player2, sb.weight)
    return seeder

def _seed_games(tournament, the_round):
    """Wrapper round GameSeeder to do the actual seeding for a round"""
    seeder = _create_game_seeder(tournament, the_round.number())
    sitters, two_gamers = _sitters_and_two_gamers(tournament, the_round)
    # Generate the games
    return seeder.seed_games(omitting_players=sitters,
                             players_doubling_up=two_gamers)

def _seed_games_and_powers(tournament, the_round):
    """Wrapper round GameSeeder to do the actual seeding for a round"""
    seeder = _create_game_seeder(tournament, the_round.number())
    sitters, two_gamers = _sitters_and_two_gamers(tournament, the_round)
    # Generate the games
    return seeder.seed_games_and_powers(omitting_players=sitters,
                                        players_doubling_up=two_gamers)

@permission_required('tournament.add_game')
def seed_games(request, tournament_id, round_num):
    """Seed players to the games for a round"""
    t = get_modifiable_tournament_or_404(tournament_id, request.user)
    r = get_round_or_404(t, round_num)
    if request.method == 'POST':
        PowerAssignFormset = formset_factory(PowerAssignForm,
                                             formset=BasePowerAssignFormset,
                                             extra=0)
        formset = PowerAssignFormset(request.POST, the_round=r)
        if formset.is_valid():
            for f in formset:
                # Update the game
                g = f.game
                g.name = f.cleaned_data['game_name']
                g.the_set = f.cleaned_data['the_set']
                try:
                    g.full_clean()
                except ValidationError as e:
                    f.add_error(None, e)
                    return render(request,
                                  'rounds/seeded_games.html',
                                  {'tournament': t,
                                   'round': r,
                                   'formset' : formset})
                g.save()
                # Assign the powers to the players
                for gp_id, field in f.cleaned_data.items():
                    if gp_id in ['the_set', 'game_name']:
                        continue
                    gp = GamePlayer.objects.get(id=gp_id)
                    gp.power = field
                    try:
                        gp.full_clean()
                    except ValidationError as e:
                        f.add_error(None, e)
                        return render(request,
                                      'rounds/seeded_games.html',
                                      {'tournament': t,
                                       'round': r,
                                       'formset' : formset})
                    gp.save()
            # Notify the players
            send_board_call(r)
            # Redirect to the index of games in the round
            return HttpResponseRedirect(reverse('game_index',
                                                args=(tournament_id, round_num)))                    
    else:
        # Delete any existing Games and GamePlayers for this round
        r.game_set.all().delete()
        # TODO It's a bit hokey to have a fixed default GameSet here
        default_set = GameSet.objects.get(pk=1)
        data = []
        # Generate a seeding, and assign powers if required
        if t.power_assignment == Tournament.AUTO:
            games = _seed_games_and_powers(t, r)
            # Add the Games and GamePlayers to the database
            for i, g in enumerate(games, start=1):
                new_game = Game.objects.create(name='R%sG%d' % (round_num, i),
                                               the_round=r,
                                               the_set=default_set)
                current = {'game_name': new_game.name,
                           'the_set': new_game.the_set}
                for tp, power in g:
                    gp = GamePlayer.objects.create(player=tp.player,
                                                   game=new_game,
                                                   power=power)
                    current[gp.id] = power
                data.append(current)
        else:
            games = _seed_games(t, r)
            # Add the Games and GamePlayers to the database
            for i, g in enumerate(games, start=1):
                new_game = Game.objects.create(name='R%sG%d' % (round_num, i),
                                               the_round=r,
                                               the_set=default_set)
                current = {'game_name': new_game.name,
                           'the_set': new_game.the_set}
                for tp in g:
                    gp = GamePlayer.objects.create(player=tp.player,
                                                   game=new_game)
                # If we're assigning powers from preferences, do so now
                if t.power_assignment == Tournament.PREFERENCES:
                    new_game.assign_powers_from_prefs()
                for tp in g:
                    gp = GamePlayer.objects.get(player=tp.player,
                                                game=new_game)
                    current[gp.id] = gp.power
                data.append(current)
        # Create a form for each of the resulting games
        PowerAssignFormset = formset_factory(PowerAssignForm,
                                             formset=BasePowerAssignFormset,
                                             extra=0)
        formset = PowerAssignFormset(the_round=r, initial=data)
    # Note that we wait for confirmation before adding them to the database
    context = {'tournament': t, 'round': r, 'games': games, 'formset': formset}
    return render(request, 'rounds/seeded_games.html', context)

@permission_required('tournament.add_game')
def create_games(request, tournament_id, round_num):
    """Provide a form to create the games for a round"""
    t = get_modifiable_tournament_or_404(tournament_id, request.user)
    r = get_round_or_404(t, round_num)
    # Do any games already exist for the round ?
    games = r.game_set.all()
    data = []
    for g in games:
        current = {'game_name': g.name,
                   'the_set': g.the_set}
        for gp in g.gameplayer_set.all():
            current[gp.power.name] = gp.roundplayer()
        data.append(current)
    # Estimate the number of games for the round
    round_players = r.roundplayer_set.count()
    expected_games = (round_players + 6) // 7
    # This can happen if there are no RoundPlayers for this round
    if expected_games < 1:
        expected_games = 1
    GamePlayersFormset = formset_factory(GamePlayersForm,
                                         extra=expected_games - games.count(),
                                         formset=BaseGamePlayersFormset)
    formset = GamePlayersFormset(request.POST or None,
                                 the_round=r,
                                 initial=data)
    if formset.is_valid():
        for f in formset:
            # Update/create the game
            try:
                g, created = Game.objects.get_or_create(name=f.cleaned_data['game_name'],
                                                        the_round=r,
                                                        the_set=f.cleaned_data['the_set'])
            except KeyError:
                # This must be an extra, unused formset
                continue
            try:
                g.full_clean()
            except ValidationError as e:
                f.add_error(None, e)
                g.delete()
                return render(request,
                              'rounds/create_games.html',
                              {'tournament': t,
                               'round': r,
                               'formset' : formset})
            if created:
                g.save()
            # Assign the players to the game
            for power, field in f.cleaned_data.items():
                try:
                    p = GreatPower.objects.get(name=power)
                except GreatPower.DoesNotExist:
                    continue
                # Is there already a player for this power in this game ?
                try:
                    i = GamePlayer.objects.get(game=g,
                                               power=p)
                except GamePlayer.DoesNotExist:
                    # Create one (default first_season and first_year)
                    i = GamePlayer(player=field.player, game=g, power=p)
                else:
                    # Change the player (if necessary)
                    i.player = field.player
                try:
                    i.full_clean()
                except ValidationError as e:
                    f.add_error(None, e)
                    # TODO Not 100% certain that this is the right thing to do here
                    i.delete()
                    return render(request,
                                  'rounds/create_games.html',
                                  {'tournament': t,
                                   'round': r,
                                   'formset' : formset})
                i.save()
        # Notify the players
        send_board_call(r)
        # Redirect to the index of games in the round
        return HttpResponseRedirect(reverse('game_index',
                                            args=(tournament_id, round_num)))                    

    return render(request,
                  'rounds/create_games.html',
                  {'tournament': t,
                   'round': r,
                   'formset' : formset})

@permission_required('tournament.change_gameplayer')
def game_scores(request, tournament_id, round_num):
    """Provide a form to enter scores for all the games in a round"""
    t = get_modifiable_tournament_or_404(tournament_id, request.user)
    r = get_round_or_404(t, round_num)
    GameScoreFormset = formset_factory(GameScoreForm,
                                       extra=0)
    # Initial data
    data = []
    the_list = r.game_set.all()
    for game in the_list:
        content = {'game_name': game.name}
        for gp in game.gameplayer_set.all():
            content[gp.power.name] = gp.score
        data.append(content)
    formset = GameScoreFormset(request.POST or None, initial=data)
    if formset.is_valid():
        for f in formset:
            # Find the game
            g = Game.objects.get(name=f.cleaned_data['game_name'],
                                 the_round=r)
            # Set the score for each player
            for power, field in f.cleaned_data.items():
                # Ignore non-GreatPower fields (game_name)
                try:
                    p = GreatPower.objects.get(name=power)
                except GreatPower.DoesNotExist:
                    continue
                # Find the matching GamePlayer
                # TODO This will fail if there was a replacement
                i = GamePlayer.objects.get(game=g,
                                           power=p)
                # Set the score
                i.score = field
                try:
                    i.full_clean()
                except ValidationError as e:
                    f.add_error(None, e)
                    return render(request,
                                  'rounds/game_score.html',
                                  {'tournament': t,
                                   'round': round_num,
                                   'formset' : formset})
                i.save()
        # Redirect to the round index
        return HttpResponseRedirect(reverse('round_index',
                                            args=(tournament_id)))

    return render(request,
                  'rounds/game_score.html',
                  {'tournament': t,
                   'round': round_num,
                   'formset' : formset})

def game_index(request, tournament_id, round_num):
    """Display a list of games in the round"""
    t = get_visible_tournament_or_404(tournament_id, request.user)
    r = get_round_or_404(t, round_num)
    the_list = r.game_set.all()
    context = {'round': r, 'game_list': the_list}
    return render(request, 'games/index.html', context)




from aputils.trainee_utils import is_trainee

from .models import GospelTrip


def gospel_trips_available(request):
  user = request.user
  if not hasattr(user, 'type') or not is_trainee(user):
    return {'gospel_trips_available': False}

  try:
    # sorts by latest open_time (most current)
    # finds first gt that is open
    admin = next((gt for gt in GospelTrip.objects.order_by('-open_time') if gt.is_open), None)
    if admin:                    
      if admin.is_open:                    
        return {'gospel_trips_available': True}                    
    return {'gospel_trips_available': False}
  except GospelTrip.DoesNotExist:
    return {'gospel_trips_available': False}

"""Base core views."""

from __future__ import unicode_literals

from django.core.urlresolvers import reverse
from django.views import generic

from django.contrib.auth import mixins as auth_mixins

from ..extensions import exts_pool


def find_nextlocation(request, user):
    """Find next location for given user after login."""
    if not user.last_login:
        # Redirect to profile on first login
        return reverse("core:user_index")
    nextlocation = request.POST.get("next", None)                    
    if nextlocation is None or nextlocation == "None":                    
        if request.user.role == "SimpleUsers":                    
            topredir = request.localconfig.parameters.get_value(                    
                "default_top_redirection")                    
            if topredir != "user":                    
                infos = exts_pool.get_extension_infos(topredir)                    
                nextlocation = infos["topredirection_url"]                    
            else:                    
                nextlocation = reverse("core:user_index")                    
        else:                    
            nextlocation = reverse("core:dashboard")                    
    return nextlocation


class RootDispatchView(auth_mixins.LoginRequiredMixin, generic.RedirectView):
    """Handle root dispatching based on role."""

    def get_redirect_url(self):
        """Find proper next hop."""
        return find_nextlocation(self.request, self.request.user)

"""Base core views."""

from __future__ import unicode_literals

from django.core.urlresolvers import reverse
from django.views import generic

from django.contrib.auth import mixins as auth_mixins

from ..extensions import exts_pool


def find_nextlocation(request, user):
    """Find next location for given user after login."""
    if not user.last_login:
        # Redirect to profile on first login
        return reverse("core:user_index")
    nextlocation = request.POST.get("next", None)                    
    if nextlocation is None or nextlocation == "None":                    
        if request.user.role == "SimpleUsers":                    
            topredir = request.localconfig.parameters.get_value(                    
                "default_top_redirection")                    
            if topredir != "user":                    
                infos = exts_pool.get_extension_infos(topredir)                    
                nextlocation = infos["topredirection_url"]                    
            else:                    
                nextlocation = reverse("core:user_index")                    
        else:                    
            nextlocation = reverse("core:dashboard")                    
    return nextlocation


class RootDispatchView(auth_mixins.LoginRequiredMixin, generic.RedirectView):
    """Handle root dispatching based on role."""

    def get_redirect_url(self):
        """Find proper next hop."""
        return find_nextlocation(self.request, self.request.user)

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import threading
import traceback

import redis                    

import ray
from ray import ray_constants
from ray import cloudpickle as pickle
from ray import profiling
from ray import utils


class ImportThread(object):
    """A thread used to import exports from the driver or other workers.

    Note:                    
    The driver also has an import thread, which is used only to                    
    import custom class definitions from calls to register_custom_serializer                    
    that happen under the hood on workers.                    

    Attributes:
        worker: the worker object in this process.
        mode: worker mode
        redis_client: the redis client used to query exports.
    """

    def __init__(self, worker, mode):                    
        self.worker = worker
        self.mode = mode
        self.redis_client = worker.redis_client

    def start(self):
        """Start the import thread."""
        t = threading.Thread(target=self._run, name="ray_import_thread")                    
        # Making the thread a daemon causes it to exit
        # when the main thread exits.
        t.daemon = True                    
        t.start()                    

    def _run(self):
        import_pubsub_client = self.redis_client.pubsub()
        # Exports that are published after the call to
        # import_pubsub_client.subscribe and before the call to
        # import_pubsub_client.listen will still be processed in the loop.
        import_pubsub_client.subscribe("__keyspace@0__:Exports")
        # Keep track of the number of imports that we've imported.
        num_imported = 0

        # Get the exports that occurred before the call to subscribe.
        with self.worker.lock:                    
            export_keys = self.redis_client.lrange("Exports", 0, -1)                    
            for key in export_keys:                    
                num_imported += 1                    
                self._process_key(key)                    
        try:
            for msg in import_pubsub_client.listen():                    
                with self.worker.lock:                    
                    if msg["type"] == "subscribe":
                        continue
                    assert msg["data"] == b"rpush"
                    num_imports = self.redis_client.llen("Exports")
                    assert num_imports >= num_imported
                    for i in range(num_imported, num_imports):
                        num_imported += 1                    
                        key = self.redis_client.lindex("Exports", i)
                        self._process_key(key)                    
        except redis.ConnectionError:                    
            # When Redis terminates the listen call will throw a
            # ConnectionError, which we catch here.
            pass                    

    def _process_key(self, key):
        """Process the given export key from redis."""
        # Handle the driver case first.
        if self.mode != ray.WORKER_MODE:
            if key.startswith(b"FunctionsToRun"):
                with profiling.profile(
                        "fetch_and_run_function", worker=self.worker):
                    self.fetch_and_execute_function_to_run(key)
            # Return because FunctionsToRun are the only things that
            # the driver should import.
            return

        if key.startswith(b"RemoteFunction"):
            with profiling.profile(
                    "register_remote_function", worker=self.worker):
                (self.worker.function_actor_manager.
                 fetch_and_register_remote_function(key))
        elif key.startswith(b"FunctionsToRun"):
            with profiling.profile(
                    "fetch_and_run_function", worker=self.worker):
                self.fetch_and_execute_function_to_run(key)
        elif key.startswith(b"ActorClass"):
            # Keep track of the fact that this actor class has been
            # exported so that we know it is safe to turn this worker
            # into an actor of that class.
            self.worker.function_actor_manager.imported_actor_classes.add(key)
        # TODO(rkn): We may need to bring back the case of
        # fetching actor classes here.
        else:
            raise Exception("This code should be unreachable.")

    def fetch_and_execute_function_to_run(self, key):
        """Run on arbitrary function on the worker."""
        (driver_id, serialized_function,
         run_on_other_drivers) = self.redis_client.hmget(
             key, ["driver_id", "function", "run_on_other_drivers"])

        if (utils.decode(run_on_other_drivers) == "False"
                and self.worker.mode == ray.SCRIPT_MODE
                and driver_id != self.worker.task_driver_id.binary()):
            return

        try:
            # Deserialize the function.
            function = pickle.loads(serialized_function)
            # Run the function.
            function({"worker": self.worker})
        except Exception:
            # If an exception was thrown when the function was run, we record
            # the traceback and notify the scheduler of the failure.
            traceback_str = traceback.format_exc()
            # Log the error message.
            utils.push_error_to_driver(
                self.worker,
                ray_constants.FUNCTION_TO_RUN_PUSH_ERROR,
                traceback_str,
                driver_id=ray.DriverID(driver_id))



from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import atexit
import json
import os
import logging
import signal
import threading
import time

import ray
import ray.ray_constants as ray_constants
from ray.tempfile_services import (
    get_logs_dir_path, get_object_store_socket_name, get_raylet_socket_name,
    new_log_monitor_log_file, new_monitor_log_file,
    new_raylet_monitor_log_file, new_plasma_store_log_file,
    new_raylet_log_file, new_webui_log_file, set_temp_root,
    try_to_create_directory)

# Logger for this module. It should be configured at the entry point
# into the program using Ray. Ray configures it by default automatically
# using logging.basicConfig in its entry/init points.
logger = logging.getLogger(__name__)


class Node(object):
    """An encapsulation of the Ray processes on a single node.

    This class is responsible for starting Ray processes and killing them.

    Attributes:
        all_processes (dict): A mapping from process type (str) to a list of
            ProcessInfo objects. All lists have length one except for the Redis
            server list, which has multiple.
    """

    def __init__(self, ray_params, head=False, shutdown_at_exit=True):
        """Start a node.

        Args:
            ray_params (ray.params.RayParams): The parameters to use to
                configure the node.
            head (bool): True if this is the head node, which means it will
                start additional processes like the Redis servers, monitor
                processes, and web UI.
            shutdown_at_exit (bool): If true, a handler will be registered to
                shutdown the processes started here when the Python interpreter
                exits.
        """
        self.all_processes = {}

        ray_params.update_if_absent(
            node_ip_address=ray.services.get_node_ip_address(),
            include_log_monitor=True,
            resources={},
            include_webui=False,
            worker_path=os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "workers/default_worker.py"))

        if head:
            ray_params.update_if_absent(num_redis_shards=1, include_webui=True)
        else:
            redis_client = ray.services.create_redis_client(
                ray_params.redis_address, ray_params.redis_password)
            ray_params.include_java = (
                ray.services.include_java_from_redis(redis_client))

        self._ray_params = ray_params
        self._config = (json.loads(ray_params._internal_config)
                        if ray_params._internal_config else None)
        self._node_ip_address = ray_params.node_ip_address
        self._redis_address = ray_params.redis_address
        self._plasma_store_socket_name = None
        self._raylet_socket_name = None
        self._webui_url = None

        self.start_ray_processes()

        if shutdown_at_exit:
            atexit.register(lambda: self.kill_all_processes(
                check_alive=False, allow_graceful=True))

    @property
    def node_ip_address(self):
        """Get the cluster Redis address."""
        return self._node_ip_address

    @property
    def redis_address(self):
        """Get the cluster Redis address."""
        return self._redis_address

    @property
    def plasma_store_socket_name(self):
        """Get the node's plasma store socket name."""
        return self._plasma_store_socket_name

    @property
    def webui_url(self):
        """Get the cluster's web UI url."""
        return self._webui_url

    @property
    def raylet_socket_name(self):
        """Get the node's raylet socket name."""
        return self._raylet_socket_name

    def prepare_socket_file(self, socket_path):
        """Prepare the socket file for raylet and plasma.

        This method helps to prepare a socket file.
        1. Make the directory if the directory does not exist.
        2. If the socket file exists, raise exception.

        Args:
            socket_path (string): the socket file to prepare.
        """
        if not os.path.exists(socket_path):
            path = os.path.dirname(socket_path)
            if not os.path.isdir(path):
                try_to_create_directory(path)
        else:
            raise Exception("Socket file {} exists!".format(socket_path))

    def start_redis(self):
        """Start the Redis servers."""
        assert self._redis_address is None
        (self._redis_address, redis_shards,
         process_infos) = ray.services.start_redis(
             self._node_ip_address,                    
             port=self._ray_params.redis_port,
             redis_shard_ports=self._ray_params.redis_shard_ports,
             num_redis_shards=self._ray_params.num_redis_shards,
             redis_max_clients=self._ray_params.redis_max_clients,
             redirect_output=self._ray_params.redirect_output,
             redirect_worker_output=self._ray_params.redirect_worker_output,
             password=self._ray_params.redis_password,
             redis_max_memory=self._ray_params.redis_max_memory)
        assert (
            ray_constants.PROCESS_TYPE_REDIS_SERVER not in self.all_processes)
        self.all_processes[ray_constants.PROCESS_TYPE_REDIS_SERVER] = (
            process_infos)

    def start_log_monitor(self):
        """Start the log monitor."""
        stdout_file, stderr_file = new_log_monitor_log_file()
        process_info = ray.services.start_log_monitor(
            self.redis_address,
            self._node_ip_address,                    
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            redis_password=self._ray_params.redis_password)                    
        assert ray_constants.PROCESS_TYPE_LOG_MONITOR not in self.all_processes
        self.all_processes[ray_constants.PROCESS_TYPE_LOG_MONITOR] = [
            process_info
        ]

    def start_ui(self):
        """Start the web UI."""
        stdout_file, stderr_file = new_webui_log_file()
        self._webui_url, process_info = ray.services.start_ui(
            self._redis_address,
            stdout_file=stdout_file,
            stderr_file=stderr_file)
        assert ray_constants.PROCESS_TYPE_WEB_UI not in self.all_processes
        if process_info is not None:
            self.all_processes[ray_constants.PROCESS_TYPE_WEB_UI] = [
                process_info
            ]

    def start_plasma_store(self):
        """Start the plasma store."""
        assert self._plasma_store_socket_name is None
        # If the user specified a socket name, use it.
        self._plasma_store_socket_name = (
            self._ray_params.plasma_store_socket_name
            or get_object_store_socket_name())
        self.prepare_socket_file(self._plasma_store_socket_name)
        stdout_file, stderr_file = (new_plasma_store_log_file(
            self._ray_params.redirect_output))
        process_info = ray.services.start_plasma_store(
            self._node_ip_address,                    
            self._redis_address,
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            object_store_memory=self._ray_params.object_store_memory,
            plasma_directory=self._ray_params.plasma_directory,
            huge_pages=self._ray_params.huge_pages,
            plasma_store_socket_name=self._plasma_store_socket_name,                    
            redis_password=self._ray_params.redis_password)                    
        assert (
            ray_constants.PROCESS_TYPE_PLASMA_STORE not in self.all_processes)
        self.all_processes[ray_constants.PROCESS_TYPE_PLASMA_STORE] = [
            process_info
        ]

    def start_raylet(self, use_valgrind=False, use_profiler=False):
        """Start the raylet.

        Args:
            use_valgrind (bool): True if we should start the process in
                valgrind.
            use_profiler (bool): True if we should start the process in the
                valgrind profiler.
        """
        assert self._raylet_socket_name is None
        # If the user specified a socket name, use it.
        self._raylet_socket_name = (self._ray_params.raylet_socket_name
                                    or get_raylet_socket_name())
        self.prepare_socket_file(self._raylet_socket_name)
        stdout_file, stderr_file = new_raylet_log_file(
            redirect_output=self._ray_params.redirect_worker_output)                    
        process_info = ray.services.start_raylet(
            self._redis_address,
            self._node_ip_address,                    
            self._raylet_socket_name,
            self._plasma_store_socket_name,
            self._ray_params.worker_path,
            self._ray_params.num_cpus,
            self._ray_params.num_gpus,
            self._ray_params.resources,
            self._ray_params.object_manager_port,
            self._ray_params.node_manager_port,
            self._ray_params.redis_password,
            use_valgrind=use_valgrind,
            use_profiler=use_profiler,
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            config=self._config,
            include_java=self._ray_params.include_java,
            java_worker_options=self._ray_params.java_worker_options,
        )
        assert ray_constants.PROCESS_TYPE_RAYLET not in self.all_processes
        self.all_processes[ray_constants.PROCESS_TYPE_RAYLET] = [process_info]

    def start_worker(self):
        """Start a worker process."""
        raise NotImplementedError

    def start_monitor(self):
        """Start the monitor."""
        stdout_file, stderr_file = new_monitor_log_file(
            self._ray_params.redirect_output)
        process_info = ray.services.start_monitor(
            self._redis_address,
            self._node_ip_address,                    
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            autoscaling_config=self._ray_params.autoscaling_config,
            redis_password=self._ray_params.redis_password)                    
        assert ray_constants.PROCESS_TYPE_MONITOR not in self.all_processes
        self.all_processes[ray_constants.PROCESS_TYPE_MONITOR] = [process_info]

    def start_raylet_monitor(self):
        """Start the raylet monitor."""
        stdout_file, stderr_file = new_raylet_monitor_log_file(
            self._ray_params.redirect_output)
        process_info = ray.services.start_raylet_monitor(
            self._redis_address,
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            redis_password=self._ray_params.redis_password,
            config=self._config)
        assert (ray_constants.PROCESS_TYPE_RAYLET_MONITOR not in
                self.all_processes)
        self.all_processes[ray_constants.PROCESS_TYPE_RAYLET_MONITOR] = [
            process_info
        ]

    def start_ray_processes(self):
        """Start all of the processes on the node."""
        set_temp_root(self._ray_params.temp_dir)
        logger.info(
            "Process STDOUT and STDERR is being redirected to {}.".format(
                get_logs_dir_path()))

        # If this is the head node, start the relevant head node processes.
        if self._redis_address is None:
            self.start_redis()
            self.start_monitor()
            self.start_raylet_monitor()

        self.start_plasma_store()
        self.start_raylet()

        if self._ray_params.include_log_monitor:
            self.start_log_monitor()
        if self._ray_params.include_webui:
            self.start_ui()

    def _kill_process_type(self,
                           process_type,
                           allow_graceful=False,
                           check_alive=True,
                           wait=False):
        """Kill a process of a given type.

        If the process type is PROCESS_TYPE_REDIS_SERVER, then we will kill all
        of the Redis servers.

        If the process was started in valgrind, then we will raise an exception
        if the process has a non-zero exit code.

        Args:
            process_type: The type of the process to kill.
            allow_graceful (bool): Send a SIGTERM first and give the process
                time to exit gracefully. If that doesn't work, then use
                SIGKILL. We usually want to do this outside of tests.
            check_alive (bool): If true, then we expect the process to be alive
                and will raise an exception if the process is already dead.
            wait (bool): If true, then this method will not return until the
                process in question has exited.

        Raises:
            This process raises an exception in the following cases:
                1. The process had already died and check_alive is true.
                2. The process had been started in valgrind and had a non-zero
                   exit code.
        """
        process_infos = self.all_processes[process_type]
        if process_type != ray_constants.PROCESS_TYPE_REDIS_SERVER:
            assert len(process_infos) == 1
        for process_info in process_infos:
            process = process_info.process
            # Handle the case where the process has already exited.
            if process.poll() is not None:
                if check_alive:
                    raise Exception("Attempting to kill a process of type "
                                    "'{}', but this process is already dead."
                                    .format(process_type))
                else:
                    continue

            if process_info.use_valgrind:
                process.terminate()
                process.wait()
                if process.returncode != 0:
                    message = ("Valgrind detected some errors in process of "
                               "type {}. Error code {}.".format(
                                   process_type, process.returncode))
                    if process_info.stdout_file is not None:
                        with open(process_info.stdout_file, "r") as f:
                            message += "\nPROCESS STDOUT:\n" + f.read()
                    if process_info.stderr_file is not None:
                        with open(process_info.stderr_file, "r") as f:
                            message += "\nPROCESS STDERR:\n" + f.read()
                    raise Exception(message)
                continue

            if process_info.use_valgrind_profiler:
                # Give process signal to write profiler data.
                os.kill(process.pid, signal.SIGINT)
                # Wait for profiling data to be written.
                time.sleep(0.1)

            if allow_graceful:
                # Allow the process one second to exit gracefully.
                process.terminate()
                timer = threading.Timer(1, lambda process: process.kill(),
                                        [process])
                try:
                    timer.start()
                    process.wait()
                finally:
                    timer.cancel()

                if process.poll() is not None:
                    continue

            # If the process did not exit within one second, force kill it.
            process.kill()
            # The reason we usually don't call process.wait() here is that
            # there's some chance we'd end up waiting a really long time.
            if wait:
                process.wait()

        del self.all_processes[process_type]

    def kill_redis(self, check_alive=True):
        """Kill the Redis servers.

        Args:
            check_alive (bool): Raise an exception if any of the processes
                were already dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_REDIS_SERVER, check_alive=check_alive)

    def kill_plasma_store(self, check_alive=True):
        """Kill the plasma store.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_PLASMA_STORE, check_alive=check_alive)

    def kill_raylet(self, check_alive=True):
        """Kill the raylet.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_RAYLET, check_alive=check_alive)

    def kill_log_monitor(self, check_alive=True):
        """Kill the log monitor.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_LOG_MONITOR, check_alive=check_alive)

    def kill_monitor(self, check_alive=True):
        """Kill the monitor.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_MONITOR, check_alive=check_alive)

    def kill_raylet_monitor(self, check_alive=True):
        """Kill the raylet monitor.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_RAYLET_MONITOR, check_alive=check_alive)

    def kill_all_processes(self, check_alive=True, allow_graceful=False):
        """Kill all of the processes.

        Note that This is slower than necessary because it calls kill, wait,
        kill, wait, ... instead of kill, kill, ..., wait, wait, ...

        Args:
            check_alive (bool): Raise an exception if any of the processes were
                already dead.
        """
        # Kill the raylet first. This is important for suppressing errors at
        # shutdown because we give the raylet a chance to exit gracefully and
        # clean up its child worker processes. If we were to kill the plasma
        # store (or Redis) first, that could cause the raylet to exit
        # ungracefully, leading to more verbose output from the workers.
        if ray_constants.PROCESS_TYPE_RAYLET in self.all_processes:
            self._kill_process_type(
                ray_constants.PROCESS_TYPE_RAYLET,
                check_alive=check_alive,
                allow_graceful=allow_graceful)

        # We call "list" to copy the keys because we are modifying the
        # dictionary while iterating over it.
        for process_type in list(self.all_processes.keys()):
            self._kill_process_type(
                process_type,
                check_alive=check_alive,
                allow_graceful=allow_graceful)

    def live_processes(self):
        """Return a list of the live processes.

        Returns:
            A list of the live processes.
        """
        result = []
        for process_type, process_infos in self.all_processes.items():
            for process_info in process_infos:
                if process_info.process.poll() is None:
                    result.append((process_type, process_info.process))
        return result

    def dead_processes(self):
        """Return a list of the dead processes.

        Note that this ignores processes that have been explicitly killed,
        e.g., via a command like node.kill_raylet().

        Returns:
            A list of the dead processes ignoring the ones that have been
                explicitly killed.
        """
        result = []
        for process_type, process_infos in self.all_processes.items():
            for process_info in process_infos:
                if process_info.process.poll() is not None:
                    result.append((process_type, process_info.process))
        return result

    def any_processes_alive(self):
        """Return true if any processes are still alive.

        Returns:
            True if any process is still alive.
        """
        return any(self.live_processes())

    def remaining_processes_alive(self):
        """Return true if all remaining processes are still alive.

        Note that this ignores processes that have been explicitly killed,
        e.g., via a command like node.kill_raylet().

        Returns:
            True if any process that wasn't explicitly killed is still alive.
        """
        return not any(self.dead_processes())

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import logging

import ray.ray_constants as ray_constants


class RayParams(object):
    """A class used to store the parameters used by Ray.

    Attributes:
        redis_address (str): The address of the Redis server to connect to. If
            this address is not provided, then this command will start Redis, a
            global scheduler, a local scheduler, a plasma store, a plasma
            manager, and some workers. It will also kill these processes when
            Python exits.
        redis_port (int): The port that the primary Redis shard should listen
            to. If None, then a random port will be chosen.
        redis_shard_ports: A list of the ports to use for the non-primary Redis
            shards.
        num_cpus (int): Number of CPUs to configure the raylet with.
        num_gpus (int): Number of GPUs to configure the raylet with.
        resources: A dictionary mapping the name of a resource to the quantity
            of that resource available.
        object_store_memory: The amount of memory (in bytes) to start the
            object store with.
        redis_max_memory: The max amount of memory (in bytes) to allow redis
            to use, or None for no limit. Once the limit is exceeded, redis
            will start LRU eviction of entries. This only applies to the
            sharded redis tables (task and object tables).
        object_manager_port int: The port to use for the object manager.
        node_manager_port: The port to use for the node manager.
        node_ip_address (str): The IP address of the node that we are on.
        object_id_seed (int): Used to seed the deterministic generation of
            object IDs. The same value can be used across multiple runs of the
            same job in order to generate the object IDs in a consistent
            manner. However, the same ID should not be used for different jobs.
        local_mode (bool): True if the code should be executed serially
            without Ray. This is useful for debugging.
        redirect_worker_output: True if the stdout and stderr of worker
            processes should be redirected to files.
        redirect_output (bool): True if stdout and stderr for non-worker
            processes should be redirected to files and false otherwise.
        num_redis_shards: The number of Redis shards to start in addition to
            the primary Redis shard.
        redis_max_clients: If provided, attempt to configure Redis with this
            maxclients number.
        redis_password (str): Prevents external clients without the password
            from connecting to Redis if provided.
        plasma_directory: A directory where the Plasma memory mapped files will
            be created.
        worker_path (str): The path of the source code that will be run by the
            worker.
        huge_pages: Boolean flag indicating whether to start the Object
            Store with hugetlbfs support. Requires plasma_directory.
        include_webui: Boolean flag indicating whether to start the web
            UI, which is a Jupyter notebook.
        logging_level: Logging level, default will be logging.INFO.
        logging_format: Logging format, default contains a timestamp,
            filename, line number, and message. See ray_constants.py.
        plasma_store_socket_name (str): If provided, it will specify the socket
            name used by the plasma store.
        raylet_socket_name (str): If provided, it will specify the socket path
            used by the raylet process.
        temp_dir (str): If provided, it will specify the root temporary
            directory for the Ray process.
        include_log_monitor (bool): If True, then start a log monitor to
            monitor the log files for all processes on this node and push their
            contents to Redis.
        autoscaling_config: path to autoscaling config file.
        include_java (bool): If True, the raylet backend can also support
            Java worker.
        java_worker_options (str): The command options for Java worker.
        _internal_config (str): JSON configuration for overriding
            RayConfig defaults. For testing purposes ONLY.
    """

    def __init__(self,
                 redis_address=None,
                 num_cpus=None,
                 num_gpus=None,
                 resources=None,
                 object_store_memory=None,
                 redis_max_memory=None,
                 redis_port=None,
                 redis_shard_ports=None,
                 object_manager_port=None,
                 node_manager_port=None,
                 node_ip_address=None,
                 object_id_seed=None,
                 num_workers=None,
                 local_mode=False,
                 driver_mode=None,
                 redirect_worker_output=False,                    
                 redirect_output=True,
                 num_redis_shards=None,
                 redis_max_clients=None,
                 redis_password=None,
                 plasma_directory=None,
                 worker_path=None,
                 huge_pages=False,
                 include_webui=None,
                 logging_level=logging.INFO,
                 logging_format=ray_constants.LOGGER_FORMAT,
                 plasma_store_socket_name=None,
                 raylet_socket_name=None,
                 temp_dir=None,
                 include_log_monitor=None,
                 autoscaling_config=None,
                 include_java=False,
                 java_worker_options=None,
                 _internal_config=None):
        self.object_id_seed = object_id_seed
        self.redis_address = redis_address
        self.num_cpus = num_cpus
        self.num_gpus = num_gpus
        self.resources = resources
        self.object_store_memory = object_store_memory
        self.redis_max_memory = redis_max_memory
        self.redis_port = redis_port
        self.redis_shard_ports = redis_shard_ports
        self.object_manager_port = object_manager_port
        self.node_manager_port = node_manager_port
        self.node_ip_address = node_ip_address
        self.num_workers = num_workers
        self.local_mode = local_mode
        self.driver_mode = driver_mode
        self.redirect_worker_output = redirect_worker_output
        self.redirect_output = redirect_output
        self.num_redis_shards = num_redis_shards
        self.redis_max_clients = redis_max_clients
        self.redis_password = redis_password
        self.plasma_directory = plasma_directory
        self.worker_path = worker_path
        self.huge_pages = huge_pages
        self.include_webui = include_webui
        self.plasma_store_socket_name = plasma_store_socket_name
        self.raylet_socket_name = raylet_socket_name
        self.temp_dir = temp_dir
        self.include_log_monitor = include_log_monitor
        self.autoscaling_config = autoscaling_config
        self.include_java = include_java
        self.java_worker_options = java_worker_options
        self._internal_config = _internal_config
        self._check_usage()

    def update(self, **kwargs):
        """Update the settings according to the keyword arguments.

        Args:
            kwargs: The keyword arguments to set corresponding fields.
        """
        for arg in kwargs:
            if hasattr(self, arg):
                setattr(self, arg, kwargs[arg])
            else:
                raise ValueError("Invalid RayParams parameter in"
                                 " update: %s" % arg)

        self._check_usage()

    def update_if_absent(self, **kwargs):
        """Update the settings when the target fields are None.

        Args:
            kwargs: The keyword arguments to set corresponding fields.
        """
        for arg in kwargs:
            if hasattr(self, arg):
                if getattr(self, arg) is None:
                    setattr(self, arg, kwargs[arg])
            else:
                raise ValueError("Invalid RayParams parameter in"
                                 " update_if_absent: %s" % arg)

        self._check_usage()

    def _check_usage(self):
        if self.resources is not None:
            assert "CPU" not in self.resources, (
                "'CPU' should not be included in the resource dictionary. Use "
                "num_cpus instead.")
            assert "GPU" not in self.resources, (
                "'GPU' should not be included in the resource dictionary. Use "
                "num_gpus instead.")

        if self.num_workers is not None:
            raise ValueError(
                "The 'num_workers' argument is deprecated. Please use "
                "'num_cpus' instead.")

        if self.include_java is None and self.java_worker_options is not None:
            raise ValueError("Should not specify `java-worker-options` "
                             "without providing `include-java`.")



from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import threading
import traceback

import redis                    

import ray
from ray import ray_constants
from ray import cloudpickle as pickle
from ray import profiling
from ray import utils


class ImportThread(object):
    """A thread used to import exports from the driver or other workers.

    Note:                    
    The driver also has an import thread, which is used only to                    
    import custom class definitions from calls to register_custom_serializer                    
    that happen under the hood on workers.                    

    Attributes:
        worker: the worker object in this process.
        mode: worker mode
        redis_client: the redis client used to query exports.
    """

    def __init__(self, worker, mode):                    
        self.worker = worker
        self.mode = mode
        self.redis_client = worker.redis_client

    def start(self):
        """Start the import thread."""
        t = threading.Thread(target=self._run, name="ray_import_thread")                    
        # Making the thread a daemon causes it to exit
        # when the main thread exits.
        t.daemon = True                    
        t.start()                    

    def _run(self):
        import_pubsub_client = self.redis_client.pubsub()
        # Exports that are published after the call to
        # import_pubsub_client.subscribe and before the call to
        # import_pubsub_client.listen will still be processed in the loop.
        import_pubsub_client.subscribe("__keyspace@0__:Exports")
        # Keep track of the number of imports that we've imported.
        num_imported = 0

        # Get the exports that occurred before the call to subscribe.
        with self.worker.lock:                    
            export_keys = self.redis_client.lrange("Exports", 0, -1)                    
            for key in export_keys:                    
                num_imported += 1                    
                self._process_key(key)                    
        try:
            for msg in import_pubsub_client.listen():                    
                with self.worker.lock:                    
                    if msg["type"] == "subscribe":
                        continue
                    assert msg["data"] == b"rpush"
                    num_imports = self.redis_client.llen("Exports")
                    assert num_imports >= num_imported
                    for i in range(num_imported, num_imports):
                        num_imported += 1                    
                        key = self.redis_client.lindex("Exports", i)
                        self._process_key(key)                    
        except redis.ConnectionError:                    
            # When Redis terminates the listen call will throw a
            # ConnectionError, which we catch here.
            pass                    

    def _process_key(self, key):
        """Process the given export key from redis."""
        # Handle the driver case first.
        if self.mode != ray.WORKER_MODE:
            if key.startswith(b"FunctionsToRun"):
                with profiling.profile(
                        "fetch_and_run_function", worker=self.worker):
                    self.fetch_and_execute_function_to_run(key)
            # Return because FunctionsToRun are the only things that
            # the driver should import.
            return

        if key.startswith(b"RemoteFunction"):
            with profiling.profile(
                    "register_remote_function", worker=self.worker):
                (self.worker.function_actor_manager.
                 fetch_and_register_remote_function(key))
        elif key.startswith(b"FunctionsToRun"):
            with profiling.profile(
                    "fetch_and_run_function", worker=self.worker):
                self.fetch_and_execute_function_to_run(key)
        elif key.startswith(b"ActorClass"):
            # Keep track of the fact that this actor class has been
            # exported so that we know it is safe to turn this worker
            # into an actor of that class.
            self.worker.function_actor_manager.imported_actor_classes.add(key)
        # TODO(rkn): We may need to bring back the case of
        # fetching actor classes here.
        else:
            raise Exception("This code should be unreachable.")

    def fetch_and_execute_function_to_run(self, key):
        """Run on arbitrary function on the worker."""
        (driver_id, serialized_function,
         run_on_other_drivers) = self.redis_client.hmget(
             key, ["driver_id", "function", "run_on_other_drivers"])

        if (utils.decode(run_on_other_drivers) == "False"
                and self.worker.mode == ray.SCRIPT_MODE
                and driver_id != self.worker.task_driver_id.binary()):
            return

        try:
            # Deserialize the function.
            function = pickle.loads(serialized_function)
            # Run the function.
            function({"worker": self.worker})
        except Exception:
            # If an exception was thrown when the function was run, we record
            # the traceback and notify the scheduler of the failure.
            traceback_str = traceback.format_exc()
            # Log the error message.
            utils.push_error_to_driver(
                self.worker,
                ray_constants.FUNCTION_TO_RUN_PUSH_ERROR,
                traceback_str,
                driver_id=ray.DriverID(driver_id))



from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import atexit
import json
import os
import logging
import signal
import threading
import time

import ray
import ray.ray_constants as ray_constants
from ray.tempfile_services import (
    get_logs_dir_path, get_object_store_socket_name, get_raylet_socket_name,
    new_log_monitor_log_file, new_monitor_log_file,
    new_raylet_monitor_log_file, new_plasma_store_log_file,
    new_raylet_log_file, new_webui_log_file, set_temp_root,
    try_to_create_directory)

# Logger for this module. It should be configured at the entry point
# into the program using Ray. Ray configures it by default automatically
# using logging.basicConfig in its entry/init points.
logger = logging.getLogger(__name__)


class Node(object):
    """An encapsulation of the Ray processes on a single node.

    This class is responsible for starting Ray processes and killing them.

    Attributes:
        all_processes (dict): A mapping from process type (str) to a list of
            ProcessInfo objects. All lists have length one except for the Redis
            server list, which has multiple.
    """

    def __init__(self, ray_params, head=False, shutdown_at_exit=True):
        """Start a node.

        Args:
            ray_params (ray.params.RayParams): The parameters to use to
                configure the node.
            head (bool): True if this is the head node, which means it will
                start additional processes like the Redis servers, monitor
                processes, and web UI.
            shutdown_at_exit (bool): If true, a handler will be registered to
                shutdown the processes started here when the Python interpreter
                exits.
        """
        self.all_processes = {}

        ray_params.update_if_absent(
            node_ip_address=ray.services.get_node_ip_address(),
            include_log_monitor=True,
            resources={},
            include_webui=False,
            worker_path=os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "workers/default_worker.py"))

        if head:
            ray_params.update_if_absent(num_redis_shards=1, include_webui=True)
        else:
            redis_client = ray.services.create_redis_client(
                ray_params.redis_address, ray_params.redis_password)
            ray_params.include_java = (
                ray.services.include_java_from_redis(redis_client))

        self._ray_params = ray_params
        self._config = (json.loads(ray_params._internal_config)
                        if ray_params._internal_config else None)
        self._node_ip_address = ray_params.node_ip_address
        self._redis_address = ray_params.redis_address
        self._plasma_store_socket_name = None
        self._raylet_socket_name = None
        self._webui_url = None

        self.start_ray_processes()

        if shutdown_at_exit:
            atexit.register(lambda: self.kill_all_processes(
                check_alive=False, allow_graceful=True))

    @property
    def node_ip_address(self):
        """Get the cluster Redis address."""
        return self._node_ip_address

    @property
    def redis_address(self):
        """Get the cluster Redis address."""
        return self._redis_address

    @property
    def plasma_store_socket_name(self):
        """Get the node's plasma store socket name."""
        return self._plasma_store_socket_name

    @property
    def webui_url(self):
        """Get the cluster's web UI url."""
        return self._webui_url

    @property
    def raylet_socket_name(self):
        """Get the node's raylet socket name."""
        return self._raylet_socket_name

    def prepare_socket_file(self, socket_path):
        """Prepare the socket file for raylet and plasma.

        This method helps to prepare a socket file.
        1. Make the directory if the directory does not exist.
        2. If the socket file exists, raise exception.

        Args:
            socket_path (string): the socket file to prepare.
        """
        if not os.path.exists(socket_path):
            path = os.path.dirname(socket_path)
            if not os.path.isdir(path):
                try_to_create_directory(path)
        else:
            raise Exception("Socket file {} exists!".format(socket_path))

    def start_redis(self):
        """Start the Redis servers."""
        assert self._redis_address is None
        (self._redis_address, redis_shards,
         process_infos) = ray.services.start_redis(
             self._node_ip_address,                    
             port=self._ray_params.redis_port,
             redis_shard_ports=self._ray_params.redis_shard_ports,
             num_redis_shards=self._ray_params.num_redis_shards,
             redis_max_clients=self._ray_params.redis_max_clients,
             redirect_output=self._ray_params.redirect_output,
             redirect_worker_output=self._ray_params.redirect_worker_output,
             password=self._ray_params.redis_password,
             redis_max_memory=self._ray_params.redis_max_memory)
        assert (
            ray_constants.PROCESS_TYPE_REDIS_SERVER not in self.all_processes)
        self.all_processes[ray_constants.PROCESS_TYPE_REDIS_SERVER] = (
            process_infos)

    def start_log_monitor(self):
        """Start the log monitor."""
        stdout_file, stderr_file = new_log_monitor_log_file()
        process_info = ray.services.start_log_monitor(
            self.redis_address,
            self._node_ip_address,                    
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            redis_password=self._ray_params.redis_password)                    
        assert ray_constants.PROCESS_TYPE_LOG_MONITOR not in self.all_processes
        self.all_processes[ray_constants.PROCESS_TYPE_LOG_MONITOR] = [
            process_info
        ]

    def start_ui(self):
        """Start the web UI."""
        stdout_file, stderr_file = new_webui_log_file()
        self._webui_url, process_info = ray.services.start_ui(
            self._redis_address,
            stdout_file=stdout_file,
            stderr_file=stderr_file)
        assert ray_constants.PROCESS_TYPE_WEB_UI not in self.all_processes
        if process_info is not None:
            self.all_processes[ray_constants.PROCESS_TYPE_WEB_UI] = [
                process_info
            ]

    def start_plasma_store(self):
        """Start the plasma store."""
        assert self._plasma_store_socket_name is None
        # If the user specified a socket name, use it.
        self._plasma_store_socket_name = (
            self._ray_params.plasma_store_socket_name
            or get_object_store_socket_name())
        self.prepare_socket_file(self._plasma_store_socket_name)
        stdout_file, stderr_file = (new_plasma_store_log_file(
            self._ray_params.redirect_output))
        process_info = ray.services.start_plasma_store(
            self._node_ip_address,                    
            self._redis_address,
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            object_store_memory=self._ray_params.object_store_memory,
            plasma_directory=self._ray_params.plasma_directory,
            huge_pages=self._ray_params.huge_pages,
            plasma_store_socket_name=self._plasma_store_socket_name,                    
            redis_password=self._ray_params.redis_password)                    
        assert (
            ray_constants.PROCESS_TYPE_PLASMA_STORE not in self.all_processes)
        self.all_processes[ray_constants.PROCESS_TYPE_PLASMA_STORE] = [
            process_info
        ]

    def start_raylet(self, use_valgrind=False, use_profiler=False):
        """Start the raylet.

        Args:
            use_valgrind (bool): True if we should start the process in
                valgrind.
            use_profiler (bool): True if we should start the process in the
                valgrind profiler.
        """
        assert self._raylet_socket_name is None
        # If the user specified a socket name, use it.
        self._raylet_socket_name = (self._ray_params.raylet_socket_name
                                    or get_raylet_socket_name())
        self.prepare_socket_file(self._raylet_socket_name)
        stdout_file, stderr_file = new_raylet_log_file(
            redirect_output=self._ray_params.redirect_worker_output)                    
        process_info = ray.services.start_raylet(
            self._redis_address,
            self._node_ip_address,                    
            self._raylet_socket_name,
            self._plasma_store_socket_name,
            self._ray_params.worker_path,
            self._ray_params.num_cpus,
            self._ray_params.num_gpus,
            self._ray_params.resources,
            self._ray_params.object_manager_port,
            self._ray_params.node_manager_port,
            self._ray_params.redis_password,
            use_valgrind=use_valgrind,
            use_profiler=use_profiler,
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            config=self._config,
            include_java=self._ray_params.include_java,
            java_worker_options=self._ray_params.java_worker_options,
        )
        assert ray_constants.PROCESS_TYPE_RAYLET not in self.all_processes
        self.all_processes[ray_constants.PROCESS_TYPE_RAYLET] = [process_info]

    def start_worker(self):
        """Start a worker process."""
        raise NotImplementedError

    def start_monitor(self):
        """Start the monitor."""
        stdout_file, stderr_file = new_monitor_log_file(
            self._ray_params.redirect_output)
        process_info = ray.services.start_monitor(
            self._redis_address,
            self._node_ip_address,                    
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            autoscaling_config=self._ray_params.autoscaling_config,
            redis_password=self._ray_params.redis_password)                    
        assert ray_constants.PROCESS_TYPE_MONITOR not in self.all_processes
        self.all_processes[ray_constants.PROCESS_TYPE_MONITOR] = [process_info]

    def start_raylet_monitor(self):
        """Start the raylet monitor."""
        stdout_file, stderr_file = new_raylet_monitor_log_file(
            self._ray_params.redirect_output)
        process_info = ray.services.start_raylet_monitor(
            self._redis_address,
            stdout_file=stdout_file,
            stderr_file=stderr_file,
            redis_password=self._ray_params.redis_password,
            config=self._config)
        assert (ray_constants.PROCESS_TYPE_RAYLET_MONITOR not in
                self.all_processes)
        self.all_processes[ray_constants.PROCESS_TYPE_RAYLET_MONITOR] = [
            process_info
        ]

    def start_ray_processes(self):
        """Start all of the processes on the node."""
        set_temp_root(self._ray_params.temp_dir)
        logger.info(
            "Process STDOUT and STDERR is being redirected to {}.".format(
                get_logs_dir_path()))

        # If this is the head node, start the relevant head node processes.
        if self._redis_address is None:
            self.start_redis()
            self.start_monitor()
            self.start_raylet_monitor()

        self.start_plasma_store()
        self.start_raylet()

        if self._ray_params.include_log_monitor:
            self.start_log_monitor()
        if self._ray_params.include_webui:
            self.start_ui()

    def _kill_process_type(self,
                           process_type,
                           allow_graceful=False,
                           check_alive=True,
                           wait=False):
        """Kill a process of a given type.

        If the process type is PROCESS_TYPE_REDIS_SERVER, then we will kill all
        of the Redis servers.

        If the process was started in valgrind, then we will raise an exception
        if the process has a non-zero exit code.

        Args:
            process_type: The type of the process to kill.
            allow_graceful (bool): Send a SIGTERM first and give the process
                time to exit gracefully. If that doesn't work, then use
                SIGKILL. We usually want to do this outside of tests.
            check_alive (bool): If true, then we expect the process to be alive
                and will raise an exception if the process is already dead.
            wait (bool): If true, then this method will not return until the
                process in question has exited.

        Raises:
            This process raises an exception in the following cases:
                1. The process had already died and check_alive is true.
                2. The process had been started in valgrind and had a non-zero
                   exit code.
        """
        process_infos = self.all_processes[process_type]
        if process_type != ray_constants.PROCESS_TYPE_REDIS_SERVER:
            assert len(process_infos) == 1
        for process_info in process_infos:
            process = process_info.process
            # Handle the case where the process has already exited.
            if process.poll() is not None:
                if check_alive:
                    raise Exception("Attempting to kill a process of type "
                                    "'{}', but this process is already dead."
                                    .format(process_type))
                else:
                    continue

            if process_info.use_valgrind:
                process.terminate()
                process.wait()
                if process.returncode != 0:
                    message = ("Valgrind detected some errors in process of "
                               "type {}. Error code {}.".format(
                                   process_type, process.returncode))
                    if process_info.stdout_file is not None:
                        with open(process_info.stdout_file, "r") as f:
                            message += "\nPROCESS STDOUT:\n" + f.read()
                    if process_info.stderr_file is not None:
                        with open(process_info.stderr_file, "r") as f:
                            message += "\nPROCESS STDERR:\n" + f.read()
                    raise Exception(message)
                continue

            if process_info.use_valgrind_profiler:
                # Give process signal to write profiler data.
                os.kill(process.pid, signal.SIGINT)
                # Wait for profiling data to be written.
                time.sleep(0.1)

            if allow_graceful:
                # Allow the process one second to exit gracefully.
                process.terminate()
                timer = threading.Timer(1, lambda process: process.kill(),
                                        [process])
                try:
                    timer.start()
                    process.wait()
                finally:
                    timer.cancel()

                if process.poll() is not None:
                    continue

            # If the process did not exit within one second, force kill it.
            process.kill()
            # The reason we usually don't call process.wait() here is that
            # there's some chance we'd end up waiting a really long time.
            if wait:
                process.wait()

        del self.all_processes[process_type]

    def kill_redis(self, check_alive=True):
        """Kill the Redis servers.

        Args:
            check_alive (bool): Raise an exception if any of the processes
                were already dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_REDIS_SERVER, check_alive=check_alive)

    def kill_plasma_store(self, check_alive=True):
        """Kill the plasma store.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_PLASMA_STORE, check_alive=check_alive)

    def kill_raylet(self, check_alive=True):
        """Kill the raylet.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_RAYLET, check_alive=check_alive)

    def kill_log_monitor(self, check_alive=True):
        """Kill the log monitor.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_LOG_MONITOR, check_alive=check_alive)

    def kill_monitor(self, check_alive=True):
        """Kill the monitor.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_MONITOR, check_alive=check_alive)

    def kill_raylet_monitor(self, check_alive=True):
        """Kill the raylet monitor.

        Args:
            check_alive (bool): Raise an exception if the process was already
                dead.
        """
        self._kill_process_type(
            ray_constants.PROCESS_TYPE_RAYLET_MONITOR, check_alive=check_alive)

    def kill_all_processes(self, check_alive=True, allow_graceful=False):
        """Kill all of the processes.

        Note that This is slower than necessary because it calls kill, wait,
        kill, wait, ... instead of kill, kill, ..., wait, wait, ...

        Args:
            check_alive (bool): Raise an exception if any of the processes were
                already dead.
        """
        # Kill the raylet first. This is important for suppressing errors at
        # shutdown because we give the raylet a chance to exit gracefully and
        # clean up its child worker processes. If we were to kill the plasma
        # store (or Redis) first, that could cause the raylet to exit
        # ungracefully, leading to more verbose output from the workers.
        if ray_constants.PROCESS_TYPE_RAYLET in self.all_processes:
            self._kill_process_type(
                ray_constants.PROCESS_TYPE_RAYLET,
                check_alive=check_alive,
                allow_graceful=allow_graceful)

        # We call "list" to copy the keys because we are modifying the
        # dictionary while iterating over it.
        for process_type in list(self.all_processes.keys()):
            self._kill_process_type(
                process_type,
                check_alive=check_alive,
                allow_graceful=allow_graceful)

    def live_processes(self):
        """Return a list of the live processes.

        Returns:
            A list of the live processes.
        """
        result = []
        for process_type, process_infos in self.all_processes.items():
            for process_info in process_infos:
                if process_info.process.poll() is None:
                    result.append((process_type, process_info.process))
        return result

    def dead_processes(self):
        """Return a list of the dead processes.

        Note that this ignores processes that have been explicitly killed,
        e.g., via a command like node.kill_raylet().

        Returns:
            A list of the dead processes ignoring the ones that have been
                explicitly killed.
        """
        result = []
        for process_type, process_infos in self.all_processes.items():
            for process_info in process_infos:
                if process_info.process.poll() is not None:
                    result.append((process_type, process_info.process))
        return result

    def any_processes_alive(self):
        """Return true if any processes are still alive.

        Returns:
            True if any process is still alive.
        """
        return any(self.live_processes())

    def remaining_processes_alive(self):
        """Return true if all remaining processes are still alive.

        Note that this ignores processes that have been explicitly killed,
        e.g., via a command like node.kill_raylet().

        Returns:
            True if any process that wasn't explicitly killed is still alive.
        """
        return not any(self.dead_processes())

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import logging

import ray.ray_constants as ray_constants


class RayParams(object):
    """A class used to store the parameters used by Ray.

    Attributes:
        redis_address (str): The address of the Redis server to connect to. If
            this address is not provided, then this command will start Redis, a
            global scheduler, a local scheduler, a plasma store, a plasma
            manager, and some workers. It will also kill these processes when
            Python exits.
        redis_port (int): The port that the primary Redis shard should listen
            to. If None, then a random port will be chosen.
        redis_shard_ports: A list of the ports to use for the non-primary Redis
            shards.
        num_cpus (int): Number of CPUs to configure the raylet with.
        num_gpus (int): Number of GPUs to configure the raylet with.
        resources: A dictionary mapping the name of a resource to the quantity
            of that resource available.
        object_store_memory: The amount of memory (in bytes) to start the
            object store with.
        redis_max_memory: The max amount of memory (in bytes) to allow redis
            to use, or None for no limit. Once the limit is exceeded, redis
            will start LRU eviction of entries. This only applies to the
            sharded redis tables (task and object tables).
        object_manager_port int: The port to use for the object manager.
        node_manager_port: The port to use for the node manager.
        node_ip_address (str): The IP address of the node that we are on.
        object_id_seed (int): Used to seed the deterministic generation of
            object IDs. The same value can be used across multiple runs of the
            same job in order to generate the object IDs in a consistent
            manner. However, the same ID should not be used for different jobs.
        local_mode (bool): True if the code should be executed serially
            without Ray. This is useful for debugging.
        redirect_worker_output: True if the stdout and stderr of worker
            processes should be redirected to files.
        redirect_output (bool): True if stdout and stderr for non-worker
            processes should be redirected to files and false otherwise.
        num_redis_shards: The number of Redis shards to start in addition to
            the primary Redis shard.
        redis_max_clients: If provided, attempt to configure Redis with this
            maxclients number.
        redis_password (str): Prevents external clients without the password
            from connecting to Redis if provided.
        plasma_directory: A directory where the Plasma memory mapped files will
            be created.
        worker_path (str): The path of the source code that will be run by the
            worker.
        huge_pages: Boolean flag indicating whether to start the Object
            Store with hugetlbfs support. Requires plasma_directory.
        include_webui: Boolean flag indicating whether to start the web
            UI, which is a Jupyter notebook.
        logging_level: Logging level, default will be logging.INFO.
        logging_format: Logging format, default contains a timestamp,
            filename, line number, and message. See ray_constants.py.
        plasma_store_socket_name (str): If provided, it will specify the socket
            name used by the plasma store.
        raylet_socket_name (str): If provided, it will specify the socket path
            used by the raylet process.
        temp_dir (str): If provided, it will specify the root temporary
            directory for the Ray process.
        include_log_monitor (bool): If True, then start a log monitor to
            monitor the log files for all processes on this node and push their
            contents to Redis.
        autoscaling_config: path to autoscaling config file.
        include_java (bool): If True, the raylet backend can also support
            Java worker.
        java_worker_options (str): The command options for Java worker.
        _internal_config (str): JSON configuration for overriding
            RayConfig defaults. For testing purposes ONLY.
    """

    def __init__(self,
                 redis_address=None,
                 num_cpus=None,
                 num_gpus=None,
                 resources=None,
                 object_store_memory=None,
                 redis_max_memory=None,
                 redis_port=None,
                 redis_shard_ports=None,
                 object_manager_port=None,
                 node_manager_port=None,
                 node_ip_address=None,
                 object_id_seed=None,
                 num_workers=None,
                 local_mode=False,
                 driver_mode=None,
                 redirect_worker_output=False,                    
                 redirect_output=True,
                 num_redis_shards=None,
                 redis_max_clients=None,
                 redis_password=None,
                 plasma_directory=None,
                 worker_path=None,
                 huge_pages=False,
                 include_webui=None,
                 logging_level=logging.INFO,
                 logging_format=ray_constants.LOGGER_FORMAT,
                 plasma_store_socket_name=None,
                 raylet_socket_name=None,
                 temp_dir=None,
                 include_log_monitor=None,
                 autoscaling_config=None,
                 include_java=False,
                 java_worker_options=None,
                 _internal_config=None):
        self.object_id_seed = object_id_seed
        self.redis_address = redis_address
        self.num_cpus = num_cpus
        self.num_gpus = num_gpus
        self.resources = resources
        self.object_store_memory = object_store_memory
        self.redis_max_memory = redis_max_memory
        self.redis_port = redis_port
        self.redis_shard_ports = redis_shard_ports
        self.object_manager_port = object_manager_port
        self.node_manager_port = node_manager_port
        self.node_ip_address = node_ip_address
        self.num_workers = num_workers
        self.local_mode = local_mode
        self.driver_mode = driver_mode
        self.redirect_worker_output = redirect_worker_output
        self.redirect_output = redirect_output
        self.num_redis_shards = num_redis_shards
        self.redis_max_clients = redis_max_clients
        self.redis_password = redis_password
        self.plasma_directory = plasma_directory
        self.worker_path = worker_path
        self.huge_pages = huge_pages
        self.include_webui = include_webui
        self.plasma_store_socket_name = plasma_store_socket_name
        self.raylet_socket_name = raylet_socket_name
        self.temp_dir = temp_dir
        self.include_log_monitor = include_log_monitor
        self.autoscaling_config = autoscaling_config
        self.include_java = include_java
        self.java_worker_options = java_worker_options
        self._internal_config = _internal_config
        self._check_usage()

    def update(self, **kwargs):
        """Update the settings according to the keyword arguments.

        Args:
            kwargs: The keyword arguments to set corresponding fields.
        """
        for arg in kwargs:
            if hasattr(self, arg):
                setattr(self, arg, kwargs[arg])
            else:
                raise ValueError("Invalid RayParams parameter in"
                                 " update: %s" % arg)

        self._check_usage()

    def update_if_absent(self, **kwargs):
        """Update the settings when the target fields are None.

        Args:
            kwargs: The keyword arguments to set corresponding fields.
        """
        for arg in kwargs:
            if hasattr(self, arg):
                if getattr(self, arg) is None:
                    setattr(self, arg, kwargs[arg])
            else:
                raise ValueError("Invalid RayParams parameter in"
                                 " update_if_absent: %s" % arg)

        self._check_usage()

    def _check_usage(self):
        if self.resources is not None:
            assert "CPU" not in self.resources, (
                "'CPU' should not be included in the resource dictionary. Use "
                "num_cpus instead.")
            assert "GPU" not in self.resources, (
                "'GPU' should not be included in the resource dictionary. Use "
                "num_gpus instead.")

        if self.num_workers is not None:
            raise ValueError(
                "The 'num_workers' argument is deprecated. Please use "
                "'num_cpus' instead.")

        if self.include_java is None and self.java_worker_options is not None:
            raise ValueError("Should not specify `java-worker-options` "
                             "without providing `include-java`.")



import os
from flask import Flask, g, url_for                    
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate
from flask_admin import Admin, helpers
from flask_security import Security
from flask_login import LoginManager
from flask_uploads import patch_request_class, configure_uploads
from werkzeug.utils import find_modules, import_string

from config import app_config

from benwaonline.database import db
from benwaonline.oauth import oauth
from benwaonline.admin import setup_adminviews
from benwaonline.models import user_datastore, User
from benwaonline.gallery import gallery                    
from benwaonline.gallery.forms import images                    
from benwaonline.user import user
from benwaonline.auth import auth

FILE_SIZE_LIMIT = 10 * 1024 * 1024

security = Security()
login_manager = LoginManager()

def create_app(config=None):
    app = Flask(__name__)
    app.config.from_object(app_config[config])

    # app.config.update(config or {})
    app.config.from_envvar('BENWAONLINE_SETTINGS', silent=True)
    app.config.from_object('secrets')

    db.init_app(app)
    migrate = Migrate(app, db)
    oauth.init_app(app)

    login_manager.init_app(app)
    @login_manager.user_loader
    def load_user(user_id):
        return User.get(user_id)

    security_ctx = security.init_app(app, user_datastore)
    @security_ctx.context_processor
    def security_context_processor():
        return dict(
            admin_base_template=admin.base_template,
            admin_view=admin.index_view,
            h=helpers,
            get_url=url_for
        )

    admin = Admin(app, name='benwaonline', template_mode='bootstrap3')
    setup_adminviews(admin, db)

    register_blueprints(app)
    register_cli(app)
    register_teardowns(app)

    app.register_blueprint(gallery)
    app.register_blueprint(auth)
    app.register_blueprint(user)

    configure_uploads(app, (images,))
    patch_request_class(app, FILE_SIZE_LIMIT)

    return app

def register_blueprints(app):
    """
    Register all blueprint modules
    Reference: Armin Ronacher, "Flask for Fun and for Profit" PyBay 2016.
    """
    for name in find_modules('benwaonline.blueprints'):
        mod = import_string(name)
        if hasattr(mod, 'bp'):
            app.register_blueprint(mod.bp)

    return None

def register_cli(app):
    @app.cli.command('initdb')
    def initdb_command():
        """Creates the database tables."""
        init_db()
        print('Initialized the database.')

def init_db():
    import benwaonline.models
    db.create_all()

def register_teardowns(app):
    @app.teardown_appcontext
    def close_db(error):
        """Closes the database again at the end of the request."""
        if hasattr(g, 'sqlite_db'):
            g.sqlite_db.close()



from flask import Blueprint, request, session, g, redirect, url_for, \                    
     render_template, flash, current_app                    

bp = Blueprint('benwaonline', __name__)

@bp.route('/')
def under_construction():
    # return redirect(url_for('gallery.show_posts'))
    return redirect(url_for('auth.test'))                    

from os.path import join
from datetime import datetime
from flask import request, redirect, url_for, render_template, flash, g, current_app                    
from werkzeug.utils import secure_filename
from flask_security import login_required, current_user

from benwaonline.database import db
from benwaonline.models import Post, Tag, Comment, Preview, Image
from benwaonline.gallery import gallery
from benwaonline.gallery.forms import CommentForm, PostForm

@gallery.before_request
def before_request():
    g.user = current_user

@gallery.route('/gallery/')
@gallery.route('/gallery/<string:tags>/')
def show_posts(tags='all'):
    if tags == 'all':
        posts = Post.query.all()
    else:
        split = tags.split(' ')
        posts = []
        for s in split:
            results = Post.query.filter(Post.tags.any(name=s))
            posts.extend(results)

    tags = Tag.query.all()

    return render_template('gallery.html', posts=posts, tags=tags)

@gallery.route('/gallery/benwa/')                    
def show_post_redirect():                    
    return redirect(url_for('gallery.show_posts'))                    

@gallery.route('/gallery/benwa/<int:post_id>')
def show_post(post_id):
    post = Post.query.paginate(post_id, 1, False)
    # Look at docs for get_or_404 or w.e
    if post.items:
        return render_template('show.html', post=post, form=CommentForm())

    flash('That Benwa doesn\'t exist yet')
    return redirect(url_for('gallery.show_posts'))                    

# Will need to add Role/Permissions to this later
@gallery.route('/gallery/benwa/add', methods=['GET', 'POST'])
@login_required
def add_post():
    form = PostForm()
    if form.validate_on_submit():
        f = form.image.data
        fname = secure_filename(f.filename)
        f.save(join(
            current_app.static_folder, current_app.config['STATIC_BENWA_DIR'], fname                    
        ))
        fpath = '/'.join(['thumbs', fname])
        created = datetime.utcnow()
        preview = Preview(filepath=fpath, created=created)
        db.session.add(preview)

        fpath = '/'.join(['imgs', fname])
        image = Image(filepath=fpath, created=created, preview=preview)
        db.session.add(image)

        # 'benwa' is the forever the first tag in the database
        tags = [Tag.query.get(1)]
        added_tags = [get_or_create_tag(db.session, tag)[0] for tag in form.tags.data if tag]
        tags.extend(added_tags)

        post = Post(title=fname, created=datetime.utcnow(), image=image, tags=tags)
        db.session.add(post)

        current_user.posts.append(post)
        db.session.commit()

        return redirect(url_for('gallery.show_post', post_id=post.id))

    flash('There was an issue with adding the benwa')
    return render_template('image_upload.html', form=form)

def get_or_create_tag(session, tagname):
    instance = Tag.query.filter_by(name=tagname).first()
    if instance:
        return instance, False
    else:
        created = datetime.utcnow()
        instance = Tag(name=tagname, created=created)
        session.add(instance)

    return instance, True

@gallery.route('/gallery/benwa/<int:post_id>/comment/add', methods=['POST'])
@login_required
def add_comment(post_id):
    form = CommentForm()
    if form.validate_on_submit():
        post = Post.query.get(post_id)
        comment = Comment(content=form.content.data,\
                created=datetime.utcnow(), user=current_user, post=post)
        db.session.add(comment)
        db.session.commit()

    return redirect(url_for('gallery.show_post', post_id=post_id))

@gallery.route('/gallery/benwa/<int:post_id>/comment/delete/<int:comment_id>', methods=['GET',  'POST'])
@login_required
# @roles_accepted('admin', 'member')
def delete_comment(post_id, comment_id):
    comment = Comment.query.get_or_404(comment_id)

    if current_user.has_role('admin') or comment.owner(current_user):
        db.session.delete(comment)
        db.session.commit()
    else:
        flash('you can\'t delete this comment')

    return redirect(url_for('gallery.show_post', post_id=post_id))

import os

BASE = os.path.abspath(os.path.dirname(__file__))

class Config(object):
    BASE_DIR = BASE
    SQLALCHEMY_MIGRATE_REPO = os.path.join(BASE_DIR, 'db_repository')
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    UPLOADED_IMAGES_DEST = '/static/'
    UPLOADED_BENWA_DIR = os.path.join(BASE, 'static', 'tempbenwas')                    

class DevConfig(Config):
    SQLALCHEMY_DATABASE_URI = 'sqlite:///' + os.path.join(BASE, 'db', 'benwaonline.db')
    DEBUG = True
    SECRET_KEY = 'not-so-secret'

class TestConfig(Config):
    SQLALCHEMY_DATABASE_URI = 'sqlite://'
    TESTING = True
    TWITTER_CONSUMER_KEY = 'consume'
    TWITTER_CONSUMER_SECRET = 'secret'
    WTF_CSRF_ENABLED = False
    SECRET_KEY = 'not-so-secret'

class ProdConfig(Config):
    DEBUG = False

app_config = {
    'dev': DevConfig,
    'test': TestConfig,
    'prod': ProdConfig
}

from sqlalchemy import Column, ForeignKey, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy import create_engine

Base = declarative_base()

class User(Base):
    __tablename__ = 'user'                    

    id = Column(Integer, primary_key=True)
    name = Column(String(250), nullable=False)
    email = Column(String(250), nullable=False)
    picture = Column(String(250))

class Grudget(Base):
    __tablename__ = 'Grudget'

    id = Column(Integer, primary_key=True)
    name = Column(String(250), nullable=False)
    user_id = Column(Integer, ForeignKey('user.id'))                    
    user = relationship(User)

    @property
    def serialize(self):
        """Return object data in easily serializeable format"""
        return {
            'name': self.name,
            'id': self.id,
        }


class Grudge(Base):
    __tablename__ = 'Grudge'

    id = Column(Integer, primary_key=True)
    name = Column(String(80), nullable=False)
    description = Column(String(450),nullable=False)
    processed = Column(String(5))                    
    takeaway = Column(String(250))
    grudget_id = Column(Integer, ForeignKey('Grudget.id'))
    grudget = relationship(Grudget)
    user_id = Column(Integer, ForeignKey('user.id'))                    
    user = relationship(User)

    @property
    def serialize(self):
        """Return object data in easily serializeable format"""
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'processed': self.processed,
            'takeaway': self.takeaway,
        }


engine = create_engine('sqlite:///grudgebucketwithusers.db', connect_args={'check_same_thread': False})


Base.metadata.create_all(engine)


"""
Django settings for the GitMate project.

Generated by 'django-admin startproject' using Django 1.9.7.

For more information on this file, see
https://docs.djangoproject.com/en/1.9/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/1.9/ref/settings/
"""

from ast import literal_eval
import os

import djcelery

# Build paths inside the project like this: os.path.join(BASE_DIR, ...)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/1.9/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.environ.get('DJANGO_SECRET_KEY',
                            ('s#x)wcdigpbgi=7nxrbqbd&$yri@2k9bs%v@'
                             '*szo#&)c=qp+3-'))

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = literal_eval(os.environ.get('DJANGO_DEBUG', 'False'))
if DEBUG and not literal_eval(os.environ.get('FORCE_CELERY',
                                             'False')):  # pragma: nocover
    # let celery invoke all tasks locally
    CELERY_ALWAYS_EAGER = True
    # make celery raise exceptions when something fails
    CELERY_EAGER_PROPAGATES_EXCEPTIONS = True

HOOK_DOMAIN = os.environ.get('HOOK_DOMAIN', 'localhost:8000')

# django>=1.11 requires tests to use allowed hosts
ALLOWED_HOSTS = ['testing.com', 'localhost', '127.0.0.1', 'localhost:4200',
                 HOOK_DOMAIN]
ALLOWED_HOSTS += os.environ.get('DJANGO_ALLOWED_HOSTS', '').split()
CORS_ORIGIN_WHITELIST = ALLOWED_HOSTS
CORS_ALLOW_CREDENTIALS = True

GITMATE_PLUGINS = [
    'code_analysis',
    'welcome_commenter',
    'auto_label_pending_or_wip',
    'pr_size_labeller',
    'issue_labeller',
    'bug_spotter',
    'ack',
]

# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'social_django',
    'gitmate_config',
    'djcelery',
    'rest_framework',
    'rest_framework_docs',
    'corsheaders',
    'db_mutex',
    'coala_online',
] + ['gitmate_'+plugin for plugin in GITMATE_PLUGINS]

REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework.authentication.BasicAuthentication',
        'rest_framework.authentication.SessionAuthentication'
    )
}

SOCIAL_AUTH_URL_NAMESPACE = 'auth'

# python-social-auth settings
SOCIAL_AUTH_LOGIN_REDIRECT_URL = os.environ.get('SOCIAL_AUTH_REDIRECT',                    
                                                'http://localhost:4200')                    
SOCIAL_AUTH_LOGIN_URL = '/login'

SOCIAL_AUTH_PIPELINE = (
    # Get the information we can about the user and return it in a simple
    # format to create the user instance later. On some cases the details are
    # already part of the auth response from the provider, but sometimes this
    # could hit a provider API.
    'social.pipeline.social_auth.social_details',

    # Get the social uid from whichever service we're authing thru. The uid is
    # the unique identifier of the given user in the provider.
    'social.pipeline.social_auth.social_uid',

    # Verifies that the current auth process is valid within the current
    # project, this is were emails and domains whitelists are applied (if
    # defined).
    'social.pipeline.social_auth.auth_allowed',

    # Checks if the current social-account is already associated in the site.
    'social.pipeline.social_auth.social_user',

    # Make up a username for this person, appends a random string at the end if
    # there's any collision.
    'social.pipeline.user.get_username',

    # Send a validation email to the user to verify its email address.
    # Disabled by default.
    # 'social.pipeline.mail.mail_validation',

    # Associates the current social details with another user account with
    # a similar email address. Disabled by default.
    'social.pipeline.social_auth.associate_by_email',

    # Create a user account if we haven't found one yet.
    'social.pipeline.user.create_user',

    # Create the record that associated the social account with this user.
    'social.pipeline.social_auth.associate_user',

    # Populate the extra_data field in the social record with the values
    # specified by settings (and the default ones like access_token, etc).
    'social.pipeline.social_auth.load_extra_data',

    # Update the user record with any changed info from the auth service.
    'social.pipeline.user.user_details',
)

# Put gitmate's corresponding OAuth details here.
WEBHOOK_SECRET = os.environ.get('WEBHOOK_SECRET')
SOCIAL_AUTH_GITHUB_KEY = os.environ.get('SOCIAL_AUTH_GITHUB_KEY')
SOCIAL_AUTH_GITHUB_SECRET = os.environ.get('SOCIAL_AUTH_GITHUB_SECRET')
SOCIAL_AUTH_GITHUB_SCOPE = [
    'admin:repo_hook',
    'repo',
]

SOCIAL_AUTH_GITLAB_KEY = os.environ.get(
    'SOCIAL_AUTH_GITLAB_KEY')
SOCIAL_AUTH_GITLAB_SECRET = os.environ.get('SOCIAL_AUTH_GITLAB_SECRET')
# This needs to be specified as is including full domain name and protocol.
# Be extra careful and use the same URL used while registering the application
# on GitLab. ex. example.com/auth/complete/gitlab/
SOCIAL_AUTH_GITLAB_REDIRECT_URL = os.environ.get(
    'SOCIAL_AUTH_GITLAB_REDIRECT_URL')
SOCIAL_AUTH_GITLAB_SCOPE = ['api']

SOCIAL_AUTH_BITBUCKET_KEY = os.environ.get('SOCIAL_AUTH_BITBUCKET_KEY')
SOCIAL_AUTH_BITBUCKET_SECRET = os.environ.get('SOCIAL_AUTH_BITBUCKET_SECRET')

AUTHENTICATION_BACKENDS = (
    'social_core.backends.github.GithubOAuth2',
    'social_core.backends.gitlab.GitLabOAuth2',
    'social_core.backends.bitbucket.BitbucketOAuth',
    'django.contrib.auth.backends.ModelBackend'
)

MIDDLEWARE_CLASSES = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.auth.middleware.SessionAuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
    'gitmate.disable_csrf.DisableCSRF',
]

ROOT_URLCONF = 'gitmate.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.debug',
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'gitmate.wsgi.application'


# Database
# https://docs.djangoproject.com/en/1.9/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql_psycopg2',
        'NAME': os.environ.get('DB_NAME', 'postgres'),
        'USER': os.environ.get('DB_USER', 'postgres'),
        'PASSWORD': os.environ.get('DB_PASSWORD', ''),
        'HOST': os.environ.get('DB_ADDRESS', ''),
        'PORT': os.environ.get('DB_PORT', '')
    }
}


# Password validation
# https://docs.djangoproject.com/en/1.9/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.'
                'UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.'
                'MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.'
                'CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.'
                'NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/1.9/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_L10N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/1.9/howto/static-files/
STATIC_ROOT = os.environ.get('DJANGO_STATIC_ROOT',
                             os.path.join(BASE_DIR, 'static'))
STATIC_URL = '/static/'
STATICFILES_DIRS = ()


# CELERY CONFIG
djcelery.setup_loader()

# RABBITMQ server base URL
BROKER_URL = os.environ.get('CELERY_BROKER_URL',
                            'amqp://admin:password@rabbit/')

# -*- coding: utf-8 -*-
from __future__ import print_function
from __future__ import unicode_literals
from __future__ import division

from django.conf.urls import patterns, url
from apps.home.views import home_page, projects, project, project_clone                    


urlpatterns = patterns(
    '',
    url(r'^$', home_page, name='home_page'),
    url(r'^draw/?$', home_page, name='home_page'),
    url(r'^account/?$', home_page, name='account'),
    url(r'^projects/$', projects, name='projects'),
    url(r'^project/$', project, name='project'),
    url(r'^project/new/', project, name='project'),
    url(r'^project/(?P<proj_id>[0-9]+)/$', project, name='project'),
    url(r'^project/(?P<proj_id>[0-9]+)/clone/?$',
        project_clone, name='project_clone'),
    url(r'^project/(?P<proj_id>[0-9]+)/scenario/(?P<scenario_id>[0-9]+)/$',
        project, name='project'),
    url(r'^project/compare/$', project, name='project'),
    url(r'^project/(?P<proj_id>[0-9]+)/compare/$', project, name='project'),
    url(r'^analyze$', home_page, name='analyze'),
    url(r'^search$', home_page, name='search'),
    url(r'^error', home_page, name='error'),
    url(r'^sign-up', home_page, name='sign_up'),
)

from datetime import datetime, timedelta

from django.conf import settings
from django.shortcuts import redirect
from django.views.generic import View


class LocaleSet(View):

    def get(self, request, *args, **kwargs):
        locale = request.GET.get('locale')
        resp = redirect(request.GET.get('next', request.META.get('HTTP_REFERER', '/')))                    
        if locale in [lc for lc, ll in settings.LANGUAGES]:
            if request.user.is_authenticated():
                request.user.locale = locale
                request.user.save()

            max_age = 10 * 365 * 24 * 60 * 60
            resp.set_cookie(settings.LANGUAGE_COOKIE_NAME, locale, max_age=max_age,
                            expires=(datetime.utcnow() + timedelta(seconds=max_age)).strftime(
                                '%a, %d-%b-%Y %H:%M:%S GMT'),
                            domain=settings.SESSION_COOKIE_DOMAIN)
        return resp

import pytest
from django.shortcuts import reverse                    
from                    



@pytest.mark.django_db
def test_user_not_logged_in(client,create_user):                    
    request = client.get(reverse('elections:vote'))
    assert request.status_code == 302
    assert reverse('login') in request.url

@pytest.mark.django_db
def test_election_not_open(client,create_user):                    
    user = create_user
    client.login(username=user.username, password='defaultpassword')

    request = client.get(reverse('elections:vote'))
    assert "Valget har ikke pnet enda" in request.content.decode('utf-8')                    
    assert '<a class="button" href="/elections/results">' in request.content.decode('utf-8')

    request = client.get(reverse('elections:has_voted'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    
    request = client.get(reverse('elections:voting'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    


@pytest.mark.django_db
def test_election_is_open(client,create_user, create_election_with_positions):                    
    election, positions = create_election_with_positions
    election = Election.objects.create()                    
    client.login(username=user.username, password='defaultpassword')
    request = client.get(reverse('elections:vote'))
    assert reverse('elections:vote') == request.url                    
    assert "Klargjres til valg" in request.content.decode('utf-8')

    request = client.get(reverse('elections:has_voted'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    
    request = client.get(reverse('elections:voting'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    





import pytest
from django.shortcuts import reverse                    
from                    



@pytest.mark.django_db
def test_user_not_logged_in(client,create_user):                    
    request = client.get(reverse('elections:vote'))
    assert request.status_code == 302
    assert reverse('login') in request.url

@pytest.mark.django_db
def test_election_not_open(client,create_user):                    
    user = create_user
    client.login(username=user.username, password='defaultpassword')

    request = client.get(reverse('elections:vote'))
    assert "Valget har ikke pnet enda" in request.content.decode('utf-8')                    
    assert '<a class="button" href="/elections/results">' in request.content.decode('utf-8')

    request = client.get(reverse('elections:has_voted'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    
    request = client.get(reverse('elections:voting'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    


@pytest.mark.django_db
def test_election_is_open(client,create_user, create_election_with_positions):                    
    election, positions = create_election_with_positions
    election = Election.objects.create()                    
    client.login(username=user.username, password='defaultpassword')
    request = client.get(reverse('elections:vote'))
    assert reverse('elections:vote') == request.url                    
    assert "Klargjres til valg" in request.content.decode('utf-8')

    request = client.get(reverse('elections:has_voted'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    
    request = client.get(reverse('elections:voting'))
    assert request.status_code == 302
    assert reverse('elections:vote') == request.url                    





#!/usr/bin/env python3

import os
import sys

import contextlib

import enum
from enum import Enum

def main():
    sh = Shell()
    sh.run()

class Shell:
    '''
    The main shell class.
    '''

    def __init__(self):
        self.builtins = {
            'exit': self._builtin_exit,
            'pwd': self._builtin_pwd,
            'cd': self._builtin_cd
        }

    def run(self):
        '''
        Run the shell.
        '''

        while True:
            try:
                line = self.readline()
                self.execute(line)
            except EOFError:
                sys.exit(0)

    def readline(self):
        '''
        Read a command from stdin to execute.

        Returns:
            A raw string read from stdin.
        '''

        while True:
            raw = input('$ ')
            if len(raw) > 0:
                return raw

    def execute(self, raw):
        '''
        Execute a command in the form of a raw string.
        '''

        tokens = Tokenizer(raw)

        parser = Parser(tokens)
        root = parser.parse()
        if root:
            root.execute(self.builtins)
            root.wait()

    # various shell builtins
    def _builtin_exit(self, name, n=0):
        sys.exit(n)

    def _builtin_pwd(self, name):
        wd = os.getcwd()
        print(wd)

    def _builtin_cd(self, name, d):
        os.chdir(d)

class TokenType(Enum):
    '''
    Token types that are recognized by the Tokenizer.
    '''

    WORD = enum.auto()
    REDIRECT_OUT = enum.auto()
    REDIRECT_APPEND = enum.auto()
    REDIRECT_IN = enum.auto()
    PIPE = enum.auto()
    COMMAND_END = enum.auto()
    EOF = enum.auto()
    UNKNOWN = enum.auto()

class Token:
    '''
    A string with an assigned meaning.

    Args:
        ttype: The token meaning.
        lexeme: The token value (optional).
        position: The location of the token in the stream.
    '''

    def __init__(self, ttype, lexeme=None, position=None):
        self.lexeme = lexeme
        self.ttype = ttype
        self.position = position

class Tokenizer:
    '''
    Performs lexical analysis on a raw string.

    Args:
        string: The raw string on which to operate.
    '''

    def __init__(self, string):
        self.string = string
        self.position = -1
        self.char = None

        self.read()

    def read(self):
        '''
        Read a single char from the stream and store it in self.char.

        Returns:
            The value of self.char.
        '''

        self.position += 1
        if self.position < len(self.string):
            self.char = self.string[self.position]
        else:
            self.char = None
        return self.char

    def token(self):
        '''
        Read a single token from the stream.

        Returns:
            The generated token.

        Throws:
            May throw a ValueError in the case that the input is malformed and
            a token cannot be correctly generated from it.
        '''

        # ignore whitespace
        while self.char and self.char.isspace():
            self.read()

        if self.char == None:
            # end-of-file
            return Token(TokenType.EOF, None, self.position)
        elif self.char == '>':
            start = self.position
            if self.read() == '>':
                self.read()
                return Token(TokenType.REDIRECT_APPEND, None, start)
            else:
                return Token(TokenType.REDIRECT_OUT, None, start)
        elif self.char == '<':
            token = Token(TokenType.REDIRECT_IN, None, self.position)
            self.read()
            return token
        elif self.char == '|':
            token = Token(TokenType.PIPE, None, self.position)
            self.read()
            return token
        elif self.char == ';':
            token = Token(TokenType.COMMAND_END, None, self.position)
            self.read()
            return token
        elif self.char in '\'"':
            # quoted word
            end = self.char
            self.read()

            start = self.position
            value = []
            while self.char and self.char != end:
                value.append(self.char)
                self.read()
            if self.char is None:
                raise ValueError('unexpected end of line while reading quoted word')
            else:
                self.read()

            return Token(TokenType.WORD, ''.join(value), start)
        elif self.char.isprintable():
            # single word
            start = self.position
            value = []
            while self.char and self.char.isprintable() and not self.char.isspace():
                value.append(self.char)
                self.read()

            return Token(TokenType.WORD, ''.join(value), start)
        else:
            # unknown
            token = Token(TokenType.UNKNOWN, self.char, self.position)
            self.read()
            return token

    def __iter__(self):
        '''
        Utility iterator to allow easy creation of a stream of tokens.
        '''

        while True:
            token = self.token()
            yield token

            if token.ttype == TokenType.EOF: break

class Parser:
    '''
    Parses a stream of tokens into an Abstract Syntax Tree for later execution.

    Args:
        tokens: The stream of tokens.
    '''

    def __init__(self, tokens):
        self.tokens = iter(tokens)
        self.token = None
        self.last = None

        self.next()

    def parse(self):
        '''
        Parse the stream of tokens.

        Returns:
            The root node of the Abstract Syntax Tree.

        Throws:
            May throw a ValueError in the case that the stream of tokens is
            malformed.
        '''

        root = self.commands()
        self.expect(TokenType.EOF)

        return root

    def commands(self):
        base = self.command()
        if self.accept(TokenType.COMMAND_END):
            other = self.commands()
            if base and other:
                return DoubleNode(base, other)
            else:
                return other
        else:
            return base

    def command(self):
        if self.accept(TokenType.WORD):
            command = self.last.lexeme

            args = []
            while self.accept(TokenType.WORD):
                args.append(self.last.lexeme)

            node = CommandNode(command, args)

            redirs = self.redirections()
            if redirs:
                node = RedirectionsNode(node, redirs)

            if self.accept(TokenType.PIPE):
                return PipeNode(node, self.command())
            else:
                return node
        else:
            return None

    def redirections(self):
        redirs = []
        redir = self.redirection()
        while redir:
            redirs.append(redir)
            redir = self.redirection()

        if len(redirs) > 0:
            return RedirectionsHelper(redirs)
        else:
            return None

    def redirection(self):
        # TODO: recognize other types of redirections
        if self.accept(TokenType.REDIRECT_OUT):
            filename = self.expect(TokenType.WORD).lexeme
            return RedirectionHelper(1, (filename, os.O_CREAT | os.O_WRONLY | os.O_TRUNC))
        elif self.accept(TokenType.REDIRECT_APPEND):
            filename = self.expect(TokenType.WORD).lexeme
            return RedirectionHelper(1, (filename, os.O_CREAT | os.O_WRONLY | os.O_APPEND))
        elif self.accept(TokenType.REDIRECT_IN):
            filename = self.expect(TokenType.WORD).lexeme
            return RedirectionHelper(0, (filename, os.O_RDONLY))
        else:
            return None

    def next(self):
        self.last = self.token
        self.token = next(self.tokens, None)
        return self.token

    def accept(self, ttype):
        if self.token and self.token.ttype == ttype:
            self.next()
            return self.last
        else:
            return None

    def expect(self, ttype):
        result = self.accept(ttype)
        if result:
            return result
        else:
            raise ValueError(f'expected token to be {ttype}, instead got {self.token.ttype}')

class Node:
    '''
    A single node in the Abstract Syntax Tree.
    '''

    def execute(self, builtins):
        '''
        Execute the node.

        Args:
            builtins: A dict of builtin commands.
        '''

        pass

    def wait(self):
        '''
        Wait for the execution of the node to finish.
        '''

        pass

class DoubleNode(Node):
    '''
    A node that executes two nodes sequentially.

    Args:
        first: The first node to execute.
        second: The second node to execute.
    '''

    def __init__(self, first, second):
        self.first = first
        self.second = second

    def execute(self, *args):
        self.first.execute(*args)
        self.first.wait()

        self.second.execute(*args)
        self.second.wait()

class PipeNode(DoubleNode):
    '''
    A node that forwards the output of one node to the input of another.

    Args:
        first: The node to pipe the output from.
        second: The node to pipe the input into.
    '''

    def __init__(self, first, second):
        self.first = first
        self.second = second

    def execute(self, builtins):
        read, write = os.pipe()
        inp = RedirectionHelper(0, read)
        outp = RedirectionHelper(1, write)

        # TODO: close inp in child process
        with outp:
            self.first.execute(builtins)
        outp.close()

        with inp:
            self.second.execute(builtins)

    def wait(self):
        self.first.wait()
        self.second.wait()

class CommandNode(Node):
    '''
    A node that contains a single shell command.

    Args:
        command: The name of the executable to run (will be looked up in PATH).
        args: The arguments to be passed to the executable.
    '''

    def __init__(self, command, args):
        self.command = command

        self.args = args
        self.args.insert(0, command)

        self.pid = None

    def execute(self, builtins):
        if self.command in builtins:
            builtins[self.command](*self.args)
        else:
            pid = os.fork()
            if pid == 0:
                # child process
                os.execv(self.full_command, self.args)
            else:
                # parent process
                self.pid = pid

    def wait(self):
        if self.pid:
            os.waitpid(self.pid, 0)

    @property
    def full_command(self):
        if os.path.exists(self.command):
            return self.command

        path = os.environ['PATH'].split(':')
        for di in path:
            cmd = os.path.join(di, self.command)
            if os.path.exists(cmd):
                return cmd

        raise FileNotFoundError('command not found')

class RedirectionsNode(Node):
    '''
    A node that performs a number of IO redirections.

    Args:
        base: The base node to operate on.
        redirections: The redirections to apply.
    '''

    def __init__(self, base, redirections):
        self.base = base
        self.redirections = redirections

    def execute(self, builtins):
        with self.redirections:
            self.base.execute(builtins)

    def wait(self):
        self.base.wait()

class RedirectionHelper:
    '''
    Helps perform a single file redirection.

    Args:
        fd: The file descriptor to modify.
        newfd: The new file descriptor.
    '''

    def __init__(self, fd, newfd):
        self.fd = fd
        self.backup = os.dup(fd)

        try:
            filename, mode = newfd                    
            self.newfd = os.open(filename, mode)                    
        except TypeError:
            self.newfd = newfd

    def close(self):
        os.close(self.newfd)

    def __enter__(self):
        os.dup2(self.newfd, self.fd)

    def __exit__(self, type, value, traceback):
        os.dup2(self.backup, self.fd)

class RedirectionsHelper:
    '''
    Helps perform multiple file redirections.

    Args:
        redirections: A list of redirections.
    '''

    def __init__(self, redirections):
        self.redirections = redirections

        self.stack = None

    def __enter__(self):
        if len(self.redirections) > 0:
            self.stack = contextlib.ExitStack()
            for redirection in self.redirections:
                self.stack.enter_context(redirection)

    def __exit__(self, type, value, traceback):
        if self.stack:
            self.stack.close()
            self.stack = None

if __name__ == "__main__":
    main()

import sys
import os
import contextlib

def IO_redirection(cmd):
    """
    Redirect input/output based characters < > >> in the command.
    < will be redirecting input, > will be output and >> is output append
    """
    #check for input redirection first
    if("<" in cmd):
        SetUpInputRedirect(cmd)                    

    if(">" in cmd):
        SetUpOutputRedirect(cmd)                    

    if(">>" in cmd):
        SetUpAppendRedirect(cmd)                    

def SetUpInputRedirect(cmd):                    
    import pdb; pdb.set_trace()                    
    pass                    

def SetUpOutputRedirect(cmd):                    
    i = cmd.index(">")                    
    sys.stdout = open(cmd[i + 1], "w")                    
    del cmd[i + 1]                    
    del cmd[i]                    
    print("this is a test")                    

def SetUpAppendRedirect(cmd):                    
    import pdb; pdb.set_trace()                    
    pass                    

from django.contrib import admin
from dashboard.models import *
from django.db.models import Count

from django import forms
from taggit_labels.widgets import LabelWidget
from dashboard.signals import *

class PUCAdminForm(forms.ModelForm):
    class Meta:
        model = PUC
        fields = ['gen_cat', 'prod_fam', 'prod_type', 'description','tags',]                    
        readonly_fields = ('num_products',)
        widgets = {
            'tags': LabelWidget(model=PUCTag),
        }

class PUCAdmin(admin.ModelAdmin):
    list_display = ('__str__', 'tag_list','num_products')
    form = PUCAdminForm
    def get_changeform_initial_data(self, request):
        get_data = super(PUCAdmin, self).get_changeform_initial_data(request)
        get_data['last_edited_by'] = request.user.pk
        return get_data
    def get_queryset(self, request):
        return super(PUCAdmin, self).get_queryset(request).prefetch_related('tags').annotate(num_products=Count('products'))
    def num_products(self, obj):
        return obj.num_products
    num_products.short_description = 'Product Count'
    num_products.admin_order_field = 'num_products'
    def tag_list(self, obj):
        return u", ".join(o.name for o in obj.tags.all())

class HHDocAdmin(admin.ModelAdmin):
    list_display = ('__str__', 'hhe_report_number')

class PUCToTagAdmin(admin.ModelAdmin):
    list_display = ('content_object', 'tag', 'assumed')
    list_filter = ('tag',)
    def tag(self, obj):
        return obj.tag    
    def assumed(self, obj):
        return obj.assumed 

# Register your models here.
admin.site.register(DataSource)
admin.site.register(GroupType)
admin.site.register(DataGroup)
admin.site.register(DocumentType)
admin.site.register(DataDocument)
admin.site.register(Script)                    
admin.site.register(Product)
admin.site.register(ProductToPUC)
admin.site.register(ProductDocument)
admin.site.register(SourceCategory)
admin.site.register(PUC, PUCAdmin)
admin.site.register(ExtractedText)
admin.site.register(ExtractedChemical)
admin.site.register(ExtractedFunctionalUse)
admin.site.register(ExtractedHabitsAndPractices)
admin.site.register(DSSToxLookup)
admin.site.register(QAGroup)
admin.site.register(UnitType)
admin.site.register(WeightFractionType)
admin.site.register(PUCTag) #,ProductTagAdmin
admin.site.register(Taxonomy)
admin.site.register(TaxonomySource)
admin.site.register(TaxonomyToPUC)
admin.site.register(ExtractedHHDoc, HHDocAdmin)
admin.site.register(ExtractedHHRec)
admin.site.register(PUCToTag, PUCToTagAdmin)

from django.contrib import admin
from dashboard.models import *
from django.db.models import Count

from django import forms
from taggit_labels.widgets import LabelWidget
from dashboard.signals import *

class PUCAdminForm(forms.ModelForm):
    class Meta:
        model = PUC
        fields = ['gen_cat', 'prod_fam', 'prod_type', 'description','tags',]                    
        readonly_fields = ('num_products',)
        widgets = {
            'tags': LabelWidget(model=PUCTag),
        }

class PUCAdmin(admin.ModelAdmin):
    list_display = ('__str__', 'tag_list','num_products')
    form = PUCAdminForm
    def get_changeform_initial_data(self, request):
        get_data = super(PUCAdmin, self).get_changeform_initial_data(request)
        get_data['last_edited_by'] = request.user.pk
        return get_data
    def get_queryset(self, request):
        return super(PUCAdmin, self).get_queryset(request).prefetch_related('tags').annotate(num_products=Count('products'))
    def num_products(self, obj):
        return obj.num_products
    num_products.short_description = 'Product Count'
    num_products.admin_order_field = 'num_products'
    def tag_list(self, obj):
        return u", ".join(o.name for o in obj.tags.all())

class HHDocAdmin(admin.ModelAdmin):
    list_display = ('__str__', 'hhe_report_number')

class PUCToTagAdmin(admin.ModelAdmin):
    list_display = ('content_object', 'tag', 'assumed')
    list_filter = ('tag',)
    def tag(self, obj):
        return obj.tag    
    def assumed(self, obj):
        return obj.assumed 

# Register your models here.
admin.site.register(DataSource)
admin.site.register(GroupType)
admin.site.register(DataGroup)
admin.site.register(DocumentType)
admin.site.register(DataDocument)
admin.site.register(Script)                    
admin.site.register(Product)
admin.site.register(ProductToPUC)
admin.site.register(ProductDocument)
admin.site.register(SourceCategory)
admin.site.register(PUC, PUCAdmin)
admin.site.register(ExtractedText)
admin.site.register(ExtractedChemical)
admin.site.register(ExtractedFunctionalUse)
admin.site.register(ExtractedHabitsAndPractices)
admin.site.register(DSSToxLookup)
admin.site.register(QAGroup)
admin.site.register(UnitType)
admin.site.register(WeightFractionType)
admin.site.register(PUCTag) #,ProductTagAdmin
admin.site.register(Taxonomy)
admin.site.register(TaxonomySource)
admin.site.register(TaxonomyToPUC)
admin.site.register(ExtractedHHDoc, HHDocAdmin)
admin.site.register(ExtractedHHRec)
admin.site.register(PUCToTag, PUCToTagAdmin)


from lxml import html

from django.test import TestCase
from dashboard.tests.loader import load_model_objects, fixtures_standard
from django.contrib.staticfiles.testing import StaticLiveServerTestCase

from dashboard.models import *
from selenium import webdriver
from django.conf import settings
from selenium.webdriver.support.select import Select
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as ec


def log_karyn_in(object):
    '''
    Log user in for further testing.
    '''
    object.browser.get(object.live_server_url + '/login/')
    body = object.browser.find_element_by_tag_name('body')
    object.assertIn('Please sign in', body.text)
    username_input = object.browser.find_element_by_name("username")
    username_input.send_keys('Karyn')
    password_input = object.browser.find_element_by_name("password")
    password_input.send_keys('specialP@55word')
    object.browser.find_element_by_class_name('btn').click()


class TestEditsWithSeedData(StaticLiveServerTestCase):
    fixtures = fixtures_standard

    def setUp(self):
        if settings.TEST_BROWSER == 'firefox':
            self.browser = webdriver.Firefox()
        else:
            self.browser = webdriver.Chrome()
        log_karyn_in(self)

    def tearDown(self):
        self.browser.quit()

    def test_break_curation(self):
        '''
        Changing the raw_cas or raw_chemname on a RawChem record with a related DssToxLookup should cause
        the relationship to be deleted.
        '''
        # currently uses a single data document
        ets_with_curation = ExtractedText.objects.filter(
            rawchem__dsstox__isnull=False).filter(pk=245401)
        for et in ets_with_curation:
            doc_qa_link = f'/qa/extractedtext/%s/' % et.data_document_id
            self.browser.get(self.live_server_url + doc_qa_link)

            rc_id = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-rawchem_ptr"]').get_attribute('value')
            true_cas = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-true_cas"]').get_attribute('value')
            rc = RawChem.objects.get(pk=rc_id)
            self.assertEqual(true_cas, rc.dsstox.true_cas,
                             'The displayed True CAS should match the object attribute')
            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()
            raw_cas_input = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-raw_cas"]')
            raw_cas_input.send_keys('changed cas')
            self.browser.find_element_by_xpath('//*[@id="save"]').click()
            rc = RawChem.objects.get(pk=rc_id)   # reload the rawchem record
            self.assertEqual(
                None, rc.dsstox, 'The same rawchem record should now have nothing in its dsstox link')

    def test_new_chem(self):
        '''
        Adding a new ExtractedChemical without a unit type should return a validation error
        '''
        # currently "loops" over just a single data document. Other cases can be added
        ets_with_curation = ExtractedText.objects.filter(
            rawchem__dsstox__isnull=False).filter(pk=245401)
        for et in ets_with_curation:
            doc_qa_link = f'/qa/extractedtext/%s/' % et.data_document_id
            self.browser.get(self.live_server_url + doc_qa_link)

            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()
            # wait for the Save button to be clickable
            wait = WebDriverWait(self.browser, 10)
            save_button = wait.until(
                ec.element_to_be_clickable((By.XPATH, "//*[@id='save']")))
            # edit the Raw CAS field
            raw_cas_input = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]')
            raw_cas_input.send_keys('test raw cas')
            # Save the edits
            save_button.send_keys("\n")
            # Check for the error message after clicking Save
            wait.until(ec.visibility_of(self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]/parent::*')))
            parent_div = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]/parent::*')
            card_div = parent_div.find_element_by_xpath(
                '../..')
            self.assertTrue("errorlist" in card_div.get_attribute("innerHTML"))

            # Try editing a new record correctly
            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()
            # wait for the Save button to be clickable
            wait = WebDriverWait(self.browser, 10)
            save_button = wait.until(
                ec.element_to_be_clickable((By.XPATH, "//*[@id='save']")))
            raw_cas_input = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]')
            raw_cas_input.send_keys('test raw cas')
            # The unit_type field is the only required one
            unit_type_select = Select(self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-unit_type"]'))
            unit_type_select.select_by_index(1)

            save_button.send_keys("\n")
            # Check for the absence of an error message after clicking Save
            parent_div = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]/parent::*')
            card_div = parent_div.find_element_by_xpath(
                '../..')
            self.assertFalse(
                "errorlist" in card_div.get_attribute("innerHTML"))

    def test_redirects(self):
        '''
        Editing the data document type should return the user to the page on which the edits were made
        '''
        for doc_id in [7]:
            # QA Page
            doc_qa_link = f'/qa/extractedtext/%s/' % doc_id
            self.browser.get(self.live_server_url + doc_qa_link)
            doc_type_select = Select(self.browser.find_element_by_xpath(
                '//*[@id="id_document_type"]'))
            option = doc_type_select.first_selected_option
            doc_type_select.select_by_visible_text("ingredient disclosure")
            self.assertIn(doc_qa_link, self.browser.current_url)

            # Data Document Detail Page
            doc_detail_link = f'/datadocument/%s/' % doc_id
            self.browser.get(self.live_server_url + doc_detail_link)
            doc_type_select = Select(self.browser.find_element_by_xpath(
                '//*[@id="id_document_type"]'))
            doc_type_select.select_by_visible_text("MSDS")
            self.assertIn(doc_detail_link, self.browser.current_url)

    def test_qa_approval(self):
        '''
        Test the QA process in the browser
        1. Open the QA page for an ExtractedText record                    
        2. Edit one of the child records
        3. Attempt to approve the document without a QA note
        4. Add a note
        5. Approve                     
        '''
        for doc_id in [7,      # Composition
                       5,      # Functional Use
                       254781,  # Chemical Presence List
                       354783,  # HHE Report
                       ]:
            # QA Page
            qa_url = self.live_server_url + f'/qa/extractedtext/{doc_id}/'
            self.browser.get(qa_url)
            # Activate the edit mode
            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()

            # Modify the first raw_chem_name field's value
            #
            raw_chem = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-raw_chem_name"]')
            # Wait for the field to be editable
            wait = WebDriverWait(self.browser, 10)
            raw_chem_name_field = wait.until(ec.element_to_be_clickable(
                (By.XPATH, "//*[@id='id_rawchem-0-raw_chem_name']")))

            old_raw_chem_name = raw_chem_name_field.get_attribute('value')

            # Get the detailed child record's ID
            rawchem_id_field = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-rawchem_ptr"]')
            rawchem_id = rawchem_id_field.get_attribute('value')
            # print(rawchem_id)

            raw_chem_name_field.send_keys(' edited')
            # save changes
            self.browser.find_element_by_xpath('//*[@id="save"]').click()

            # Confirm the changes in the ORM
            rc = RawChem.objects.get(pk=rawchem_id)
            self.assertEqual(rc.raw_chem_name, f'%s edited' %
                             old_raw_chem_name, 'The raw_chem_name field should have changed')

            et = ExtractedText.objects.get(pk=doc_id)
            # print(et.data_document.data_group.group_type)
            self.assertTrue(
                et.qa_edited, 'The qa_edited attribute should be True')

            # Click Approve without any notes and confirm validation failure
            self.browser.find_element_by_xpath('//*[@id="approve"]').click()
            # The QA notes field should be invalid
            qa_notes_field = self.browser.find_element_by_xpath(
                '//*[@id="id_qa_notes"]')
            self.assertIn('is-invalid', qa_notes_field.get_attribute('class'))
            et.refresh_from_db()
            self.assertFalse(
                et.qa_checked, 'The qa_checked attribute should be False')

            # Add the mandatory QA note
            qa_notes_field.send_keys('Some QA Notes')
            # Click "Approve" again
            self.browser.find_element_by_xpath('//*[@id="approve"]').click()
            et.refresh_from_db()
            self.assertTrue(
                et.qa_checked, 'The qa_checked attribute should be True')

    def test_datadoc_add_extracted(self):
        '''
        Test that when a datadocument has no ExtractedText,
        the user can add one in the browser
        1.                     
        '''

        for doc_id in [155324   # CO record with no ExtractedText
                       ]:
            # QA Page
            dd_url = self.live_server_url + f'/datadocument/{doc_id}/'
            self.browser.get(dd_url)
            # Activate the edit mode
            self.browser.find_element_by_xpath(
                '//*[@id="btn-add-or-edit-extracted-text"]').click()

            # Verify that the modal window appears by finding the Cancel button
            # The modal window does not immediately appear, so the browser
            # should wait for the button to be clickable
            wait = WebDriverWait(self.browser, 10)
            cancel_button = wait.until(
                ec.element_to_be_clickable(
                    (By.XPATH, "//*[@id='extracted-text-modal-cancel']")
                )
            )
            self.assertEqual("Cancel", cancel_button.text,
                             'The Cancel button should say Cancel')
            cancel_button.click()
            # Verify that no ExtractedText record was created
            self.assertEqual(0, ExtractedText.objects.filter(
                data_document_id=doc_id).count(),
                "the count of ExtractedText records related to the \
                data document should be zero")

            # Wait for the modal div to disappear
            edit_modal = wait.until(
                ec.invisibility_of_element(
                    (By.XPATH, '//*[@id="extextModal"]')
                )
            )
            # Click the Add button again to reopen the editor
            add_button = self.browser.find_element_by_xpath(
                '//*[@id="btn-add-or-edit-extracted-text"]')
            add_button.click()
            # Once again, check that the controls on the modal form are clickable
            # before trying to interact with them
            cancel_button = wait.until(
                ec.element_to_be_clickable(
                    (By.XPATH, "//*[@id='extracted-text-modal-cancel']")
                )
            )
            prod_name_box = self.browser.find_element_by_id(
                'id_prod_name')
            # Add a prod_name value to the box
            prod_name_box.send_keys('Fake Product')
            save_button = self.browser.find_element_by_id(
                'extracted-text-modal-save')
            save_button.click()
            # Confirm the presence of the new ExtractedText record
            et = ExtractedText.objects.get(data_document_id=doc_id)
            self.assertEqual('Fake Product', et.prod_name,
                             "The prod_name of the new object should match what was entered")
            

import csv
import logging
import datetime

from django import forms
from django.db import connection
from django.urls import reverse
from django.http import HttpResponse, HttpResponseRedirect
from django.contrib import messages
from django.shortcuts import render
from django.db.models import Count, Q, Value, IntegerField, Subquery, OuterRef, F, Sum
from django.forms.models import model_to_dict

from dashboard.models import *
from dashboard.forms import HabitsPUCForm


def get_data(request, template_name='get_data/get_data.html'):
    hnp = None
    form = HabitsPUCForm()
    context = { 'hnp' : hnp,
                'form': form,
                'first': None,
                }
    if request.method == 'POST':
        form = HabitsPUCForm(request.POST)
        if form.is_valid():
            puc = PUC.objects.get(pk=form['puc'].value())
            pucs = puc.get_the_kids()
            link_table = ExtractedHabitsAndPracticesToPUC
            links = link_table.objects.filter(PUC__in=pucs).values_list(
                                            'extracted_habits_and_practices',
                                            flat=True)
            hnp = ExtractedHabitsAndPractices.objects.filter(pk__in=links)
            context['form'] = form
            context['hnp'] = hnp if len(hnp)>0 else 0
            if len(hnp)>0:
                context['first'] = hnp[0].pk
    return render(request, template_name, context)                    


def stats_by_dtxsids(dtxs):
    """
    PUCS.n
    The number of unique PUCs (product categories) the chemical is associated with
    datadocs.n
    "The number of data documents (e.g.  MSDS, SDS, ingredient list, product label)
    the chemical is appears in"
    datadocs_w_wf.n
    "The number of data documents with associated weight fraction data
    that the chemical appears in (weight fraction data may be reported or predicted data,
     i.e., predicted from an ingredient list)"
    products.n
    "The number of products the chemical appears in, where a product is defined as a
    product entry in Factotum."
    """
    # print('List of DTXSIDs provided:')
    # print(dtxs)


    # The number of unique PUCs (product categories) the chemical is associated with
    pucs_n = DSSToxLookup.objects.filter(sid__in=dtxs).\
        annotate(pucs_n=Count('curated_chemical__extracted_text__data_document__product__puc')).\
        values('sid','pucs_n').order_by()

    # "The number of data documents (e.g.  MSDS, SDS, ingredient list, product label)
    # the chemical appears in
    dds_n = RawChem.objects.filter(dsstox__sid__in=dtxs).values('dsstox__sid').\
        annotate(sid=F('dsstox__sid'), dds_n=Count('extracted_text__data_document')).\
        values('sid','dds_n').order_by()

    #print('dds_n:')
    #print(dds_n)

    # The number of data documents with associated weight fraction data
    # that the chemical appears in (weight fraction data may be reported or predicted data,
    # i.e., predicted from an ingredient list)
    # This query only applies to ExtractedChemical objects, so the RawChem model can be bypassed
    wf_ecs = ExtractedChemical.objects.filter(dsstox__sid__in=dtxs).filter(
                Q(raw_max_comp__isnull=False) |
                Q(raw_min_comp__isnull=False) |
                Q(raw_central_comp__isnull=False)
            )
    dds_wf_n = DSSToxLookup.objects.filter(sid__in=dtxs).filter(curated_chemical__in=wf_ecs).\
        annotate(dds_wf_n=Count('curated_chemical__extracted_text_id', distinct=True)).\
        order_by().values('sid','dds_wf_n')






    # The number of products the chemical appears in, where a product is defined as a
    # product entry in Factotum.
    products_n = RawChem.objects.filter(dsstox__sid__in=dtxs).values('dsstox__sid').\
       annotate(products_n=Count('extracted_text__data_document__product')).\
       annotate(sid=F('dsstox__sid')).values('sid', 'products_n')

    # build a list of stats, starting with the pucs_n object
    stats = pucs_n\
    .annotate(dds_n=Value(-1, output_field=IntegerField())) \
    .annotate(dds_wf_n=Value(-1, output_field=IntegerField())) \
    .annotate(products_n=Value(-1, output_field=IntegerField())) 

    for row in stats:
        row['dds_n'] = int(dds_n.get(sid=row['sid'])['dds_n'] or 0)

        if not dds_wf_n.filter(sid=row['sid']):
            row['dds_wf_n'] = 0
        else:
            row['dds_wf_n'] = int(dds_wf_n.get(sid=row['sid'])['dds_wf_n'] or 0)
            
        row['products_n'] = int(products_n.get(sid=row['sid'])['products_n'] or 0)
        
    return stats

def download_chem_stats(stats):
    response = HttpResponse(content_type='text/csv')                    
    response['Content-Disposition'] = 'attachment; filename="chem_summary_metrics_%s.csv"' % (datetime.datetime.now().strftime("%Y%m%d"))

    writer = csv.writer(response)                    
    writer.writerow(['DTXSID',  'pucs_n', 'dds_n', 'dds_wf_n', 'products_n'])
    for stat in stats:
        writer.writerow([stat['sid'], stat['pucs_n'], stat['dds_n'], stat['dds_wf_n'], stat['products_n']])

    return response                    

def get_data_dsstox_csv_template(request):
    response = HttpResponse(content_type='text/csv')                    
    response['Content-Disposition'] = 'attachment; filename="dsstox_lookup_template.csv"'
    writer = csv.writer(response)                    
    writer.writerow(['DTXSID'])
    return response                    


def upload_dtxsid_csv(request):
    data = {}
    if "GET" == request.method:
        return render(request, "get_data/get_data.html", data)                    
    # if not GET, then proceed
    try:
        csv_file = request.FILES["csv_file"]
        if not csv_file.name.endswith('.csv'):
            messages.error(request,'File is not CSV type')
            return HttpResponseRedirect(reverse("upload_dtxsid_csv"))
        #if file is too large, return
        if csv_file.multiple_chunks():
            messages.error(request,"Uploaded file is too big (%.2f MB)." % (csv_file.size/(1000*1000),))
            return HttpResponseRedirect(reverse("upload_dtxsid_csv"))

        file_data = csv_file.read().decode("utf-8")

        lines = file_data.split("\n")
        #loop over the lines
        dtxsids = []
        for line in lines:
            #print(line)
            if DSSToxLookup.objects.filter(sid=str.strip(line)).count() > 0:
                dtxsids.append(str.strip(line)) # only add DTXSIDs that appear in the database

    except Exception as e:
        logging.getLogger("error_logger").error("Unable to upload file. "+repr(e))
        messages.error(request,"Unable to upload file. "+repr(e))

    stats = stats_by_dtxsids(dtxsids)
    #stats  = {'pucs_n': 0, 'dds_n': 0, 'dds_wf_n': 0, 'products_n': 0}
    resp = download_chem_stats(stats)
    #print(resp)
    return resp                    

def download_raw_chems(stats):                    
    response = HttpResponse(content_type='text/csv')                    
    response['Content-Disposition'] = 'attachment; filename="uncurated_chemicals_%s.csv"' % (datetime.datetime.now().strftime("%Y%m%d"))                    

    writer = csv.writer(response)                    
    writer.writerow(['data_group_id', 'dashboard_rawchem_id', 'raw_cas', 'raw_chem_name', 'rid'])                    
    for rawchem in RawChem.objects.filter(dsstox_id=None):                    
        writer.writerow([rawchem.extracted_text.data_document.data_group.id, rawchem.id, rawchem.raw_cas, rawchem.raw_chem_name, rawchem.rid if rawchem.rid else '' ])                    

    return response                    

from urllib import parse

from django.urls import resolve
from django.utils import timezone, safestring
from django.shortcuts import redirect
from django.db.models import Count, Q
from django.shortcuts import render, get_object_or_404
from django.contrib.auth.decorators import login_required
from django.forms import ModelForm
from dashboard.models import *
from dashboard.forms import (ProductPUCForm, ProductLinkForm, 
                            BulkProductPUCForm, BulkProductTagForm, 
                            BulkPUCForm, ProductForm)

from taggit.forms import TagField
from taggit_labels.widgets import LabelWidget
from django.core.paginator import Paginator
from django.db.models import Max

class FilteredLabelWidget(LabelWidget):
    # overriding django-taggit-label function to display subset of tags
    def tag_list(self, tags):
        # must set form_instance in form __init__()
        puc = self.form_instance.instance.get_uber_puc() or None
        qs = self.model.objects.filter(content_object=puc,assumed=False)
        filtered = [unassumed.tag for unassumed in qs]
        return [(tag.name, 'selected taggit-tag' if tag.name in tags else 'taggit-tag')
                for tag in filtered]

class ProductTagForm(ModelForm):
    tags = TagField(required=False, widget=FilteredLabelWidget(model=PUCToTag))
    class Meta:
        model = Product
        fields = ['tags']
    def __init__(self, *args, **kwargs):
        super(ProductTagForm, self).__init__(*args, **kwargs)
        self.fields['tags'].widget.form_instance = self


@login_required()
def product_curation_index(request, template_name='product_curation/product_curation_index.html'):
    # List of all data sources which have had at least 1 data
    # document matched to a registered record
    data_sources = DataSource.objects.annotate(uploaded=Count('datagroup__datadocument'))\
        .filter(uploaded__gt=0)
    # A separate queryset of data sources and their related products without PUCs assigned
    # Changed in issue 232. Instead of filtering products based on their prod_cat being null,
    #   we now exclude all products that have a product_id contained in the ProductToPUC object set
    qs_no_puc = Product.objects.values('data_source').exclude(id__in=(ProductToPUC.objects.values_list('product_id', flat=True))).\
        filter(data_source__isnull=False).annotate(no_category=Count('id')).order_by('data_source')
    # Convert the queryset to a list
    list_no_puc = [ds_no_puc for ds_no_puc in qs_no_puc]

    for ds in data_sources:
        try:
            ds.no_category = next((item for item in list_no_puc if item["data_source"] == ds.id), False)['no_category']
        except:
            ds.no_category = 0
        dgs = ds.datagroup_set.all()
        for dg in dgs:
            dg.unlinked = dg.datadocument_set.count() - dg.datadocument_set.filter(productdocument__document__isnull=False).count()
        ds.data_groups = dgs

    return render(request, template_name, {'data_sources': data_sources})

@login_required()
def category_assignment(request, pk, template_name=('product_curation/'
                                                'category_assignment.html')):
    """Deliver a datasource and its associated products"""
    ds = DataSource.objects.get(pk=pk)
    products = ds.source.exclude(id__in=(ProductToPUC.objects.values_list('product_id', flat=True))).order_by('-created_at')
    return render(request, template_name, {'datasource': ds, 'products': products})

@login_required()
def link_product_list(request,  pk, template_name='product_curation/link_product_list.html'):
    dg = DataGroup.objects.get(pk=pk)
    documents = dg.datadocument_set.filter(productdocument__document__isnull=True)
    npage = 20 # TODO: make this dynamic someday in its own ticket
    paginator = Paginator(documents, npage) # Show npage data documents per page
    page = request.GET.get('page')
    page = 1 if page is None else page
    docs_page = paginator.page(page)
    return render(request, template_name, {'documents':docs_page, 'datagroup':dg})

@login_required()
def link_product_form(request, pk, template_name=('product_curation/'
                                                    'link_product_form.html')):
    doc = DataDocument.objects.get(pk=pk)
    ds_id = doc.data_group.data_source_id
    initial = {   'upc': ('stub_' + str(Product.objects.all().aggregate(Max('id'))["id__max"] + 1)),
        'document_type': doc.document_type,
           'return_url': request.META.get('HTTP_REFERER')}
    form = ProductLinkForm(initial=initial)
    # limit document type options to those matching parent datagroup group_type
    queryset = DocumentType.objects.filter(group_type=doc.data_group.group_type)
    form.fields['document_type'].queryset = queryset
    if request.method == 'POST':
        form = ProductLinkForm(request.POST or None)
        if form.is_valid():
            upc = form['upc'].value()
            title = form['title'].value()
            product, created = Product.objects.get_or_create(upc=upc,
                                                        data_source_id = ds_id)
            if created:
                product.title = title
                product.manufacturer = form['manufacturer'].value()
                product.brand_name = form['brand_name'].value()
                product.upc = form['upc'].value()
                product.size = form['size'].value()
                product.color = form['color'].value()
                product.save()
            if not ProductDocument.objects.filter(document=doc,
                                                    product=product).exists():
                p = ProductDocument(product=product, document=doc)
                p.save()
            document_type = form['document_type'].value()
            if document_type != doc.document_type: # update if user changes
                doc.document_type = DocumentType.objects.get(pk=document_type)
                doc.save()
            if 'datadocument' in form['return_url'].value():
                return redirect('data_document', pk=doc.pk)
            else:
                return redirect('link_product_list', pk=doc.data_group.pk)
        else:
            pass #form is invalid
    return render(request, template_name,{'document': doc, 'form': form})

@login_required()
def detach_puc_from_product(request, pk):
    p = Product.objects.get(pk=pk)
    pp = ProductToPUC.objects.get(product=p)
    pp.delete()
    return redirect('product_detail', pk=p.pk)

@login_required()
def bulk_assign_tag_to_products(request):
    template_name = 'product_curation/bulk_product_tag.html'
    products = {}
    msg = ''
    puc_form = BulkPUCForm(request.POST or None)
    form = BulkProductTagForm()
    if puc_form['puc'].value():
        puc = PUC.objects.get(pk = puc_form['puc'].value())
        assumed_tags = puc.get_assumed_tags()
        puc2tags = (PUCToTag.objects.filter(content_object=puc,assumed=False).
                                                values_list('tag', flat=True))
        form.fields['tag'].queryset = PUCTag.objects.filter(id__in=puc2tags)
        prod2pucs = (ProductToPUC.objects.filter(puc = puc).
                                        values_list('product_id', flat=True))
        products = Product.objects.filter(id__in=prod2pucs)
    if request.method == 'POST' and 'save' in request.POST:
        form = BulkProductTagForm(request.POST or None)
        form.fields['tag'].queryset = PUCTag.objects.filter(id__in=puc2tags)
        if form.is_valid():
            assign_tag = PUCTag.objects.filter(id=form['tag'].value())
            tags = assumed_tags | assign_tag
            product_ids = form['id_pks'].value().split(",")
            for id in product_ids:
                product = Product.objects.get(id=id)
                #add the assumed tags to the update
                for tag in tags:
                    ProductToTag.objects.update_or_create(tag=tag,
                                                        content_object=product)
            puc_form = BulkPUCForm()
            form = BulkProductTagForm()
            tag = assign_tag[0]
            msg = f'The "{tag.name}" Attribute was assigned to {len(product_ids)} Product(s).'
            if assumed_tags:
                msg += (' Along with the assumed tags: '
                            f'{" | ".join(x.name for x in assumed_tags)}')
            products = {}
    return render(request, template_name, {'products': products,
                                            'puc_form': puc_form,
                                            'form': form, 
                                            'msg': msg})

@login_required()
def bulk_assign_puc_to_product(request, template_name=('product_curation/'
                                                      'bulk_product_puc.html')):
    max_products_returned = 50
    q = safestring.mark_safe(request.GET.get('q', '')).lstrip()
    if q > '':
        p = (Product.objects
            .filter( Q(title__icontains=q) | Q(brand_name__icontains=q) )
            .exclude(id__in=(ProductToPUC.objects.values_list('product_id', flat=True))
            )[:max_products_returned])
        full_p_count = Product.objects.filter( Q(title__icontains=q) | Q(brand_name__icontains=q) ).count()                    
    else:
        p = {}
        full_p_count = 0
    form = BulkProductPUCForm(request.POST or None)
    if form.is_valid():
        puc = PUC.objects.get(id=form['puc'].value())
        product_ids = form['id_pks'].value().split(",")
        for id in product_ids:
            product = Product.objects.get(id=id)
            ProductToPUC.objects.create(puc=puc, product=product, classification_method='MB',
                                    puc_assigned_usr=request.user)
    form['puc'].label = 'PUC to Assign to Selected Products'
    return render(request, template_name, {'products': p, 'q': q, 'form': form, 'full_p_count': full_p_count})

@login_required()
def assign_puc_to_product(request, pk, template_name=('product_curation/'
                                                      'product_puc.html')):
    p = Product.objects.get(pk=pk)
    p2p = ProductToPUC.objects.filter(classification_method='MA', product=p).first()
    form = ProductPUCForm(request.POST or None, instance=p2p)
    if form.is_valid():
        if p2p:
            p2p.save()
        else:
            puc = PUC.objects.get(id=form['puc'].value())
            p2p = ProductToPUC.objects.create(puc=puc, product=p, classification_method='MA',
                                        puc_assigned_usr=request.user)
        referer = request.POST.get('referer') if request.POST.get('referer') else 'category_assignment'
        pk = p2p.product.pk if referer == 'product_detail' else p2p.product.data_source.pk
        return redirect(referer, pk=pk)
    form.referer = resolve(parse.urlparse(request.META['HTTP_REFERER']).path).url_name\
        if 'HTTP_REFERER' in request.META else 'category_assignment'
    form.referer_pk = p.id if form.referer == 'product_detail' else p.data_source.id
    return render(request, template_name,{'product': p, 'form': form})

@login_required()
def product_detail(request, pk):
    template_name = 'product_curation/product_detail.html'
    p = get_object_or_404(Product, pk=pk, )
    tagform = ProductTagForm(request.POST or None, instance=p)
    tagform['tags'].label = ''
    puc = p.get_uber_puc()
    assumed_tags = puc.get_assumed_tags() if puc else PUCTag.objects.none()
    if tagform.is_valid():
        tagform.save()
    docs = p.datadocument_set.order_by('-created_at')
    return render(request, template_name, {'product'      : p,
                                            'puc'         : puc,
                                            'tagform'     : tagform,
                                            'docs'        : docs,
                                            'assumed_tags': assumed_tags
                                            })

@login_required()
def product_update(request, pk, template_name=('product_curation/'
                                               'product_edit.html')):
    p = Product.objects.get(pk=pk)
    form = ProductForm(request.POST or None, instance=p)
    if form.is_valid():
        form.save()
        return redirect('product_detail', pk=p.pk)
    return render(request, template_name,{'product': p, 'form': form})

@login_required()
def product_delete(request, pk):
    p = Product.objects.get(pk=pk)
    p.delete()
    return redirect('product_curation')

@login_required()
def product_list(request):
    template_name = 'product_curation/products.html'
    products = Product.objects.all()
    data = {}
    data['products'] = products
    return render(request, template_name, data)

from taggit.models import TaggedItemBase, TagBase
from taggit.managers import TaggableManager

from django.db import models
from django.urls import reverse
from django.utils.translation import ugettext_lazy as _

from .common_info import CommonInfo
from .extracted_habits_and_practices_to_puc import (
                                            ExtractedHabitsAndPracticesToPUC)
from .extracted_habits_and_practices import ExtractedHabitsAndPractices


class PUC(CommonInfo):
    KIND_CHOICES = (
        ('UN', 'unknown'),
        ('FO', 'formulations'),
        ('AR', 'articles'),
        ('OC', 'occupational'))

    kind = models.CharField(max_length=2, blank=True, default='UN',
                             choices=KIND_CHOICES)
    gen_cat = models.CharField(max_length=50, blank=False)
    prod_fam = models.CharField(max_length=50, blank=True, default='')
    prod_type = models.CharField(max_length=100, blank=True, default='')
    description = models.TextField(null=False, blank=False)
    last_edited_by = models.ForeignKey('auth.User', on_delete=models.CASCADE,
                                                                    default=1)
    products = models.ManyToManyField('Product', through='ProductToPUC')
    extracted_habits_and_practices = models.ManyToManyField(
                        'dashboard.ExtractedHabitsAndPractices',
                        through='dashboard.ExtractedHabitsAndPracticesToPUC')
    tags = TaggableManager(through='dashboard.PUCToTag',
                           to='dashboard.PUCTag',
                           blank=True,
                           help_text='A set of PUC Attributes applicable to this PUC')

    class Meta:
        ordering = ['gen_cat', 'prod_fam', 'prod_type']
        verbose_name_plural = 'PUCs'

    def __str__(self):
        cats = [self.gen_cat, self.prod_fam, self.prod_type]
        return ' - '.join(cat for cat in cats if cat is not None)

    def natural_key(self):
        return self.gen_cat

    def tag_list(self, obj):
        return u", ".join(o.name for o in obj.tags.all())


    def get_level(self):
        if self.is_level_one:
            return 1
        if self.is_level_two:
            return 2
        else:
            return 3


    @property
    def is_level_one(self): # gen_cat only
        return self.prod_fam is '' and self.prod_type is ''

    @property
    def is_level_two(self): # no prod_type
        return not self.prod_fam is '' and self.prod_type is ''

    @property
    def is_level_three(self): # most granular PUC
        return not self.prod_fam is '' and not self.prod_type is ''

    def get_the_kids(self):
        if self.is_level_one:
            return PUC.objects.filter(gen_cat=self.gen_cat)
        if self.is_level_two:
            return PUC.objects.filter(gen_cat=self.gen_cat,
                                        prod_fam=self.prod_fam)
        if self.is_level_three:
            return PUC.objects.filter(pk=self.pk)

    @property
    def product_count(self):
        '''Don't use this in large querysets. It uses a SQL query for each 
        PUC record. '''
        return self.products.count()

    @property
    def admin_url(self):
        return reverse('admin:dashboard_puc_change', args=(self.pk,))
        
    def get_assumed_tags(self):
        '''Queryset of used to filter which PUCs a Product can have '''
        qs = PUCToTag.objects.filter(content_object=self, assumed=True)
        return PUCTag.objects.filter(dashboard_puctotag_items__in=qs)


class PUCToTag(TaggedItemBase, CommonInfo):
    content_object = models.ForeignKey(PUC, on_delete=models.CASCADE)
    tag = models.ForeignKey('PUCTag', on_delete=models.CASCADE,
                            related_name="%(app_label)s_%(class)s_items")
    assumed = models.BooleanField(default=False)

    def __str__(self):
        return str(self.content_object)                    


class PUCTag(TagBase, CommonInfo):

    class Meta:
        verbose_name = _("PUC Attribute")
        verbose_name_plural = _("PUC Attributes")
        ordering = ('name',)

    def __str__(self):
        return self.name

import csv
import time
from lxml import html

from django.urls import resolve
from django.test import TestCase

from dashboard.tests.loader import load_model_objects, fixtures_standard
from dashboard import views
from dashboard.models import *


class DashboardTest(TestCase):

    def setUp(self):
        self.objects = load_model_objects()
        # self.test_start = time.time()

    # def tearDown(self):
    #     self.test_elapsed = time.time() - self.test_start
    #     print('\nFinished with ' + self._testMethodName + ' in {:.2f}s'.format(self.test_elapsed))

    def test_public_navbar(self):
        self.client.logout()
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        self.assertIn('factotum', response_html.xpath('string(/html/body/nav//a[@href="/"]/text())'),
                      'The app name factotum should appear in the public navbar')
        self.assertNotIn('QA', response_html.xpath('string(/html/body/nav//a[@href="/qa/extractionscript/"])'),
                         'The link to /qa/ should not appear in the public navbar')

    def test_logged_in_navbar(self):
        self.client.login(username='Karyn', password='specialP@55word')
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        self.assertIn('QA', response_html.xpath('string(//*[@id="navbarQADropdownMenuLink"])'),
                      'The link to /qa/ must be in the logged-in navbar')
        found = resolve('/qa/extractionscript/')
        self.assertEqual(found.func, views.qa_extractionscript_index)

    def test_percent_extracted_text_doc(self):
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        extracted_doc_count = response_html.xpath(
            '/html/body/div[1]/div[1]/div[4]/div/div')[0].text
        self.assertEqual('0%', extracted_doc_count)

        self.objects.doc.extracted = True
        self.objects.doc.save()
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        extracted_doc_count = response_html.xpath(
            '/html/body/div[1]/div[1]/div[4]/div/div')[0].text
        self.assertEqual('100%', extracted_doc_count)

    def test_PUC_download(self):
        p = self.objects.puc                    
        puc_line = (p.gen_cat + ',' + p.prod_fam + ',' + p.prod_type + ',' + p.description +
                    ',' + str(p.get_level()) + ',' + str(p.product_count))                    
        # get csv
        response = self.client.get('/dl_pucs/')
        self.assertEqual(response.status_code, 200)
        csv_lines = response.content.decode('ascii').split('\r\n')
        # check header
        self.assertEqual(csv_lines[0], ('gen_cat,prod_fam,prod_type,description,'                    
                                        'PUC_type,num_prods'))
        # check the PUC from loader
        self.assertEqual(csv_lines[1], puc_line)                    


class DashboardTestWithFixtures(TestCase):
    fixtures = fixtures_standard

    def test_chemical_card(self):
        response = self.client.get('/').content.decode('utf8')
        self.assertIn('DSS Tox Chemicals', response,
                      'Where is the DSS Tox Chemicals card???')
        response_html = html.fromstring(response)
        num_dss = int(response_html.xpath('//*[@name="dsstox"]')[0].text)
        dss_table_count = DSSToxLookup.objects.count()
        self.assertEqual(num_dss, dss_table_count,
                         'The number shown should match the number of records in DSSToxLookup')


class DashboardTestWithFixtures(TestCase):
    fixtures = fixtures_standard

    def test_producttopuc_counts(self):
        response = self.client.get('/').content.decode('utf8')
        self.assertIn('Products Linked To PUC', response,
                      'Where is the Products Linked to PUC card???')
        response_html = html.fromstring(response)
        num_prods = int(response_html.xpath(
            '//*[@name="product_with_puc_count"]')[0].text)

        orm_prod_puc_count = ProductToPUC.objects.values(
            'product_id').distinct().count()
        self.assertEqual(num_prods, orm_prod_puc_count,
                         'The page should show %s Products linked to PUCs' % orm_prod_puc_count)

        # Assign an already-assigned product to a different PUC with a different method
        # and confirm that the count has not changed
        p2puc = ProductToPUC.objects.first()
        p2puc.id = None
        p2puc.classification_method = 'MB'
        p2puc.puc_id = 21
        p2puc.save()

        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        num_prods = int(response_html.xpath(
            '//*[@name="product_with_puc_count"]')[0].text)
        self.assertEqual(num_prods, orm_prod_puc_count,
                         'The page should show %s Products linked to PUCs' % orm_prod_puc_count)

        # Assign a previously unassigned product to a different PUC with a different method
        # and confirm that the count has gone up
        assigned_prods = ProductToPUC.objects.values_list('product_id')
        # print(assigned_prods)
        prod = Product.objects.exclude(id__in=assigned_prods).first()
        puc21 = PUC.objects.get(id=21)
        p2puc = ProductToPUC.objects.create(
            product=prod, puc=puc21, classification_method='MA')
        p2puc.save()

        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        num_prods = int(response_html.xpath(
            '//*[@name="product_with_puc_count"]')[0].text)
        self.assertEqual(num_prods, orm_prod_puc_count + 1,
                         'The page should show %s Products linked to PUCs' % str(orm_prod_puc_count + 1))

import csv
import datetime
from dateutil.relativedelta import relativedelta

from django.http import HttpResponse
from django.shortcuts import render
from django.db.models import Count, F, DateField, DateTimeField
from django.db.models.functions import Trunc
from django.contrib.auth.decorators import login_required

from dashboard.models import *

from dashboard.models import *

current_date = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d')
chart_start_datetime = datetime.datetime(datetime.datetime.now().year - 1, min(12,datetime.datetime.now().month + 1), 1)


def index(request):
    stats = {}
    stats['datagroup_count'] = DataGroup.objects.count()
    stats['datasource_count'] = DataSource.objects.count()

    stats['datadocument_count'] = DataDocument.objects.count()
    stats['datadocument_with_extracted_text_percent'] =\
        DataDocument.objects.filter(extracted = True).count()/DataDocument.objects.count()*100
    stats['datadocument_count_by_date'] = datadocument_count_by_date()
    stats['datadocument_count_by_month'] = datadocument_count_by_month()
    stats['product_count'] = Product.objects.count()
    stats['dss_tox_count'] = DSSToxLookup.objects.count()
    stats['chemical_count'] = ExtractedChemical.objects.count()
    stats['product_with_puc_count'] = ProductToPUC.objects.values('product_id').distinct().count()
    stats['product_with_puc_count_by_month'] = product_with_puc_count_by_month()
    return render(request, 'dashboard/index.html', stats)


def datadocument_count_by_date():
    # Datasets to populate linechart with document-upload statistics
    # Number of datadocuments, both overall and by type, that have been uploaded as of each date
    select_upload_date = {"upload_date": """date(dashboard_datadocument.created_at)"""}
    document_stats = {}
    document_stats['all'] = list(DataDocument.objects.extra(select=select_upload_date) \
                                 .values('upload_date') \
                                 .annotate(document_count = Count('id')) \
                                 .order_by('upload_date'))
    document_stats_by_type = DataDocument.objects.extra(select=select_upload_date) \
        .values('upload_date') \
        .annotate(source_type = F('document_type__title'), document_count = Count('id')) \
        .order_by('upload_date')
    document_stats['product'] = list(document_stats_by_type.filter(source_type = 'product'))
    document_stats['msds_sds'] = list(document_stats_by_type.filter(source_type = 'msds/sds'))
    for type in {'all'}:
        document_count = 0
        for item in document_stats[type]:
            if isinstance(item['upload_date'], datetime.date):
                item['upload_date'] = datetime.date.strftime((item['upload_date']), '%Y-%m-%d')
            document_count += item['document_count']
            item['document_count'] = document_count
        # if final record isn't for current date, create one
        for item in document_stats[type][len(document_stats[type])-1:]:
            if item['upload_date'] != current_date:
                document_stats[type].append({'upload_date': current_date
                                                , 'document_count': document_count})
    return document_stats


def datadocument_count_by_month():
    # GROUP BY issue solved with https://stackoverflow.com/questions/8746014/django-group-by-date-day-month-year
    document_stats = list(DataDocument.objects.filter(created_at__gte=chart_start_datetime)\
        .annotate(upload_month = (Trunc('created_at', 'month', output_field=DateTimeField()))) \
        .values('upload_month') \
        .annotate(document_count = (Count('id'))) \
        .values('document_count', 'upload_month') \
        .order_by('upload_month'))
    if len(document_stats) < 12:
        for i in range(0, 12):
            chart_month = chart_start_datetime + relativedelta(months=i)
            if i + 1 > len(document_stats) or document_stats[i]['upload_month'] != chart_month:
                document_stats.insert(i, {'document_count': '0', 'upload_month': chart_month})
    return document_stats


def product_with_puc_count_by_month():
    # GROUP BY issue solved with https://stackoverflow.com/questions/8746014/django-group-by-date-day-month-year

    product_stats = list(ProductToPUC.objects
        .filter(created_at__gte=chart_start_datetime)
        .annotate(
            puc_assigned_month = (Trunc('created_at', 'month', output_field=DateField()))
        )
        .values('puc_assigned_month')
        .annotate(product_count=Count('product', distinct=True))
        .order_by('puc_assigned_month')
        )

    if len(product_stats) < 12:
        for i in range(0, 12):
            chart_month = chart_start_datetime + relativedelta(months=i)
            if i + 1 > len(product_stats) or product_stats[i]['puc_assigned_month'] != chart_month:
                product_stats.insert(i, {'product_count': '0', 'puc_assigned_month': chart_month})
    return product_stats


def download_PUCs(request):
    '''This view gets called every time we call the index view and is used to
    populate the bubble plot. It is also used to download all of the PUCs in 
    csv form. The "bubbles" parameter in the request will either be "True" or 
    "None", it's worth noting that if when making the call to here from the 
    index page we were to use ?bubbles=False it would also give us the filtered
    PUCs because the if expression is just checking whether that parameter is 
    there.
    '''
    response = HttpResponse(content_type='text/csv')
    response['Content-Disposition'] = 'attachment; filename="PUCs.csv"'
    bubbles = request.GET.get('bubbles')
    writer = csv.writer(response)
    cols = ['gen_cat','prod_fam','prod_type','description','PUC_type','num_prods']                    
    writer.writerow(cols)
    pucs = PUC.objects.filter(kind='FO') if bubbles else PUC.objects.all()
    for puc in pucs:
        row = [ puc.gen_cat,
                puc.prod_fam, 
                puc.prod_type, 
                puc.description, 
                puc.get_level(), 
                puc.product_count
                ]
        writer.writerow(row)

    return response

from dal import autocomplete
from bootstrap_datepicker_plus import DatePickerInput

from django import forms
from django.forms import BaseInlineFormSet

from django.utils.translation import ugettext_lazy as _

from dashboard.models import *
from django.db.models import F                    
from dashboard.utils import get_extracted_models


class DataGroupForm(forms.ModelForm):
    required_css_class = 'required'  # adds to label tag

    class Meta:
        model = DataGroup
        fields = ['name', 'description', 'url', 'group_type', 'downloaded_by',
                  'downloaded_at', 'download_script', 'data_source', 'csv']
        widgets = {'downloaded_at': DatePickerInput()}
        labels = {'csv': _('Register Records CSV File'),
                  'url': _('URL'), }

    def __init__(self, *args, **kwargs):
        qs = Script.objects.filter(script_type='DL')
        self.user = kwargs.pop('user', None)
        super(DataGroupForm, self).__init__(*args, **kwargs)
        self.fields['csv'].widget.attrs.update({'accept': '.csv'})
        self.fields['download_script'].queryset = qs


class ExtractionScriptForm(forms.Form):
    required_css_class = 'required'  # adds to label tag
    script_selection = forms.ModelChoiceField(
        queryset=Script.objects.filter(script_type='EX'),
        label="Extraction Script")
    weight_fraction_type = forms.ModelChoiceField(
        queryset=WeightFractionType.objects.all(),
        label="Weight Fraction Type",
        initial="1")
    extract_file = forms.FileField(label="Extracted Text CSV File")

    def __init__(self, *args, **kwargs):
        self.dg_type = kwargs.pop('dg_type', 0)
        self.user = kwargs.pop('user', None)
        super(ExtractionScriptForm, self).__init__(*args, **kwargs)
        self.fields['weight_fraction_type'].widget.attrs.update(
            {'style': 'height:2.75rem; !important'})
        self.fields['script_selection'].widget.attrs.update(
            {'style': 'height:2.75rem; !important'})
        self.fields['extract_file'].widget.attrs.update({'accept': '.csv'})
        if self.dg_type in ['FU', 'CP']:
            del self.fields['weight_fraction_type']
        self.collapsed = True


class CleanCompDataForm(forms.Form):
    required_css_class = 'required'  # adds to label tag
    script_selection = forms.ModelChoiceField(
        queryset=Script.objects.filter(script_type='DC'),
        label="Data Cleaning Script",
        required=True)
    clean_comp_data_file = forms.FileField(label="Clean Composition Data CSV File",
                                           required=True)

    def __init__(self, *args, **kwargs):
        super(CleanCompDataForm, self).__init__(*args, **kwargs)
        self.fields['script_selection'].widget.attrs.update(
            {'style': 'height:2.75rem; !important'})
        self.fields['clean_comp_data_file'].widget.attrs.update(
            {'accept': '.csv'})
        self.collapsed = True


class DataSourceForm(forms.ModelForm):
    required_css_class = 'required'

    class Meta:
        model = DataSource
        fields = ['title', 'url', 'estimated_records', 'state', 'priority',
                  'description']


class PriorityForm(forms.ModelForm):
    class Meta:
        model = DataSource
        fields = ['priority']

    def __init__(self, *args, **kwargs):
        super(PriorityForm, self).__init__(*args, **kwargs)
        self.fields['priority'].label = ''
        self.fields['priority'].widget.attrs.update({
            'onchange': 'form.submit();'
        })


class QANotesForm(forms.ModelForm):
    class Meta:
        model = QANotes
        fields = ['qa_notes']
        widgets = {
            'qa_notes': forms.Textarea,                    
        }
        labels = {
            'qa_notes': _('QA Notes (required if approving edited records)'),
        }


class ExtractedTextQAForm(forms.ModelForm):
    required_css_class = 'required'  # adds to label tag

    class Meta:
        model = ExtractedText
        fields = ['prod_name', 'data_document', 'qa_checked']


class ProductLinkForm(forms.ModelForm):
    required_css_class = 'required'  # adds to label tag
    document_type = forms.ModelChoiceField(
        queryset=DocumentType.objects.all(),
        label="Data Document Type",
        required=True)
    return_url = forms.CharField()

    class Meta:
        model = Product
        fields = ['title', 'manufacturer',
                  'brand_name', 'upc', 'size', 'color']

    def __init__(self, *args, **kwargs):
        super(ProductLinkForm, self).__init__(*args, **kwargs)
        self.fields['return_url'].widget = forms.HiddenInput()


class ProductForm(forms.ModelForm):
    required_css_class = 'required'  # adds to label tag

    class Meta:
        model = Product
        fields = ['title', 'manufacturer', 'brand_name', 'size', 'color',
                  'model_number', 'short_description', 'long_description']


class ProductViewForm(ProductForm):
    class Meta(ProductForm.Meta):
        exclude = ('title', 'long_description',)

    def __init__(self, *args, **kwargs):
        super(ProductForm, self).__init__(*args, **kwargs)
        for f in self.fields:
            self.fields[f].disabled = True


class BasePUCForm(forms.ModelForm):
    puc = forms.ModelChoiceField(
        queryset=PUC.objects.all(),
        label='Category',
        widget=autocomplete.ModelSelect2(
            url='puc-autocomplete',
            attrs={'data-minimum-input-length': 3, })
    )


class ProductPUCForm(BasePUCForm):
    class Meta:
        model = ProductToPUC
        fields = ['puc']


class HabitsPUCForm(BasePUCForm):
    class Meta:
        model = ExtractedHabitsAndPracticesToPUC
        fields = ['puc']


class BulkProductPUCForm(forms.ModelForm):
    id_pks = forms.CharField(label='Product Titles',
                             widget=forms.HiddenInput(),
                             required=True)

    class Meta:
        model = ProductToPUC
        fields = ['puc', 'id_pks']


class BulkPUCForm(BasePUCForm):
    class Meta:
        model = ProductToPUC
        fields = ['puc']

    def __init__(self, *args, **kwargs):
        super(BulkPUCForm, self).__init__(*args, **kwargs)
        lbl = 'Select PUC for Attribute to Assign to Selected Products'
        self.fields['puc'].label = lbl
        self.fields['puc'].widget.attrs['onchange'] = 'form.submit();'


class BulkProductTagForm(forms.ModelForm):
    required_css_class = 'required'  # adds to label tag
    tag = forms.ModelChoiceField(queryset=PUCTag.objects.none(),
                                 label='Attribute')
    id_pks = forms.CharField(label='Product Titles',
                             widget=forms.HiddenInput())

    class Meta:
        model = ProductToPUC
        fields = ['tag', 'id_pks']

    def __init__(self, *args, **kwargs):
        super(BulkProductTagForm, self).__init__(*args, **kwargs)
        lbl = 'Select Attribute to Assign to Selected Products'
        self.fields['tag'].label = lbl


class ExtractedTextForm(forms.ModelForm):
    class Meta:
        model = ExtractedText
        fields = ['prod_name', 'doc_date', 'rev_num']

        widgets = {
            'data_document': forms.HiddenInput(),
            'extraction_script': forms.HiddenInput(),
        }


class ExtractedCPCatForm(ExtractedTextForm):

    class Meta:
        model = ExtractedCPCat
        fields = ['doc_date', 'cat_code',                    
                  'description_cpcat', 'cpcat_sourcetype']                    


class ExtractedCPCatEditForm(ExtractedCPCatForm):

    class Meta(ExtractedCPCatForm.Meta):
        fields = ExtractedCPCatForm.Meta.fields + \
            ['prod_name', 'doc_date', 'rev_num', 'cpcat_code']


class ExtractedHHDocForm(ExtractedTextForm):

    class Meta:
        model = ExtractedHHDoc
        fields = ['hhe_report_number', 'study_location', 'naics_code', 'sampling_date', 'population_gender',
                  'population_age', 'population_other', 'occupation', 'facility']


class ExtractedHHDocEditForm(ExtractedHHDocForm):

    class Meta(ExtractedHHDocForm.Meta):
        fields = ExtractedHHDocForm.Meta.fields + \
            ['prod_name', 'doc_date', 'rev_num']


class DocumentTypeForm(forms.ModelForm):
    class Meta:
        model = DataDocument
        fields = ['document_type']

    def __init__(self, *args, **kwargs):
        super(DocumentTypeForm, self).__init__(*args, **kwargs)
        self.fields['document_type'].label = ''
        self.fields['document_type'].widget.attrs.update({
            'onchange': 'form.submit();'
        })


def include_extract_form(dg):
    '''Returns the ExtractionScriptForm based on conditions of DataGroup
    type as well as whether all records are matched, but not extracted
    '''
    if not dg.type in ['FU', 'CO', 'CP']:
        return False
    if dg.all_matched() and not dg.all_extracted():
        return ExtractionScriptForm(dg_type=dg.type)
    else:
        return False


class ExtractedChemicalFormSet(BaseInlineFormSet):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)


class ExtractedChemicalForm(forms.ModelForm):
    def __init__(self, *args, **kwargs):
        super(ExtractedChemicalForm, self).__init__(*args, **kwargs)
        # the non-field properties need to be explicitly added
        if hasattr(self.instance, 'dsstox') and self.instance.dsstox is not None:
            self.fields['true_cas'] = forms.CharField(max_length=200)
            self.fields['true_cas'].initial = self.instance.dsstox.true_cas
            self.fields['true_cas'].disabled = True
            self.fields['true_chemname'] = forms.CharField(max_length=400)
            self.fields['true_chemname'].initial = self.instance.dsstox.true_chemname
            self.fields['true_chemname'].disabled = True
            self.fields['SID'] = forms.CharField(max_length=50)
            self.fields['SID'].initial = self.instance.dsstox.sid
            self.fields['SID'].disabled = True

    class Meta:
        model = ExtractedChemical
        fields = '__all__'


def include_clean_comp_data_form(dg):
    '''Returns the CleanCompDataForm based on conditions of DataGroup
    type = Composition and at least 1 document extracted
    '''
    if not dg.type in ['CO']:
        return False
    if dg.extracted_docs() > 0:
        return CleanCompDataForm()
    else:
        return False


def create_detail_formset(document, extra=1, can_delete=False, exclude=[]):
    '''Returns the pair of formsets that will be needed based on group_type.
    .                       ('CO'),('CP'),('FU'),('HP'),('HH')
    Parameters
        ----------
        document : DataDocument
            The parent DataDocument
        extra : integer
            How many empty forms should be created for new records
        can_delete : boolean
            whether a delete checkbox is included
        exclude : list
            which fields to leave out of the form
    .

    '''
    group_type = document.data_group.type
    parent, child = get_extracted_models(group_type)
    extracted = hasattr(document, 'extractedtext')

    def make_formset(parent_model, model,
                     formset=BaseInlineFormSet,
                     form=forms.ModelForm,
                     exclude=exclude):
        formset_fields = model.detail_fields()
        if exclude:
            formset_fields = [in_field for in_field in formset_fields if not in_field in exclude]
        return forms.inlineformset_factory(parent_model=parent_model,
                                           model=model,
                                           fields=formset_fields,
                                           formset=formset,  # this specifies a custom formset
                                           form=form,
                                           extra=extra,
                                           can_delete=can_delete)

    def one():  # for chemicals or unknown
        ChemicalFormSet = make_formset(
            parent_model=parent,
            model=child,
            formset=ExtractedChemicalFormSet,
            form=ExtractedChemicalForm
        )
        return (ExtractedTextForm, ChemicalFormSet)

    def two():  # for functional_use
        FunctionalUseFormSet = make_formset(parent, child)
        return (ExtractedTextForm, FunctionalUseFormSet)

    def three():  # for habits_and_practices
        HnPFormSet = make_formset(parent, child)
        return (ExtractedTextForm, HnPFormSet)

    def four():  # for extracted_list_presence
        ListPresenceFormSet = make_formset(parent, child)
        ParentForm = ExtractedCPCatForm if extracted else ExtractedCPCatEditForm


        return (ParentForm, ListPresenceFormSet)

    def five():  # for extracted_hh_rec
        HHFormSet = make_formset(parent, child)
        ParentForm = ExtractedHHDocForm if extracted else ExtractedHHDocEditForm
        return (ParentForm, HHFormSet)
    dg_types = {
        'CO': one,
        'UN': one,
        'FU': two,
        'HP': three,
        'CP': four,
        'HH': five,
    }
    func = dg_types.get(group_type, lambda: None)
    return func()

from taggit.models import TaggedItemBase, TagBase
from taggit.managers import TaggableManager

from django.db import models
from django.urls import reverse
from django.utils.translation import ugettext_lazy as _

from .common_info import CommonInfo
from .extracted_habits_and_practices_to_puc import (
                                            ExtractedHabitsAndPracticesToPUC)                    
from .extracted_habits_and_practices import ExtractedHabitsAndPractices                    


class PUC(CommonInfo):
    KIND_CHOICES = (
        ('UN', 'unknown'),
        ('FO', 'formulations'),
        ('AR', 'articles'),
        ('OC', 'occupational'))

    kind = models.CharField(max_length=2, blank=True, default='UN',
                             choices=KIND_CHOICES)
    gen_cat = models.CharField(max_length=50, blank=False)
    prod_fam = models.CharField(max_length=50, blank=True, default='')
    prod_type = models.CharField(max_length=100, blank=True, default='')
    description = models.TextField(null=False, blank=False)
    last_edited_by = models.ForeignKey('auth.User', on_delete=models.CASCADE,
                                                                    default=1)
    products = models.ManyToManyField('Product', through='ProductToPUC')
    extracted_habits_and_practices = models.ManyToManyField(
                        'dashboard.ExtractedHabitsAndPractices',
                        through='dashboard.ExtractedHabitsAndPracticesToPUC')
    tags = TaggableManager(through='dashboard.PUCToTag',
                           to='dashboard.PUCTag',
                           blank=True,
                           help_text='A set of PUC Attributes applicable to this PUC')

    class Meta:
        ordering = ['gen_cat', 'prod_fam', 'prod_type']
        verbose_name_plural = 'PUCs'

    def __str__(self):
        cats = [self.gen_cat, self.prod_fam, self.prod_type]
        return ' - '.join(cat for cat in cats if cat is not None)

    def natural_key(self):
        return self.gen_cat

    def tag_list(self, obj):
        return u", ".join(o.name for o in obj.tags.all())


    def get_level(self):
        if self.is_level_one:
            return 1
        if self.is_level_two:
            return 2
        else:
            return 3


    @property
    def is_level_one(self): # gen_cat only
        return self.prod_fam is '' and self.prod_type is ''

    @property
    def is_level_two(self): # no prod_type
        return not self.prod_fam is '' and self.prod_type is ''

    @property
    def is_level_three(self): # most granular PUC
        return not self.prod_fam is '' and not self.prod_type is ''

    def get_the_kids(self):
        if self.is_level_one:
            return PUC.objects.filter(gen_cat=self.gen_cat)
        if self.is_level_two:
            return PUC.objects.filter(gen_cat=self.gen_cat,
                                        prod_fam=self.prod_fam)
        if self.is_level_three:
            return PUC.objects.filter(pk=self.pk)

    @property
    def product_count(self):
        '''Don't use this in large querysets. It uses a SQL query for each 
        PUC record. '''
        return self.products.count()

    @property
    def admin_url(self):
        return reverse('admin:dashboard_puc_change', args=(self.pk,))
        
    def get_assumed_tags(self):
        '''Queryset of used to filter which PUCs a Product can have '''
        qs = PUCToTag.objects.filter(content_object=self, assumed=True)
        return PUCTag.objects.filter(dashboard_puctotag_items__in=qs)


class PUCToTag(TaggedItemBase, CommonInfo):
    content_object = models.ForeignKey(PUC, on_delete=models.CASCADE)
    tag = models.ForeignKey('PUCTag', on_delete=models.CASCADE,
                            related_name="%(app_label)s_%(class)s_items")
    assumed = models.BooleanField(default=False)

    def __str__(self):
        return str(self.content_object)                    


class PUCTag(TagBase, CommonInfo):

    class Meta:
        verbose_name = _("PUC Attribute")
        verbose_name_plural = _("PUC Attributes")
        ordering = ('name',)

    def __str__(self):
        return self.name

from .common_info import CommonInfo
from .data_source import DataSource
from .group_type import GroupType
from .data_group import DataGroup
from .document_type import DocumentType
from .data_document import DataDocument
from .ingredient import Ingredient
from .product import Product
from .source_category import SourceCategory
from .product_document import ProductDocument
from .extracted_text import ExtractedText
from .extracted_cpcat import ExtractedCPCat
from .extracted_chemical import ExtractedChemical
from .extracted_functional_use import ExtractedFunctionalUse
from .extracted_habits_and_practices import ExtractedHabitsAndPractices
from .extracted_list_presence import ExtractedListPresence                    
from .extracted_hhdoc import ExtractedHHDoc
from .extracted_hhrec import ExtractedHHRec
from .script import Script
from .dsstox_lookup import DSSToxLookup
from .qa_group import QAGroup
from .unit_type import UnitType
from .weight_fraction_type import WeightFractionType
from .PUC import PUC, PUCToTag, PUCTag
from .product_to_tag import ProductToTag
from .product_to_puc import ProductToPUC
from .extracted_habits_and_practices_to_puc import ExtractedHabitsAndPracticesToPUC
from .qa_notes import QANotes
from .raw_chem import RawChem
from .taxonomy import Taxonomy
from .taxonomy_source import TaxonomySource
from .taxonomy_to_PUC import TaxonomyToPUC

from django.db import models
from .common_info import CommonInfo
from django.urls import reverse
from django.utils import timezone
from .document_type import DocumentType
from django.core.exceptions import ValidationError


class DataDocument(CommonInfo):
    """
    A DataDocument object is a single source of Factotum data. 

    ``filename``
        the name of the document's source file

    ``title``
        the title of the document
    
    ``url``
        an optional URL to the document's remote source

    ``raw_category``

    ``data_group``
        the DataGroup object to which the document belongs. The
        type of the data group determines which document types the
        document might be among, and determines much of the available 
        relationships and behavior associated with the document's 
        extracted data
    
    ``products``
        Products are associated with the data document in a many-to-many relationship

    ``matched``
        When a source file for the document has been uploaded to the
        file system, the document is considered "matched" to that
        source file. 
    
    ``extracted``
        When the content of a data document has been extracted by manual data entry
        or by an extraction script, a new ExtractedText record is created
        with the DataDocument's id as its primary key. 
    
    ``document_type``
        each type of data group may only contain certain types of data documents. The
        clean() method checks to make sure that the assigned document type is among the
        types allowed by the group type

    ``organization``

    ``note``

    """

    filename = models.CharField(max_length=255)
    title = models.CharField(max_length=255)
    url = models.CharField(null=True, blank=True, max_length=275)
    raw_category = models.CharField(null=True, blank=True, max_length=100)
    data_group = models.ForeignKey('DataGroup', on_delete=models.CASCADE)
    products = models.ManyToManyField('Product', through='ProductDocument')
    matched = models.BooleanField(default=False)
    #############################################################
    #  T E C H N I C A L   D E B T 
    # Storing this as a boolean field might not be a good idea. If someone 
    # deletes an ExtractedText object in the admin panel or in the database,
    # the bit will not flip, so the document will remain "extracted"
    # even in the absence of an ExtractedText object
    extracted = models.BooleanField(default=False)  
    # The is_extracted method below should replace this attribute
    #############################################################
    document_type = models.ForeignKey(DocumentType, on_delete=models.PROTECT,
                                                        null=True, blank=True)
    organization = models.CharField(max_length=255, blank=True)
    note = models.TextField(blank=True, null=True)

    class Meta:
        ordering = ['-id']

    def __str__(self):
        return str(self.title)
    
    @property
    def detail_page_editable(self):
        # this could be moved to settings
        return self.data_group.group_type.code in ['CP', 'HH', 'CO', ] 

    @property
    def is_extracted(self):
        return hasattr(self,'extractedtext')

    def get_absolute_url(self):
        return reverse('data_document', kwargs={'pk': self.pk})

    def get_abstract_filename(self):
        ext = self.filename.split('.')[-1] #maybe not all are PDF??
        return f'document_{self.pk}.{ext}'

    def pdf_url(self):
        dg = self.data_group
        fn = self.get_abstract_filename()
        return f'/media/{dg.fs_id}/pdf/{fn}'

    def clean(self):
        # the document_type must be one of the children types
        # of the datadocument's parent datagroup
        this_type = self.data_group.group_type
        doc_types = DocumentType.objects.filter(group_type=this_type)                    
        if not self.document_type in doc_types:
            raise ValidationError(('The document type must be allowed by '
                                                    'the parent data group.'))

import os
import shutil
import uuid
from factotum import settings
from pathlib import Path, PurePath

from django.db import models
from .common_info import CommonInfo                    
from django.urls import reverse
from django.db.models.signals import pre_save                    
from django.dispatch import receiver
from model_utils import FieldTracker
from django.core.exceptions import ValidationError

from .group_type import GroupType
from .extracted_text import ExtractedText
from .extracted_cpcat import ExtractedCPCat
from .extracted_chemical import ExtractedChemical
from .extracted_functional_use import ExtractedFunctionalUse
from .extracted_list_presence import ExtractedListPresence

# could be used for dynamically creating filename on instantiation
# in the 'upload_to' param on th FileField
def update_filename(instance, filename):
    name_fill_space = instance.name.replace(' ', '_')
    # potential space errors in name
    name = '{0}/{0}_{1}'.format(name_fill_space, filename)
    return name


def csv_upload_path(instance, filename):
    # potential space errors in name
    name = '{0}/{1}'.format(instance.fs_id, filename)
    return name

extract_models = {
    'CO': (ExtractedText, ExtractedChemical),
    'FU': (ExtractedText, ExtractedFunctionalUse),
    'CP': (ExtractedCPCat, ExtractedListPresence)
}



class DataGroup(CommonInfo):

    name = models.CharField(max_length=50)
    description = models.TextField(null=True, blank=True)
    downloaded_by = models.ForeignKey('auth.User',
                                    on_delete=models.SET_DEFAULT, default = 1)
    downloaded_at = models.DateTimeField()
    download_script = models.ForeignKey('Script',
                                    on_delete=models.SET_NULL, default=None,
                                    null=True, blank=True)
    data_source = models.ForeignKey('DataSource', on_delete=models.CASCADE)
    fs_id = models.UUIDField(default=uuid.uuid4, editable=False)
    csv = models.FileField(upload_to=csv_upload_path, null=True)
    zip_file = models.CharField(max_length=100)
    group_type = models.ForeignKey(GroupType, on_delete=models.SET_DEFAULT,
                                            default=1, null=True, blank=True)
    url = models.CharField(max_length=150, blank=True)

    tracker = FieldTracker()

    @property
    def type(self):
        return str(self.group_type.code)

    @property
    def is_composition(self):
        return self.type == 'CO'

    @property
    def is_habits_and_practices(self):
        return self.type == 'HP'

    @property
    def is_functional_use(self):
        return self.type == 'FU'

    @property
    def is_chemical_presence(self):
        return self.type == 'CP'

    @property
    def is_hh(self):
        return self.type == 'HH'


    def get_extract_models(self):
        '''returns a tuple with parent/child extract models'''
        return extract_models.get(self.type)

    def save(self, *args, **kwargs):
        super(DataGroup, self).save(*args, **kwargs)

    def matched_docs(self):
        return self.datadocument_set.filter(matched=True).count()

    def all_matched(self):
        return all(self.datadocument_set.values_list('matched', flat=True))

    def all_extracted(self):
        return all(self.datadocument_set.values_list('extracted', flat=True))

    def registered_docs(self):
        return self.datadocument_set.count()

    def extracted_docs(self):
        return self.datadocument_set.filter(extracted=True).count()

    def __str__(self):
        return self.name

    def get_absolute_url(self):
        return reverse('data_group_edit', kwargs={'pk': self.pk})

    def get_name_as_slug(self):
        return self.name.replace(' ', '_')

    def get_dg_folder(self):
        uuid_dir = f'{settings.MEDIA_ROOT}{str(self.fs_id)}'
        name_dir = f'{settings.MEDIA_ROOT}{self.get_name_as_slug()}'

        #this needs to handle missing csv files
        if bool(self.csv.name):
            # parse the media folder from the penultimate piece of csv file path
            p = PurePath(self.csv.path)
            csv_folder=p.parts[-2]
            csv_fullfolderpath   = f'{settings.MEDIA_ROOT}{csv_folder}'

        if os.path.isdir(uuid_dir):
            return uuid_dir # UUID-based folder
        elif bool(self.csv.name) and os.path.isdir(csv_fullfolderpath):
            return csv_fullfolderpath # csv path-based folder
        else:
            return 'no_folder_found'

    @property
    def dg_folder(self):
        '''This is a "falsy" property. If the folder cannot be found,
        dg.dg_folder evaluates to boolean False '''
        if self.get_dg_folder() != 'no_folder_found':
            return self.get_dg_folder()
        else:
            return False


    @property
    def csv_url(self):
        '''This is a "falsy" property. If the csv file cannot be found,
        dg.csv_url evaluates to boolean False '''
        try:
            self.csv.size
            csv_url = self.csv.url
        except ValueError:
            csv_url = False
        except:
            csv_url = False
        return csv_url


    @property
    def zip_url(self):
        '''This is a "falsy" property. If the zip file cannot be found,
        dg.zip_url evaluates to boolean False '''
        if self.get_zip_url()!='no_path_found':
            return(self.get_zip_url)
        else:
            return False
        

    def get_zip_url(self):
        # the path if the data group's folder was built from a UUID:
        uuid_path = f'{self.get_dg_folder()}/{str(self.fs_id)}.zip'
        # path if the data group's folder was built from old name-based method
        zip_file_path = f'{self.get_dg_folder()}/{self.get_name_as_slug()}.zip'
        if os.path.isfile(uuid_path):   # it is a newly-added data group
            zip_url = uuid_path
        elif os.path.isfile(zip_file_path): # it is a pre-UUID data group
            zip_url = zip_file_path
        else:
            zip_url = 'no_path_found'
        return zip_url


    def get_extracted_template_fieldnames(self):
        extract_fields = ['data_document_id','data_document_filename',
                            'prod_name', 'doc_date','rev_num', 'raw_category',
                            'raw_cas', 'raw_chem_name', 'report_funcuse']
        if self.type == 'FU':
            return extract_fields
        if self.type == 'CO':
            return extract_fields + ['raw_min_comp','raw_max_comp', 'unit_type',
                                        'ingredient_rank', 'raw_central_comp']
        if self.type == 'CP':
            for name in ['prod_name','rev_num','report_funcuse']:
                extract_fields.remove(name)
            return extract_fields + ['cat_code','description_cpcat',
                                    'cpcat_code','cpcat_sourcetype']

    def get_clean_comp_data_fieldnames(self):
        return ['id','lower_wf_analysis','central_wf_analysis', 'upper_wf_analysis']

    def clean_fields(self, exclude=None):
        super().clean_fields(exclude=exclude)
        if self.tracker.has_changed('group_type_id') and self.extracted_docs():
            msg = "The Group Type may not be changed once extracted documents have been associated with the group."
            raise ValidationError({'group_type': msg})


@receiver(models.signals.post_delete, sender=DataGroup)
def auto_delete_file_on_delete(sender, instance, **kwargs):
    """
    Deletes datagroup directory from filesystem
    when datagroup instance is deleted.
    """
    dg_folder = instance.get_dg_folder()
    if os.path.isdir(dg_folder):
        #print('deleting folder %s for data group %s'%(dg_folder, instance.pk))
        shutil.rmtree(dg_folder)

from django.db import models
from .common_info import CommonInfo
from django.core.exceptions import ValidationError
from .extracted_text import ExtractedText                    
from .unit_type import UnitType
from .weight_fraction_type import WeightFractionType
from .raw_chem import RawChem


def validate_ingredient_rank(value):
    if value < 1 or value > 999:
        raise ValidationError(
            (f'Quantity {value} is not allowed'), params={'value': value},)


class ExtractedChemical(CommonInfo, RawChem):

    raw_cas_old = models.CharField(
        "Raw CAS", max_length=100, null=True, blank=True)
    raw_chem_name_old = models.CharField("Raw chemical name", max_length=500,
                                         null=True, blank=True)
    raw_min_comp = models.CharField("Raw minimum composition", max_length=100,
                                    null=True, blank=True)
    raw_max_comp = models.CharField("Raw maximum composition", max_length=100,
                                    null=True, blank=True)
    unit_type = models.ForeignKey(UnitType, on_delete=models.PROTECT)
    report_funcuse = models.CharField("Reported functional use", max_length=100,
                                      null=True, blank=True)
    weight_fraction_type = models.ForeignKey(WeightFractionType,
                                             on_delete=models.PROTECT, null=True, default='1')
    ingredient_rank = models.PositiveIntegerField("Ingredient rank", null=True, blank=True,
                                                  validators=[validate_ingredient_rank])
    raw_central_comp = models.CharField("Raw central composition", max_length=100, null=True, blank=True)

    def __str__(self):
        return str(self.raw_chem_name) if self.raw_chem_name else ''

    @classmethod
    def detail_fields(cls):
        return ['extracted_text', 'raw_chem_name', 'raw_cas', 'raw_min_comp', 'raw_central_comp',
                'raw_max_comp', 'unit_type', 'weight_fraction_type', 'report_funcuse',
                'ingredient_rank', 'rawchem_ptr']

    def get_datadocument_url(self):
        return self.extracted_text.data_document.get_absolute_url()

    @property
    def data_document(self):
        return self.extracted_text.data_document

    def indexing(self):
        obj = ExtractedChemicalIndex(
            meta={'id': self.id},
            chem_name=self.raw_chem_name,
            raw_cas=self.raw_cas,
            raw_chem_name=self.raw_chem_name,
            facet_model_name='Extracted Chemical',
        )
        obj.save()
        return obj.to_dict(include_meta=True)

    def get_extractedtext(self):
        return self.extracted_text

    @property
    def true_cas(self):
        if hasattr(self, 'curated_chemical') and self.curated_chemical is not None:
            return self.curated_chemical.true_cas
        else:
            return None

    @property
    def true_chemname(self):
        if hasattr(self, 'curated_chemical') and self.curated_chemical is not None:
            return self.curated_chemical.true_chemname
        else:
            return None

    @property
    def sid(self):
        if hasattr(self, 'curated_chemical') and self.curated_chemical is not None:
            return self.curated_chemical.sid
        else:
            return None

from django.db import models
from .common_info import CommonInfo
from django.core.exceptions import ValidationError                    
from .extracted_text import ExtractedText                    
from .raw_chem import RawChem

class ExtractedFunctionalUse(CommonInfo, RawChem):

    raw_cas_old = models.CharField("Raw CAS", max_length=50, null=True, blank=True)
    raw_chem_name_old = models.CharField("Raw chemical name", max_length=500,
                                  null=True, blank=True)
    report_funcuse = models.CharField("Reported functional use",
                                        max_length=100, null=True, blank=True)

    def __str__(self):
        return self.raw_chem_name

    @classmethod
    def detail_fields(cls):
        return ['extracted_text','raw_cas','raw_chem_name','report_funcuse']

    def get_extractedtext(self):
        return self.extracted_text

    @property
    def data_document(self):
        return self.extracted_text.data_document

from django.db import models                    

from dashboard.models import CommonInfo                    
from .raw_chem import RawChem

class ExtractedListPresence(CommonInfo, RawChem):                    

    raw_cas_old = models.CharField("Raw CAS", max_length=100,
                                        null=True, blank=True)
    raw_chem_name_old = models.CharField("Raw chemical name", max_length=500,
                                        null=True, blank=True)
    qa_flag = models.BooleanField(default=False)

    @classmethod
    def detail_fields(cls):
        return ['raw_cas','raw_chem_name']

    def __str__(self):
        return str(self.raw_chem_name) if self.raw_chem_name else ''

    def get_datadocument_url(self):
        return self.extracted_cpcat.data_document.get_absolute_url()

    def get_extractedtext(self):
        return self.extracted_cpcat.extractedtext_ptr
    
    @property
    def data_document(self):
        return self.extracted_text.data_document


from django.db import models
from .common_info import CommonInfo
from django.core.exceptions import ValidationError
from .weight_fraction_type import WeightFractionType                    
from .extracted_chemical import ExtractedChemical                    
from .script import Script


def validate_wf_analysis(value):
    if value < 0 or value > 1:
        raise ValidationError(
            (f'Quantity {value} must be between 0 and 1'),params={'value': value})


class Ingredient(CommonInfo):
    lower_wf_analysis = models.DecimalField(max_digits=16, decimal_places=15,
                                            null=True, blank=True,
                                            validators=[validate_wf_analysis])
    central_wf_analysis = models.DecimalField(max_digits=16, decimal_places=15,
                                              null=True, blank=True,
                                              validators=[validate_wf_analysis])
    upper_wf_analysis = models.DecimalField(max_digits=16, decimal_places=15,
                                            null=True, blank=True,
                                            validators=[validate_wf_analysis])

    script = models.ForeignKey(to=Script, on_delete=models.CASCADE,
                                                    null=True, blank=True)
                                                    
    rawchem_ptr = models.OneToOneField(related_name='ingredient', parent_link=True,
        on_delete=models.CASCADE, to='dashboard.RawChem')

    def __str__(self):
        return str(self.id)

from django.db import models
from .common_info import CommonInfo
from django.core.exceptions import ValidationError
from django.utils.translation import ugettext_lazy as _

from dashboard.models import ExtractedText


class QANotes(CommonInfo):
    extracted_text = models.OneToOneField(ExtractedText, on_delete=models.CASCADE)                    
    qa_notes = models.TextField(null=True, blank=True)

    def __str__(self):
        return 'Notes for {}'.format(self.extracted_text)                    

    def clean(self):
        if self.extracted_text.qa_edited and not self.qa_notes:                    
            raise ValidationError(
                    _('Before approving, please add a note explaining your edits to the extracted data'))                    

from django.db import models
from .dsstox_lookup import DSSToxLookup                    
from .extracted_text import ExtractedText                    
from model_utils.managers import InheritanceManager
from django.apps import apps
from django.db.models.signals import pre_save
from django.dispatch import receiver                    

from model_utils import FieldTracker


class RawChem(models.Model):
    extracted_text = models.ForeignKey(ExtractedText, related_name = 'rawchem',                     
        on_delete=models.CASCADE, null=False, blank = False)

    raw_cas = models.CharField("Raw CAS", max_length=100, null=True, blank=True)
    raw_chem_name = models.CharField("Raw chemical name", max_length=500,
                                                        null=True, blank=True)
    temp_id = models.IntegerField(default=0, null=True, blank=True)
    temp_obj_name = models.CharField(max_length=255, null=True, blank=True)

    rid = models.CharField(max_length=50, null=True, blank=True)

    dsstox = models.ForeignKey(DSSToxLookup, related_name = 'curated_chemical', on_delete=models.PROTECT,                    
                                                    null=True, blank=True)

    objects = InheritanceManager()

    tracker = FieldTracker()

    def __str__(self):
        return str(self.raw_chem_name) if self.raw_chem_name else ''

    @property
    def sid(self):
        '''If there is no DSSToxLookup record via the 
        curated_chemical relationship, it evaluates to boolean False '''
        try:
            return self.curated_chemical.sid
        except AttributeError:
            return False


    def get_data_document(self):
        '''Find the child object by trying each of the classes, then return the 
            datadocument id from it
            NOTE: this will be obsolete once we move the data_document 
            foreign key into RawChem in ticket 654
         '''
        id=self.id
        try:
            return apps.get_model('dashboard.ExtractedChemical').objects.get(rawchem_ptr=id).data_document
        except apps.get_model('dashboard.ExtractedChemical').DoesNotExist:
            try: 
                return apps.get_model('dashboard.ExtractedFunctionalUse').objects.get(rawchem_ptr=id).data_document
            except apps.get_model('dashboard.ExtractedFunctionalUse').DoesNotExist:
                try: 
                    return apps.get_model('dashboard.ExtractedListPresence').objects.get(rawchem_ptr=id).data_document
                except apps.get_model('dashboard.ExtractedListPresence').DoesNotExist: 
                    return False

    @staticmethod
    def pre_save(sender, **kwargs):
        instance = kwargs.get('instance')
        previous_raw_cas = instance.tracker.previous('raw_cas')
        previous_raw_chem_name = instance.tracker.previous('raw_chem_name')
       
        if instance.tracker.has_changed('raw_cas') or \
        instance.tracker.has_changed('raw_chem_name'):
            instance.dsstox = None

pre_save.connect(RawChem.pre_save, sender=RawChem)

import math
from random import shuffle

from django.db import models
from django.urls import reverse
from django.core.validators import (URLValidator, MaxValueValidator, 
                                                    MinValueValidator)

from .common_info import CommonInfo
from .data_document import DataDocument


class Script(CommonInfo):

    TYPE_CHOICES = (('DL', 'download'),
                    ('EX', 'extraction'),
                    ('PC', 'product categorization'),
                    ('DC', 'data cleaning'))

    # Specify the share of a script's ExtractedText objects that must be
    # approved in order for the script's QA sat
    QA_COMPLETE_PERCENTAGE = 0.2


    title = models.CharField(max_length=50)
    url = models.CharField(max_length  = 100,                    
                            null       = True,
                            blank      = True,
                            validators = [URLValidator()])
    qa_begun = models.BooleanField(default=False)
    script_type = models.CharField( max_length = 2,
                                    choices    = TYPE_CHOICES,
                                    blank      = False,
                                    default    = 'EX')
    confidence = models.PositiveSmallIntegerField('Confidence', blank=True,
                                                validators=[
                                                        MaxValueValidator(100),
                                                        MinValueValidator(1)],
                                                                default=1)

    def __str__(self):
        return str(self.title)

    def get_absolute_url(self):
        return reverse('extraction_script_edit', kwargs={'pk': self.pk})

    def get_datadocument_count(self):
        return DataDocument.objects.filter(
                extractedtext__extraction_script=self.pk).count()

    def get_qa_complete_extractedtext_count(self):
        return DataDocument.objects.filter(extractedtext__qa_checked=True,
                            extractedtext__extraction_script=self.pk).count()

    def get_pct_checked(self):
        count = self.get_datadocument_count()
        pct = (0 if count == 0 else (
                      self.get_qa_complete_extractedtext_count() / count * 100))
        return "{0:.0f}%".format(pct)

    def get_pct_checked_numeric(self):
        count = self.get_datadocument_count()
        pct = (0 if count == 0 else (
                      self.get_qa_complete_extractedtext_count() / count * 100))
        return pct

    def qa_button_text(self):
        if self.get_qa_status():
            return "QA Complete" 
        elif self.qa_begun:
            return "Continue QA"
        else:
            return "Begin QA"

    def get_qa_status(self):
        """
        Compare the derived percent checked against the threshold constant
        Return true when the percent checked is above the threshold
        """
        return self.get_pct_checked_numeric() >= self.QA_COMPLETE_PERCENTAGE * 100

    def create_qa_group(self, force_doc_id=None):
        """
        Creates a QA Group for the specified Script object;
        Use all the related ExtractedText records or, if there are more than 100,
        select 20% of them. 
        """
        from .qa_group import QAGroup
        from .extracted_text import ExtractedText
        es = self
        # Handle cases where a QA group already exists for the script
        if QAGroup.objects.filter(extraction_script = es).count() == 1:
            # This is a valid state
            return QAGroup.objects.get(extraction_script = es)
        elif QAGroup.objects.filter(extraction_script = es).count() > 1:
            # this is a failure mode induced by the system's allowing
            # duplicate QA Groups to be created for a single script
            return QAGroup.objects.filter(extraction_script = es).first()

        
        # Create a new QA Group for the ExtractionScript es
        qa_group = QAGroup.objects.create(extraction_script=es)
        # Collect all the ExtractedText object keys that are related
        # to the Script being QA'd and have not yet been checked
        doc_text_ids = list(ExtractedText.objects.filter(extraction_script=es,
                                                    qa_checked=False
                                                    ).values_list('pk',
                                                                flat=True))
        # If there are fewer than 100 related records, they make up the entire QA Group
        if len(doc_text_ids) < 100 and len(doc_text_ids) > 0:
            texts = ExtractedText.objects.filter(pk__in=doc_text_ids)
        # Otherwise sample 20 percent
        elif len(doc_text_ids) >= 100 :
            # Otherwise sample 20% of them
            random_20 = math.ceil(len(doc_text_ids)/5)
            shuffle(doc_text_ids)  # this is used to make random selection of texts
            texts = ExtractedText.objects.filter(pk__in=doc_text_ids[:random_20])
        else:
            # If there are no related ExtractedText records, something has gone wrong
            # Don't make a new QA Group with zero ExtractedTexts
            # print('The Script has no related ExtractedText records')
            texts = None

        # Set the qa_group attribute of each ExtractedText record to the new QA Group    
        if texts is not None:
            for text in texts:
                text.qa_group = qa_group
                text.save()

        # If the force_doc_id argument was populated, make sure it gets assigned 
        # to the new QA Group
        if force_doc_id is not None and ExtractedText.objects.filter(pk=force_doc_id).exists():
            text = ExtractedText.objects.get(pk=force_doc_id)
            text.qa_group = qa_group
            text.save()
        
        return qa_group

        

from django.db import models
from .common_info import CommonInfo


class Taxonomy(CommonInfo):
    title = models.CharField(max_length=100, blank=False, null=False)                    
    description = models.TextField(null=True, blank=True)
    parent = models.ForeignKey('Taxonomy', on_delete=models.CASCADE,
                                                    null=True, blank=True)
    source = models.ForeignKey('TaxonomySource', on_delete=models.CASCADE)
    category_code = models.CharField(max_length=40, null=True, blank=True)
    last_edited_by = models.ForeignKey('auth.User',
                                                on_delete=models.SET_DEFAULT,
                                                default=1)
    product_category = models.ManyToManyField('PUC', through='TaxonomyToPUC')

    class Meta:
        verbose_name_plural = 'Taxonomies'

    def __str__(self):
        return str(self.title)

import csv
import time
from lxml import html

from django.urls import resolve
from django.test import TestCase

from dashboard.tests.loader import load_model_objects, fixtures_standard
from dashboard import views
from dashboard.models import *


class DashboardTest(TestCase):

    def setUp(self):
        self.objects = load_model_objects()
        # self.test_start = time.time()

    # def tearDown(self):
    #     self.test_elapsed = time.time() - self.test_start
    #     print('\nFinished with ' + self._testMethodName + ' in {:.2f}s'.format(self.test_elapsed))

    def test_public_navbar(self):
        self.client.logout()
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        self.assertIn('factotum', response_html.xpath('string(/html/body/nav//a[@href="/"]/text())'),
                      'The app name factotum should appear in the public navbar')
        self.assertNotIn('QA', response_html.xpath('string(/html/body/nav//a[@href="/qa/extractionscript/"])'),
                         'The link to /qa/ should not appear in the public navbar')

    def test_logged_in_navbar(self):
        self.client.login(username='Karyn', password='specialP@55word')
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        self.assertIn('QA', response_html.xpath('string(//*[@id="navbarQADropdownMenuLink"])'),
                      'The link to /qa/ must be in the logged-in navbar')
        found = resolve('/qa/extractionscript/')
        self.assertEqual(found.func, views.qa_extractionscript_index)

    def test_percent_extracted_text_doc(self):
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        extracted_doc_count = response_html.xpath(
            '/html/body/div[1]/div[1]/div[4]/div/div')[0].text
        self.assertEqual('0%', extracted_doc_count)

        self.objects.doc.extracted = True
        self.objects.doc.save()
        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        extracted_doc_count = response_html.xpath(
            '/html/body/div[1]/div[1]/div[4]/div/div')[0].text
        self.assertEqual('100%', extracted_doc_count)

    def test_PUC_download(self):
        p = self.objects.puc                    
        puc_line = (p.gen_cat + ',' + p.prod_fam + ',' + p.prod_type + ',' + p.description +
                    ',' + str(p.get_level()) + ',' + str(p.product_count))                    
        # get csv
        response = self.client.get('/dl_pucs/')
        self.assertEqual(response.status_code, 200)
        csv_lines = response.content.decode('ascii').split('\r\n')
        # check header
        self.assertEqual(csv_lines[0], ('gen_cat,prod_fam,prod_type,description,'                    
                                        'PUC_type,num_prods'))
        # check the PUC from loader
        self.assertEqual(csv_lines[1], puc_line)                    


class DashboardTestWithFixtures(TestCase):
    fixtures = fixtures_standard

    def test_chemical_card(self):
        response = self.client.get('/').content.decode('utf8')
        self.assertIn('DSS Tox Chemicals', response,
                      'Where is the DSS Tox Chemicals card???')
        response_html = html.fromstring(response)
        num_dss = int(response_html.xpath('//*[@name="dsstox"]')[0].text)
        dss_table_count = DSSToxLookup.objects.count()
        self.assertEqual(num_dss, dss_table_count,
                         'The number shown should match the number of records in DSSToxLookup')


class DashboardTestWithFixtures(TestCase):
    fixtures = fixtures_standard

    def test_producttopuc_counts(self):
        response = self.client.get('/').content.decode('utf8')
        self.assertIn('Products Linked To PUC', response,
                      'Where is the Products Linked to PUC card???')
        response_html = html.fromstring(response)
        num_prods = int(response_html.xpath(
            '//*[@name="product_with_puc_count"]')[0].text)

        orm_prod_puc_count = ProductToPUC.objects.values(
            'product_id').distinct().count()
        self.assertEqual(num_prods, orm_prod_puc_count,
                         'The page should show %s Products linked to PUCs' % orm_prod_puc_count)

        # Assign an already-assigned product to a different PUC with a different method
        # and confirm that the count has not changed
        p2puc = ProductToPUC.objects.first()
        p2puc.id = None
        p2puc.classification_method = 'MB'
        p2puc.puc_id = 21
        p2puc.save()

        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        num_prods = int(response_html.xpath(
            '//*[@name="product_with_puc_count"]')[0].text)
        self.assertEqual(num_prods, orm_prod_puc_count,
                         'The page should show %s Products linked to PUCs' % orm_prod_puc_count)

        # Assign a previously unassigned product to a different PUC with a different method
        # and confirm that the count has gone up
        assigned_prods = ProductToPUC.objects.values_list('product_id')
        # print(assigned_prods)
        prod = Product.objects.exclude(id__in=assigned_prods).first()
        puc21 = PUC.objects.get(id=21)
        p2puc = ProductToPUC.objects.create(
            product=prod, puc=puc21, classification_method='MA')
        p2puc.save()

        response = self.client.get('/').content.decode('utf8')
        response_html = html.fromstring(response)
        num_prods = int(response_html.xpath(
            '//*[@name="product_with_puc_count"]')[0].text)
        self.assertEqual(num_prods, orm_prod_puc_count + 1,
                         'The page should show %s Products linked to PUCs' % str(orm_prod_puc_count + 1))

from lxml import html

from django.test import Client                    
from django.urls import reverse
from django.test import TestCase, override_settings
from django.core.exceptions import ObjectDoesNotExist

from dashboard.forms import *
from factotum.settings import EXTRA
from dashboard.tests.loader import *


@override_settings(ALLOWED_HOSTS=['testserver'])
class DataDocumentDetailTest(TestCase):
    fixtures = fixtures_standard

    def setUp(self):
        self.client.login(username='Karyn', password='specialP@55word')

    def test_absent_extracted_text(self):
        # Check every data document and confirm that its detail page loads,
        # with or without a detail formset
        for dd in DataDocument.objects.all():
            ddid = dd.id
            resp = self.client.get('/datadocument/%s/' % ddid)
            self.assertEqual(resp.status_code, 200, 'The page must return a 200 status code')
            try:
                extracted_text = ExtractedText.objects.get(data_document=dd)
            except ExtractedText.DoesNotExist:
                #print(dd.id)
                self.assertContains(resp, 'No Extracted Text exists for this Data Document')
            else:
                self.assertContains(resp, '<h4>Extracted Text')

    def test_script_links(self):
        doc = DataDocument.objects.first()
        #response = self.client.get(f'/datadocument/{doc.pk}/')
        response = self.client.get(f'/datadocument/179486/')
        self.assertIn('Download Script',response.content.decode('utf-8'))
        self.assertIn('Extraction Script',response.content.decode('utf-8'))

    def test_product_card_location(self):
        response = self.client.get('/datadocument/179486/')
        html = response.content.decode('utf-8')
        e_idx = html.index('<h4>Extracted Text')
        p_idx = html.index('<h4 class="d-inline">Products')
        self.assertTrue(p_idx > e_idx, ('Product card should come after ' 
                                        'Extracted Text card'))

    def test_product_create_link(self):
        response = self.client.get('/datadocument/167497/')
        self.assertContains(response, '/link_product_form/167497/')
        data = {'title'        : ['New Product'],
                'upc'          : ['stub_1860'],
                'document_type': [1],
                'return_url'   : ['/datadocument/167497/']}
        response = self.client.post('/link_product_form/167497/', data=data)
        self.assertRedirects(response,'/datadocument/167497/')
        response = self.client.get(response.url)
        self.assertContains(response, 'New Product')

    def test_product_title_duplication(self):
        response = self.client.get('/datadocument/245401/')
        self.assertContains(response, '/link_product_form/245401/')
        # Add a new Product
        data = {'title'        : ['Product Title'],
                'upc'          : ['stub_9100'],
                'document_type': [1],
                'return_url'   : ['/datadocument/245401/']}
        response = self.client.post('/link_product_form/245401/', data=data)
        self.assertRedirects(response,'/datadocument/245401/')
        response = self.client.get(response.url)
        new_product = Product.objects.get(upc='stub_9100')
        self.assertContains(response, f'product/%s' % new_product.id )

        # Add another new Product with the same title
        data = {'title'        : ['Product Title'],
                'upc'          : ['stub_9101'],
                'document_type': [1],
                'return_url'   : ['/datadocument/245401/']}
        response = self.client.post('/link_product_form/245401/', data=data)
        self.assertRedirects(response,'/datadocument/245401/')
        response = self.client.get(response.url)
        new_product = Product.objects.get(upc='stub_9101')
        self.assertContains(response, f'product/%s' % new_product.id )

    def test_add_extracted(self):
        '''Check that the user has the ability to create an extracted record
        when the document doesn't yet have an extracted record for data 
        group types 'CP' and 'HH'
        '''
        doc = DataDocument.objects.get(pk=354784)
        self.assertFalse(doc.extracted, ("This document is matched "
                                                    "but not extracted"))
        data = {'hhe_report_number': ['47']}
        response = self.client.post('/extractedtext/edit/354784/', data=data,
                                                            follow=True)
        doc = DataDocument.objects.get(pk=354784)
        self.assertTrue(doc.extracted, "This document is not extracted ")
        page = html.fromstring(response.content)
        hhe_no = page.xpath('//dd[contains(@class, "hh-report-no")]')[0].text
        self.assertIn('47', hhe_no)


class TestDynamicDetailFormsets(TestCase):
    fixtures = fixtures_standard

    def setUp(self):

        self.client.login(username='Karyn', password='specialP@55word')

    def test_fetch_extracted_records(self):                    
        ''' Confirm that each detail child object returned by the fetch_extracted_records                    
        function has the correct parent '''
        for et in ExtractedText.objects.all():
            #print('Fetching extracted child records from %s: %s ' % (et.pk , et))
            for ex_child in et.fetch_extracted_records():                    
                child_model = ex_child.__class__ # the fetch_extracted_records function returns different classes                    
                #print('    %s: %s' % (ex_child.__class__.__name__ , ex_child ))
                self.assertEqual(et.pk , child_model.objects.get(pk=ex_child.pk).extracted_text.pk,
                    'The ExtractedChemical object with the returned child pk should have the correct extracted_text parent')

    def test_extractedsubclasses(self):
        ''' Confirm that the inheritance manager is returning appropriate
            subclass objects and ExtractedText base class objects 
         '''
        for doc in DataDocument.objects.all():
            try:
                extsub = ExtractedText.objects.get_subclass(data_document=doc)
                # A document with the CP data group type should be linked to 
                # ExtractedCPCat objects
                if doc.data_group.group_type.code=='CP':
                    #print(f'%s %s %s' % (doc.id, extsub, type(extsub)))
                    self.assertEqual(type(extsub) , ExtractedCPCat)
                elif doc.data_group.group_type.code=='HH':
                    self.assertEqual(type(extsub) , ExtractedHHDoc)
                else:
                    self.assertEqual(type(extsub) , ExtractedText)
            except ObjectDoesNotExist:
                pass
                #print('No extracted text for data document %s' % doc.id)


    def test_every_extractedtext(self):
        ''''Loop through all the ExtractedText objects and confirm that the new
        create_detail_formset method returns forms based on the correct models
        '''
        for et in ExtractedText.objects.all():
            dd = et.data_document
            ParentForm, ChildForm = create_detail_formset(dd, EXTRA)
            extracted_text_form = ParentForm(instance=et)                    
            child_formset = ChildForm(instance=et)
            # Compare the model of the child formset's QuerySet to the model
            # of the ExtractedText object's child objects
            dd_child_model  = get_extracted_models(dd.data_group.group_type.code)[1]
            childform_model = child_formset.__dict__.get('queryset').__dict__.get('model')
            self.assertEqual(dd_child_model, childform_model)

    def test_curated_chemical(self):
        ''''Confirm that if an ExtractedChemical record has been matched to DSSToxLookup, the 
            DSSToxLookup fields are displayed in the card
            This checks every data document.
        '''
        for et in ExtractedText.objects.all():
            dd = et.data_document
            ParentForm, ChildForm = create_detail_formset(dd)
            child_formset = ChildForm(instance=et)
            #print('Data doc %s , Group Type: %s ' % (dd.id, dd.data_group.type ))
            for form in child_formset.forms:
                if dd.data_group.type in ['CO','UN']:
                    ec = form.instance
                    if ec.dsstox is not None:
                        self.assertTrue( 'true_cas' in form.fields )
                        self.assertTrue( 'SID' in form.fields )
                    else:
                        self.assertFalse( 'true_cas' in form.fields )
                        self.assertFalse( 'SID' in form.fields )
                else:
                    self.assertFalse( 'true_cas' in form.fields )
            
    def test_num_forms(self):
        ''''Assure that the number of child forms is appropriate for the group                    
        type.
        '''
        group_models = {                    
                        'CO': ExtractedChemical,                    
                        'FU': ExtractedFunctionalUse,                    
                        'HP': ExtractedHabitsAndPractices,                    
                        'CP': ExtractedListPresence,                    
                        'HH': ExtractedHHRec                    
        }
        for code, model in group_models.items():                    
            if DataDocument.objects.filter(
                                document_type__group_type__code=code,
                                extractedtext__isnull=False
            ):

                doc = DataDocument.objects.filter(
                                    document_type__group_type__code=code,
                                    extractedtext__isnull=False
                ).first()
                response = self.client.get(
                                    reverse('data_document',kwargs={'pk': doc.pk})
                )
                num_forms = response.context['detail_formset'].total_form_count()
                children = model.objects.filter(
                                    extracted_text=doc.extractedtext
                ).count()

                if doc.detail_page_editable:
                    error = (f'{model.__module__} should have one more forms'
                                                                ' than instances')
                    self.assertEqual(num_forms, children + 1, error)
                else:
                    error = (f'{model.__module__} should have the same number'
                                                        ' of forms as instances')
                    self.assertEqual(num_forms, children, error)



from lxml import html                    
from importlib import import_module                    

from django.test import Client                    
from django.test import TestCase
from dashboard.tests.loader import load_model_objects, fixtures_standard
from dashboard.views.data_group import ExtractionScriptForm, DataGroupForm                    
from django.core.files.uploadedfile import SimpleUploadedFile                    
from django.contrib.auth.models import User
from django.test import Client                    
from importlib import import_module                    
from django.db.models import Max

from dashboard.forms import *

from dashboard.models import *

class DataGroupDetailTest(TestCase):

    def setUp(self):
        self.objects = load_model_objects()
        self.client.login(username='Karyn', password='specialP@55word')

    def test_detail_form_load(self):
        pk = self.objects.dg.pk
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertFalse(self.objects.doc.matched,
                    ('Document should start w/ matched False'))
        self.assertFalse(self.objects.doc.extracted,
                    ('Document should start w/ extracted False'))
        self.assertFalse(response.context['datagroup'].all_matched(),
                    ('UploadForm should be included in the page!'))
        self.assertFalse(response.context['extract_form'],
                    ('ExtractForm should not be included in the page!'))
        self.objects.doc.matched = True
        self.objects.doc.save()
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertTrue(response.context['datagroup'].all_matched(), (
                    'UploadForm should not be included in the page!'))
        self.assertIsInstance(response.context['extract_form'],
                                            ExtractionScriptForm,
                    ('ExtractForm should be included in the page!'))
        self.objects.doc.extracted = True
        self.objects.doc.save()
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertTrue(response.context['datagroup'].all_matched(),
                    ('UploadForm should not be included in the page!'))
        self.assertFalse(response.context['extract_form'],
                    ('ExtractForm should not be included in the page!'))

    def test_detail_template_fieldnames(self):
        pk = self.objects.dg.pk
        self.assertEqual(str(self.objects.dg.group_type),'Composition',
        'Type of DataGroup needs to be "composition" for this test.')
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertEqual(response.context['extract_fields'],
                ['data_document_id','data_document_filename',
                'prod_name','doc_date','rev_num', 'raw_category',
                 'raw_cas', 'raw_chem_name',
                'report_funcuse','raw_min_comp','raw_max_comp', 'unit_type',
                'ingredient_rank', 'raw_central_comp'],
                "Fieldnames passed are incorrect!")
        self.objects.gt.title = 'Functional use'
        self.objects.gt.code = 'FU'
        self.objects.gt.save()
        self.assertEqual(str(self.objects.dg.group_type),'Functional use',
            'Type of DataGroup needs to be "FU" for this test.')
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertEqual(response.context['extract_fields'],
                ['data_document_id','data_document_filename',
                'prod_name','doc_date','rev_num', 'raw_category',
                 'raw_cas', 'raw_chem_name','report_funcuse'],
                "Fieldnames passed are incorrect!")

    def test_unidentifed_group_type(self):
        pk = self.objects.dg.pk
        self.objects.doc.matched = True
        self.objects.doc.save()
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertIsInstance(response.context['extract_form'],
                                            ExtractionScriptForm,
                    ('ExtractForm should be included in the page!'))
        self.objects.gt.code = 'UN'
        self.objects.gt.save()
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertFalse(response.context['extract_form'],
                    ('ExtractForm should not be included in the page!'))

    def test_bulk_create_products_form(self):
        response = self.client.get(f'/datagroup/{self.objects.dg.pk}/')
        self.assertEqual(response.context['bulk'], 0,
                'Product linked to all DataDocuments, no bulk_create needed.')
        doc = DataDocument.objects.create(data_group=self.objects.dg)
        doc.matched = True
        self.objects.doc.matched = True
        doc.save()
        self.objects.doc.save()
        response = self.client.get(f'/datagroup/{self.objects.dg.pk}/')
        self.assertEqual(response.context['bulk'], 1,
                'Not all DataDocuments linked to Product, bulk_create needed')
        self.assertIn('Bulk Create', response.content.decode(),
                            "Bulk create button should be present.")
        p = Product.objects.create(upc='stub_47',data_source=self.objects.ds)
        ProductDocument.objects.create(document=doc, product=p)
        response = self.client.get(f'/datagroup/{self.objects.dg.pk}/')
        self.assertEqual(response.context['bulk'], 0,
        'Product linked to all DataDocuments, no bulk_create needed.')
        self.objects.dg.group_type = GroupType.objects.create(
                                                title='Habits and practices')
        response = self.client.get(f'/datagroup/{self.objects.dg.pk}/')
        self.assertNotIn('Bulk Create', response.content.decode(),
                            ("Bulk button shouldn't be present w/ "
                            "Habits and practices group_type."))

    def test_bulk_create_post(self):
        '''test the POST to create Products and link if needed'''
        # create a new DataDocument with no Product
        doc = DataDocument.objects.create(data_group=self.objects.dg)
        response = self.client.get(f'/datagroup/{self.objects.dg.pk}/')
        self.assertEqual(response.context['bulk'], 1,
                'Not all DataDocuments linked to Product, bulk_create needed')
        new_stub_id = Product.objects.all().aggregate(Max('id'))["id__max"] + 1
        response = self.client.post(f'/datagroup/{self.objects.dg.pk}/',
                                                                {'bulk':1})
        self.assertEqual(response.context['bulk'], 0,
                'Products linked to all DataDocuments, no bulk_create needed.')
        product = ProductDocument.objects.get(document=doc).product
        self.assertEqual(product.title, 'unknown',
                                        'Title should be unknown in bulk_create')
        
        self.assertEqual(product.upc, f'stub_%s' % new_stub_id,
                                    'UPC should be created for second Product')

    def test_upload_note(self):
        response = self.client.get(f'/datagroup/{DataGroup.objects.first().id}/').content.decode('utf8')
        self.assertIn('Please limit upload to <600 documents at one time', response,
                      'Note to limit upload to <600 should be on the page')

    def test_extracted_count(self):
        response = self.client.get(f'/datagroup/{DataGroup.objects.first().id}/').content.decode('utf8')
        self.assertIn('0 extracted', response,
                      'Data Group should contain a count of 0 total extracted documents')
        self.objects.doc.extracted = True
        self.objects.doc.save()
        response = self.client.get(f'/datagroup/{DataGroup.objects.first().id}/').content.decode('utf8')
        self.assertIn('1 extracted', response,
                      'Data Group should contain a count of 1 total extracted documents')

    def test_delete_doc_button(self):
        url = f'/datagroup/{DataGroup.objects.first().id}/'
        response = self.client.get(url).content.decode('utf8')
        span = '<span class="oi oi-trash"></span>'
        self.assertIn(span, response,
                      'Trash button should be present if not matched.')
        self.objects.doc.matched = True
        self.objects.doc.save()
        response = self.client.get(url).content.decode('utf8')
        span = '<span class="oi oi-circle-check" style="color:green;"></span>'
        self.assertIn(span, response,
                      'Check should be present if matched.')

    def test_detail_table_headers(self):
        pk = self.objects.dg.pk
        response = self.client.get(f'/datagroup/{pk}/').content.decode('utf8')
        self.assertIn('<th>Product</th>', response,
                      'Data Group should have Product column.')
        fu = GroupType.objects.create(title='Functional use')
        self.objects.dg.group_type = fu
        self.objects.dg.save()
        response = self.client.get(f'/datagroup/{pk}/').content.decode('utf8')
        self.assertNotIn('<th>Product</th>', response,
                      'Data Group should have Product column.')

    def test_detail_datasource_link(self):
        pk = self.objects.dg.pk
        response = self.client.get(f'/datagroup/{pk}/')
        self.assertContains(response,'<a href="/datasource/',
                    msg_prefix='Should be able to get back to DataSource from here.')

    def test_edit_redirect(self):
        dgpk = self.objects.dg.pk
        dspk = str(self.objects.ds.pk)
        gtpk = str(self.objects.gt.pk)
        data = {'name': ['Changed Name'],
                'group_type': [gtpk],
                'downloaded_by': [str(User.objects.get(username='Karyn').pk)],
                'downloaded_at': ['08/20/2017'],
                'data_source': [dspk]}
        response = self.client.post(f'/datagroup/edit/{dgpk}/', data=data)
        self.assertEqual(response.status_code, 302,
                                         "User is redirected to detail page.")
        self.assertEqual(response.url, f'/datagroup/{dgpk}/',
                                         "Should go to detail page.")

class DataGroupDetailTestWithFixtures(TestCase):
    fixtures = fixtures_standard

    def setUp(self):
        self.client.login(username='Karyn', password='specialP@55word')

    def test_download_raw_comp_data(self):
        # Ability to download, by data group, a csv file of raw extracted chemical composition data.
        # Download button would appear on data group detail page,
        # Download button would appear if any data documents have extracted text.
        # Only applies for data group type Composition. (group_type = 2)
        # Unidentified is excluded as of issue #502
        dg_co = DataGroup.objects.filter(group_type__code = 'CO').first()
        resp = self.client.get(f'/datagroup/%s/' % dg_co.id)
        self.assertIn(b'Download Raw', resp.content)

        # Test download on all data groups with ExtractedChemicals, whether
        # they are CO or UN
        dg_ids = DataDocument.objects.filter(
            id__in=ExtractedChemical.objects.all().values('extracted_text_id')
            ).order_by().values_list('data_group_id',flat=True).distinct()

        for dg_id in dg_ids:
            #resp = self.client.get(f'/datagroup/%s/' % dg_id)
            resp = self.client.get(f'/datagroup/raw_extracted_records/%s/' % dg_id)
            self.assertEqual(resp.status_code, 200)

        # File downloaded must include [specified fields]
        resp = self.client.get(f'/datagroup/raw_extracted_records/%s/' % dg_ids[0])
        field_list = 'ExtractedChemical_id,raw_cas,raw_chem_name,raw_min_comp,raw_central_comp,raw_max_comp,unit_type'
        content = list(i.decode('utf-8') for i in resp.streaming_content)
        self.assertIn(field_list, content[1])

from django.test import TestCase
from dashboard.tests.loader import load_model_objects
from dashboard.models import QAGroup, ExtractedText



class ExtractedQaTest(TestCase):

    def setUp(self):
        self.objects = load_model_objects()
        self.client.login(username='Karyn', password='specialP@55word')

    def test_qa_group_creation(self):
        # test the assignment of a qa_group to extracted text objects
        pk = self.objects.extext.pk
        self.assertIsNone(self.objects.extext.qa_group)
        self.assertEqual(len(QAGroup.objects.all()),0)
        pk = self.objects.extext.extraction_script.pk
        response = self.client.get(f'/qa/extractionscript/{pk}/')
        self.assertEqual(response.status_code,200)
        qa_group = QAGroup.objects.get(
                        extraction_script=self.objects.extext.extraction_script)
        ext = ExtractedText.objects.get(qa_group=qa_group)
        self.assertIsNotNone(ext.qa_group)
        response = self.client.get(f'/qa/extractedtext/{ext.pk}/')

    def test_qa_approval_redirect(self):
        # first need to create a QAGroup w/ this get request.
        self.client.get(f'/qa/extractionscript/{self.objects.exscript.pk}/')
        pk = self.objects.extext.pk
        response = self.client.post(f'/qa/extractedtext/{pk}/',{'approve':[47]})                    
        self.assertEqual(response.url, '/qa/extractionscript/',("User should be redirected to "
                                "QA homepage after last extext is approved."))

from django.test import TestCase
from django.test.client import Client
from lxml import html

from django.urls import resolve
from django.contrib.auth.models import User
from dashboard.tests.loader import fixtures_standard


class FacetedSearchTest(TestCase):
    fixtures = fixtures_standard

    def setUp(self):
        self.c = Client()

    def test_faceted_search_excludes_chemicals(self):
        response = self.c.get('/find/?q=ethyl')
        self.assertContains(response, 'Data Document')
        self.assertNotContains(response, 'Extracted Chemical')
        self.assertNotContains(response, 'DSSTox Substance')

    def test_faceted_search_returns_upc(self):
        response = self.c.get('/find/?q=avcat')
        self.assertContains(response, 'stub_1845')


    def test_group_type_facet(self):
        response = self.c.get('/find/?q=diatom')
        self.assertContains(response, 'Filter by Group Type')

        response = self.c.get('/find/?q=diatom&group_type=Unidentified')                    
        self.assertContains(response, 'Showing 1 - 20 of')

        response = self.c.get('/find/?q=diatom&group_type=BadGroupName')
        self.assertContains(response, 'Sorry, no result found')

    def test_faceted_search_renders_div(self):
        response = self.c.get('/find/?q=terro')
        self.assertNotContains(response, '<table')
        self.assertContains(response, '<div class="results-wrapper">')

    def test_product_facet_returns(self):
        response = self.c.get('/find/?q=insecticide')
        brands = response.content.count(b'name="brand_name"')
        # default set to options = {"size": 0} in /dashboard/views/search.py
        self.assertTrue(brands>10, ('There should be ~143 product returns '
                                                        'for this search term'))

from django.test import Client
from dashboard.tests.loader import *
from django.test import TestCase, override_settings, RequestFactory
from dashboard.models import DataDocument, Script, ExtractedText, ExtractedChemical, QAGroup
from django.db.models import Count


@override_settings(ALLOWED_HOSTS=['testserver'])
class TestQaPage(TestCase):
    fixtures = fixtures_standard

    def setUp(self):
        self.factory = RequestFactory()
        self.client.login(username='Karyn', password='specialP@55word')

    def test_qa_begin(self):
        """
        Check that starting the QA process flips the variable on the Script
        """
        self.assertFalse(Script.objects.get(pk=5).qa_begun,
                         'The Script should have qa_begun of False at the beginning')
        response = self.client.get('/qa/extractionscript/5/')
        self.assertTrue(Script.objects.get(pk=5).qa_begun,
                        'qa_begun should now be true')

    def test_new_qa_group_urls(self):
        # Begin from the QA index page
        response = self.client.get(f'/qa/extractionscript/')
        self.assertIn(
            f"/qa/extractionscript/15/'> Begin QA".encode(), response.content)
        # Script 15 has one ExtractedText object
        pk = 15
        response = self.client.get(f'/qa/extractionscript/{pk}/')
        et = ExtractedText.objects.filter(extraction_script=pk).first()
        self.assertIn(f'/qa/extractedtext/{et.pk}/'.encode(), response.content)
        # After opening the URL, the following should be true:
        # One new QA group should be created
        group_count = QAGroup.objects.filter(extraction_script_id=pk).count()
        self.assertTrue(group_count == 1)
        # The ExtractionScript's qa_begun property should be set to True
        self.assertTrue(Script.objects.get(pk=15).qa_begun)
        # The ExtractedText object should be assigned to the QA Group
        group_pk = QAGroup.objects.get(extraction_script_id=pk).pk
        et = ExtractedText.objects.filter(extraction_script=pk).first()
        self.assertTrue(et.qa_group_id == group_pk)
        # The link on the QA index page should now say "Continue QA"
        response = self.client.get(f'/qa/extractionscript/')
        self.assertIn(
            f"'/qa/extractionscript/15/\'> Continue QA".encode(), response.content)

    def test_qa_script_without_ext_text(self):
        # Begin from the QA index page
        response = self.client.get(f'/qa/extractionscript/')
        self.assertIn(
            f"/qa/extractionscript/15/'> Begin QA".encode(), response.content)
        # Script 9 has no ExtractedText objects
        pk = 9
        # a user will see no link on the QA index page, but it's still
        # possible to enter the URL
        response = self.client.get(f'/qa/extractionscript/{pk}/', follow=True)
        self.assertEqual(response.status_code, 200)                    

    def test_data_document_qa(self):
        # Open the QA page for a Composition ExtractedText record that has no QA group
        # and is in a Script with < 100 documents
        scr = Script.objects.annotate(num_ets=Count('extractedtext')).filter(
            num_ets__lt=100).filter(script_type='EX').first()
        pk = ExtractedText.objects.filter(qa_group=None).filter(extraction_script=scr
                                                                ).filter(
            data_document__data_group__group_type__code='CO').first().pk
        response = self.client.get(f'/qa/extractedtext/{pk}/')

        # After opening the QA link from the data document detail page, the
        # following should be true:
        # One new QA group should be created
        scr = ExtractedText.objects.get(pk=pk).extraction_script
        group_count = QAGroup.objects.filter(extraction_script=scr).count()
        self.assertTrue(group_count == 1)
        # The ExtractionScript's qa_begun property should be set to True
        self.assertTrue(scr.qa_begun)
        # The ExtractedText object should be assigned to the QA Group
        new_group = QAGroup.objects.get(extraction_script=scr)
        et = ExtractedText.objects.get(pk=pk)
        self.assertTrue(et.qa_group == new_group)
        # The link on the QA index page should now say "Continue QA"
        response = self.client.get(f'/qa/extractionscript/')
        self.assertIn(
            f"'/qa/extractionscript/{scr.pk}/\'> Continue QA".encode(), response.content)

        # Open the QA page for an ExtractedText record that has no QA group and
        # is related to a script with over 100 documents
        scr = Script.objects.annotate(num_ets=Count(
            'extractedtext')).filter(num_ets__gt=100).first()
        pk = ExtractedText.objects.filter(extraction_script=scr).first().pk
        response = self.client.get(f'/qa/extractedtext/{pk}/')
        scr = ExtractedText.objects.get(pk=pk).extraction_script
        # After opening the QA link from the data document detail page, the
        # following should be true:
        # One new QA group should be created
        new_group = QAGroup.objects.get(extraction_script=scr)

        # There should be a lot of ExtractedText records assigned to the QA Group
        initial_qa_count = ExtractedText.objects.filter(
            qa_group=new_group).count()
        self.assertTrue(initial_qa_count > 100)

        # Select a document that shares a Script with the
        # QA Group created above BUT DOES NOT BELONG TO THE QA GROUP
        pk = ExtractedText.objects.filter(
            extraction_script_id=scr.id).filter(qa_group=None).first().pk
        # Open its QA page via the /datdocument/qa path
        response = self.client.get(f'/qa/extractedtext/{pk}/')
        # Make sure that the number of documents in the QA Group has increased
        self.assertGreater(ExtractedText.objects.filter(
            qa_group=new_group).count(), initial_qa_count)

    def test_habitsandpractices(self):
        # Begin from the QA index page
        response = self.client.get(f'/habitsandpractices/54/')
        self.assertContains(response, '<b>Add New Habit and Practice</b>')

    def test_dd_link(self):
        # Open the Script page to create a QA Group
        response = self.client.get('/qa/extractedtext/5', follow=True)
        self.assertIn(b'/datadocument/5', response.content)

    def test_approval(self):
        # Open the Script page to create a QA Group
        response = self.client.get('/qa/extractionscript/5', follow=True)
        # Follow the first approval link
        response = self.client.get('/qa/extractedtext/7', follow=True)
        # print(response.context['extracted_text'])

    def test_hidden_fields(self):
        '''ExtractionScript 15 includes a functional use data group with pk = 5.
        Its QA page should hide the composition fields '''
        # Create the QA group by opening the Script's page
        response = self.client.get('/qa/extractionscript/15/', follow=True)
        # Open the DataGroup's first QA approval link
        response = self.client.get('/qa/extractedtext/5/', follow=True)
        # A raw_cas field should be in the page
        self.assertIn(
            b'<input type="text" name="rawchem-1-raw_cas"', response.content)
        # There should not be any unit_type field in the functional use QA display
        self.assertNotIn(
            b'<input type="text" name="rawchem-1-unit_type"', response.content)
        # The values shown should match the functional use record, not the chemical record
        self.assertIn(b'Functional Use Chem1', response.content)

        # Go back to a different ExtractionScript
        response = self.client.get('/qa/extractionscript/5', follow=True)
        # Open the QA page for a non-FunctionalUse document
        response = self.client.get('/qa/extractedtext/7/', follow=True)
        # This page should include a unit_type input form
        self.assertIn(b'rawchem-1-unit_type', response.content)

    def test_cpcat_qa(self):
        # Begin from the Chemical Presence QA index page
        response = self.client.get(f'/qa/chemicalpresence/')
        self.assertIn(
            f"/qa/chemicalpresencegroup/49/\'> View Chemical Presence Lists".encode(), response.content)

        response = self.client.get(
            f'/qa/chemicalpresencegroup/49', follow=True)
        # The table should include the "Begin QA" link
        self.assertIn(
            f'/qa/extractedtext/254781/"> Begin QA'.encode(), response.content)

        elps = ExtractedListPresence.objects.filter(
            extracted_text__data_document_id=254781)
        self.assertEqual(elps.filter(qa_flag=True).count(), 0)
        response = self.client.get(f'/qa/extractedtext/254781/', follow=True)
        # Navigating to the extractedtext QA page should cause
        # the sampled child records to be flagged with qa_flag=True
        elps = ExtractedListPresence.objects.filter(
            extracted_text__data_document_id=254781)
        self.assertEqual(elps.filter(qa_flag=True).count(), 30)

        # The QA page should only show the flagged records
        elp_flagged = elps.filter(qa_flag=True).first()
        self.assertIn(elp_flagged.raw_cas.encode(), response.content)

        elp_not_flagged = elps.filter(qa_flag=False).first()
        self.assertNotIn(elp_not_flagged.raw_cas.encode(), response.content)

    def test_every_extractedtext_qa(self):
        # Attempt to open a QA page for every ExtractedText record
        for et in ExtractedText.objects.all():
            response = self.client.get(f'/qa/extractedtext/%s' % et.data_document_id, follow=True)                    
            if response.status_code != 200:
                print(et.data_document_id)
            self.assertEqual(response.status_code, 200)                    

from lxml import html                    

from django.test import TestCase                    
from dashboard.tests.loader import load_model_objects, fixtures_standard                    
from django.contrib.staticfiles.testing import StaticLiveServerTestCase

from dashboard.models import *
from selenium import webdriver                    
from django.conf import settings                    
from selenium.webdriver.support.select import Select                    
from selenium.webdriver.common.by import By                    
from selenium.webdriver.support.ui import WebDriverWait                    
from selenium.webdriver.support import expected_conditions as ec                    


def log_karyn_in(object):
    '''
    Log user in for further testing.
    '''
    object.browser.get(object.live_server_url + '/login/')
    body = object.browser.find_element_by_tag_name('body')
    object.assertIn('Please sign in', body.text)
    username_input = object.browser.find_element_by_name("username")
    username_input.send_keys('Karyn')
    password_input = object.browser.find_element_by_name("password")
    password_input.send_keys('specialP@55word')
    object.browser.find_element_by_class_name('btn').click()


class TestEditsWithSeedData(StaticLiveServerTestCase):
    fixtures = fixtures_standard

    def setUp(self):
        if settings.TEST_BROWSER == 'firefox':                    
            self.browser = webdriver.Firefox()                    
        else:                    
            self.browser = webdriver.Chrome()                    
        log_karyn_in(self)

    def tearDown(self):
        self.browser.quit()

    def test_break_curation(self):
        '''
        Changing the raw_cas or raw_chemname on a RawChem record with a related DssToxLookup should cause
        the relationship to be deleted.
        '''
        # currently uses a single data document
        ets_with_curation = ExtractedText.objects.filter(
            rawchem__dsstox__isnull=False).filter(pk=245401)
        for et in ets_with_curation:
            doc_qa_link = f'/qa/extractedtext/%s/' % et.data_document_id
            self.browser.get(self.live_server_url + doc_qa_link)

            rc_id = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-rawchem_ptr"]').get_attribute('value')
            true_cas = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-true_cas"]').get_attribute('value')
            rc = RawChem.objects.get(pk=rc_id)
            self.assertEqual(true_cas, rc.dsstox.true_cas,
                             'The displayed True CAS should match the object attribute')
            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()
            raw_cas_input = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-raw_cas"]')
            raw_cas_input.send_keys('changed cas')
            self.browser.find_element_by_xpath('//*[@id="save"]').click()
            rc = RawChem.objects.get(pk=rc_id)   # reload the rawchem record
            self.assertEqual(
                None, rc.dsstox, 'The same rawchem record should now have nothing in its dsstox link')

    def test_new_chem(self):
        '''
        Adding a new ExtractedChemical without a unit type should return a validation error
        '''
        # currently "loops" over just a single data document. Other cases can be added
        ets_with_curation = ExtractedText.objects.filter(
            rawchem__dsstox__isnull=False).filter(pk=245401)
        for et in ets_with_curation:
            doc_qa_link = f'/qa/extractedtext/%s/' % et.data_document_id
            self.browser.get(self.live_server_url + doc_qa_link)

            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()
            # wait for the Save button to be clickable
            wait = WebDriverWait(self.browser, 10)
            save_button = wait.until(
                ec.element_to_be_clickable((By.XPATH, "//*[@id='save']")))
            # edit the Raw CAS field
            raw_cas_input = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]')
            raw_cas_input.send_keys('test raw cas')
            # Save the edits
            save_button.send_keys("\n")
            # Check for the error message after clicking Save
            wait.until(ec.visibility_of(self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]/parent::*')))
            parent_div = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]/parent::*')
            card_div = parent_div.find_element_by_xpath(
                '../..')
            self.assertTrue("errorlist" in card_div.get_attribute("innerHTML"))

            # Try editing a new record correctly
            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()
            # wait for the Save button to be clickable
            wait = WebDriverWait(self.browser, 10)
            save_button = wait.until(
                ec.element_to_be_clickable((By.XPATH, "//*[@id='save']")))
            raw_cas_input = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]')
            raw_cas_input.send_keys('test raw cas')
            # The unit_type field is the only required one
            unit_type_select = Select(self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-unit_type"]'))
            unit_type_select.select_by_index(1)

            save_button.send_keys("\n")
            # Check for the absence of an error message after clicking Save
            parent_div = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-1-raw_cas"]/parent::*')
            card_div = parent_div.find_element_by_xpath(
                '../..')
            self.assertFalse(
                "errorlist" in card_div.get_attribute("innerHTML"))

    def test_redirects(self):
        '''
        Editing the data document type should return the user to the page on which the edits were made
        '''
        for doc_id in [7]:
            # QA Page
            doc_qa_link = f'/qa/extractedtext/%s/' % doc_id
            self.browser.get(self.live_server_url + doc_qa_link)
            doc_type_select = Select(self.browser.find_element_by_xpath(                    
                '//*[@id="id_document_type"]'))                    
            option = doc_type_select.first_selected_option
            doc_type_select.select_by_visible_text("ingredient disclosure")
            self.assertIn(doc_qa_link, self.browser.current_url)

            # Data Document Detail Page
            doc_detail_link = f'/datadocument/%s/' % doc_id                    
            self.browser.get(self.live_server_url + doc_detail_link)                    
            doc_type_select = Select(self.browser.find_element_by_xpath(                    
                '//*[@id="id_document_type"]'))                    
            doc_type_select.select_by_visible_text("MSDS")                    
            self.assertIn(doc_detail_link, self.browser.current_url)                    

    def test_qa_approval(self):
        '''
        Test the QA process in the browser
        1. Open the QA page for an ExtractedText record
        2. Edit one of the child records
        3. Attempt to approve the document without a QA note
        4. Add a note

        5. Approve
        '''
        for doc_id in [7,      # Composition
                       5,      # Functional Use
                       254781,  # Chemical Presence List
                       354783,  # HHE Report
                       ]:

            # QA Page
            qa_url = self.live_server_url + f'/qa/extractedtext/{doc_id}/'
            self.browser.get(qa_url)
            # Activate the edit mode
            self.browser.find_element_by_xpath(
                '//*[@id="btn-toggle-edit"]').click()

            # Modify the first raw_chem_name field's value

            raw_chem = self.browser.find_element_by_xpath(                    
                '//*[@id="id_rawchem-0-raw_chem_name"]')                    
            # Wait for the field to be editable
            wait = WebDriverWait(self.browser, 10)
            raw_chem_name_field = wait.until(ec.element_to_be_clickable(
                (By.XPATH, "//*[@id='id_rawchem-0-raw_chem_name']")))

            old_raw_chem_name = raw_chem_name_field.get_attribute('value')

            # Get the detailed child record's ID
            rawchem_id_field = self.browser.find_element_by_xpath(
                '//*[@id="id_rawchem-0-rawchem_ptr"]')
            rawchem_id = rawchem_id_field.get_attribute('value')
            # print(rawchem_id)

            raw_chem_name_field.send_keys(' edited')
            # save changes
            self.browser.find_element_by_xpath('//*[@id="save"]').click()

            # Confirm the changes in the ORM
            rc = RawChem.objects.get(pk=rawchem_id)
            self.assertEqual(rc.raw_chem_name, f'%s edited' %
                             old_raw_chem_name, 'The raw_chem_name field should have changed')

            et = ExtractedText.objects.get(pk=doc_id)
            # print(et.data_document.data_group.group_type)
            self.assertTrue(
                et.qa_edited, 'The qa_edited attribute should be True')

            # Click Approve without any notes and confirm validation failure
            self.browser.find_element_by_xpath('//*[@id="approve"]').click()
            # The QA notes field should be invalid
            qa_notes_field = self.browser.find_element_by_xpath(                    
                '//*[@id="id_qa_notes"]')                    
            self.assertIn('is-invalid', qa_notes_field.get_attribute('class'))                    
            et.refresh_from_db()
            self.assertFalse(
                et.qa_checked, 'The qa_checked attribute should be False')

            # Add the mandatory QA note
            qa_notes_field.send_keys('Some QA Notes')
            # Click "Approve" again
            self.browser.find_element_by_xpath('//*[@id="approve"]').click()
            et.refresh_from_db()
            self.assertTrue(
                et.qa_checked, 'The qa_checked attribute should be True')


    def test_datadoc_add_extracted(self):
        '''
        Test that when a datadocument has no ExtractedText,
        the user can add one in the browser
        1.
        '''

        for doc_id in [155324   # CO record with no ExtractedText
                       ]:
            # QA Page
            dd_url = self.live_server_url + f'/datadocument/{doc_id}/'
            self.browser.get(dd_url)
            # Activate the edit mode
            self.browser.find_element_by_xpath(
                '//*[@id="btn-add-or-edit-extracted-text"]').click()

            # Verify that the modal window appears by finding the Cancel button
            # The modal window does not immediately appear, so the browser
            # should wait for the button to be clickable
            wait = WebDriverWait(self.browser, 10)
            cancel_button = wait.until(
                ec.element_to_be_clickable(
                    (By.XPATH, "//*[@id='extracted-text-modal-cancel']")
                )
            )
            self.assertEqual("Cancel", cancel_button.text,
                             'The Cancel button should say Cancel')
            cancel_button.click()
            # Verify that no ExtractedText record was created
            self.assertEqual(0, ExtractedText.objects.filter(
                data_document_id=doc_id).count(),
                "the count of ExtractedText records related to the \
                data document should be zero")

            # Wait for the modal div to disappear
            edit_modal = wait.until(
                ec.invisibility_of_element(
                    (By.XPATH, '//*[@id="extextModal"]')
                )
            )
            # Click the Add button again to reopen the editor
            add_button = self.browser.find_element_by_xpath(
                '//*[@id="btn-add-or-edit-extracted-text"]')
            add_button.click()
            # Once again, check that the controls on the modal form are clickable
            # before trying to interact with them
            cancel_button = wait.until(
                ec.element_to_be_clickable(
                    (By.XPATH, "//*[@id='extracted-text-modal-cancel']")
                )
            )
            prod_name_box = self.browser.find_element_by_id(
                'id_prod_name')
            # Add a prod_name value to the box
            prod_name_box.send_keys('Fake Product')
            save_button = self.browser.find_element_by_id(
                'extracted-text-modal-save')
            save_button.click()
            # Confirm the presence of the new ExtractedText record
            et = ExtractedText.objects.get(data_document_id=doc_id)
            self.assertEqual('Fake Product', et.prod_name,
                             "The prod_name of the new object should match what was entered")



from lxml import html                    
from django.test import TestCase                    
from dashboard.tests.loader import load_model_objects                    
from dashboard.models import *                    
import os
import csv                    
import time                    
import unittest                    
import collections                    
import json                    
import re                    
from selenium import webdriver                    
from selenium.webdriver.support.select import Select                    
from selenium.webdriver.support.ui import WebDriverWait                    
from selenium.webdriver.support import expected_conditions as EC                    
from selenium.webdriver.common.by import By                    
from selenium.webdriver.common.keys import Keys                    
from selenium.common.exceptions import NoSuchElementException                    
from django.conf import settings                    
from django.contrib.staticfiles.testing import StaticLiveServerTestCase
from dashboard.models import *                    


def log_karyn_in(object):
    '''
    Log user in for further testing.
    '''
    object.browser.get(object.live_server_url + '/login/')
    body = object.browser.find_element_by_tag_name('body')
    object.assertIn('Please sign in', body.text)
    username_input = object.browser.find_element_by_name("username")
    username_input.send_keys('Karyn')
    password_input = object.browser.find_element_by_name("password")
    password_input.send_keys('specialP@55word')
    object.browser.find_element_by_class_name('btn').click()


class TestIntegration(StaticLiveServerTestCase):

    def setUp(self):
        self.objects = load_model_objects()
        if settings.TEST_BROWSER == 'firefox':                    
            self.browser = webdriver.Firefox()                    
        else:                    
            self.browser = webdriver.Chrome()                    
        log_karyn_in(self)

    def tearDown(self):
        self.browser.quit()

    def test_hem(self):
        for i in range(27):
            ds = DataSource.objects.create(title=f'Test_DS_{i}')
        list_url = self.live_server_url + '/datasources/'
        self.browser.get(list_url)
        row_count = len(self.browser.find_elements_by_xpath("//table[@id='sources']/tbody/tr"))
        self.assertEqual(row_count, 25, 'Should be 25 datasources in the table')
        # go to edit page from datasource list
        self.browser.find_element_by_xpath('//*[@title="edit"]').click()
        btn = self.browser.find_element_by_name('cancel')
        self.assertEqual(btn.get_attribute("href"), list_url,
                         "User should go back to list view when clicking cancel")
        self.browser.find_element_by_name('submit').click()
        self.assertIn('/datasource/', self.browser.current_url,
                      "User should always return to detail page after submit")
        detail_url = self.live_server_url + f'/datasource/{ds.pk}'
        self.browser.get(detail_url)
        # go to edit page from datasource detail
        self.browser.find_element_by_xpath('//*[@title="edit"]').click()
        btn = self.browser.find_element_by_name('cancel')
        self.assertEqual(btn.get_attribute("href"), detail_url,
                         "User should go back to detail view when clicking cancel")
        self.browser.find_element_by_name('submit').click()
        self.assertIn('/datasource/', self.browser.current_url,
                      "User should always return to detail page after submit")

        num_pucs = len(PUC.objects.filter(kind='FO'))
        self.browser.get(self.live_server_url)
        import time                    
        time.sleep(3)  # or however long you think it'll take you to scroll down to bubble chart
        bubbles = self.browser.find_elements_by_class_name('bubble')
        self.assertEqual(num_pucs, len(bubbles), ('There should be a circle'
                                                  'drawn for every PUC'))

    def test_datagroup(self):
        list_url = self.live_server_url + '/datagroups/'
        self.browser.get(list_url)
        self.browser.find_element_by_xpath('//*[@title="edit"]').click()
        btn = self.browser.find_element_by_name('cancel')
        self.assertEqual(btn.get_attribute("href"), list_url,
                         "User should go back to list view when clicking cancel")

        dg = DataGroup.objects.first()
        ds_detail_url = f'{self.live_server_url}/datasource/{dg.data_source.pk}'
        self.browser.get(ds_detail_url)
        self.browser.find_elements_by_xpath('//*[@title="edit"]')[1].click()
        btn = self.browser.find_element_by_name('cancel')
        self.assertEqual(btn.get_attribute("href"), ds_detail_url,
                         "User should go back to detail view when clicking cancel")

        dg_detail_url = f'{self.live_server_url}/datagroup/{dg.pk}/'
        self.browser.get(dg_detail_url)
        self.browser.find_element_by_xpath('//*[@title="edit"]').click()
        btn = self.browser.find_element_by_name('cancel')
        self.assertEqual(btn.get_attribute("href"), dg_detail_url,
                         "User should go back to detail view when clicking cancel")

        edit_url = f'{self.live_server_url}/datagroup/edit/{dg.pk}/'
        self.browser.get(edit_url)
        self.browser.find_element_by_name('cancel').click()
        self.assertIn('/datagroups/', self.browser.current_url,
                      "User should always return to detail page after submit")

    def test_product(self):
        p = self.objects.p
        puc = self.objects.puc
        tag = self.objects.pt
        PUCToTag.objects.create(content_object=puc, tag=tag)
        ProductToPUC.objects.create(product=p, puc=puc)
        url = self.live_server_url + f'/product/{p.pk}/'
        self.browser.get(url)
        submit = self.browser.find_element_by_id('tag_submit')
        self.assertFalse(submit.is_enabled(), "Button should be disabled")
        tag = self.browser.find_element_by_class_name('taggit-tag')
        tag.click()
        self.assertTrue(submit.is_enabled(), "Button should be enabled")

    def test_field_exclusion(self):
        doc = self.objects.doc
        # The element should not appear on the QA page
        qa_url = self.live_server_url + f'/qa/extractedtext/{doc.pk}/'
        self.browser.get(qa_url)
        with self.assertRaises(NoSuchElementException):
            self.browser.find_element_by_xpath('//*[@id="id_rawchem-0-weight_fraction_type"]')
        with self.assertRaises(NoSuchElementException):
            self.browser.find_element_by_xpath('//*[@id="id_rawchem-0-true_cas"]')
        with self.assertRaises(NoSuchElementException):
            self.browser.find_element_by_xpath('//*[@id="id_rawchem-0-true_chemname"]')
        with self.assertRaises(NoSuchElementException):
            self.browser.find_element_by_xpath('//*[@id="id_rawchem-0-SID"]')
        # make sure the test can pick up one that should be there
        try:
            self.browser.find_element_by_xpath('//*[@id="id_rawchem-0-raw_cas"]')
        except NoSuchElementException:
            self.fail("Absence of raw_cas element raised exception")

        # The element should appear on the datadocument page
        dd_url = self.live_server_url + f'/datadocument/{doc.pk}/'
        self.browser.get(dd_url)
        try:
            self.browser.find_element_by_xpath('//*[@id="id_rawchem-0-weight_fraction_type"]')
        except NoSuchElementException:
            self.fail("Absence of weight_fraction_type element raised exception")


from django.utils import timezone
from django.contrib.auth.models import User

from dashboard.models import *

fixtures_standard = [ '00_superuser',
                      '01_lookups',
                      '02_datasource',
                      '03_datagroup',
                      '04_PUC', 
                      '05_product',
                      '06_datadocument',
                      '07_rawchem_etc',
                       '08_script',                    
                    '09_productdocument',  
                    '10_habits_and_practices',                    
                     '11_habits_and_practices_to_puc',                    
                      '12_product_to_puc',
                        '13_puc_tag'                    
                        ]                    

class dotdict(dict):
    """dot.notation access to dictionary attributes"""
    __getattr__ = dict.get
    __setattr__ = dict.__setitem__
    __delattr__ = dict.__delitem__

def load_model_objects():
    user = User.objects.create_user(username='Karyn',
                                        password='specialP@55word')
    superuser = User.objects.create_superuser(username='SuperKaryn',
                                              password='specialP@55word',
                                              email='me@epa.gov')
    ds = DataSource.objects.create(title='Data Source for Test',
                                        estimated_records=2, state='AT',
                                        priority='HI')
    script = Script.objects.create(title='Test Download Script',
                                        url='http://www.epa.gov/',
                                        qa_begun=False, script_type='DL')
    exscript = Script.objects.create(title='Test Extraction Script',
                                   url='http://www.epa.gov/',
                                   qa_begun=False, script_type='EX')
    gt = GroupType.objects.create(title='Composition', code='CO')
    dg = DataGroup.objects.create(name='Data Group for Test',
                                        description='Testing...',
                                        data_source = ds,
                                        download_script=script,
                                        downloaded_by=user,
                                        downloaded_at=timezone.now(),
                                        group_type=gt,
                                        csv='register_records_matching.csv',
                                        url='https://www.epa.gov')
    dt = DocumentType.objects.create(title='MSDS',
                                    code='MS', group_type=gt)

    doc = DataDocument.objects.create(title='test document',
                                            data_group=dg,
                                            document_type=dt,
                                            filename='example.pdf')
    p = Product.objects.create(data_source=ds,
                                upc='Test UPC for ProductToPUC')

    puc = PUC.objects.create(gen_cat='Test General Category',
                              prod_fam='Test Product Family',
                              prod_type='Test Product Type',
                             description='Test Product Description',
                             last_edited_by = user,
                             kind='FO')

    extext = ExtractedText.objects.create(
                                    prod_name='Test Extracted Text Record',
                                    data_document=doc,
                                    extraction_script=exscript
                                    )
    ut = UnitType.objects.create(title='percent composition')
    wft = WeightFractionType.objects.create(title= 'reported', description= 'reported')
    ec = ExtractedChemical.objects.create(extracted_text=extext,
                                        unit_type=ut,
                                        weight_fraction_type = wft,
                                        raw_chem_name= 'Test Chem Name',
                                        raw_cas='test_cas'
                                        )
    rc = ec.rawchem_ptr
    ing = Ingredient.objects.create(lower_wf_analysis = 0.123456789012345,
                                    central_wf_analysis = 0.2,
                                    upper_wf_analysis = 1,
                                    script = script,
                                    rawchem_ptr = rc)
    
    pt = PUCTag.objects.create(name="Test PUC Attribute")
    pd = ProductDocument.objects.create(product=p, document=doc)
    ehp = ExtractedHabitsAndPractices.objects.create(extracted_text=extext,
                                                     product_surveyed='Test Product Surveyed',
                                                     prevalence='Continuous')


    return dotdict({'user':user,
                    'superuser':superuser,
                    'ds':ds,
                    'script':script,
                    'exscript':exscript,
                    'dg':dg,
                    'doc':doc,
                    'p':p,
                    'puc':puc,
                    'extext':extext,
                    'ut':ut,
                    'wft':wft,
                    'rc':rc,
                    'ec':ec,
                    'pt':pt,
                    'pd':pd,
                    'ing':ing,
                    'dt':dt,
                    'gt':gt,
                    'ehp':ehp
                    })

from django.test import TestCase
from django.utils import timezone
from django.contrib.auth.models import User
from django.core.exceptions import ValidationError                    

from dashboard.tests.loader import load_model_objects                    
from dashboard.models import ExtractedText, QANotes


class ExtractedTest(TestCase):

    def setUp(self):
        self.objects = load_model_objects()

    def test_extracted_doc_date_validation(self):
        # check validation for proper length string
        text = ExtractedText(doc_date= 'Wednesday, January 21, 2014',
                                data_document=self.objects.doc,
                                extraction_script=self.objects.script)
        self.assertRaises(ValidationError, text.clean())
        # check validation not thrown for arbitrary date string less than 25 chars
        text = ExtractedText(doc_date= 'January 1984',
                             data_document=self.objects.doc,
                             extraction_script=self.objects.script)
        try:
            text.clean()
        except ValidationError:
            self.fail("clean() raised ExceptionType unexpectedly!")

        # check validation not thrown if doc_date is null
        text = ExtractedText(data_document=self.objects.doc,
                                extraction_script=self.objects.script)
        try:
            text.clean()
        except ValidationError:
            self.fail("clean() raised ExceptionType unexpectedly!")

    def test_extracted_text_qa_notes(self):                    
        self.objects.extext.qa_edited = True                    
        note = QANotes.objects.create(extracted_text=self.objects.extext)                    
        self.assertEqual(note.qa_notes, None)                    
        self.assertRaises(ValidationError, note.clean)                    

    def test_long_qa_notes(self):
        self.objects.extext.qa_edited = True                    
        note = QANotes.objects.create(extracted_text=self.objects.extext)                    
        self.assertEqual(note.qa_notes, None)                    
        note.qa_notes = "A short QA note"
        try:
            note.clean()
        except Exception as ex:
            template = "An exception of type {0} occurred. Arguments:\n{1!r}"
            message = template.format(type(ex).__name__, ex.args)

        long_note = 'A long QA note' * 200
        note.qa_notes = long_note
        try:
            note.clean()
        except Exception as ex:
            template = "An exception of type {0} occurred. Arguments:\n{1!r}"
            message = template.format(type(ex).__name__, ex.args)

from django.urls import resolve
from django.test import TestCase
from django.http import HttpRequest                    

from lxml import html                    

from dashboard import views
from dashboard.models import *                    
from dashboard.forms import create_detail_formset
from dashboard.tests.loader import load_model_objects



class HabitViewTest(TestCase):
    multi_db = True
    def setUp(self):
        self.objects = load_model_objects()


    def test_habitsandpractices(self):
        found = resolve(f'/habitsandpractices/{self.objects.doc.pk}/')
        self.assertEqual(found.func, views.habitsandpractices)

    def test_link_habitandpractice_to_puc(self):
        found = resolve(f'/link_habitandpractice_to_puc/{self.objects.ehp.pk}/')
        self.assertEqual(found.func, views.link_habitsandpractices)

    def test_product_surveyed_field(self):
        self.objects.gt.code = 'HP'
        self.objects.gt.save()
        _, HnPFormSet = create_detail_formset(self.objects.doc)
        data = {'habits-TOTAL_FORMS':'2',
                'habits-INITIAL_FORMS':'1',
                'habits-MIN_NUM_FORMS':'0',
                'habits-MAX_NUM_FORMS':'1000',
                'habits-0-id': self.objects.ehp.pk,
                'habits-0-product_surveyed':'',
        }
        hp_formset = HnPFormSet(data, prefix='habits')
        self.assertFalse(hp_formset.is_valid())

        data = {'habits-TOTAL_FORMS':'2',
                'habits-INITIAL_FORMS':'1',
                'habits-MIN_NUM_FORMS':'0',
                'habits-MAX_NUM_FORMS':'1000',
                'habits-0-id': self.objects.ehp.pk,
                'habits-0-product_surveyed':'monster trucks',
        }
        hp_formset = HnPFormSet(data, prefix='habits')

        self.assertTrue(hp_formset.is_valid())

    def test_edit_hnp_detail(self):
        self.objects.exscript.title = 'Manual (dummy)'
        self.objects.exscript.save()
        self.client.login(username='Karyn', password='specialP@55word')
        pk = self.objects.doc.pk
        response = self.client.get(f'/habitsandpractices/{pk}/')
        self.assertNotContains(response, 'Raw Category', html=True)

        # Ensure there are Cancel and Back buttons with the correct URL to return to the DG detail page
        self.assertContains(response, f'href="/datagroup/{self.objects.dg.pk}/" role="button">Cancel</a>')
        self.assertContains(response, f'href="/datagroup/{self.objects.dg.pk}/" role="button">Back</a>')

        # Ensure that the URL above responds correctly
        response2 = self.client.get(f'/datagroup/{self.objects.dg.pk}/')
        self.assertContains(response2, 'Data Group Detail: Data Group for Test')

import csv
import datetime
from dateutil.relativedelta import relativedelta

from django.http import HttpResponse
from django.shortcuts import render
from django.db.models import Count, F, DateField, DateTimeField
from django.db.models.functions import Trunc
from django.contrib.auth.decorators import login_required

from dashboard.models import *

from dashboard.models import *

current_date = datetime.datetime.strftime(datetime.datetime.now(), '%Y-%m-%d')
chart_start_datetime = datetime.datetime(datetime.datetime.now().year - 1, min(12,datetime.datetime.now().month + 1), 1)


def index(request):
    stats = {}
    stats['datagroup_count'] = DataGroup.objects.count()
    stats['datasource_count'] = DataSource.objects.count()

    stats['datadocument_count'] = DataDocument.objects.count()
    stats['datadocument_with_extracted_text_percent'] =\
        DataDocument.objects.filter(extracted = True).count()/DataDocument.objects.count()*100
    stats['datadocument_count_by_date'] = datadocument_count_by_date()
    stats['datadocument_count_by_month'] = datadocument_count_by_month()
    stats['product_count'] = Product.objects.count()
    stats['dss_tox_count'] = DSSToxLookup.objects.count()
    stats['chemical_count'] = ExtractedChemical.objects.count()
    stats['product_with_puc_count'] = ProductToPUC.objects.values('product_id').distinct().count()
    stats['product_with_puc_count_by_month'] = product_with_puc_count_by_month()
    return render(request, 'dashboard/index.html', stats)


def datadocument_count_by_date():
    # Datasets to populate linechart with document-upload statistics
    # Number of datadocuments, both overall and by type, that have been uploaded as of each date
    select_upload_date = {"upload_date": """date(dashboard_datadocument.created_at)"""}
    document_stats = {}
    document_stats['all'] = list(DataDocument.objects.extra(select=select_upload_date) \
                                 .values('upload_date') \
                                 .annotate(document_count = Count('id')) \
                                 .order_by('upload_date'))
    document_stats_by_type = DataDocument.objects.extra(select=select_upload_date) \
        .values('upload_date') \
        .annotate(source_type = F('document_type__title'), document_count = Count('id')) \
        .order_by('upload_date')
    document_stats['product'] = list(document_stats_by_type.filter(source_type = 'product'))
    document_stats['msds_sds'] = list(document_stats_by_type.filter(source_type = 'msds/sds'))
    for type in {'all'}:
        document_count = 0
        for item in document_stats[type]:
            if isinstance(item['upload_date'], datetime.date):
                item['upload_date'] = datetime.date.strftime((item['upload_date']), '%Y-%m-%d')
            document_count += item['document_count']
            item['document_count'] = document_count
        # if final record isn't for current date, create one
        for item in document_stats[type][len(document_stats[type])-1:]:
            if item['upload_date'] != current_date:
                document_stats[type].append({'upload_date': current_date
                                                , 'document_count': document_count})
    return document_stats


def datadocument_count_by_month():
    # GROUP BY issue solved with https://stackoverflow.com/questions/8746014/django-group-by-date-day-month-year
    document_stats = list(DataDocument.objects.filter(created_at__gte=chart_start_datetime)\
        .annotate(upload_month = (Trunc('created_at', 'month', output_field=DateTimeField()))) \
        .values('upload_month') \
        .annotate(document_count = (Count('id'))) \
        .values('document_count', 'upload_month') \
        .order_by('upload_month'))
    if len(document_stats) < 12:
        for i in range(0, 12):
            chart_month = chart_start_datetime + relativedelta(months=i)
            if i + 1 > len(document_stats) or document_stats[i]['upload_month'] != chart_month:
                document_stats.insert(i, {'document_count': '0', 'upload_month': chart_month})
    return document_stats


def product_with_puc_count_by_month():
    # GROUP BY issue solved with https://stackoverflow.com/questions/8746014/django-group-by-date-day-month-year

    product_stats = list(ProductToPUC.objects
        .filter(created_at__gte=chart_start_datetime)
        .annotate(
            puc_assigned_month = (Trunc('created_at', 'month', output_field=DateField()))
        )
        .values('puc_assigned_month')
        .annotate(product_count=Count('product', distinct=True))
        .order_by('puc_assigned_month')
        )

    if len(product_stats) < 12:
        for i in range(0, 12):
            chart_month = chart_start_datetime + relativedelta(months=i)
            if i + 1 > len(product_stats) or product_stats[i]['puc_assigned_month'] != chart_month:
                product_stats.insert(i, {'product_count': '0', 'puc_assigned_month': chart_month})
    return product_stats


def download_PUCs(request):
    '''This view gets called every time we call the index view and is used to
    populate the bubble plot. It is also used to download all of the PUCs in 
    csv form. The "bubbles" parameter in the request will either be "True" or 
    "None", it's worth noting that if when making the call to here from the 
    index page we were to use ?bubbles=False it would also give us the filtered
    PUCs because the if expression is just checking whether that parameter is 
    there.
    '''
    response = HttpResponse(content_type='text/csv')
    response['Content-Disposition'] = 'attachment; filename="PUCs.csv"'
    bubbles = request.GET.get('bubbles')
    writer = csv.writer(response)
    cols = ['gen_cat','prod_fam','prod_type','description','PUC_type','num_prods']                    
    writer.writerow(cols)
    pucs = PUC.objects.filter(kind='FO') if bubbles else PUC.objects.all()
    for puc in pucs:
        row = [ puc.gen_cat,
                puc.prod_fam, 
                puc.prod_type, 
                puc.description, 
                puc.get_level(), 
                puc.product_count
                ]
        writer.writerow(row)

    return response

from django import forms                    
from django.http import HttpResponse
from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404

from djqscsv import render_to_csv_response

from dashboard.forms import *
# if this goes to 0, tests will fail because of what num form we search for
from factotum.settings import EXTRA
from dashboard.models import *


@login_required()
def data_document_detail(request, pk):
    template_name = 'data_document/data_document_detail.html'
    doc = get_object_or_404(DataDocument, pk=pk, )
    code = doc.data_group.group_type.code
    edit = 1 if doc.detail_page_editable else 0
    # edit adds an extra record to the formset, but is also a switch in the
    # template and to add the delete input, this will only work if we add one at
    # a time...
    ParentForm, ChildFormSet = create_detail_formset(
        doc, extra=edit, can_delete=edit)                    
    document_type_form = DocumentTypeForm(request.POST or None, instance=doc)
    qs = DocumentType.objects.filter(group_type=doc.data_group.group_type)
    document_type_form.fields['document_type'].queryset = qs
    context = {'doc': doc,
               'edit': edit,
               'document_type_form': document_type_form}
    if doc.is_extracted:

        extracted_text = ExtractedText.objects.get_subclass(pk=doc.pk)                     
        extracted_text_form = ParentForm(instance=extracted_text)                    
        child_formset = ChildFormSet(instance=extracted_text)

        if not edit:
            for form in child_formset.forms:                    
                for field in form.fields:
                    form.fields[field].widget.attrs['disabled'] = True

        context.update(
            {'edit_text_form': ParentForm(instance=extracted_text),
             'extracted_text': extracted_text,
             'detail_formset': child_formset}
        )

        colors = ['#d6d6a6', '#dfcaa9', '#d8e5bf'] * 47                    
        color = (hex for hex in colors)                    
        for form in child_formset.forms:                    
            form.color = next(color)                    
    else:                    
        context['edit_text_form'] = ParentForm()
    return render(request, template_name, context)


@login_required()
def save_doc_form(request, pk):
    '''Writes changes to the data document form 
    
    The request object should have a 'referer' key to redirect the 
    browser to the appropriate place after saving the edits

    Invoked by changing the document type in the data document detail view or the
    extracted text QA page template
    '''

    referer = request.POST['referer'] if request.POST['referer'] else 'data_document'                    
    doc = get_object_or_404(DataDocument, pk=pk)                    
    document_type_form = DocumentTypeForm(request.POST, instance=doc)
    if document_type_form.is_valid() and document_type_form.has_changed():
        document_type_form.save()
    return redirect(referer, pk=pk)


@login_required()
def data_document_note(request, pk):
    doc = get_object_or_404(DataDocument, pk=pk)                    
    doc_note = request.POST['dd_note']
    doc.note = doc_note
    doc.save()
    return redirect('data_document', pk=pk)


@login_required()
def save_ext_form(request, pk):
    referer = request.POST['referer'] if request.POST['referer'] else 'data_document'                    
    doc = get_object_or_404(DataDocument, pk=pk)                    
    ExtractedTextForm, _ = create_detail_formset(doc)
    extracted_text = ExtractedText.objects.get_subclass(pk=pk)
    ext_text_form = ExtractedTextForm(request.POST, instance=extracted_text)
    if ext_text_form.is_valid() and ext_text_form.has_changed():
        ext_text_form.save()
    return redirect(referer, pk=pk)


@login_required()
def data_document_delete(request, pk, template_name='data_source/datasource_confirm_delete.html'):
    doc = get_object_or_404(DataDocument, pk=pk)                    
    datagroup_id = doc.data_group_id
    if request.method == 'POST':
        doc.delete()
        return redirect('data_group_detail', pk=datagroup_id)
    return render(request, template_name, {'object': doc})


@login_required
def dg_dd_csv_view(request, pk):
    qs = DataDocument.objects.filter(data_group_id=pk)
    filename = DataGroup.objects.get(pk=pk).name
    return render_to_csv_response(qs, filename=filename, append_datestamp=True)


@login_required
def data_document_edit(request, pk):                    

    referer = request.POST['referer'] if request.POST['referer'] else 'data_document'                    
    doc = get_object_or_404(DataDocument, pk=pk)                    
    ParentForm, _ = create_detail_formset(doc, extra=0, can_delete=False)                    
    model = ParentForm.Meta.model                    
    script = Script.objects.get(title__icontains='Manual (dummy)')                    
    exttext, _ = model.objects.get_or_create(extraction_script=script,                    
                                             data_document_id=pk)                    
    form = ParentForm(request.POST, instance=exttext)                    
    if form.is_valid():
        form.save()
        return redirect(referer, pk=doc.pk)                    
    else:                    
        return HttpResponse("Houston, we have a problem.")                    


@login_required
def extracted_text_edit(request, pk):
    doc = get_object_or_404(DataDocument, pk=pk)                    
    ParentForm, _ = create_detail_formset(doc, extra=0, can_delete=False)                    
    model = ParentForm.Meta.model                    
    script = Script.objects.get(title__icontains='Manual (dummy)', script_type='EX')
    exttext, _ = model.objects.get_or_create(extraction_script=script,                    
                                             data_document_id=pk)                    
    form = ParentForm(request.POST, instance=exttext)                    
    if form.is_valid():
        form.save()
        doc.extracted = True
        doc.save()
        return redirect('data_document', pk=doc.pk)
    else:                    
        extext.delete()
        return HttpResponse("Houston, we have a problem.")                    


@login_required
def extracted_child_edit(request, pk):
    doc = get_object_or_404(DataDocument, pk=pk)                    
    _, ChildFormSet = create_detail_formset(doc, extra=1, can_delete=True)
    formset = ChildFormSet(request.POST, instance=doc.extractedtext)
    if formset.is_valid():
        formset.save()
    return redirect('data_document', pk=doc.pk)

import os
import csv
import zipfile
from itertools import islice                    
from collections import OrderedDict                    
from djqscsv import render_to_csv_response
from pathlib import Path

from django import forms                    
from django.urls import reverse                    
from django.conf import settings
from django.core.files import File
from django.core.exceptions import ValidationError
from django.core.files.storage import FileSystemStorage
from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.http import HttpResponse
from django.core.paginator import Paginator

from dashboard.models import *
from dashboard.forms import (DataGroupForm,
                             ExtractionScriptForm,                    
                             CleanCompDataForm,                    
                             create_detail_formset,                    
                             include_extract_form,                    
                             include_clean_comp_data_form)                    
from dashboard.utils import get_extracted_models, clean_dict, update_fields
from django.db.models import Max


@login_required()
def data_group_list(request, template_name='data_group/datagroup_list.html'):
    datagroup = DataGroup.objects.all()
    data = {}
    data['object_list'] = datagroup
    return render(request, template_name, data)

@login_required()
def data_group_detail(request, pk,
                      template_name='data_group/datagroup_detail.html'):
    dg = get_object_or_404(DataGroup, pk=pk, )
    dg.doc_types = DocumentType.objects.filter(group_type=dg.group_type)
    docs = dg.datadocument_set.get_queryset()#this needs to be updated after matching...
    prod_link = ProductDocument.objects.filter(document__in=docs)
    page = request.GET.get('page')
    paginator = Paginator(docs, 50) # TODO: make this dynamic someday in its own ticket
    store = settings.MEDIA_URL + str(dg.fs_id)
    ext = ExtractedText.objects.filter(data_document_id__in=docs).first()
    context = { 'datagroup'      : dg,
                'documents'      : paginator.page(1 if page is None else page),
                'all_documents'  : docs, # this used for template download
                'extract_fields' : dg.get_extracted_template_fieldnames(),
                'ext_err'        : {},
                'clean_comp_err'        : {},
                'extract_form'   : include_extract_form(dg),
                'clean_comp_data_form'   : include_clean_comp_data_form(dg),
                'bulk'           : len(docs) - len(prod_link),
                'msg'            : '',
                }
    if request.method == 'POST' and 'upload' in request.POST:
        # match filename to pdf name
        matched_files = [f for d in docs for f
                in request.FILES.getlist('multifiles') if f.name == d.filename]
        if not matched_files:
            context['msg'] = ('There are no matching records in the '
                                                        'selected directory.')
            return render(request, template_name, context)
        zf = zipfile.ZipFile(dg.zip_file, 'a', zipfile.ZIP_DEFLATED)
        while matched_files:
            f = matched_files.pop(0)
            doc = DataDocument.objects.get(filename=f.name,
                                            data_group=dg.pk)
            if doc.matched:
                continue
            doc.matched = True
            doc.save()
            fs = FileSystemStorage(store + '/pdf')
            afn = doc.get_abstract_filename()
            fs.save(afn, f)
            zf.write(store + '/pdf/' + afn, afn)
        zf.close()
        form = include_extract_form(dg)
        # update docs so it appears in the template table w/ "matched" docs
        context['all_documents'] = dg.datadocument_set.get_queryset()
        context['extract_form'] = form
        context['msg'] = 'Matching records uploaded successfully.'
    if request.method == 'POST' and 'extract_button' in request.POST:
        extract_form = ExtractionScriptForm(request.POST,
                                                request.FILES,dg_type=dg.type)
        if extract_form.is_valid():
            csv_file = request.FILES.get('extract_file')
            script_pk = int(request.POST['script_selection'])
            script = Script.objects.get(pk=script_pk)
            info = [x.decode('ascii','ignore') for x in csv_file.readlines()]
            table = csv.DictReader(info)
            missing =  list(set(dg.get_extracted_template_fieldnames())-
                                                        set(table.fieldnames))
            if missing: #column names are NOT a match, send back to user
                context['msg'] = ('The following columns need to be added or '
                                            f'renamed in the csv: {missing}')
                return render(request, template_name, context)
            good_records = []
            ext_parent, ext_child = get_extracted_models(dg.type)
            for i, row in enumerate(csv.DictReader(info)):
                d = docs.get(pk=int(row['data_document_id']))
                d.raw_category = row.pop('raw_category')
                wft = request.POST.get('weight_fraction_type', None)
                if wft: # this signifies 'Composition' type
                    w = 'weight_fraction_type'
                    row[w] = WeightFractionType.objects.get(pk=int(wft))
                    unit_type_id = int(row['unit_type'])
                    row['unit_type'] = UnitType.objects.get(pk=unit_type_id)
                    rank = row['ingredient_rank']
                    row['ingredient_rank'] = None if rank == '' else rank
                ext, created = ext_parent.objects.get_or_create(data_document=d,
                                                    extraction_script=script)
                if not created and ext.one_to_one_check(row):
                    # check that there is a 1:1 relation ExtParent and DataDoc
                    col = 'cat_code' if hasattr(ext,'cat_code') else 'prod_name' 
                    err_msg = ['must be 1:1 with "data_document_id".']
                    context['ext_err'][i+1] = {col: err_msg}
                if created:
                    update_fields(row, ext)
                row['extracted_text'] = ext
                if (ext_child == ExtractedListPresence):
                    row['extracted_cpcat'] = ext.extractedtext_ptr
                row = clean_dict(row, ext_child)
                try:
                    ext.full_clean()
                    ext.save()
                    record = ext_child(**row)
                    record.full_clean()
                    good_records.append((d,ext,record))
                except ValidationError as e:
                    context['ext_err'][i+1] = e.message_dict
            if context['ext_err']: # if errors, send back with errors
                [e[1].delete() for e in good_records] # delete any created exts
                return render(request, template_name, context)
            if not context['ext_err']:  # no saving until all errors are removed
                for doc,text,record in good_records:
                    doc.extracted = True
                    doc.save()
                    text.save()
                    record.save()
                fs = FileSystemStorage(store)
                fs.save(str(dg)+'_extracted.csv', csv_file)
                context['msg'] = (f'{len(good_records)} extracted records '
                                                    'uploaded successfully.')
                context['extract_form'] = include_extract_form(dg)
    if request.method == 'POST' and 'bulk' in request.POST:
        # get the set of documents that have not been matched
        a = set(docs.values_list('pk',flat=True))
        b = set(prod_link.values_list('document_id',flat=True))
        # DataDocs to make products for...
        docs_needing_products = DataDocument.objects.filter(pk__in=list(a-b))
        stub = Product.objects.all().aggregate(Max('id'))["id__max"] + 1
        for doc in docs_needing_products:
            # Try to name the new product from the ExtractedText record's prod_name
            try:
                ext = ExtractedText.objects.get(data_document_id=doc.id)
                if ext:
                    if ext.prod_name:
                        new_prod_title = ext.prod_name
                    else:
                        new_prod_title = None
            except ExtractedText.DoesNotExist:
                new_prod_title = None
            # If the ExtractedText record can't provide a title, use the DataDocument's title
            if not new_prod_title:
                if doc.title:
                    new_prod_title = '%s stub' % doc.title
                else:
                    new_prod_title = 'unknown'
            product = Product.objects.create(
                                    title=new_prod_title,
                                    upc=f'stub_{stub}',
                                    data_source_id=doc.data_group.data_source_id
                                    )
            ProductDocument.objects.create(product=product, document=doc)
            stub += 1
        context['bulk'] = 0
    if request.method == 'POST' and 'clean_comp_data_button' in request.POST:
        clean_comp_data_form = CleanCompDataForm(request.POST, request.FILES)
        if clean_comp_data_form.is_valid():
            script_pk = int(request.POST['script_selection'])
            script = Script.objects.get(pk=script_pk)
            csv_file = request.FILES.get('clean_comp_data_file')
            info = [x.decode('ascii','ignore') for x in csv_file.readlines()]
            table = csv.DictReader(info)
            missing =  list(set(dg.get_clean_comp_data_fieldnames())-
                                                        set(table.fieldnames))
            if missing: #column names are NOT a match, send back to user
                context['clean_comp_data_form'].collapsed = False
                context['msg'] = ('The following columns need to be added or '
                                            f'renamed in the csv: {missing}')
                return render(request, template_name, context)

            good_records = []
            for i, row in enumerate(csv.DictReader(info)):
                try:
                    extracted_chemical = ExtractedChemical.objects.get(rawchem_ptr=int(row['id']))
                except ExtractedChemical.DoesNotExist as e:
                    extracted_chemical = None
                    context['clean_comp_err'][i + 1] = {'id': ['No ExtractedChemical matches rawchem_ptr_id ' + row['id'], ]}
                    print('No ExtractedChemical matches rawchem_ptr_id %s' % row['id'])
                try:
                    ingredient = Ingredient.objects.get(rawchem_ptr=extracted_chemical.rawchem_ptr)
                except Ingredient.DoesNotExist as e:
                    ingredient = Ingredient(rawchem_ptr=extracted_chemical.rawchem_ptr)
                ingredient.lower_wf_analysis = row['lower_wf_analysis']
                ingredient.central_wf_analysis = row['central_wf_analysis']
                ingredient.upper_wf_analysis = row['upper_wf_analysis']
                ingredient.script = script
                try:
                    ingredient.full_clean()
                except ValidationError as e:
                    context['clean_comp_err'][i+1] = e.message_dict
                good_records.append(ingredient)
            if context['clean_comp_err']: # if errors, send back with errors
                context['clean_comp_data_form'].collapsed = False
                return render(request, template_name, context)
            if not context['clean_comp_err']:  # no saving until all errors are removed
                for ingredient in good_records:
                    ingredient.save()
                context['msg'] = (f'{len(good_records)} clean composition data records '
                                                    'uploaded successfully.')
                context['clean_comp_data_form'] = include_clean_comp_data_form(dg)
        else:
            context['clean_comp_data_form'].collapsed = False

    return render(request, template_name, context)


@login_required()
def data_group_create(request, pk,
                        template_name='data_group/datagroup_form.html'):
    datasource = get_object_or_404(DataSource, pk=pk)
    group_key = DataGroup.objects.filter(data_source=datasource).count() + 1
    default_name = '{} {}'.format(datasource.title, group_key)
    header = 'Create New Data Group For Data Source "' + str(datasource) + '"'
    initial_values = {'downloaded_by' : request.user,
                      'name'          : default_name,
                      'data_source'   : datasource}
    if request.method == 'POST':
        form = DataGroupForm(request.POST, request.FILES,
                             user    = request.user,
                             initial = initial_values)
        if form.is_valid():
            # what's the pk of the newly created datagroup?
            datagroup = form.save()
            info = [x.decode('ascii',
                             'ignore') for x in datagroup.csv.readlines()]
            table = csv.DictReader(info)
            good_fields = ['filename','title','document_type',
                                                    'url','organization']
            if not table.fieldnames == good_fields:
                datagroup.csv.close()
                datagroup.delete()
                return render(request, template_name,
                              {'field_error': table.fieldnames,
                              'good_fields': good_fields,
                               'form': form})
            text = ['DataDocument_id,' + ','.join(table.fieldnames)+'\n']
            errors = []
            filenames = []
            count = 0
            for line in table: # read every csv line, create docs for each
                count+=1
                doc_type = DocumentType.objects.get(pk=1)
                code = line['document_type']
                if line['filename'] == '' :
                    errors.append([count,"Filename can't be empty!"])
                    continue
                if len(line['filename'])>255:
                    errors.append([count,"Filename too long!"])
                    continue
                if line['filename'] in filenames:
                    errors.append([count, "Duplicate filename found in csv"])
                    continue
                if line['title'] == '': # updates title in line object
                    line['title'] = line['filename'].split('.')[0]
                if code == '':
                    errors.append([count,
                                    "'document_type' field can't be empty"])
                    continue
                if DocumentType.objects.filter(group_type=datagroup.group_type,
                                                            code=code).exists():
                    doc_type = DocumentType.objects.get(
                                    group_type=datagroup.group_type,code=code)
                else:
                    errors.append([count,"DocumentType code doesn't exist."])

                filenames.append(line['filename'])
                doc=DataDocument(filename=line['filename'],
                                 title=line['title'],
                                 document_type=doc_type,
                                 url=line['url'],
                                 organization=line['organization'],
                                 data_group=datagroup)
                doc.save()
                # update line to hold the pk for writeout
                text.append(str(doc.pk)+','+ ','.join(line.values())+'\n')
            if errors:
                datagroup.csv.close()
                datagroup.delete()
                return render(request, template_name, {'line_errors': errors,
                                                       'form': form})
            #Save the DG to make sure the pk exists
            datagroup.save()
            #Let's even write the csv first
            with open(datagroup.csv.path,'w') as f:
                myfile = File(f)
                myfile.write(''.join(text))
            #Let's explicitly use the full path for the actually writing of the zipfile
            new_zip_name = Path(settings.MEDIA_URL + "/" + str(datagroup.fs_id) + "/" + str(datagroup.fs_id) + ".zip")
            new_zip_path = Path(settings.MEDIA_ROOT + "/" + str(datagroup.fs_id) + "/" + str(datagroup.fs_id) + ".zip")
            zf = zipfile.ZipFile(str(new_zip_path), 'w',
                                 zipfile.ZIP_DEFLATED)
            datagroup.zip_file = new_zip_name
            zf.close()
            datagroup.save()
            return redirect('data_group_detail', pk=datagroup.id)
    else:
        groups = GroupType.objects.all()
        for group in groups:
            group.codes = DocumentType.objects.filter(group_type=group)
        form = DataGroupForm(user=request.user, initial=initial_values)
    context = {'form': form, 'header': header,
                'datasource': datasource, 'groups' : groups}
    return render(request, template_name, context)


@login_required()
def data_group_update(request, pk, template_name='data_group/datagroup_form.html'):
    # TODO: Resolve whether this form save ought to also update Datadocuments
    #  in the case the "Register Records CSV file" is updated.
    datagroup = get_object_or_404(DataGroup, pk=pk)
    form = DataGroupForm(request.POST or None, instance=datagroup)
    header = f'Update Data Group for Data Source "{datagroup.data_source}"'
    if form.is_valid():
        if form.has_changed():
            form.save()
        return redirect('data_group_detail', pk=datagroup.id)
    form.referer = request.META.get('HTTP_REFERER', None)
    if datagroup.extracted_docs():
        form.fields['group_type'].disabled = True
    groups = GroupType.objects.all()
    for group in groups:
            group.codes = DocumentType.objects.filter(group_type=group)
    return render(request, template_name, {'datagroup': datagroup, 
                                            'form': form,
                                            'header': header,
                                            'groups': groups})

@login_required()
def data_group_delete(request, pk, template_name='data_source/datasource_confirm_delete.html'):
    datagroup = get_object_or_404(DataGroup, pk=pk)
    if request.method == 'POST':
        datagroup.delete()
        return redirect('data_group_list')
    return render(request, template_name, {'object': datagroup})

@login_required
def dg_pdfs_zip_view(request, pk):
    dg = DataGroup.objects.get(pk=pk)
    #print('opening zip file from %s' % dg.get_zip_url())
    zip_file_name = f'{dg.fs_id}.zip'
    zip_file = open(dg.get_zip_url(), 'rb')
    response = HttpResponse(zip_file, content_type='application/zip')
    response['Content-Disposition'] = 'attachment; filename=%s' % zip_file_name
    return response

@login_required
def data_group_registered_records_csv(request, pk):
    columnlist = ['filename','title','document_type','url','organization']
    dg = DataGroup.objects.filter(pk=pk).first()
    if dg:
        columnlist.insert(0, "id")
        qs = DataDocument.objects.filter(data_group_id=pk).values(*columnlist)
        return render_to_csv_response(qs, filename=(dg.get_name_as_slug() +
                                                    "_registered_records.csv"),
                                  field_header_map={"id": "DataDocument_id"},
                                  use_verbose_names=False)
    else:
        qs = DataDocument.objects.filter(data_group_id=0).values(*columnlist)
        return render_to_csv_response(qs, filename="registered_records.csv",
                                        use_verbose_names=False)

@login_required()
def habitsandpractices(request, pk,
                      template_name='data_group/habitsandpractices.html'):
    doc = get_object_or_404(DataDocument, pk=pk, )
    script = Script.objects.get(title='Manual (dummy)', script_type='EX')
    extext, created = ExtractedText.objects.get_or_create(data_document=doc,
                                                    extraction_script=script)
    if created:
        extext.doc_date = 'please add...'
    ExtractedTextForm, HPFormSet = create_detail_formset(doc)
    # print(extext.pk)
    ext_form = ExtractedTextForm(request.POST or None, instance=extext)
    hp_formset = HPFormSet(request.POST or None, instance=extext, prefix='habits')
    context = {   'doc'         : doc,
                  'ext_form'    : ext_form,
                  'hp_formset'  : hp_formset,
                  }
    if request.method == 'POST' and 'save' in request.POST:
        if hp_formset.is_valid():
            hp_formset.save()
        if ext_form.is_valid():
            ext_form.save()
        doc.extracted = True
        doc.save()
        context = {   'doc'         : doc,
                      'ext_form'    : ext_form,
                      'hp_formset'  : hp_formset,
                      }
    return render(request, template_name, context)

@login_required
def dg_raw_extracted_records(request, pk):
    columnlist = ['extracted_text_id','id','raw_cas','raw_chem_name','raw_min_comp','raw_central_comp','raw_max_comp','unit_type__title']
    dg = DataGroup.objects.get(pk=pk)
    et = ExtractedText.objects.filter(data_document__data_group = dg).first()
    if et:
        dg_name = dg.get_name_as_slug()
        qs = ExtractedChemical.objects.filter(extracted_text__data_document__data_group_id=pk).values(*columnlist)
        #print('Writing %s records to csv' % len(qs) )
        return render_to_csv_response(qs, filename=(dg_name +
                                                    "_raw_extracted_records.csv"),
                                  field_header_map={"id": "ExtractedChemical_id"},
                                  use_verbose_names=False)
    else:
        qs = ExtractedChemical.objects.filter(extracted_text__data_document__id=pk).values(*columnlist)
        return render_to_csv_response(qs, filename='raw_extracted_records.csv' ,
                                        use_verbose_names=False)

from datetime import datetime                    

from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404

from dashboard.forms import DataSourceForm, PriorityForm
from dashboard.models import DataSource, DataGroup, DataDocument
from .data_group import DataGroupForm                    
from django.db.models import Count, Q



@login_required()
def data_source_list(request, template_name='data_source/datasource_list.html'):
    datasources = DataSource.objects.all()
    ds_list, frm_list = [], []
    for ds in datasources:
        frm_list.append(PriorityForm(request.POST or None, instance=ds))
    registered = Count('datagroup__datadocument') 
    uploaded   = Count('datagroup__datadocument', filter=Q(datagroup__datadocument__matched=True))
    extracted  = Count('datagroup__datadocument__extractedtext')
    ds_list    = DataSource.objects.annotate(registered=registered).annotate(uploaded=uploaded, extracted=extracted)
    out = zip(ds_list, frm_list)
    if request.method == 'POST':
        datasource = DataSource.objects.get(pk=request.POST['ds_pk'])
        form = PriorityForm(request.POST or None, instance=datasource)
        if form.is_valid():
            priority = form.cleaned_data['priority']
            datasource.priority = priority
            datasource.save()
            return redirect('data_source_list')
    return render(request, template_name, {'object_list': out})


@login_required()
def data_source_detail(request, pk,
                        template_name='data_source/datasource_detail.html'):
    datasource = get_object_or_404(DataSource, pk=pk, )
    docs = DataDocument.objects.filter(data_group__in=DataGroup.objects.filter(data_source=datasource))
    datasource.registered = (len(docs)/float(datasource.estimated_records))*100
    datasource.uploaded = (len(docs.filter(matched=True))/float(
                                            datasource.estimated_records))*100

    form = PriorityForm(request.POST or None, instance=datasource)
    if request.method == 'POST':
        if form.is_valid():
            priority = form.cleaned_data['priority']
            datasource.priority = priority
            datasource.save()
    datagroup_list = DataGroup.objects.filter(data_source=pk)
    context =     {'object':             datasource,
                'datagroup_list':    datagroup_list,
                'form':             form}
    return render(request, template_name, context)


@login_required()
def data_source_create(request, template_name=('data_source/'
                                                'datasource_form.html')):
    form = DataSourceForm(request.POST or None)
    if form.is_valid():
        form.save()
        return redirect('data_source_list')
    return render(request, template_name, {'form': form})


@login_required()
def data_source_update(request, pk, template_name=('data_source/'
                                                    'datasource_form.html')):
    datasource = get_object_or_404(DataSource, pk=pk)
    form = DataSourceForm(request.POST or None, instance=datasource)
    if form.is_valid():
        if form.has_changed():
            form.save()
        return redirect('data_source_detail', pk=pk)
    form.referer = request.META.get('HTTP_REFERER', None)
    return render(request, template_name, {'form': form})

@login_required()
def data_source_delete(request, pk,
                        template_name=('data_source/'
                                        'datasource_confirm_delete.html')):
    datasource = get_object_or_404(DataSource, pk=pk)
    if request.method == 'POST':
        datasource.delete()
        return redirect('data_source_list')
    return render(request, template_name, {'object': datasource})

import csv
import logging
import datetime

from django import forms                    
from django.db import connection                    
from django.urls import reverse
from django.http import HttpResponse, HttpResponseRedirect
from django.contrib import messages
from django.shortcuts import render
from django.db.models import Count, Q, Value, IntegerField, Subquery, OuterRef, F, Sum                    
from django.forms.models import model_to_dict                    

from dashboard.models import *
from dashboard.forms import HabitsPUCForm


def get_data(request, template_name='get_data/get_data.html'):
    hnp = None
    form = HabitsPUCForm()
    context = { 'hnp' : hnp,
                'form': form,
                'first': None,
                }
    if request.method == 'POST':
        form = HabitsPUCForm(request.POST)
        if form.is_valid():
            puc = PUC.objects.get(pk=form['puc'].value())
            pucs = puc.get_the_kids()
            link_table = ExtractedHabitsAndPracticesToPUC
            links = link_table.objects.filter(PUC__in=pucs).values_list(
                                            'extracted_habits_and_practices',
                                            flat=True)
            hnp = ExtractedHabitsAndPractices.objects.filter(pk__in=links)
            context['form'] = form
            context['hnp'] = hnp if len(hnp)>0 else 0
            if len(hnp)>0:
                context['first'] = hnp[0].pk
    return render(request, template_name, context)


def stats_by_dtxsids(dtxs):
    """
    PUCS.n
    The number of unique PUCs (product categories) the chemical is associated with
    datadocs.n
    "The number of data documents (e.g.  MSDS, SDS, ingredient list, product label)
    the chemical is appears in"
    datadocs_w_wf.n
    "The number of data documents with associated weight fraction data
    that the chemical appears in (weight fraction data may be reported or predicted data,
     i.e., predicted from an ingredient list)"
    products.n
    "The number of products the chemical appears in, where a product is defined as a
    product entry in Factotum."
    """
    # print('List of DTXSIDs provided:')
    # print(dtxs)


    # The number of unique PUCs (product categories) the chemical is associated with
    pucs_n = DSSToxLookup.objects.filter(sid__in=dtxs).\
        annotate(pucs_n=Count('curated_chemical__extracted_text__data_document__product__puc')).\
        values('sid','pucs_n').order_by()

    # "The number of data documents (e.g.  MSDS, SDS, ingredient list, product label)
    # the chemical appears in
    dds_n = RawChem.objects.filter(dsstox__sid__in=dtxs).values('dsstox__sid').\
        annotate(sid=F('dsstox__sid'), dds_n=Count('extracted_text__data_document')).\
        values('sid','dds_n').order_by()

    #print('dds_n:')
    #print(dds_n)

    # The number of data documents with associated weight fraction data
    # that the chemical appears in (weight fraction data may be reported or predicted data,
    # i.e., predicted from an ingredient list)
    # This query only applies to ExtractedChemical objects, so the RawChem model can be bypassed
    wf_ecs = ExtractedChemical.objects.filter(dsstox__sid__in=dtxs).filter(
                Q(raw_max_comp__isnull=False) |
                Q(raw_min_comp__isnull=False) |
                Q(raw_central_comp__isnull=False)
            )
    dds_wf_n = DSSToxLookup.objects.filter(sid__in=dtxs).filter(curated_chemical__in=wf_ecs).\
        annotate(dds_wf_n=Count('curated_chemical__extracted_text_id', distinct=True)).\
        order_by().values('sid','dds_wf_n')






    # The number of products the chemical appears in, where a product is defined as a
    # product entry in Factotum.
    products_n = RawChem.objects.filter(dsstox__sid__in=dtxs).values('dsstox__sid').\
       annotate(products_n=Count('extracted_text__data_document__product')).\
       annotate(sid=F('dsstox__sid')).values('sid', 'products_n')

    # build a list of stats, starting with the pucs_n object
    stats = pucs_n\
    .annotate(dds_n=Value(-1, output_field=IntegerField())) \
    .annotate(dds_wf_n=Value(-1, output_field=IntegerField())) \
    .annotate(products_n=Value(-1, output_field=IntegerField())) 

    for row in stats:
        row['dds_n'] = int(dds_n.get(sid=row['sid'])['dds_n'] or 0)

        if not dds_wf_n.filter(sid=row['sid']):
            row['dds_wf_n'] = 0
        else:
            row['dds_wf_n'] = int(dds_wf_n.get(sid=row['sid'])['dds_wf_n'] or 0)
            
        row['products_n'] = int(products_n.get(sid=row['sid'])['products_n'] or 0)
        
    return stats

def download_chem_stats(stats):
    response = HttpResponse(content_type='text/csv')
    response['Content-Disposition'] = 'attachment; filename="chem_summary_metrics_%s.csv"' % (datetime.datetime.now().strftime("%Y%m%d"))

    writer = csv.writer(response)
    writer.writerow(['DTXSID',  'pucs_n', 'dds_n', 'dds_wf_n', 'products_n'])
    for stat in stats:
        writer.writerow([stat['sid'], stat['pucs_n'], stat['dds_n'], stat['dds_wf_n'], stat['products_n']])

    return response

def get_data_dsstox_csv_template(request):
    response = HttpResponse(content_type='text/csv')
    response['Content-Disposition'] = 'attachment; filename="dsstox_lookup_template.csv"'
    writer = csv.writer(response)
    writer.writerow(['DTXSID'])
    return response


def upload_dtxsid_csv(request):
    data = {}
    if "GET" == request.method:
        return render(request, "get_data/get_data.html", data)
    # if not GET, then proceed
    try:
        csv_file = request.FILES["csv_file"]
        if not csv_file.name.endswith('.csv'):
            messages.error(request,'File is not CSV type')
            return HttpResponseRedirect(reverse("upload_dtxsid_csv"))
        #if file is too large, return
        if csv_file.multiple_chunks():
            messages.error(request,"Uploaded file is too big (%.2f MB)." % (csv_file.size/(1000*1000),))
            return HttpResponseRedirect(reverse("upload_dtxsid_csv"))

        file_data = csv_file.read().decode("utf-8")

        lines = file_data.split("\n")
        #loop over the lines
        dtxsids = []
        for line in lines:
            #print(line)
            if DSSToxLookup.objects.filter(sid=str.strip(line)).count() > 0:
                dtxsids.append(str.strip(line)) # only add DTXSIDs that appear in the database

    except Exception as e:
        logging.getLogger("error_logger").error("Unable to upload file. "+repr(e))
        messages.error(request,"Unable to upload file. "+repr(e))

    stats = stats_by_dtxsids(dtxsids)
    #stats  = {'pucs_n': 0, 'dds_n': 0, 'dds_wf_n': 0, 'products_n': 0}
    resp = download_chem_stats(stats)
    #print(resp)
    return resp



from dal import autocomplete                    

from django.shortcuts import (render, redirect, get_object_or_404,                    
                                                HttpResponseRedirect)                    
from django.utils.translation import ugettext_lazy as _                    
from django.contrib.auth.decorators import login_required

from dashboard.models import *
from dashboard.forms import HabitsPUCForm, create_detail_formset


@login_required()
def habitsandpractices(request, pk,
                      template_name='data_group/habitsandpractices.html'):
    doc = get_object_or_404(DataDocument, pk=pk, )
    script = Script.objects.get(title='Manual (dummy)', script_type='EX')
    extext, created = ExtractedText.objects.get_or_create(data_document=doc,
                                                    extraction_script=script)
    if created:
        extext.doc_date = 'please add...'
    ExtractedTextForm, HnPFormSet = create_detail_formset(doc)
    ext_form = ExtractedTextForm(request.POST or None, instance=extext)
    hp_formset = HnPFormSet(request.POST or None,
                            instance=extext, prefix='habits')
    if request.method == 'POST' and 'save' in request.POST:
        if hp_formset.is_valid() and ext_form.is_valid():
            if not doc.extracted:
                doc.extracted = True
                doc.save()
            hp_formset.save()
            ext_form.save()
            return HttpResponseRedirect(f'/habitsandpractices/{doc.pk}')
    context = {   'doc'         : doc,
                  'ext_form'    : ext_form,
                  'hp_formset'  : hp_formset,
                  }
    return render(request, template_name, context)


@login_required()
def link_habitsandpractices(request, pk,
                        template_name='data_group/habitsandpractices_to_puc.html'):
    hnp = get_object_or_404(ExtractedHabitsAndPractices, pk=pk, )
    form = HabitsPUCForm()
    if request.method == 'POST':
        form = HabitsPUCForm(request.POST)
        if form.is_valid():
            puc = PUC.objects.get(id=form['puc'].value())
            # make sure the PUC link doesn't already exist
            if not ExtractedHabitsAndPracticesToPUC.objects.filter(
                    PUC=puc,
                    extracted_habits_and_practices=hnp).exists():
                ExtractedHabitsAndPracticesToPUC.objects.create(
                        PUC=puc,
                        extracted_habits_and_practices=hnp
                )
                form = HabitsPUCForm()
    linked = ExtractedHabitsAndPracticesToPUC.objects.filter(
                    extracted_habits_and_practices=hnp).values('PUC')
    hnp_puc = PUC.objects.filter(pk__in=linked)
    print(hnp_puc)
    context = {'hnp': hnp,
                'form': form,
                'hnp_puc': hnp_puc,
    }
    return render(request, template_name, context)

from urllib import parse

from django.urls import resolve
from django.utils import timezone, safestring                    
from django.shortcuts import redirect
from django.db.models import Count, Q
from django.shortcuts import render, get_object_or_404
from django.contrib.auth.decorators import login_required
from django.forms import ModelForm                    
from dashboard.models import *
from dashboard.forms import (ProductPUCForm, ProductLinkForm,                     
                            BulkProductPUCForm, BulkProductTagForm,                     
                            BulkPUCForm, ProductForm)                    
from taggit.forms import TagField                    
from taggit_labels.widgets import LabelWidget                    
from django.core.paginator import Paginator
from django.db.models import Max


class FilteredLabelWidget(LabelWidget):                    
    # overriding django-taggit-label function to display subset of tags
    def tag_list(self, tags):                    
        # must set form_instance in form __init__()
        puc = self.form_instance.instance.get_uber_puc() or None                    
        qs = self.model.objects.filter(content_object=puc,assumed=False)                    
        filtered = [unassumed.tag for unassumed in qs]                    
        return [(tag.name, 'selected taggit-tag' if tag.name in tags else 'taggit-tag')                    
                for tag in filtered]                    


class ProductTagForm(ModelForm):                    
    tags = TagField(required=False, widget=FilteredLabelWidget(model=PUCToTag))                    

    class Meta:                    
        model = Product                    
        fields = ['tags']                    

    def __init__(self, *args, **kwargs):                    
        super(ProductTagForm, self).__init__(*args, **kwargs)                    
        self.fields['tags'].widget.form_instance = self                    


@login_required()
def product_curation_index(request, template_name='product_curation/product_curation_index.html'):
    # List of all data sources which have had at least 1 data
    # document matched to a registered record
    data_sources = DataSource.objects.annotate(uploaded=Count('datagroup__datadocument'))\
        .filter(uploaded__gt=0)
    # A separate queryset of data sources and their related products without PUCs assigned
    # Changed in issue 232. Instead of filtering products based on their prod_cat being null,
    #   we now exclude all products that have a product_id contained in the ProductToPUC object set
    qs_no_puc = Product.objects.values('data_source').exclude(id__in=(ProductToPUC.objects.values_list('product_id', flat=True))).\
        filter(data_source__isnull=False).annotate(no_category=Count('id')).order_by('data_source')
    # Convert the queryset to a list
    list_no_puc = [ds_no_puc for ds_no_puc in qs_no_puc]

    for ds in data_sources:
        try:
            ds.no_category = next((item for item in list_no_puc if item["data_source"] == ds.id), False)['no_category']
        except:
            ds.no_category = 0
        dgs = ds.datagroup_set.all()
        for dg in dgs:
            dg.unlinked = dg.datadocument_set.count() - dg.datadocument_set.filter(productdocument__document__isnull=False).count()
        ds.data_groups = dgs
    return render(request, template_name, {'data_sources': data_sources})


@login_required()
def category_assignment(request, pk, template_name=('product_curation/'
                                                'category_assignment.html')):
    """Deliver a datasource and its associated products"""
    ds = DataSource.objects.get(pk=pk)
    products = ds.source.exclude(id__in=(ProductToPUC.objects.values_list('product_id', flat=True))).order_by('-created_at')
    return render(request, template_name, {'datasource': ds, 'products': products})


@login_required()
def link_product_list(request,  pk, template_name='product_curation/link_product_list.html'):
    dg = DataGroup.objects.get(pk=pk)
    documents = dg.datadocument_set.filter(productdocument__document__isnull=True)
    npage = 20 # TODO: make this dynamic someday in its own ticket
    paginator = Paginator(documents, npage) # Show npage data documents per page
    page = request.GET.get('page')
    page = 1 if page is None else page
    docs_page = paginator.page(page)
    return render(request, template_name, {'documents':docs_page, 'datagroup':dg})


@login_required()
def link_product_form(request, pk, template_name=('product_curation/'
                                                    'link_product_form.html')):
    doc = DataDocument.objects.get(pk=pk)
    ds_id = doc.data_group.data_source_id
    initial = {   'upc': ('stub_' + str(Product.objects.all().aggregate(Max('id'))["id__max"] + 1)),
        'document_type': doc.document_type,
           'return_url': request.META.get('HTTP_REFERER')}
    form = ProductLinkForm(initial=initial)
    # limit document type options to those matching parent datagroup group_type
    queryset = DocumentType.objects.filter(group_type=doc.data_group.group_type)
    form.fields['document_type'].queryset = queryset
    if request.method == 'POST':
        form = ProductLinkForm(request.POST or None)
        if form.is_valid():
            upc = form['upc'].value()
            title = form['title'].value()
            product, created = Product.objects.get_or_create(upc=upc,
                                                        data_source_id = ds_id)
            if created:
                product.title = title
                product.manufacturer = form['manufacturer'].value()
                product.brand_name = form['brand_name'].value()
                product.upc = form['upc'].value()
                product.size = form['size'].value()
                product.color = form['color'].value()
                product.save()
            if not ProductDocument.objects.filter(document=doc,
                                                    product=product).exists():
                p = ProductDocument(product=product, document=doc)
                p.save()
            document_type = form['document_type'].value()
            if document_type != doc.document_type: # update if user changes
                doc.document_type = DocumentType.objects.get(pk=document_type)
                doc.save()
            if 'datadocument' in form['return_url'].value():
                return redirect('data_document', pk=doc.pk)
            else:
                return redirect('link_product_list', pk=doc.data_group.pk)
        else:
            pass #form is invalid
    return render(request, template_name,{'document': doc, 'form': form})


@login_required()
def detach_puc_from_product(request, pk):
    p = Product.objects.get(pk=pk)
    pp = ProductToPUC.objects.get(product=p)
    pp.delete()
    return redirect('product_detail', pk=p.pk)


@login_required()
def bulk_assign_tag_to_products(request):
    template_name = 'product_curation/bulk_product_tag.html'
    products = {}
    msg = ''
    puc_form = BulkPUCForm(request.POST or None)
    form = BulkProductTagForm()
    if puc_form['puc'].value():
        puc = PUC.objects.get(pk = puc_form['puc'].value())
        assumed_tags = puc.get_assumed_tags()
        puc2tags = (PUCToTag.objects.filter(content_object=puc,assumed=False).
                                                values_list('tag', flat=True))
        form.fields['tag'].queryset = PUCTag.objects.filter(id__in=puc2tags)
        prod2pucs = (ProductToPUC.objects.filter(puc = puc).
                                        values_list('product_id', flat=True))
        products = Product.objects.filter(id__in=prod2pucs)
    if request.method == 'POST' and 'save' in request.POST:
        form = BulkProductTagForm(request.POST or None)
        form.fields['tag'].queryset = PUCTag.objects.filter(id__in=puc2tags)
        if form.is_valid():
            assign_tag = PUCTag.objects.filter(id=form['tag'].value())
            tags = assumed_tags | assign_tag
            product_ids = form['id_pks'].value().split(",")
            for id in product_ids:
                product = Product.objects.get(id=id)
                #add the assumed tags to the update
                for tag in tags:
                    ProductToTag.objects.update_or_create(tag=tag,
                                                        content_object=product)
            puc_form = BulkPUCForm()
            form = BulkProductTagForm()
            tag = assign_tag[0]
            msg = f'The "{tag.name}" Attribute was assigned to {len(product_ids)} Product(s).'
            if assumed_tags:
                msg += (' Along with the assumed tags: '
                            f'{" | ".join(x.name for x in assumed_tags)}')
            products = {}
    return render(request, template_name, {'products': products,
                                            'puc_form': puc_form,
                                            'form': form, 
                                            'msg': msg})


@login_required()
def bulk_assign_puc_to_product(request, template_name=('product_curation/'
                                                      'bulk_product_puc.html')):
    max_products_returned = 50
    q = safestring.mark_safe(request.GET.get('q', '')).lstrip()
    if q > '':
        p = (Product.objects
            .filter( Q(title__icontains=q) | Q(brand_name__icontains=q) )
            .exclude(id__in=(ProductToPUC.objects.values_list('product_id', flat=True))
            )[:max_products_returned])
        full_p_count = Product.objects.filter(Q(title__icontains=q) | Q(brand_name__icontains=q)).count()
    else:
        p = {}
        full_p_count = 0
    form = BulkProductPUCForm(request.POST or None)
    if form.is_valid():
        puc = PUC.objects.get(id=form['puc'].value())
        product_ids = form['id_pks'].value().split(",")
        for id in product_ids:
            product = Product.objects.get(id=id)
            ProductToPUC.objects.create(puc=puc, product=product, classification_method='MB',
                                    puc_assigned_usr=request.user)
    form['puc'].label = 'PUC to Assign to Selected Products'
    return render(request, template_name, {'products': p, 'q': q, 'form': form, 'full_p_count': full_p_count})


@login_required()
def assign_puc_to_product(request, pk, template_name=('product_curation/'
                                                      'product_puc.html')):
    p = Product.objects.get(pk=pk)
    p2p = ProductToPUC.objects.filter(classification_method='MA', product=p).first()
    form = ProductPUCForm(request.POST or None, instance=p2p)
    if form.is_valid():
        if p2p:
            p2p.save()
        else:
            puc = PUC.objects.get(id=form['puc'].value())
            p2p = ProductToPUC.objects.create(puc=puc, product=p, classification_method='MA',
                                        puc_assigned_usr=request.user)
        referer = request.POST.get('referer') if request.POST.get('referer') else 'category_assignment'
        pk = p2p.product.pk if referer == 'product_detail' else p2p.product.data_source.pk
        return redirect(referer, pk=pk)
    form.referer = resolve(parse.urlparse(request.META['HTTP_REFERER']).path).url_name\
        if 'HTTP_REFERER' in request.META else 'category_assignment'
    form.referer_pk = p.id if form.referer == 'product_detail' else p.data_source.id
    return render(request, template_name,{'product': p, 'form': form})


@login_required()
def product_detail(request, pk):
    template_name = 'product_curation/product_detail.html'
    p = get_object_or_404(Product, pk=pk, )
    tagform = ProductTagForm(request.POST or None, instance=p)
    tagform['tags'].label = ''
    puc = p.get_uber_puc()
    assumed_tags = puc.get_assumed_tags() if puc else PUCTag.objects.none()
    if tagform.is_valid():
        tagform.save()
    docs = p.datadocument_set.order_by('-created_at')
    return render(request, template_name, {'product'      : p,
                                            'puc'         : puc,
                                            'tagform'     : tagform,
                                            'docs'        : docs,
                                            'assumed_tags': assumed_tags
                                            })


@login_required()
def product_update(request, pk, template_name=('product_curation/'
                                               'product_edit.html')):
    p = Product.objects.get(pk=pk)
    form = ProductForm(request.POST or None, instance=p)
    if form.is_valid():
        form.save()
        return redirect('product_detail', pk=p.pk)
    return render(request, template_name,{'product': p, 'form': form})


@login_required()
def product_delete(request, pk):
    p = Product.objects.get(pk=pk)
    p.delete()
    return redirect('product_curation')


@login_required()
def product_list(request):
    template_name = 'product_curation/products.html'
    products = Product.objects.all()
    data = {}
    data['products'] = products
    return render(request, template_name, data)

from django.http import HttpResponse
from django.contrib.auth.decorators import login_required
from django.shortcuts import render, redirect, get_object_or_404
from django.core.exceptions import ObjectDoesNotExist
from djqscsv import render_to_csv_response

from dashboard.forms import *
from dashboard.forms import ExtractedListPresenceTagForm
# if this goes to 0, tests will fail because of what num form we search for
from factotum.settings import EXTRA
from dashboard.models import *


@login_required()
def data_document_detail(request, pk):
    template_name = 'data_document/data_document_detail.html'
    doc = get_object_or_404(DataDocument, pk=pk, )
    code = doc.data_group.group_type.code
    edit = 1 if doc.detail_page_editable else 0
    # edit adds an extra record to the formset, but is also a switch in the
    # template and to add the delete input, this will only work if we add one at
    # a time...
    ParentForm, ChildFormSet = create_detail_formset(
        doc, extra=edit, can_delete=bool(edit))
    document_type_form = DocumentTypeForm(request.POST or None, instance=doc)
    qs = DocumentType.objects.filter(group_type=doc.data_group.group_type)
    document_type_form.fields['document_type'].queryset = qs
    context = {'doc': doc,
               'edit': edit,
               'document_type_form': document_type_form}
    if code == 'CP':
        # although keywords display as if at the datadocument level, they are
        # attached to each list_presence record. To display, we're getting the
        # tags associated with the first list_presence record, but on saving
        # (in save_list_presence_tag_form()) we loop over the whole set
        try:
            list_presence = doc.extractedtext.rawchem.select_subclasses('extractedlistpresence').first()
            list_presence_tag_form = ExtractedListPresenceTagForm(instance=list_presence)
            context.update({'list_presence_tag_form': list_presence_tag_form})
        except ObjectDoesNotExist:
            pass
    if doc.is_extracted:
        extracted_text = ExtractedText.objects.get_subclass(pk=doc.pk)
        child_formset = ChildFormSet(instance=extracted_text)
        if not edit:
            for form in child_formset.forms:
                for field in form.fields:
                    form.fields[field].widget.attrs['disabled'] = True
        context.update(
            {'edit_text_form': ParentForm(instance=extracted_text),
             'extracted_text': extracted_text,
             'detail_formset': child_formset}
        )

    else:
        context['edit_text_form'] = ParentForm()
    return render(request, template_name, context)


@login_required()
def save_doc_form(request, pk):
    '''Writes changes to the data document form 
    
    The request object should have a 'referer' key to redirect the 
    browser to the appropriate place after saving the edits

    Invoked by changing the document type in the data document detail view or the
    extracted text QA page template
    '''

    referer = request.POST.get('referer', 'data_document')
    doc = get_object_or_404(DataDocument, pk=pk)
    document_type_form = DocumentTypeForm(request.POST, instance=doc)
    if document_type_form.is_valid() and document_type_form.has_changed():
        document_type_form.save()
    return redirect(referer, pk=pk)


@login_required()
def data_document_note(request, pk):
    doc = get_object_or_404(DataDocument, pk=pk)
    doc_note = request.POST['dd_note']
    doc.note = doc_note
    doc.save()
    return redirect('data_document', pk=pk)


@login_required()
def save_ext_form(request, pk):
    referer = request.POST.get('referer', 'data_document')
    doc = get_object_or_404(DataDocument, pk=pk)
    ExtractedTextForm, _ = create_detail_formset(doc)
    extracted_text = ExtractedText.objects.get_subclass(pk=pk)
    ext_text_form = ExtractedTextForm(request.POST, instance=extracted_text)
    if ext_text_form.is_valid() and ext_text_form.has_changed():
        ext_text_form.save()
    return redirect(referer, pk=pk)

@login_required()
def save_list_presence_tag_form(request, pk):
    referer = request.POST.get('referer', 'data_document')
    extracted_text = get_object_or_404(ExtractedText, pk=pk)
    for extracted_list_presence in extracted_text.rawchem.select_subclasses('extractedlistpresence'):
        tag_form = ExtractedListPresenceTagForm(request.POST or None, instance=extracted_list_presence)
        if tag_form.is_valid():
            tag_form.save()
    return redirect(referer, pk=pk)

@login_required()
def data_document_delete(request, pk, template_name='data_source/datasource_confirm_delete.html'):
    doc = get_object_or_404(DataDocument, pk=pk)
    datagroup_id = doc.data_group_id
    if request.method == 'POST':
        doc.delete()
        return redirect('data_group_detail', pk=datagroup_id)
    return render(request, template_name, {'object': doc})

@login_required
def dg_dd_csv_view(request, pk):
    qs = DataDocument.objects.filter(data_group_id=pk)
    filename = DataGroup.objects.get(pk=pk).name
    return render_to_csv_response(qs, filename=filename, append_datestamp=True)

@login_required
def data_document_edit(request, pk, template_name=('data_document/'
                                                    'data_document_form.html')):
    datadocument = get_object_or_404(DataDocument, pk=pk)
    form = DataDocumentForm(request.POST or None, instance=datadocument)
    if form.is_valid():
        if form.has_changed():
            form.save()
        return redirect('data_document', pk=pk)
    form.referer = request.META.get('HTTP_REFERER', None)
    return render(request, template_name, {'form': form})


@login_required
def extracted_text_edit(request, pk):
    doc = get_object_or_404(DataDocument, pk=pk)
    ParentForm, _ = create_detail_formset(doc, extra=0, can_delete=False)
    model = ParentForm.Meta.model
    script = Script.objects.get(title__icontains='Manual (dummy)', script_type='EX')
    exttext, _ = model.objects.get_or_create(extraction_script=script,                    
                                             data_document_id=pk)                    
    form = ParentForm(request.POST, instance=exttext)
    if form.is_valid():
        form.save()
        doc.extracted = True
        doc.save()
        return redirect('data_document', pk=doc.pk)
    else:
        extext.delete()
        return HttpResponse("Houston, we have a problem.")


@login_required
def extracted_child_edit(request, pk):
    doc = get_object_or_404(DataDocument, pk=pk)
    _, ChildFormSet = create_detail_formset(doc, extra=1, can_delete=True)
    formset = ChildFormSet(request.POST, instance=doc.extractedtext)
    if formset.is_valid():
        formset.save()
    return redirect('data_document', pk=doc.pk)

from flask import Flask, redirect, url_for, render_template, request, session, flash
from flask.ext.sqlalchemy import SQLAlchemy
from oauth import OAuthSignIn
from subprocess import check_output, STDOUT, CalledProcessError
from werkzeug import generate_password_hash, check_password_hash, secure_filename

from database.database_create import Base, User
from database.database_insert import insert_user, insert_social_user
from database.database_query import query_user,query_social_user, number_of_users

import base64
import json
import os
import shutil
import tempfile

import parser

DEBUG = True                    
app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret'
app.config['OAUTH_CREDENTIALS'] = {
    'facebook': {
        'id': '604820106335654',
        'secret': '5eb3f15f84c722df9cbc577206557cc8'
    },
    'twitter': {
        'id': 'cGFr2WV93py7an7FrGXXNDS6p',
        'secret': 'U9ufkrhicVHrj5CGojmQ7ZCxSwytoShSgM0t9WCq0HbqcfKwL8'
    }
}
app.secret_key = 'fe2917b485cc985c47071f3e38273348' # echo team paddy paddy | md5sum
app.config['UPLOAD_FOLDER'] = 'userFiles/'
app.config['ALLOWED_EXTENSIONS'] = set(['pml'])


def get_resource_as_string(name, charset='utf-8'):
    with app.open_resource(name) as f:
        return f.read().decode(charset)
app.jinja_env.globals['get_resource_as_string'] = get_resource_as_string

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1] in app.config['ALLOWED_EXTENSIONS']

@app.route("/", methods=["POST"])
def my_form_post():
    with tempfile.NamedTemporaryFile(mode='w+t', suffix='.pml') as f:
        fname = f.name

        f.write(request.form["program"])
        f.flush()

        try:
            return check_output(["./pmlcheck", fname], stderr=STDOUT).decode().replace(fname+':', "Line ")
        except CalledProcessError as e:
            return e.output.decode().replace(fname+':', "Line "), 400


@app.route("/")
def editor(filename = ""):
    editor_content = "";
    if session.get('tempFile') is not None:
        if session['tempFile'] != "":
            editor_content = open(session['tempFile']).read();

    if 'filename' in request.args or filename != "" or 'currentFile' in session:
        if not filename:
            if 'filename' in request.args:
                filename = request.args['filename']
            else:
                 filename = session['currentFile']
        if ('email' in session) or ('social' in session):
            if 'email' in session:
                email = session['email']
            elif 'social' in session:
                email = session['social']
            userpath = os.path.join(app.config['UPLOAD_FOLDER'], email)
            filepath = os.path.join(userpath, filename)
            session['currentFile'] = filename
            try:
                with open(filepath) as f:
                    editor_content = f.read()
            except FileNotFoundError:
                editor_content = "" #TODO: some kind of message here

    return render_template("editor.html", editor_content=editor_content)


@app.route('/openFile')
def openFile():
    if (not 'email' in session) and (not 'social' in session):
        if 'diagram' in request.args:
            return redirect('/login?return_url=openFile&diagram=true')
        return redirect('/login?return_url=openFile')

    files = []
    if 'email' in session:
        email = session['email']
    elif 'social' in session:
        email = session['social']
    userpath = os.path.join(app.config['UPLOAD_FOLDER'], email)
    try:
        files = os.listdir(userpath)
    except: # userpath doesn't exist yet; create it and assume empty
        os.makedirs(userpath, exist_ok=True)
    # print ("CURRENT file: ", session['currentFile'])
    return render_template('openFile.html', files=files)

@app.route('/upload', methods=['POST'])
def upload():
    if (not 'email' in session) and (not 'social' in session):
        return "", 401 # not authorised
    if 'email' in session:
        email = session['email']
    elif 'social' in session:
        email = session['social']
    file = request.files['file']
    filename = ""
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        userpath = os.path.join(app.config['UPLOAD_FOLDER'], email)
        os.makedirs(userpath, exist_ok=True)
        file.save(os.path.join(userpath, filename))
        session['currentFile'] = filename
        if 'diagram' in request.referrer:
            return redirect('/diagram?filename=%s'%filename)
        return redirect('/?filename=%s'%filename)
    flash("Invalid file")
    return redirect('/openFile')


@app.route('/save')
def save():
    if (not 'email' in session) and (not 'social' in session):
        return redirect('/login?return_url=saveAs')
    if 'currentFile' in session:
        return saveFile(session['currentFile'])
    if 'diagram' in request.referrer:
        return saveAs(True)
    return saveAs()

@app.route('/saveAs')
def saveAs(diagram=False):
    if (not 'email' in session) and (not 'social' in session):
        if 'diagram' in request.args or diagram:
            return redirect('/login?return_url=saveAs&diagram=true')
        return redirect('/login?return_url=saveAs')
    else:
        return render_template('saveFile.html', diagram=diagram)

@app.route('/saveAs', methods=['POST'])
@app.route('/save', methods=['POST'])
def saveFile(fname=None):
    if (not 'email' in session) and (not 'social' in session):
        return "", 401 # not authorised

    name = fname if fname else request.form['filename']
    if name:
        if name[-4:] != ".pml": # check for '.pml' extension
            name += ".pml"

        if allowed_file(name):
            session['currentFile'] = name
            if 'email' in session:
                email = session['email']
            elif 'social' in session:
                email = session['social']
            savepath = os.path.join(app.config['UPLOAD_FOLDER'], email)
            os.makedirs(savepath, exist_ok=True) # make the users save dir if it doesn't already exist

            saveFilePath = os.path.join(savepath, name)
            tempFilePath = session.pop("tempFile", None)

            if tempFilePath:
                shutil.copy(tempFilePath, saveFilePath)
                if "diagram" in request.referrer or 'diagram' in request.args or 'diagram' in request.form:
                    return redirect('/diagram?filename=%s'%name)
                else:
                    return redirect('/?filename=%s'%name)

    flash("Invalid File")
    return redirect('/saveAs')

@app.route("/diagram")
def diagram():
    if 'filename' in request.args:
        filename = request.args['filename']
        if('email' in session) or ('social' in session):
            if 'email' in session:
                email = session['email']
            elif 'social' in session:
                email = session['social']
            userpath = os.path.join(app.config['UPLOAD_FOLDER'], email)
            filepath = os.path.join(userpath, filename)
            session['currentFile'] = filename
            try:
                with open(filepath) as f:
                    data = f.read()
                    parsed = parser.parse(data)
                    return render_template("diagramEditor.html", data=json.dumps(parsed))
            except parser.ParserException: pass
            except FileNotFoundError:
                editor_content = ""

    elif 'tempFile' in session or 'currentFile' in session:
        if 'tempFile' in session:
            filepath = session['tempFile']
        if 'currentFile' in session and ('email' in session) or ('social' in session):
            if 'email' in session:
                email = session['email']
            elif 'social' in session:
                email = session['social']
            filename = session['currentFile']
            userpath = os.path.join(app.config['UPLOAD_FOLDER'], email)
            filepath = os.path.join(userpath, filename)
        with open(filepath) as f:
            data = f.read()
            try:
                parsed = parser.parse(data) #TODO: proper error message
                return render_template("diagramEditor.html", data=json.dumps(parsed))
            except parser.ParserException: pass

    return render_template("diagramEditor.html")

@app.route("/signup")
def renderSignUp():
    if 'return_url' in request.args:
        session['return_url'] = request.args['return_url']

    return render_template("register.html")


@app.route("/signup", methods=["POST"])
def signUpButton():
    email = request.form["email"]
    user = query_user(email)
    if user == None:
        password = request.form["password"]
        password_hash = generate_password_hash(password)
        insert_user(email, password_hash)
        session['email'] = email

        returnUrl = session.pop('return_url', None)
        if returnUrl:
            return redirect(returnUrl)
        else:
            return redirect('/')
    # email has been used
    flash('Email already in use')
    return redirect('/signup')



@app.route("/login")
def login():
    if 'return_url' in request.args:
        session['return_url'] = request.args['return_url']
    return render_template("login.html")


@app.route("/login", methods=["POST"])
def loginButton():
    email = request.form["email"]
    password = request.form["password"]
    user = query_user(email)
    if user != None:
        if check_password_hash(user.password, password):
            session['email'] = email
            returnUrl = session.pop('return_url', None)
            if returnUrl:
                return redirect(returnUrl)
            else:
                return redirect('/')

    flash('Incorrect Email/Password')
    return redirect('/login')


@app.route("/logout")
def logout():
    session.clear()
    if 'return_url' in request.args:
        return redirect(request.args['return_url'])
    else:
        return redirect('/')

@app.route("/tmp", methods=["POST"])
def tmp():
    with tempfile.NamedTemporaryFile(mode="w+t", delete=False) as f:
        content = base64.b64decode(request.form["content"]).decode()
        f.write(content)
        session["tempFile"] = f.name
        return ""

@app.route("/resetCurrent")
def resetCurrent():
    session.pop('currentFile', None)
    session.pop('tempFile', None)
    return ""
@app.route('/authorize/<provider>')
def oauth_authorize(provider):
    oauth = OAuthSignIn.get_provider(provider)
    return oauth.authorize()


@app.route('/callback/<provider>')
def oauth_callback(provider):
    oauth = OAuthSignIn.get_provider(provider)
    social, username, email = oauth.callback()
    if social is None:
        flash('Authentication failed.')
        return redirect(url_for('login'))
    user = query_social_user(social);
    session['social'] = social
    if user is None:
        insert_social_user(social)
    return redirect('/')

if __name__ == "__main__":
	app.run(host="localhost", port=8000, debug=DEBUG)

from optparse import OptionParser
from dependencies import read_dependencies_from_filename
import os
import platform
import threading
import sys
import subprocess
import shutil
import time
import ctypes
import datetime

VERSION = 5

DEFAULT_STEPS = "default"
ALL_STEPS = "all"
ILLEGAL_STEP_NAMES = [DEFAULT_STEPS, ALL_STEPS]

class BaseUserLock(object):
    def __init__(self, filename):
        self.filename = filename
        self.locktime = None
    def __enter__(self):
        dirname = os.path.split(os.path.abspath(self.filename))[0]
        if not os.path.exists(dirname):
            os.makedirs(dirname)
        while True:
            if self.tryacquire(self.filename):
                break
            print "Lockfile "+self.filename+" not available."
            print "Wait 30s..."
            time.sleep(30.0)
        self.locktime = datetime.datetime.now()
        print "Lock acquired at "+str(self.locktime)
    def __exit__(self, etype, einstance, etraceback):
        self.release()
        unlocktime = datetime.datetime.now()
        print "Lock released at "+str(unlocktime)
        print "Lock was held for "+str(unlocktime - self.locktime)

class WindowsUserLock(BaseUserLock):
    def __init__(self, name):
        BaseUserLock.__init__(self, os.environ["APPDATA"]+"\\openhome-build\\"+name+".lock")
    def tryacquire(self, filename):
        self.handle = ctypes.windll.kernel32.CreateFileA(filename,7,0,0,2,0x04000100,0)
        return self.handle != -1
    def release(self):
        ctypes.windll.kernel32.CloseHandle(self.handle)

class PosixUserLock(BaseUserLock):
    def __init__(self, name):
        BaseUserLock.__init__(self, os.environ["HOME"]+"/.openhome-build/"+name+".lock")
    def tryacquire(self, filename):
        import fcntl
        self.f = file(filename, "w")
        try:
            fcntl.lockf(self.f, fcntl.LOCK_EX)
            return True
        except IOError:
            self.f.close()
            return False
    def release(self):
        self.f.close()

def userlock(name):
    '''
    Acquire a lock scoped to the local user. Only one build at a time can run
    with the given name per user per machine. While waiting for the lock, prints
    a notice to stdout every 30s.
    '''
    if platform.system() == 'Windows':
        return WindowsUserLock(name)
    return PosixUserLock(name)

def get_vsvars_environment():
    """
    Returns a dictionary containing the environment variables set up by vsvars32.bat

    win32-specific
    """
    vs100comntools = os.environ['VS100COMNTOOLS']
    if vs100comntools is None:
        raise Exception("VS100COMNTOOLS is not set in environment.")
    vsvars32 = os.path.join(vs100comntools, 'vsvars32.bat')
    python = sys.executable
    process = subprocess.Popen('("%s">nul)&&"%s" -c "import os; print repr(os.environ)"' % (vsvars32, python), stdout=subprocess.PIPE, shell=True)
    stdout, _ = process.communicate()
    exitcode = process.wait()
    if exitcode != 0:
        raise Exception("Got error code %s from subprocess!" % exitcode)
    return eval(stdout.strip())

def default_platform():
    if platform.system() == 'Windows':
        return 'Windows-x86'
    if platform.system() == 'Linux' and platform.architecture()[0] == '32bit':
        return 'Linux-x86'
    if platform.system() == 'Linux' and platform.architecture()[0] == '64bit':
        return 'Linux-x64'
    return None

def delete_directory(path, logfile=None):
    if logfile is None:
        logfile = open(os.devnull, "w")
    path = os.path.abspath(path)
    logfile.write('Deleting "'+path+'"... ')
    shutil.rmtree(path, ignore_errors=True)
    if os.path.isdir(path):
        logfile.write('\nFailed.\n')
        raise Exception('Failed to delete "%s"' % path)
    logfile.write('\nDone.\n')

class BuildStep(object):
    def __init__(self, name, action):
        if name in ILLEGAL_STEP_NAMES:
            fail("'{0}' is not allowed as a build step name.".format(name))
        self.name = name
        self.condition_sets = []
        self.is_optional = False
        self.is_enabled_by_default = True
        self.action = action
    def add_conditions(self, condition_set):
        self.condition_sets.append(condition_set)
    def set_default(self, enabled_by_default):
        self.is_enabled_by_default = enabled_by_default
    def set_optional(self, optional):
        self.is_optional = optional
    def test_conditions(self, env):
        if len(self.condition_sets) == 0:
            return True
        for conditions in self.condition_sets:
            if all(key in env and env[key]==value for (key, value) in conditions.items()):
                return True
        return False
    def run(self, context):
        return self.action(context)

class BuildContext(object):
    pass

def flatten_string_list(arglist):
    """
    Assemble a list of string, such as for a subprocess call.
    Input should be a string or a list containing only
    strings or similar lists.
    Output will be a list containing only strings.
    """
    if isinstance(arglist, (str, unicode)):
        return [arglist]
    return sum([flatten_string_list(x) for x in arglist], [])

def flatten_comma_list(arglist):
    return sum([s.split(",") for s in arglist], [])

def process_kwargs(func_name, kwarg_dict, defaults_dict):
    result = dict(defaults_dict)
    for key, value in kwarg_dict.items():
        if key in result:
            result[key] = value
        else:
            raise TypeError("{0}() got an unexpected keyword argument '{1}'".format(func_name, key))
    return result

class Builder(object):
    def __init__(self):
        self._steps = []
        self._optionParser = OptionParser()
        self.add_bool_option("-v", "--verbose")
        self._enabled_options = set()
        self._disabled_options = set()
        self._disable_all_options = False
        self._enable_all_options = False
        #self._context = BuildContext()
    def build_condition(self, name=None, **conditions):
        """Decorator applied to functions in the build_behaviour file."""
        def decorator_func(f):
            if not hasattr(f, "buildstep"):
                f.buildstep = BuildStep(name or f.__name__, f)
                self._steps.append(f.buildstep)
            f.buildstep.add_conditions(conditions)
            return f
        return decorator_func
    def build_step(self, name=None, optional=False, default=True):
        def decorator_func(f):
            if not hasattr(f, "buildstep"):
                f.buildstep = BuildStep(f.__name__, f)
                self._steps.append(f.buildstep)
            if name is not None:
                f.buildstep.name = name
            f.buildstep.set_optional(optional)
            f.buildstep.set_default(default)
            return f
        return decorator_func
    def get_optional_steps(self):
        return (step.name for step in self._steps if self.is_optional)
    def specify_optional_steps(self, *steps):
        '''
        Specify which optional steps to include in the build.
        "default" includes all default steps.
        "all" includes all steps.
        "foo" or "+foo" includes step foo.
        "-foo" excludes step foo, even if "default" or "all" is present.
        '''
        steps = flatten_string_list(steps)
        steps = flatten_comma_list(steps)
        self._enable_all_options = ALL_STEPS in steps
        #self._enable_default_options = DEFAULT_STEPS in steps
        self._disable_all_options = DEFAULT_STEPS not in steps
        self._disabled_options = set(s[1:] for s in steps if s.startswith("-"))
        self._enabled_options = set(s[1:] for s in steps if s.startswith("+"))
        self._enabled_options = self._enabled_options.union(
                s for s in steps if s[0] not in "+-")
    def modify_optional_steps(self, *steps):
        '''
        Add or remove optional steps in the build.
        "+foo" include step foo.
        "-foo" exclude step foo.
        '''
        for name in steps:
            if name.startswith("+"):
                name = name[1:]
                self._disabled_options.discard(name)
                self._enabled_options.add(name)
            elif name.startswith("-"):
                name = name[1:]
                self._enabled_options.discard(name)
                self._disabled_options.add(name)
            else:
                raise TypeError("Each step must be a string beginning with '+' or '-'.")

    def select_optional_steps(self, *args, **kwargs):
        '''
        Deprecated. Use specify_optional_steps or modify_optional_steps instead.
        '''
        kwargs = process_kwargs(
            "select_optional_steps",
            kwargs,
            {"disable_others":False})
        if kwargs["disable_others"]:
            self._enabled_options.clear()
            self._disable_all_options = True
        args = flatten_string_list(args)
        args = flatten_comma_list(args)
        self.modify_optional_steps(*args)

    def run(self, argv=None):
        self._context = BuildContext()
        options, args = self._optionParser.parse_args(argv)
        self._context.options = options
        self._context.args = args
        self._context.env = dict(os.environ)
        for step in self._steps:
            if step.test_conditions(self._context.env):
                enabled = True
                if step.is_optional:
                    enabled = step.is_enabled_by_default
                    if self._disable_all_options:
                        enabled = False
                    if step.name in self._enabled_options:
                        enabled = True
                    if step.name in self._disabled_options:
                        enabled = False
                if enabled:
                    print step.name
                    step.run(self._context)
    def add_bool_option(self, *args, **kwargs):
        kwargs=dict(kwargs)
        kwargs["default"] = False
        kwargs["action"] = "store_true"
        self.add_option(*args, **kwargs)
    def add_option(self, *args, **kwargs):
        self._optionParser.add_option(*args, **kwargs)

    def _check_call(self, *args, **kwargs):
        if self._context.options.verbose:
            argstring = [", ".join([repr(arg) for arg in args])]
            kwargstring = [", ".join(["%s=%r" % (k,v) for (k,v) in kwargs.items()])]
            print "subprocess.check_call(%s)" % (", ".join(argstring+kwargstring))
        subprocess.check_call(*args, **kwargs)

    def python(self, *args, **kwargs):
        args = flatten_string_list(args)
        self._check_call([sys.executable] + args, env=self._context.env, **kwargs)
    def shell(self, *args, **kwargs):
        args = flatten_string_list(args)
        self._check_call(args, env=self._context.env, shell=True, **kwargs)
    def rsync(self, *args, **kwargs):
        args = flatten_string_list(args)
        self._check_call(["rsync"] + args, **kwargs)
    def _dependency_collection(self):
        return read_dependencies_from_filename(os.path.join('projectdata', 'dependencies.txt'), logfile=sys.stdout)
    def fetch_dependencies(self, *dependencies, **kwargs):
        kwargs = process_kwargs(
            "fetch_dependencies",
            kwargs,
            {"platform":None})
        dependencies = flatten_string_list(dependencies)
        platform = kwargs['platform'] or self._context.env["PLATFORM"]
        dependency_collection = self._dependency_collection()
        delete_directory(os.path.join('dependencies', platform), logfile=sys.stdout)
        if len(dependencies) > 0:
            if not dependency_collection.fetch(dependencies, self._context.env):
                raise AbortRunException()
    def get_dependency_args(self, *dependencies):
        dependencies = flatten_string_list(dependencies)
        dependency_collection = self._dependency_collection()
        return dependency_collection.get_args(dependencies, self._context.env)

class SshSession(object):
    def __init__(self, host, username):
        import paramiko
        self.ssh = paramiko.SSHClient()
        self.ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        self.ssh.connect(host, username=username, look_for_keys='True')
    def call(self, *args, **kwargs):
        stdin, stdout, stderr = self.ssh.exec_command(*args, **kwargs)
        def pump_output_thread(source, destination):
            for line in source:
                destination.write(line)
                destination.flush()
        stdout_thread = threading.Thread(target=pump_output_thread, args=(stdout, sys.stdout))
        stderr_thread = threading.Thread(target=pump_output_thread, args=(stderr, sys.stderr))
        stdout_thread.start()
        stderr_thread.start()
        stdout_thread.join()
        stderr_thread.join()
        return stdout.channel.recv_exit_status()
    def __call__(self, *args):
        return self.call(*args)
    def __enter__(self):
        return self
    def __exit__(self, ex_type, ex_value, ex_traceback):
        self.ssh.close()

class AbortRunException(Exception):
    def __init__(self, message="Aborted due to error.", exitcode=1):
        Exception.__init__(self, message)
        self.message = message
        self.exitcode = exitcode

def fail(*args, **kwargs):
    '''
    fail(message, exitcode=1)
    Abort the build with an error message.
    '''
    raise AbortRunException(*args, **kwargs)

def require_version(required_version):
    '''Fail if the version of ohDevTools is too old.'''
    if VERSION<required_version:
        fail("This build requires a newer version of ohDevTools. You have version {0}, but need version {1}.".format(VERSION, required_version),32)

def windows_program_exists(program):
    return subprocess.call(["where", "/q", program], shell=False)==0

def other_program_exists(program):
    return subprocess.call(["/bin/sh", "-c", "command -v "+program], shell=False, stdout=open(os.devnull), stderr=open(os.devnull))==0                    

program_exists = windows_program_exists if platform.platform().startswith("Windows") else other_program_exists

def scp(*args):
    program = None
    for p in ["scp", "pscp"]:
        if program_exists(p):
            program = p
            break
    if program is None:
        raise "Cannot find scp (or pscp) in the path."
    subprocess.check_call([program] + list(args))

def run(buildname="build", argv=None):
    builder = Builder()
    behaviour_globals = {
            'fetch_dependencies':builder.fetch_dependencies,
            'get_dependency_args':builder.get_dependency_args,
            'add_option':builder.add_option,
            'add_bool_option':builder.add_bool_option,
            'python':builder.python,
            'shell':builder.shell,
            'rsync':builder.rsync,
            'build_step':builder.build_step,
            'build_condition':builder.build_condition,
            'default_platform':default_platform,
            'get_vsvars_environment':get_vsvars_environment,
            'SshSession':SshSession,
            'select_optional_steps':builder.select_optional_steps,
            'modify_optional_steps':builder.modify_optional_steps,
            'specify_optional_steps':builder.specify_optional_steps,
            'userlock':userlock,
            'fail':fail,
            'scp':scp,
            'require_version':require_version
        }
    try:
        execfile(os.path.join('projectdata', buildname+'_behaviour.py'), behaviour_globals)
        builder.run(argv)
    except AbortRunException as e:
        print e.message
        sys.exit(e.exitcode)

from utility import *
import json

def createGetScript(endpoint, params):
    script = 'curl '+start_url+endpoint+'?'
    keys = params.keys()
    values = params.values()
    pair = [keys[i]+'='+values[i] for i in range(len(keys))]
    evil_param = '&'.join(pair)
    script+=evil_param
    return script

def createPostScript(endpoint, params):
    keys = params.keys()
    values = params.values()
    pair = [keys[i]+'='+values[i] for i in range(len(keys))]
    evil_param = '&'.join(pair)
    script = 'curl -d ' + '"'+ evil_param  +'" '+'-X POST '+start_url+endpoint
    return script

def genDT(endpoint,params,method):
    scope = {
        'class':DT,
        'results':{
            start_url: [
                {
                    'endpoint': endpoint,
                    'params': params,
                    'method': method
                }
            ]
        }
    }    

    script = ''
    if method == 'GET':
        script = createGetScript(endpoint, params)
        
    return scope, script

def genSI(endpoint, params, method):
    scope = {
        'class':SI,
        'results':{
            start_url: [
                {
                    'endpoint': endpoint,
                    'params': params,
                    'method': method
                }
            ]
        }
    }

    if method == 'POST':
        script = createPostScript(endpoint,params)
    
    return scope, script

def genSCI():
    pass                    

def genSSCI():
    pass                    

def genCSRF():
    pass                    

def genOR():                    
    pass                    

render = {
    DT: genDT,
    SI: genSI,
    CSRF: genCSRF,
    OR: genOR,
    SSCI: genSSCI,
    SCI: genSCI
}

class generator(object):
    def __init__(self,category):
        self.scope = {}
        self.category = category
        self.cate_str = '_'.join(category.split(' '))
        self.count = 0
        
    def updateScope(self,scope):
        if(self.count):
            self.scope['results'][start_url]+=scope['results'][start_url]
        else:
            self.scope=scope
        self.count += 1
        
    def saveScript(self,script):
        script_name = 'result/'+self.cate_str+'_attack'+str(self.count)+'.sh'
        with open(script_name, 'w') as f:
            f.write(script)

    def saveScope(self):
        file_name = 'result/'+self.cate_str+'_scope.json'
        with open(file_name,'w+') as f:
            json.dump(self.scope,f)


import requests
from utility import *

banner(OR)
links = read_links()

for link in links:
    url = get_url(link)
    params = get_params(url)
    params['redirect'] = 'https://www.google.com'                    
    fullURL = generate_url_with_params(url, params)                    
    req = requests.get(fullURL)                    
    if req.content.find('google') != -1:                    
        success_message(fullURL)                    

print '\n'

###########################################################################
# IMPORTS - GEN ###########################################################

from flask import (Flask,
                   # Flask allows app object
                   session, flash,
                   # session allows use of session storage for login
                   render_template, redirect,
                   # render_template allows html render functionality
                   request,
                   # request allows use of forms in html templates
                   jsonify)
from flask_debugtoolbar import DebugToolbarExtension
import jinja2
import random
from model import (db, connect_to_db,
                   User, Team, UserTeam, Board, Project, Phase)
import query as q
import helper as h

# import pdb; pdb.set_trace()


###########################################################################
# FLASK APP SETUP #########################################################

app = Flask(__name__)  # makes app object
app.secret_key = "It's great to stay up late"
    # allows session use 'under the hood'

app.jinja_env.undefined = jinja2.StrictUndefined
    # Normally, if you refer to an undefined variable in a Jinja template,
        # Jinja silently ignores this. "This makes debugging difficult, so
        # we'll set an attribute of the Jinja environment that says to make
        # this an error.""
app.jinja_env.auto_reload = True
    # Fixes error that will sometimes happen where (in some versions of Flask)
        # you have to re-start your server with every change on your template.


###########################################################################
# SESSION STORAGE #########################################################

# Keys:
    # "is_logged_in" (bool)
    # "user_id" (int)
    # "team_id" (int)
    # "new_user" (bool)
    # "displayname" (str)
    # "current_board" (int)


###########################################################################
# INDEX ###################################################################

@app.route("/")
def index():
    """Return index (homepage)."""

    logged_in = session.get("is_logged_in")

    # How do I check for logged in status before rendering?
    # What do I want to show for people who are logged in?
    return render_template("home.html")


###########################################################################
# REGISTRATION ############################################################

@app.route("/register", methods=["POST"])
def make_new_user():
    """Validate new user form entry, register user if valid."""

    email = request.form.get('email')
    pw = request.form.get('pw')
    displayname = request.form.get('displayname')

    user_record = User.query.filter(User.email == email).first()
    # queries user table for first record for email; returns None if no record
    if user_record is None:

        new_user = q.make_user(email, pw, displayname)
        q.add_to_db(new_user)

        user = q.get_user_by_email(email)
        h.update_session_for_good_login(user.u_id, user.displayname)

        session["new_user"] = True  # Pending: Tutorial
        flash("Account created!")
        return redirect("/dashboard")

    else:
        flash("That email address has already been registered")
        return redirect("/")


###########################################################################
# LOG IN ##################################################################

@app.route("/login", methods=["GET"])
def display_login():
    """Load login form."""

    return render_template("login.html")


@app.route("/login", methods=["POST"])
def log_in_returning_user():
    """Validate login entry."""

    # update login count to calculate attempts and remaining
    num_attempts = h.get_login_attempts()
    remaining = h.calc_attempts_remaining(num_attempts)

    # getting data from user input in login.html form
    email = request.form.get('email')
    pw = request.form.get('pw')

    user_record = q.get_user_by_email(email)

    if user_record is None:
        flash("No account found with that email. Would you like to register?")
        return redirect("/login")

    else:  # the email is valid

        # validate password, handle accordingly
        if user_record.password != pw:
            template = h.handle_bad_attempts(remaining)
            return render_template(template)

        # is valid password, handle accordingly
        else:
            h.update_session_for_good_login(user_record.u_id,
                                            user_record.displayname)
            flash("Welcome back to SamePage")
            return redirect("/dashboard")


 # LOGIN: PASSWORD HANDLING ##############################################

@app.route("/login/password-recovery")
def password_recovery():
    """Displays form to send email to user for password recovery"""

    return "OOOOOOOPS"


###########################################################################
# DASHBOARD ###############################################################

@app.route("/dashboard")
def dashboard():
    """Renders dashboard view, grabbing existing teams for display"""

    session["team_id"] = None
        # Creates a session key for team_id, which is needed in the new board
        # route, and therefore must be reset.

    if session.get("new_user"):
        flash("""Welcome to SamePage. Hover over different areas on our pages
            for tutorial tips. You can turn the tutorial off and on from your
            Dashboard.""")

    if session.get("is_logged_in") is True:
        # Fossil from validation version; does not hurt to keep
        teams_list = []
        invites_list = []
        user_id = session.get("user_id")
        user_object = q.get_user_object(user_id)

        ut_objects = user_object.userteams  # makes a list of objects
        for userteam in ut_objects:
            if userteam.is_member:
                team_dict = {"team_id": userteam.team_id,
                             "name": userteam.team.name,
                             "desc": userteam.team.desc}
                teams_list.append(team_dict)
            elif userteam.is_member is None:
            # null value means invite decision pending
                invite_dict = {"team_id": userteam.team_id,
                               "name": userteam.team.name,
                               "desc": userteam.team.desc}
                invites_list.append(invite_dict)

        return render_template('dashboard.html',                     
                               teams_list=teams_list,
                               invites_list=invites_list,                     
                               displayname=user_object.displayname)

    else:
        return redirect("/")
            # Prevents view if not logged in
            # Fossil from validation version; does not hurt to keep


@app.route("/new-team", methods=["POST"])
def create_team():
    """Create Team model and UserTeam model, updating database each time."""

    name = request.form.get("name", "Untitled")
    desc = request.form.get("description", None)

    user_id = session.get("user_id")

    new_team = q.make_team(name, desc)
    q.add_to_db(new_team)

    # We now have the team id, so we can make the UserTeam relationship
    new_userteam = q.make_userteam(user_id, new_team.t_id)
    q.add_to_db(new_userteam)

    # flash("Team created! MAKE POPUP TO ASK To GO STRAIGHT TO THE TEAM PAGE")
    return jsonify({"teamId": new_team.t_id})


@app.route("/team-invitation", methods=["POST"])
def update_team_membership():
    """Update UserTeam membership field's value to true;
    update Dashboard with a redirect."""

    # This route is currently in contrast to the style of making a new team,
        # which is an ajax request.
    user_id = session["user_id"]
    team_id = request.form.get("team")
    user_choice = request.form.get("is_joining")
        # in dashboard.html hidden value; True or False

    # Cleanse data from html as soon as possible
    if user_choice == "True":
        user_choice = True  # this line doesn't work
    else:
        user_choice = False

    q.update_userteam_relationship(user_id, team_id, user_choice)

    flash("Your team invites have been updated!")

    return redirect("/dashboard")


@app.route("/ignored-teams", methods=["GET"])
def display_ignored_teams():
    """PENDING PENDING PENDING"""
    return "Pending my good lady"


###########################################################################
# TEAM MAIN AND BOARDS ####################################################

@app.route("/view-team")
def view_team():
    """Renders view of team page, with board"""

    team_id = session.get("team_id")

    team_object = Team.query.filter_by(t_id=team_id).first()  # REFACTOR THIS

    return render_template("team-main.html", team=team_object)


@app.route("/view-team", methods=["POST"])
def view_team_and_update_session():
    """Renders view of team page, with board"""

    team_id = request.form.get("team")

    session["team_id"] = team_id

    team_object = Team.query.filter_by(t_id=team_id).first()  # REFACTOR THIS

    return render_template("team-main.html", team=team_object)


@app.route("/new-board", methods=["POST"])
def make_new_board():
    """Make a new board and update page without refresh; ajax."""

    ##### VALIDATION HERE PLEASE ######
    user_id = session.get("user_id")

    name = request.form.get("new-board-name", "Untitled")  # board's name input
        # Is this a good way to handle not requiring the team or board name
            # in the form, but in the data fields?
    desc = request.form.get("new-board-desc", None)  # board's desc input
    team_id = request.form.get("team-id")

    session["team_id"] = team_id
    # Not sure if I need this; it should already be there, but this keeps it
        # current

    new_board = q.make_board(name, desc, team_id)
    q.add_to_db(new_board)

    flash("Board created! MAKE THAT BOARD SHOW AS DEFAULT!!!!")                    
    return redirect("/view-team")


@app.route("/current-board", methods=["POST"])
def update_most_recently_clicked_board():
    """ """

    # Below is v1.0. Next version involves updating the db model to track this
    # information, so the board is displayed on login.

    board_id = request.form.get("boardId")
    session["current_board"] = board_id
    print "Session updated with board {}.".format(board_id)

    return "HTTP-status-code: 200"


@app.route("/claim-project", methods=["POST"])
def assign_user_to_project():
    """Update database with user_id for the project."""

    user_id = session.get("user_id")
    project_id = request.form.get("projectId")

    q.update_user_claiming_project(user_id, project_id)
        # Also updates project to "item"

    return "HTTP-status-code: 200"


@app.route("/add-to-board", methods=["POST"])
def add_new_project_to_board():
    """Update database with new project and display on correct board
    on team main."""

    # make the board that the project was added to show by default. important
    title = request.form.get("new-project-title", "Untitled")
    # The title text box is required, but this is in case I change that soon.
    notes = request.form.get("new-project-notes", None)
    phase_code = request.form.get("project-phase")
    board_id = request.form.get("board-id")

    new_project = q.make_project(title, notes, phase_code, board_id)
    q.add_to_db(new_project)

    # need to use datetime, rather than session key, pick which board to have
        # open...how do we update datetime, and how do
    flash("New a new {} has been added to your board!".format(phase_code))
    return redirect("/view-team")


@app.route("/view-details/<int:project_id>", methods=['GET'])
def open_project_details(project_id):
    """ """

    project_object = Project.query.filter_by(p_id=project_id).first()
    user_id = session.get("user_id")
    results = {"userId": user_id,
               "pOwnerId": project_object.user_id,
               "pTitle": project_object.title,
               "pNotes": project_object.notes,
               "pPhase": project_object.phase_code,
               "pUpvotes": project_object.upvotes,
               "pUpdated": project_object.updated
               }
    if project_object.user_id:
        results["pOwnerName"] = project_object.user.displayname
    print results.keys
    return jsonify(results)


@app.route("/save-update/<int:project_id>", methods=['POST'])
def save_updated_project_details(project_id):
    """ """
    project_object = Project.query.filter_by(p_id=project_id).first()

    # One checkbox with name completed, so using .get is fine
    checked_lst = request.form.get("completion")
    updated_notes = request.form.get("notes")

    project_object.notes = updated_notes

    congratulatory_messages = ["High five!", "Nice work!", "You rock.",
                               "Nice."]

    if checked_lst == "is-checked":  # making explicit

        project_object.phase_code = "done"
        flash("Action item is completed. {}".format
              (random.choice(congratulatory_messages)))
        # A little corny...but that is on brand. So why not.
    else:
        flash("Changes saved.")
    db.session.commit()

    return redirect("/view-team")


@app.route("/invite-teammates/<int:team_id>", methods=['POST'])
def invite_new_teammates(team_id):
    """ """

    team_object = Team.query.filter_by(t_id=team_id).first()

    emails_lst = request.form.getlist("email")
    messages_list = request.form.getlist("email-message")
    sender = session.get("displayname")

    default_message = """{sender} has invited you to join the team
    {team_name} on SamePage. Accept to help complete projects for
    {team_name}.""".format(sender=sender, team_name=team_object.name)

    flash_message = "Emails sent to\n"
    for i in xrange(len(emails_lst)):
        if not messages_list[i]:
            message = default_message
        else:
            message = messages_list[i]
        flash_message = flash_message + emails_lst[i] + "\n"

        h.send_team_invite(emails_lst[i],
                           sender,
                           message,
                           team_object.name)

    flash(flash_message)
    return redirect("/view-team")


###########################################################################
# ACTION BOARD ############################################################

@app.route("/actions-board")
def display_user_actions_board():
    """Retrieve user and project data from db,
    render projects on action page. """

    if session.get("is_logged_in") is True:
        # Fossil from validation version; does not hurt to keep
        user_id = session.get("user_id")
        projects_objects = q.get_projects_by_user(user_id)

    return render_template("actions-board.html", projects=projects_objects)


###########################################################################
# LOG OUT #################################################################

@app.route("/logout", methods=["POST"])
def logout_user():
    """ """

    session.clear()
    # flash("You have been logged out.")

    return redirect("/")


@app.route("/logout", methods=["GET"])
def logout_user_when_site_crashes():
    """ """

    return redirect("/")


###########################################################################
# EDIT HEADERS ############################################################

@app.after_request
def add_header(r):
    """Flask utility to force a cache reload by adding settings in headers"""

    r.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
    # To fix the issue of making a new team on the dashboard, and using the
    #browser's nav button to go back
    return r

###########################################################################
# DIRECT FILE CALL ########################################################

if __name__ == "__main__":

    app.debug = True
    # prevents server side caching while in debug mode?
    app.jinja_env.auto_reload = app.debug

    connect_to_db(app)  # model file houses all ORM
    DebugToolbarExtension(app)  # Use the DebugToolbar
    app.run(host='0.0.0.0')  # DO NOT FORGET TO CHANGE THIS FOR RELEASE

import arrow                    
import logging
import json
import os
from urllib.parse import urlparse

from channels import Group
from rest_framework.generics import CreateAPIView                    
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from rest_framework import status

from django.conf import settings
from realpal.apps.chat.models import Message                    
from realpal.apps.chat.serializers import MessageSerializer                    
from realpal.apps.chat.consumers import get_room_group_channel
from realpal.apps.chat.models import Room                    

logger = logging.getLogger(__name__)


class MessageCreateAPIView(CreateAPIView):
    """
    Creates a new message object with a file attachment

    Returns on the socket

        {
            'id': "id",
            'sent_by':'user_id',
            'room':"room_id",
            'text':message.txt,
            'file_name': message.attachment,
            'file_link': message.attachment.path
        }
    """
    model = Message
    serializer_class = MessageSerializer
    permission_classes = [IsAuthenticated, ]

    def create(self, request, *args, **kwargs):
        room_id = self.request.data.get('room')
        try:
            self.room = Room.objects.get(pk=room_id)
            self.request.data['sent_by'] = self.request.user.id
            self.request.data['room'] = self.room.id
            self.request.data['text'] = self.request.data.get('message')
            serializer = self.get_serializer(data=request.data)
            self.perform_create(serializer)
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        except Room.DoesNotExist:
            return Response(status=status.HTTP_400_BAD_REQUEST)

    def perform_create(self, serializer):
        serializer.is_valid(self)
        instance = serializer.save(sent_by=self.request.user, room=self.room)
        if not settings.IS_TESTING:
            data = {
                'id': instance.id.__str__(),
                'timestamp': instance.time_ago,
                'timestamp_string': instance.timestamp_string,
                'user_handle': self.request.user.full_name,
                'user_type': self.request.user.user_type,
                'message': instance.text,
                'file_name': os.path.basename(urlparse(instance.attachment.path).path) if instance.attachment else None,
                'file_link': instance.file_download_link if instance.attachment else None,
            }
            group_channel = get_room_group_channel(instance.room.id)
            self.push_socket_update(group_channel, data)

    @staticmethod
    def push_socket_update(group_channel, data):
        Group(group_channel).send({"text": json.dumps(data)})

from rest_framework import serializers
from rest_framework.validators import ValidationError                    

from .models import Message                    


class MessageSerializer(serializers.ModelSerializer):
    """
    Message Serializer class
    """

    class Meta:
        model = Message
        fields = ('sent_by', 'room', 'text', 'attachment')

from django.conf.urls import url

from realpal.apps.chat.views import ChatRoomView
from realpal.apps.chat.api import MessageCreateAPIView                    

urlpatterns = [
    url(r'^$', ChatRoomView.as_view(), name='chat-room'),
    url(r'^(?P<room_id>[0-9]+)/', ChatRoomView.as_view(), name='chat-room'),
    url(r'^file/$', MessageCreateAPIView.as_view(), name='chat-file'),

]

from django.test import RequestFactory
from django.shortcuts import reverse
from test_plus.test import TestCase
from django.test import Client
from realpal.apps.users.constants import *
from realpal.apps.users.views import UserRedirectView, UserUpdateView


class BaseUserTestCase(TestCase):
    def setUp(self):
        self.user = self.make_user()
        self.factory = RequestFactory()


class TestUserRedirectView(BaseUserTestCase):
    client = Client()

    def test_get_redirect_url(self):
        # Instantiate the view directly. Never do this outside a test!
        view = UserRedirectView()
        # Generate a fake request
        request = self.factory.get('/fake-url')
        # Attach the user to the request
        request.user = self.user
        # Attach the request to the view
        view.request = request
        # Expect: '/users/testuser/', as that is the default username for
        #   self.make_user()
        self.assertEqual(
            view.get_redirect_url(),
            '/users/testuser/'
        )


class TestUserUpdateView(BaseUserTestCase):
    def setUp(self):
        # call BaseUserTestCase.setUp()
        super(TestUserUpdateView, self).setUp()
        # Instantiate the view directly. Never do this outside a test!
        self.view = UserUpdateView()
        # Generate a fake request
        request = self.factory.get('/fake-url')
        # Attach the user to the request
        request.user = self.user
        # Attach the request to the view
        self.view.request = request

    def test_get_success_url(self):
        # Expect: '/users/testuser/', as that is the default username for
        #   self.make_user()
        self.assertEqual(
            self.view.get_success_url(),
            '/users/~update/#success'
        )

    def test_get_object(self):
        # Expect: self.user, as that is the request's user object
        self.assertEqual(
            self.view.get_object(),
            self.user
        )

    def test_updating_user_info(self):
        update_url = reverse('users:update')
        data = {
            'purchase_step_form': {'purchase_step': PS_DAP},
            'marital_status_form': {'status': SC_SI},
            'first_home_form': {'firsthome': True},
            'house_type_form': {'house_type': HT_SF, 'house_age': HA_15, 'house_cond': HC_SL},
            'city_form': {'preferred_city': ''},
            'max_budget_form': {'budget': 1200.59},
            'current_rent_form': {'current_rent': 321.49},
            'how_soon_form': {'how_soon': HS_3},
            'personal_profile_form': {
                'first_name': 'TestFirstName',
                'last_name': 'TestLastName',
                'zipcode': '10118',
                'phone_number': '+263771819478',
                'email': 'test_email@gmail.com',
            },
        }

        # let's login first since this view is only reachable after login
        self.client.login(username='testuser', password='password')                    

        # test to see if we reached the user update profile page
        self.assertTemplateUsed('users/update.html')

        for form in data:
            data_to_pass = data[form]
            data[form][form] = 'Update'
            response = self.client.post(update_url, data_to_pass)                    
            self.assertEqual(response.status_code, 302)
            self.assertTemplateUsed('users/update.html')

        # test to see that trying to update with incorrect data will never save the new data
        data = {'purchase_step': 8}  # 8 is not a valid option
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().purchase_step, PS_DAP)  # the default

        # testing marital status update
        data = {'status': 8}  # 8 is not a valid option
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().status, None)

        # testing house type update
        data = {'house_type': 8, 'house_age': 8, 'house_cond': 8}  # 8 is not a valid option
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().house_type, None)
        self.assertEqual(self.view.get_object().house_age, None)
        self.assertEqual(self.view.get_object().house_cond, None)

        # testing budget update
        data = {'budget': 'TEXT'}  # 8 is not a valid option
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().budget, None)

        # testing current rent update
        data = {'current_rent': 'TEXT'}  # TEXT is not a valid number
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().current_rent, None)

        # testing how soon update
        data = {'how_soon': 8}  # 8 is not a valid option
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().how_soon, None)

        # testing profile update
        data = {
                   'first_name': 'TestFirstName',
                   'last_name': 'TestLastName',
                   'zipcode': '10118',
                   'phone_number': '+26334465657456774567',  # number too long
                   'email': 'test_email@gmail.com',
               }
        self.client.post(update_url, data)                    
        self.assertEqual(self.view.get_object().first_name, '')
        self.assertEqual(self.view.get_object().zipcode, None)
        self.assertEqual(self.view.get_object().email, 'testuser')

from django.http import Http404
from django.views.generic.simple import direct_to_template
from oi.projects.models import Project, OINeedsPrjPerms                    
from oi.helpers import OI_READ                    


def get_feature(request, id):
    task = Project.objects.get(id=id)
    if not task.has_perm(request.user, OI_READ):
        raise Http404
    return direct_to_template(request, template="funding/feature.html", extra_context={'object': task.master, 'task': task})

import os
import sys
import threading
import traceback
import types
from importlib.abc import InspectLoader

from cauldron import environ
from cauldron import templating
from cauldron.cli import threads
from cauldron.runner import redirection
from cauldron.session import projects


class UserAbortError(Exception):
    pass


def set_executing(on: bool):
    """

    :param on:
    :return:
    """

    my_thread = threading.current_thread()

    if isinstance(my_thread, threads.CauldronThread):
        my_thread.is_executing = on


def run(
        project: 'projects.Project',
        step: 'projects.ProjectStep',
) -> dict:
    """

    :param project:
    :param step:
    :return:
    """

    module_name = step.definition.name.rsplit('.', 1)[0]
    module = types.ModuleType(module_name)

    with open(step.source_path, 'r') as f:                    
        source_code = f.read()                    

    try:
        code = InspectLoader.source_to_code(source_code, step.source_path)
    except SyntaxError as error:
        return render_syntax_error(project, source_code, error)

    setattr(module, '__file__', step.source_path)
    setattr(
        module,
        '__package__',
        '.'.join(
            [project.id.replace('.', '-')] +
            step.filename.rsplit('.', 1)[0].split(os.sep)
        )
    )

    def exec_test():
        step.test_locals = dict()
        step.test_locals.update(module.__dict__)
        exec(code, step.test_locals)

    try:
        set_executing(True)
        threads.abort_thread()

        if environ.modes.has(environ.modes.TESTING):
            exec_test()
        else:
            exec(code, module.__dict__)
        out = None
    except threads.ThreadAbortError:
        out = {'success': False}
    except UserAbortError:
        out = None
    except Exception as error:
        out = render_error(project, error)

    set_executing(False)

    return {'success': True} if out is None else out


def render_syntax_error(
        project: 'projects.Project',
        code: str,
        error: SyntaxError
) -> dict:
    """

    :param project:
    :param code:
    :param error:
    :return:
    """

    stack = [dict(
        filename=error.filename,
        location=None,
        line_number=error.lineno,
        line=error.text.rstrip()
    )]

    render_data = dict(
        type=error.__class__.__name__,
        message='{}'.format(error),
        stack=stack
    )

    return dict(
        success=False,
        error=error,
        message=templating.render_template(
            'user-code-error.txt',
            **render_data
        ),
        html_message=templating.render_template(
            'user-code-error.html',
            **render_data
        )
    )


def get_stack_frames():
    """

    :return:
    """

    cauldron_path = environ.paths.package()
    resources_path = environ.paths.resources()
    frames = list(traceback.extract_tb(sys.exc_info()[-1])).copy()

    def is_cauldron_code(test_filename: str) -> bool:
        if not test_filename or not test_filename.startswith(cauldron_path):
            return False

        if test_filename.startswith(resources_path):
            return False

        return True

    while len(frames) > 1 and is_cauldron_code(frames[0].filename):
        frames.pop(0)

    return frames


def format_stack_frame(stack_frame, project: 'projects.Project'):
    """

    :param stack_frame:
    :param project:
    :return:
    """

    filename = stack_frame.filename
    if filename.startswith(project.source_directory):
        filename = filename[len(project.source_directory) + 1:]

    location = stack_frame.name
    if location == '<module>':
        location = None

    return dict(
        filename=filename,
        location=location,
        line_number=stack_frame.lineno,
        line=stack_frame.line
    )


def render_error(
        project: 'projects.Project',
        error: Exception
) -> dict:
    """

    :param project:
    :param error:
    :return:
    """

    render_data = dict(
        type=error.__class__.__name__,
        message='{}'.format(error),
        stack=[format_stack_frame(f, project) for f in get_stack_frames()]
    )

    return dict(
        success=False,
        error=error,
        message=templating.render_template(
            'user-code-error.txt',
            **render_data
        ),
        html_message=templating.render_template(
            'user-code-error.html',
            **render_data
        )
    )

import io
import time

from cauldron.cli.threads import abort_thread


class RedirectBuffer(io.TextIOWrapper):
    """
    A class for intercepting and independently storing buffer writes for use
    within Cauldron step display.
    """

    def __init__(self, redirection_source):
        self.active = False
        self.bytes_buffer = io.BytesIO()
        self.redirection_source = redirection_source
        self.last_write_time = 0

        super(RedirectBuffer, self).__init__(
            buffer=self.bytes_buffer,
            encoding=redirection_source.encoding,
            write_through=True
        )

    @property
    def source_encoding(self):
        if self.redirection_source.encoding:
            return self.redirection_source.encoding
        return 'utf8'                    

    def read_all(self) -> str:                    
        """
        Reads the current state of the buffer and returns a string those
        contents

        :return:
            A string for the current state of the print buffer contents
        """

        try:
            buffered_bytes = self.bytes_buffer.getvalue()
            if buffered_bytes is None:
                return ''

            return buffered_bytes.decode(self.source_encoding)                    
        except Exception as err:
            return 'Redirect Buffer Error: {}'.format(err)

    def flush_all(self) -> str:                    
        """

        :return:
        """

        self.bytes_buffer.seek(0)
        contents = self.bytes_buffer.read()
        self.bytes_buffer.truncate(0)
        self.bytes_buffer.seek(0)

        if contents is None:
            return ''

        return contents.decode(self.source_encoding)                    

    def write_both(self, *args, **kwargs):
        abort_thread()

        if self.active:
            # Only write to this buffer if redirection is active. This prevents
            # race conditions from mixing buffers when attaching or removing
            # the write buffer from its sys output.
            self.last_write_time = time.time()
            super(RedirectBuffer, self).write(*args, **kwargs)

        return self.redirection_source.write(*args, **kwargs)

    def __getattribute__(self, item):
        """

        :param item:
        :return:
        """

        abort_thread()

        if item == 'write':
            # Writing should be done to both the source buffer and the redirect
            # buffer so that they have identical copies of the same information
            # for their separate uses
            return self.write_both
        elif item == 'close':
            # The source buffer should not be closed. The redirect buffer is
            # what should be closed by calls to instances of this class
            return super(RedirectBuffer, self).__getattribute__(item)

        # Access the source buffer using a super call to prevent recursion
        source = super(RedirectBuffer, self) \
            .__getattribute__('redirection_source')

        if hasattr(source, item):
            # Preference should be given to the source buffer for all other
            # operations given that this class is a wrapper around the source
            # buffer with the only added functionality being the intercepting
            # and duplication of write operations
            return getattr(source, item)

        # If the source buffer doesn't have a particular attribute it should
        # an attribute specific to this class
        return super(RedirectBuffer, self).__getattribute__(item)

import os
import time

from cauldron.render import texts as render_texts
from cauldron.session.buffering import RedirectBuffer
from cauldron.session.caching import SharedCache


class Report(object):
    """
    The display management class for each step in a project. These class
    instances are exposed to Cauldron users, which provide the functionality
    for adding various element types to the display.
    """

    def __init__(self, step=None):
        self.step = step
        self.body = []
        self.css = []
        self.data = SharedCache()
        self.files = SharedCache()
        self.title = self.definition.get('title')
        self.subtitle = self.definition.get('subtitle')
        self.summary = self.definition.get('summary')
        self.library_includes = []
        self.stdout_interceptor = None  # type: RedirectBuffer
        self.stderr_interceptor = None  # type: RedirectBuffer

        self._last_update_time = 0

    @property
    def last_update_time(self) -> float:
        """ The last time at which the report was modified """
        stdout = self.stdout_interceptor
        stderr = self.stderr_interceptor

        return max([
            self._last_update_time,
            stdout.last_write_time if stdout else 0,
            stderr.last_write_time if stderr else 0,
        ])

    @property
    def project(self):
        return self.step.project if self.step else None

    @property
    def results_cache_path(self) -> str:
        """
        Location where step report is cached between sessions to
        prevent loss of display data between runs

        :return:
        """

        if not self.project:
            return ''
        return os.path.join(
            self.project.results_path,
            '.cache',
            'steps',
            '{}.json'.format(self.id)
        )

    @property
    def id(self):
        return self.step.definition.name if self.step else None

    @property
    def definition(self) -> dict:
        return self.step.definition if self.step else None

    def clear(self) -> 'Report':
        """
        Clear all user-data stored in this instance and reset it to its
        originally loaded state

        :return:
            The instance that was called for method chaining
        """
        self.body = []
        self.data = SharedCache()
        self.files = SharedCache()
        self._last_update_time = time.time()
        return self

    def append_body(self, dom: str):
        """

        :param dom:
        :return:
        """

        self.flush_stdout()
        self.body.append(dom)
        self._last_update_time = time.time()

    def read_stdout(self):
        """
        Reads the current state of the print buffer (if it exists) and returns
        a body-ready dom object of those contents without adding them to the
        actual report body. This is useful for creating intermediate body
        values for display while the method is still executing.

        :return:
            A dom string for the current state of the print buffer contents
        """

        try:
            contents = self.stdout_interceptor.read_all()                    
        except Exception as err:
            contents = ''

        return render_texts.preformatted_text(contents)

    def flush_stdout(self):
        """
        Empties
        """

        try:
            contents = self.stdout_interceptor.flush_all()                    
        except Exception:
            return

        if len(contents) > 0:
            self.body.append(render_texts.preformatted_text(contents))
            self._last_update_time = time.time()

        return contents

    def read_stderr(self):
        """
        Returns the current state of the stderr redirect buffer This is useful
        for creating intermediate display values while the step is still
        executing.

        :return:
            A string of the current state of the stderr redirect buffer contents
        """

        try:
            return self.stderr_interceptor.read_all()                    
        except Exception:
            return ''

    def flush_stderr(self) -> str:
        """
        Empties
        """

        try:
            return self.stderr_interceptor.flush_all()                    
        except Exception:
            return ''


import codecs
import locale
import sys

# Wrap sys.stdout into a StreamWriter to allow writing unicode.
sys.stdout = codecs.getwriter(locale.getpreferredencoding())(sys.stdout) 




import acsetup
import acedu.paths
from fsitem import File

from acminidom import getText, attributesOf, parse

import os

import pprint

from hwml import Problem, Assignment

from collections import defaultdict

import string

class HWML_processor(object):

	def prepare_for_processing(self):                    

		self.d = acedu.paths.corresponding()

		# I need a pretty printer for debugging purposes
		self.p = pprint.PrettyPrinter(indent=2)

		self.homeworks = []

		for homework_file in self.d:
			try:
				if homework_file.basename() != ".DS_Store":
					self.homeworks.append(parse(homework_file.path))
			except:
				print "parsing error in "+homework_file.path
				raise

		self.assignments = []

		for homework in self.homeworks:
			for assignment in homework.getElementsByTagName("assignment"):
				self.assignments.append(assignment)

		if True:
			for assignment in self.assignments:
				attrs = attributesOf(assignment)
				print attrs["student"]                    
				print attrs["book_edition"]                    
				print attrs["chapter"]                    
				problems = assignment.getElementsByTagName("problem")
				for problem in problems:
					attrs = attributesOf(problem)
					print attrs["number"]                    
					print getText(problem.childNodes)                    

		self.assignments = map(Assignment,self.assignments)

		self.book_editions = defaultdict(list)
		for assignment in self.assignments:
			self.book_editions[assignment.book_edition].append(assignment)
		#print self.book_editions

		for assignment in self.assignments:
			assert(assignment.chapter == int(sys.argv[1]))                    
			num_probs = len(assignment.problems)
			print "num_probs was "+str(num_probs)+" for student "+assignment.student                    

		self.problems = []

		for assignment in self.assignments:
			for problem in assignment.problems:
				prob_id = (assignment.book_edition,assignment.chapter,problem.number)
				prob_data = (assignment.student,problem.text)
				prob = (prob_id,prob_data)
				self.problems.append(prob)

		print len(self.problems)                    
		
		self.problem_groups = defaultdict(list)

		self.code_list = []
		for problem in self.problems:
			prob_id, prob_data = problem
			assignment_student,problem_text = prob_data
			prob_code_data = (assignment_student,prob_id)
			prob_code = str(hash(prob_code_data))
			self.code_list.append((prob_code,prob_code_data))
			self.problem_groups[prob_id].append(prob_code+"\n"+("="*50)+"\n"+problem_text)

		self.p.pprint(self.code_list)                    

		#print "by groups"
		self.count_by_groups = 0
		for group in self.problem_groups.values():
			self.count_by_groups += len(group)
		print self.count_by_groups                    
		
	def process_hwml(self):                    
		self.prepare_for_processing()                    

		another_count_by_groups = 0

		for key,value in self.problem_groups.items():
			book_edition,chapter,problem_number = key
			print "In book edition "+str(book_edition)+" on problem "+problem_number                    

			for item in value:
				print "="*50                    
				print item                    
				print "="*50                    
				another_count_by_groups += 1
				print "problem count is now: "+str(another_count_by_groups)                    
			
	def detect_cheating(self):
		self.prepare_for_processing()                    
		
		problem_text_students = defaultdict(list)
		
		for assignment in self.assignments:
			for problem in assignment.problems:
				p_text = string.join(string.split(problem.text))
				problem_text_students[p_text].append(assignment.student)

		for t,s in problem_text_students.items():
			if len(s) > 1:
				print (t,s)                    

def process_problem_scores(code_list):                    
	problems = []

	class problem(object):
		def __init__(self,student,book_edition,chapter,number,code):
			self.student = student
			self.book_edition = book_edition
			self.chapter = chapter
			self.number = number
			self.code = code

	from collections import defaultdict

	problem_groups = defaultdict(list)

	for code_item in code_list:
		(prob_code,prob_code_data) = code_item
		(assignment_student,prob_id) = prob_code_data
		(book_edition,chapter,problem_number) = prob_id
		problem_groups[prob_id].append(problem(assignment_student,book_edition,chapter,problem_number,prob_code))                    
	
	another_count_by_groups = 0

	print "Answer ID Number, Book Edition, Student Name, Problem Number, Problem Order, Score, Notes"                    

	for key,value in problem_groups.items():
		book_edition,chapter,problem_number = key
		for item in value:
			another_count_by_groups += 1
			print str(item.code)+", "+str(book_edition)+", "+str(item.student)+", "+str(item.number)+", "+str(another_count_by_groups)                    
		
		
def process_hwml():
	hp = HWML_processor()
	hp.process_hwml()

def detect_cheating():
	hp = HWML_processor()
	hp.detect_cheating()

"""
	Use
		file:///Users/chenan/Other/python-2.7.2-docs-html/library/os.html#files-and-directories
	and
		file:///Users/chenan/Other/python-2.7.2-docs-html/library/os.path.html

	but make a more OO interface to dealing with files and folders.

	Envisioned class hierarchy would be something like:

	FSItem
		Folder
		File

	and there would be intuitive properties/methods
	for FSItem, Folder, and File
"""

import os
import os.path
import fnmatch

def specialized(p):
	if os.path.isdir(p):
		return Folder(p)
	elif os.path.isfile(p):
		return File(p)
	elif os.path.islink(p):
		return Link(p)
	else:
		return FSItem(p)

def fs_object(p):
	p = os.path.abspath(p)
	return specialized(p)

class FSPath(object):
	def __init__(self,path):
		self.path = path
	def __sub__(self,other):
		if (self.path.startswith(other.path)):
			r = self.path[len(other.path):]
			assert((other.path+r) == self.path)
			return r[1:]
		else:
			raise IndexError, (other.path,self.path)
	
	# from os.path
	def abspath(self):
		return FSPath(os.path.abspath(self.path))
	def basename(self):
		return os.path.basename(self.path)
	def dirname(self):
		return FSPath(os.path.dirname(self.path))
	def exists(self):
		return FSPath(os.path.exists(self.path))
	def lexists(self):
		return FSPath(os.path.lexists(self.path))
	def expanduser(self):
		return FSPath(os.path.expanduser(self.path))
	def expandvars(self):
		return FSPath(os.path.expandvars(self.path))
	def getatime(self):
		return os.path.getatime(self.path)
	def getctime(self):
		return os.path.getctime(self.path)
	def getsize(self):
		return os.path.getsize(self.path)
	def isabs(self):
		return os.path.isabs(self.path)
	def isfile(self):
		return os.path.isfile(self.path)
	def isdir(self):
		return os.path.isdir(self.path)
	def islink(self):
		return os.path.islink(self.path)
	def ismount(self):
		return os.path.ismount(self.path)
	def normcase(self):
		return FSPath(os.path.normcase(self.path))
	def realpath(self):
		return FSPath(os.path.realpath(self.path))
	def relpath(self,start=None):
		if start is None:
			return FSPath(os.path.relpath(self.path))
		else:
			return FSPath(os.path.relpath(self.path,start))
	def samefile(self,other):
		if isinstance(other,FSPath):
			return os.path.samefile(self.path,other.path)
		else:
			return os.path.samefile(self.path,other)
	def split(self):
		head,tail = os.path.split(self.path)
		return (FSPath(head),FSPath(tail))
	def splitdrive(self):
		return os.path.splitdrive(self.path)
	def splitext(self):
		return os.path.splitext(self.path)
	def splitunc(self):
		return os.path.splitunc(self.path)
	
	# from os
	def access(self,mode):
		return os.access(self.path,mode)
	def chdir(self):
		return os.chdir(self.path)
		
	@staticmethod
	def getcwd(self):
		return FSPath(os.getcwd())
	
	def chflags(self,flags):
		return os.chflags(self.path,flags)
	def chroot(self):
		return os.chroot(self.path)
	def chmod(self,mode):
		return os.chmod(self.path,mode)
	def chown(self,uid=-1,gid=-1):
		return os.chown(self.path,uid,gid)
	def lchflags(self,flags):
		return os.lchflags(self.path,flags)
	def lchmod(self,mode):
		return os.lchmod(self.path,mode)
	def lchown(self,uid=-1,gid=-1):
		return os.lchown(self.path,uid,gid)
	def link(self,link_name):
		return os.link(self.path,link_name)
	def listdir(self):
		# need to wrap this better in a subclass
		return os.listdir(self.path)
	def lstat(self):
		return os.lstat(self.path)
	def mkfifo(self,mode=None):
		if mode is None:
			return os.mkfifo(self.path)
		else:
			return os.mkfifo(self.path,mode)
	# mknod, major, minor, makedev not implemented
	def mkdir(self,mode=None):
		if mode is None:
			return os.mkdir(self.path)
		else:
			return os.mkdir(self.path,mode)
	def makedirs(self,mode=None):
		if mode is None:
			return os.makedirs(self.path)
		else:
			return os.makedirs(self.path,mode)
	# pathconf, pathconf_names not implemented
	def readlink(self):
		return FSPath(os.readlink(self.path))
	def remove(self):
		return os.remove(self.path)
	def removedirs(self):
		return os.removedirs(self.path)
	def rename(self,other):
		if isinstance(other,FSPath):
			return os.rename(self.path,other.path)
		else:
			return os.rename(self.path,other)
	def renames(self,other):
		if isinstance(other,FSPath):
			return os.renames(self.path,other.path)
		else:
			return os.renames(self.path,other)
	def rmdir(self):
		return os.rmdir(self.path)
	def stat(self):
		return os.stat(self.path)
	def statvfs(self):
		return os.statvfs(self.path)
	def symlink(self,link_name):
		return os.symlink(self.path,link_name)
	def unlink(self):
		return os.unlink(self.path)
	def utime(self,times):
		return os.utime(self.path,times)
	def walk(self,topdown=True, onerror=None, followlinks=False):
		return os.walk(self.path,topdown,onerror,followlinks)


class FSPathList(list):
	def _raw(self):
		return map(lambda x: x.path,self)
	
	# from os.path
	def commonprefix(self):
		return FSPath(os.path.commonprefix(self._raw()))
	def join(self):
		return FSPath(*(self._raw()))

class FSItem(FSPath):
	def __init__(self,path):
		super(FSItem,self).__init__(path)
		assert(self.isabs())
		assert(self.lexists())
	def parent(self):
		p = self.dirname()
		return Folder(p.path)
	def ancestors(self):
		c = FSItem(self.path)
		p = c.parent()
		while c.path is not p.path:
			yield p
			c = p
			p = c.parent()
		
	def common_parent(self,other):
		l = FSPathList()
		l.append(self)
		l.append(other)
		r = l.commonprefix()
		if r.isdir():
			return Folder(r.path)
		else:
			return Folder(r.dirname().path)
	def walk(self,*args,**kwargs):
		r = super(FSItem,self).walk(*args,**kwargs)
		for root, dirs, files in r:
			folder_list = [Folder(os.path.join(root,dir)) for dir in dirs]
			file_list = [File(os.path.join(root,a_file)) for a_file in files]
			yield (Folder(root),folder_list,file_list)

class Folder(FSItem):
	def __init__(self,path):
		super(Folder,self).__init__(path)
		assert(self.isdir())
	def __iter__(self):
		r = self.items()
		return r
	def items(self):
		for item in self.listdir():
			p = os.path.abspath(os.path.join(self.path,item))
			yield specialized(p)
	def __getitem__(self,name):
		for item in self.items():
			if item.basename() == name:
				return item
		if name == "":
			return self
		raise IndexError, (name,self.path)
	def folders(self):
		for item in self.listdir():
			p = os.path.abspath(os.path.join(self.path,item))
			if os.path.isdir(p):
				yield Folder(p)
	def files(self):
		for item in self.listdir():
			p = os.path.abspath(os.path.join(self.path,item))
			if os.path.isfile(p):
				yield File(p)
	
	def create(self,what,name):
		t = os.path.join(self.path,name)
		if what is Folder:
			os.mkdir(t)
			return Folder(t)
		elif what is File:
			f = open(t,"w")
			f.close()
			return File(t)
		else:
			raise NotImplementedError
	
	def file_with_name(self,name):
		try:
			the_file = self[name]
		except IndexError:
			the_file = self.create(File,name)
		return the_file


class Line(object):
	def __init__(self,file,number,text):                    
		self.file = file
		self.number = number
		self.text = text

class File(FSItem):
	def __init__(self,path):
		super(File,self).__init__(path)
		assert(self.isfile())
	def read(self):
		f = open(self.path,"rU")
		r = f.read()
		f.close()
		return r
	def readlines(self):
		f = open(self.path,"rU")
		r = f.readlines()
		f.close()
		return r
	def read_Lines(self):	
		with open(self.path,"rU") as f:
			count = 0
			for l in f:
				count += 1
				yield Line(self,count,l)
	def write(self,o):
		f = open(self.path,"wb")
		r = f.write(o)
		f.close()
		return r
	def writelines(self,o):
		f = open(self.path,"wb")
		r = f.writelines(o)
		f.close()
		return r
	def open(self,mode):
		return open(self.path,mode)
		

class Link(FSItem):
	def __init__(self,path):
		super(Link,self).__init__(path)
		assert(self.islink())

def current():
	r = Folder(os.getcwd())
	return r

def root():
	return Folder("/")

def home():
	return Folder(os.path.expanduser("~"))

def FSItemList(FSPathList):
	def common_parent(self):
		r = None
		for item in self:
			if r is None:
				r = item
			else:
				r = r.common_parent(item)
		return r
	def filter(self,pattern):
		return fnmatch.filter(self,pattern)

if __name__ == "__main__":
	print "current has "
	for item in current():
		print item.path
	print "root has "
	for item in root():
		print item.path
	print "home has "
	for item in home():
		print item.path

from urllib.parse import urlencode, quote_plus

from django.http import HttpResponse, JsonResponse
from django.conf import settings

from experiences.factories import create_get_experience_interactor
from profiles.factories import create_get_profile_interactor

EMAIL_CONFIRMATION_PATH = '/people/me/email-confirmation'
LOGIN_PATH = '/people/me/login'
EXPERIENCE_PATH = '/e'
PROFILE_PATH = '/p'
EXPERIENCE_DEEPLINK_PATH = '/experiences'
PROFILE_DEEPLINK_PATH = '/profiles'


def email_confirmation_redirect(request):
    response = HttpResponse('', status=302)
    response['Location'] = '{}{}?{}'.format(settings.APP_DEEPLINK_DOMAIN,
                                            EMAIL_CONFIRMATION_PATH, request.GET.urlencode())
    return response


def login_redirect(request):
    response = HttpResponse('', status=302)
    response['Location'] = '{}{}?{}'.format(settings.APP_DEEPLINK_DOMAIN,
                                            LOGIN_PATH, request.GET.urlencode())
    return response


def experience_redirect(request, experience_share_id):
    dynamic_link = settings.DYNAMIC_LINK
    if len(dynamic_link) > 0:
        real_link = '{}{}/{}'.format(settings.PUBLIC_DOMAIN, EXPERIENCE_PATH, experience_share_id)
        link = dynamic_link.format(real_link)

        get_experience_interactor = create_get_experience_interactor()
        experience = get_experience_interactor.set_params(experience_share_id=experience_share_id,
                                                          logged_person_id='-1') \
                                              .execute()
        desc = (experience.description[:77] + '...') if len(experience.description) > 77 else experience.description
        preview_content = {'st': experience.title, 'sd': desc, 'si': experience.picture.small_url}
        preview_encoded = urlencode(preview_content, quote_via=quote_plus)
        link = '{}&{}'.format(link, preview_encoded)
    else:
        link = '{}{}/{}'.format(settings.APP_DEEPLINK_DOMAIN, EXPERIENCE_DEEPLINK_PATH, experience_share_id)

    response = HttpResponse('', status=302)
    response['Location'] = link
    return response


def profile_redirect(request, username):
    dynamic_link = settings.DYNAMIC_LINK
    if len(dynamic_link) > 0:
        real_link = '{}{}/{}'.format(settings.PUBLIC_DOMAIN, PROFILE_PATH, username)
        link = dynamic_link.format(real_link)

        get_profile_interactor = create_get_profile_interactor()
        profile = get_profile_interactor.set_params(username=username, logged_person_id='-1').execute()
        preview_content = {'st': '@{}'.format(profile.username), 'sd': profile.bio, 'si': profile.picture.small_url}
        preview_encoded = urlencode(preview_content, quote_via=quote_plus)
        link = '{}&{}'.format(link, preview_encoded)
    else:
        link = '{}{}/{}'.format(settings.APP_DEEPLINK_DOMAIN, PROFILE_DEEPLINK_PATH, username)

    response = HttpResponse('', status=302)
    response['Location'] = link
    return response


def root_redirect(request):                    
    dynamic_link = settings.DYNAMIC_LINK
    if len(dynamic_link) > 0:
        link = dynamic_link.format('{}/'.format(settings.PUBLIC_DOMAIN))                    
    else:
        link = '{}/'.format(settings.APP_DEEPLINK_DOMAIN)                    

    response = HttpResponse('', status=302)
    response['Location'] = link
    return response


def aasa_redirect(request):
    return JsonResponse({"applinks": {"apps": [], "details": [{"appID": settings.APPLE_APPID, "paths": ["*"]}]}})

import json

from django.conf import settings
from django.test import TestCase, Client
from django.urls import reverse

from experiences.models import ORMExperience
from people.models import ORMPerson
from profiles.models import ORMProfile


class RedirectConfirmEmailTestCase(TestCase):

    def test_when_called_redirect_view_redirects_to_apps_url(self):
        RedirectConfirmEmailTestCase.ScenarioMaker() \
                .when_call_get_email_confirmation() \
                .then_response_should_be_a_redirect_to_app_deeplink_with_params()

    class ScenarioMaker:

        def when_call_get_email_confirmation(self):
            client = Client()
            self.response = client.get('{}?{}'.format(reverse('email-confirmation-redirect'), 'token=ABXZ'))
            return self

        def then_response_should_be_a_redirect_to_app_deeplink_with_params(self):
            assert self.response.status_code == 302
            assert self.response['Location'] == '{}{}?token=ABXZ'.format(settings.APP_DEEPLINK_DOMAIN,
                                                                         '/people/me/email-confirmation')
            return self


class RedirectLoginEmailTestCase(TestCase):

    def test_when_called_redirect_view_redirects_to_apps_url(self):
        RedirectLoginEmailTestCase.ScenarioMaker() \
                .when_call_login_email_redirect() \
                .then_response_should_be_a_redirect_to_app_deeplink_with_params()

    class ScenarioMaker:

        def when_call_login_email_redirect(self):
            client = Client()
            self.response = client.get('{}?{}'.format(reverse('login-redirect'), 'token=ABXZ'))
            return self

        def then_response_should_be_a_redirect_to_app_deeplink_with_params(self):
            assert self.response.status_code == 302
            assert self.response['Location'] == '{}{}?token=ABXZ'.format(settings.APP_DEEPLINK_DOMAIN,
                                                                         '/people/me/login')
            return self


class RedirectExperienceTestCase(TestCase):

    def test_when_there_is_a_dynamic_link_wraps_public_domain_url(self):
        RedirectExperienceTestCase.ScenarioMaker() \
                .given_an_experience_on_db(title='a', description='d', share_id='AsdE43E4', pic='url') \
                .given_a_public_domain('http://pachatary.com') \
                .given_a_dynamic_link('http://dynamic.link/link={}&other=param') \
                .when_call_experience_redirect('AsdE43E4') \
                .then_response_should_be_a_redirect_to(
                    'http://dynamic.link/link=http://pachatary.com/e/AsdE43E4&other=param'
                    '&st=a&sd=d&si=%2Fmedia%2Furl.small')

    def test_when_there_is_no_dynamic_link_returns_deep_link(self):
        RedirectExperienceTestCase.ScenarioMaker() \
                .given_a_deep_link_domain('pachatary://app') \
                .given_a_dynamic_link('') \
                .when_call_experience_redirect('AsdE43E4') \
                .then_response_should_be_a_redirect_to('pachatary://app/experiences/AsdE43E4')

    class ScenarioMaker:

        def given_an_experience_on_db(self, title, description, share_id, pic):
            orm_person = ORMPerson.objects.create()
            ORMProfile.objects.create(person=orm_person, username='u')
            experience = ORMExperience.objects.create(title=title, description=description,
                                                      share_id=share_id, author=orm_person)
            experience.picture = pic
            experience.save()
            return self

        def given_a_public_domain(self, public_domain):
            settings.PUBLIC_DOMAIN = public_domain
            return self

        def given_a_dynamic_link(self, dynamic_link):
            settings.DYNAMIC_LINK = dynamic_link
            return self

        def given_a_deep_link_domain(self, deep_link_domain):
            settings.APP_DEEPLINK_DOMAIN = deep_link_domain
            return self

        def when_call_experience_redirect(self, share_id):
            client = Client()
            self.response = client.get(reverse('experience-redirect', args=[share_id]))
            return self

        def then_response_should_be_a_redirect_to(self, url):
            assert self.response.status_code == 302
            assert self.response['Location'] == url
            return self


class RedirectProfileTestCase(TestCase):

    def test_when_there_is_a_dynamic_link_wraps_public_domain_url(self):
        RedirectProfileTestCase.ScenarioMaker() \
                .given_a_profile(username='a_b.c', bio='my info', pic='url') \
                .given_a_public_domain('http://pachatary.com') \
                .given_a_dynamic_link('http://dynamic.link/link={}&other=param') \
                .when_call_profile_redirect('a_b.c') \
                .then_response_should_be_a_redirect_to(
                        'http://dynamic.link/link=http://pachatary.com/p/a_b.c&other=param'
                        '&st=%40a_b.c&sd=my+info&si=%2Fmedia%2Furl.small')

    def test_when_there_is_no_dynamic_link_returns_deep_link(self):
        RedirectProfileTestCase.ScenarioMaker() \
                .given_a_deep_link_domain('pachatary://app') \
                .given_a_dynamic_link('') \
                .when_call_profile_redirect('a_b.c') \
                .then_response_should_be_a_redirect_to('pachatary://app/profiles/a_b.c')

    class ScenarioMaker:

        def given_a_profile(self, username, bio, pic):
            orm_person = ORMPerson.objects.create()
            profile = ORMProfile.objects.create(username=username, bio=bio, person=orm_person)
            profile.picture = pic
            profile.save()
            return self

        def given_a_public_domain(self, public_domain):
            settings.PUBLIC_DOMAIN = public_domain
            return self

        def given_a_dynamic_link(self, dynamic_link):
            settings.DYNAMIC_LINK = dynamic_link
            return self

        def given_a_deep_link_domain(self, deep_link_domain):
            settings.APP_DEEPLINK_DOMAIN = deep_link_domain
            return self

        def when_call_profile_redirect(self, username):
            client = Client()
            self.response = client.get(reverse('profile-redirect', args=[username]))
            return self

        def then_response_should_be_a_redirect_to(self, url):
            assert self.response.status_code == 302
            assert self.response['Location'] == url
            return self


class RedirectRootTestCase(TestCase):                    

    def test_when_there_is_a_dynamic_link_wraps_public_domain_url(self):
        RedirectRootTestCase.ScenarioMaker() \                    
                .given_a_public_domain('http://pachatary.com') \
                .given_a_dynamic_link('http://dynamic.link/link={}&other=param') \
                .when_call_root_redirect() \                    
                .then_response_should_be_a_redirect_to('http://dynamic.link/link=http://pachatary.com/&other=param')                    

    def test_when_there_is_no_dynamic_link_returns_deep_link(self):
        RedirectRootTestCase.ScenarioMaker() \                    
                .given_a_deep_link_domain('pachatary://app') \
                .given_a_dynamic_link('') \
                .when_call_root_redirect() \                    
                .then_response_should_be_a_redirect_to('pachatary://app/')                    

    class ScenarioMaker:

        def given_a_public_domain(self, public_domain):
            settings.PUBLIC_DOMAIN = public_domain
            return self

        def given_a_dynamic_link(self, dynamic_link):
            settings.DYNAMIC_LINK = dynamic_link
            return self

        def given_a_deep_link_domain(self, deep_link_domain):
            settings.APP_DEEPLINK_DOMAIN = deep_link_domain
            return self

        def when_call_root_redirect(self):                    
            client = Client()
            self.response = client.get(reverse('root-redirect'))                    
            return self

        def then_response_should_be_a_redirect_to(self, url):
            assert self.response.status_code == 302
            assert self.response['Location'] == url
            return self


class AASATestCase(TestCase):

    def test_aasa_returns_json_with_appid(self):
        AASATestCase.ScenarioMaker() \
                .given_an_apple_appid('ASDF.com.myapp.ios') \
                .when_call_aasa() \
                .then_response_should_be_json(
                    '{"applinks": {"apps": [], "details": [{"appID": "ASDF.com.myapp.ios", "paths": ["*"]}]}}')

    class ScenarioMaker:

        def given_an_apple_appid(self, appid):
            settings.APPLE_APPID = appid
            return self

        def when_call_aasa(self):
            client = Client()
            self.response = client.get(reverse('aasa'))
            return self

        def then_response_should_be_json(self, json_string):
            assert json.loads(self.response.content) == json.loads(json_string)
            return self


from django.apps import apps
from clickgestion.transactions.forms import TransactionEditForm, TransactionPayForm
from clickgestion.transactions.models import BaseConcept, Transaction
from django.shortcuts import get_object_or_404, render, redirect, reverse
from django.utils.translation import gettext, gettext_lazy
from clickgestion.transactions.filters import ConceptFilter, TransactionFilter
from clickgestion.core.utilities import invalid_permission_redirect
from django.views.generic import ListView
from django.contrib.auth.decorators import login_required
from pure_pagination.mixins import PaginationMixin
from django.http import HttpResponse, QueryDict
from django.conf import settings
from django.utils import timezone
from django_xhtml2pdf.utils import generate_pdf


@login_required()
def concept_delete(request, *args, **kwargs):
    extra_context = {}

    # Check permissions

    # Get the concept and form
    concept, concept_form = get_concept_and_form_from_kwargs(**kwargs)
    extra_context['concept'] = concept

    # Get the transaction
    transaction = concept.transaction
    if transaction.closed:
        return redirect('message', message=gettext('Transaction Closed'))
    extra_context['transaction'] = transaction

    # Use default delete view
    extra_context['header'] = gettext('Delete {}?'.format(concept.concept_type))
    extra_context['message'] = concept.description_short
    extra_context['next'] = request.META['HTTP_REFERER']

    # POST
    if request.method == 'POST':
        default_next = reverse('transaction_detail', kwargs={'transaction_code': concept.transaction.code})
        concept.delete()
        next_page = request.POST.get('next', default_next)
        return redirect(next_page)

    # GET
    else:
        return render(request, 'core/delete.html', extra_context)


@login_required()
def concept_detail(request, *args, **kwargs):
    extra_context = {}

    # Check permissions

    # Get the concept and form
    concept, concept_form = get_concept_and_form_from_kwargs(**kwargs)
    extra_context['concept'] = concept

    # Get the transaction
    transaction = concept.transaction
    extra_context['transaction'] = transaction

    return render(request, 'transactions/concept_detail.html', extra_context)


@login_required()
def concept_edit(request, *args, **kwargs):
    extra_context = {}

    # Check permissions

    # Get the concept and form
    concept, concept_form = get_concept_and_form_from_kwargs(**kwargs)
    extra_context['concept'] = concept

    # Get the transaction
    transaction = concept.transaction
    if transaction.closed:
        return redirect('message', message=gettext('Transaction Closed'))
    extra_context['transaction'] = transaction

    # POST
    if request.method == 'POST':
        form = concept_form(request.POST, instance=concept)
        if form.is_valid():
            form.save()
            return redirect('transaction_edit', transaction_code=transaction.code)

        else:
            extra_context['form'] = form
            return render(request, 'transactions/concept_edit.html', extra_context)

    # GET
    else:

        # Get the form
        form = concept_form(instance=concept)
        extra_context['form'] = form
        return render(request, 'transactions/concept_edit.html', extra_context)


class ConceptList(PaginationMixin, ListView):

    template_name = 'transactions/concept_list.html'
    model = BaseConcept
    context_object_name = 'concepts'
    paginate_by = 8
    # ListView.as_view will pass custom arguments here
    queryset = None
    header = gettext_lazy('Concepts')
    request = None
    filter = None
    filter_data = None
    is_filtered = False

    def get(self, request, *args, **kwargs):
        # First

        # Check permissions
        if not request.user.is_authenticated:
            return invalid_permission_redirect(request)

        # Get arguments
        self.request = request
        self.filter_data = kwargs.pop('filter_data', {})

        # Call super
        return super().get(self, request, *args, **kwargs)

    def get_context_data(self, **kwargs):
        # Third

        # Call the base implementation first
        context = super().get_context_data(**kwargs)

        # Add data
        context['header'] = self.header
        context['filter'] = self.filter
        context['is_filtered'] = self.is_filtered

        return context

    def get_queryset(self):
        # Second

        # Create filter querydict
        data = QueryDict('', mutable=True)
        # Add filters passed from view
        data.update(self.filter_data)
        # Add filters selected by user
        data.update(self.request.GET)

        # Record as filtered
        self.is_filtered = False
        if len([k for k in data.keys() if k != 'page']) > 0:
            self.is_filtered = True

        # Add filters by permission

        # Filter the queryset
        self.filter = ConceptFilter(data)
        self.queryset = self.filter.qs.select_related('transaction') \
            .prefetch_related('value__currency') \
            .order_by('-id') # 79q 27ms

        # Return
        return self.queryset


def get_available_concepts(employee, transaction):
    """
    Get a list of the available concepts that can be added to the given transaction.

    :param employee: The employee executing the transaction (current user)
    :param transaction: The open transaction
    :return: A list of dictionaries.
    """

    # get permissions according to transaction
    concepts_permitted_by_transaction = transaction.get_all_permissions()

    # get permissions according to employee
    concepts_permitted_by_employee = employee.get_all_permissions()

    # create the list of permitted concepts
    available_concepts = []
    for concept in settings.CONCEPTS:
        permission = concept.replace('.','.add_')
        concept_model = apps.get_model(concept)

        # Skip this concept if not permitted by the user
        if not permission in concepts_permitted_by_employee:
            continue

        # set default values
        disabled = False
        url = concept_model._url.format('new/{}'.format(transaction.code))

        # disable this concept if not permitted by the transaction
        if not permission in concepts_permitted_by_transaction:
            disabled = True
            url = '#'

        # add to the list
        available_concepts.append(
            {
                'name': concept_model._meta.verbose_name,
                'url': url,
                'disabled': disabled,
            }
        )

    return available_concepts


def get_transaction_from_kwargs(**kwargs):
    # Get the transaction
    transaction_code = kwargs.get('transaction_code', None)
    transaction = get_object_or_404(Transaction, code=transaction_code)
    return transaction


def get_concept_and_form_from_kwargs(**kwargs):

    # Get the form
    concept_form = kwargs.get('concept_form', None)

    # Get the concept class
    concept_class = concept_form._meta.model

    # If a transaction code is provided, this is a new concept
    transaction_code = kwargs.get('transaction_code', None)
    if transaction_code:
        transaction = get_transaction_from_kwargs(**kwargs)
        return concept_class(transaction=transaction), concept_form

    # Get the existing concept
    concept_code = kwargs.get('concept_code', None)
    concept = get_object_or_404(concept_class, code=concept_code)
    return concept, concept_form


def transaction_delete(request, *args, **kwargs):
    extra_context = {}

    # Check permissions
    if not request.user.is_authenticated:
        return invalid_permission_redirect(request)

    # Get the object
    transaction_code = kwargs.get('transaction_code', None)
    transaction = get_object_or_404(Transaction, code=transaction_code)
    extra_context['transaction'] = transaction

    # Use default delete view
    extra_context['header'] = gettext('Delete Transaction?')
    extra_context['message'] = transaction.description_short
    extra_context['next'] = request.META['HTTP_REFERER']

    # POST
    if request.method == 'POST':
        default_next = reverse('transactions_open')
        transaction.delete()
        next_page = request.POST.get('next', default_next)
        return redirect(next_page)

    # GET
    else:
        return render(request, 'core/delete.html', extra_context)


@login_required
def transaction_detail(request, *args, **kwargs):
    extra_context = {}

    # Check permissions
    if not request.user.is_authenticated:
        return invalid_permission_redirect(request)

    # Get the transaction
    transaction_code = kwargs.get('transaction_code', None)
    transaction = get_object_or_404(Transaction, code=transaction_code)
    extra_context['transaction'] = transaction
    return render(request, 'transactions/transaction_detail.html', extra_context)


@login_required
def transaction_edit(request, *args, **kwargs):
    extra_context = {}

    # Check permissions
    if not request.user.is_authenticated:
        return invalid_permission_redirect(request)

    # Get the transaction
    transaction_code = kwargs.get('transaction_code', None)
    if not transaction_code:
        transaction = Transaction.objects.create(employee=request.user)
        return redirect('transaction_edit', transaction_code=transaction.code)

    transaction = get_object_or_404(Transaction, code=transaction_code)
    extra_context['transaction'] = transaction

    # Check that the transaction is open
    if transaction.closed:
        return redirect('message', message=gettext('Transaction Closed'))

    # Get available concepts to add
    available_concepts = get_available_concepts(request.user, transaction)
    extra_context['available_concepts'] = available_concepts

    # POST
    if request.method == 'POST':
        form = TransactionEditForm(request.POST, instance=transaction)
        valid = form.is_valid()

        # Delete and go home
        # Note that the form.data value is still a string before validating
        if form.data['cancel_button'] == 'True':
            transaction.delete()
            return redirect('index')

        # If valid
        if valid:

            # Save the transaction
            transaction.save()

            # Finish later
            if form.cleaned_data['save_button']:
                return redirect('transaction_detail', transaction_code=transaction.code)

            # Proceed to pay
            return redirect('transaction_pay', transaction_code=transaction.code)

        else:
            extra_context['form'] = form
            return render(request, 'transactions/transaction_edit.html', extra_context)

    # GET
    else:

        # Create the form
        form = TransactionEditForm(instance=transaction)
        extra_context['form'] = form
        return render(request, 'transactions/transaction_edit.html', extra_context)


class TransactionList(PaginationMixin, ListView):

    model = Transaction
    context_object_name = 'transactions'
    paginate_by = 8
    # ListView.as_view will pass custom arguments here
    queryset = None
    header = gettext_lazy('Transactions')
    request = None
    filter = None
    filter_data = None
    is_filtered = False

    def get(self, request, *args, **kwargs):
        # First

        # Check permissions
        if not request.user.is_authenticated:
            return invalid_permission_redirect(request)

        # Get arguments
        self.request = request
        self.filter_data = kwargs.pop('filter_data', {})

        # Call super
        return super().get(self, request, *args, **kwargs)

    def get_context_data(self, **kwargs):
        # Third

        # Call the base implementation first
        context = super().get_context_data(**kwargs)

        # Add data
        context['header'] = self.header
        context['filter'] = self.filter
        context['is_filtered'] = self.is_filtered

        return context

    def get_queryset(self):
        # Second

        # Create filter querydict
        data = QueryDict('', mutable=True)
        # Add filters passed from view
        data.update(self.filter_data)
        # Add filters selected by user
        data.update(self.request.GET)

        # Record as filtered
        self.is_filtered = False
        if len([k for k in data.keys() if k != 'page']) > 0:
            self.is_filtered = True

        # Add filters by permission

        # Filter the queryset
        self.filter = TransactionFilter(data)
        self.queryset = self.filter.qs.select_related('cashclose')\
            .prefetch_related('concepts__value__currency') \
            .order_by('-id')  # 79q 27ms

        # Return
        return self.queryset

    def post(self, request, *args, **kwargs):

        # Check permissions
        if not request.user.is_authenticated:
            return invalid_permission_redirect(request)

        print_transaction = request.POST.get('print_transaction', None)
        if print_transaction:
            # Get the transaction
            transaction = get_object_or_404(Transaction, code=print_transaction)
            # Create an http response
            resp = HttpResponse(content_type='application/pdf')
            resp['Content-Disposition'] = 'attachment; filename="{}.pdf"'.format(transaction.code)
            # Set context
            context = {
                'transaction': transaction,
            }
            # Generate the pdf
            result = generate_pdf('transactions/invoice.html', file_object=resp, context=context)
            return result

        # Return same
        request.method = 'GET'
        return self.get(request, *args, **kwargs)



@login_required
def transaction_pay(request, *args, **kwargs):
    extra_context = {}

    # Check permissions
    if not request.user.is_authenticated:
        return invalid_permission_redirect(request)

    # Get the transaction
    transaction_code = kwargs.get('transaction_code', None)
    transaction = get_object_or_404(Transaction, code=transaction_code)
    extra_context['transaction'] = transaction

    # Check that the transaction is open
    if transaction.closed:
        return redirect('message', message=gettext('Transaction Closed'))

    # Get required payment fields

    # POST
    if request.method == 'POST':
        form = TransactionPayForm(request.POST, instance=transaction)
        valid = form.is_valid()

        # If cancel has been set, delete and go home
        # Note that value is still string before validating
        if form.data['cancel_button'] == 'True':
            transaction.delete()
            return redirect('index')

        # If valid
        if valid:

            # Close the transaction
            if form.cleaned_data['confirm_button']:
                transaction.closed = True
                transaction.closed_date = timezone.datetime.now()
                transaction.save()
                return redirect('transaction_detail', transaction_code=transaction.code)

            # Save the transaction
            if form.cleaned_data['save_button']:
                transaction.save()
                return redirect('transaction_detail', transaction_code=transaction.code)

        else:
            extra_context['form'] = form
            return render(request, 'transactions/transaction_pay.html', extra_context)

    # GET
    else:

        # Create the form
        form = TransactionPayForm(instance=transaction)
        extra_context['form'] = form
        return render(request, 'transactions/transaction_pay.html', extra_context)


def transactions_open(request, *args, **kwargs):

    # Check permissions
    if not request.user.is_authenticated:
        return invalid_permission_redirect(request)

    # Set initial filter data
    filter_data = {
        'closed': False,
    }

    # Return
    listview = TransactionList.as_view()                    
    return listview(request, filter_data=filter_data)                    

USER_ID = 'user_id'
STEP_1 = 'view_introduction'
STEP_2 = 'instructor_intro'                    
STEP_3 = 'create_course'
STEP_4 = 'create_courselet'
STEP_5 = 'create_thread'
STEP_6 = 'preview_courselet'
STEP_7 = 'next_steps'
STEP_8 = 'invite_somebody'                    

# settings

INTRODUCTION_COURSE_ID = 'introduction_course_id'
VIEW_INTRODUCTION = STEP_1
INTRODUCTION_INTRO = STEP_2
CREATE_COURSE = STEP_3
CREATE_COURSELET = STEP_4
CREATE_THREAD = STEP_5
PREVIEW_COURSELET = STEP_6
NEXT_STEPS = STEP_7
INVITE_SOMEBODY = STEP_8                    

"""
Various utilities.
"""
import functools

from django.dispatch import receiver
from django.conf import settings
from django.core.mail import send_mail
from django.template import loader, Context

from core.common.mongo import c_onboarding_status, c_onboarding_settings
from core.common import onboarding


def send_email(context_data, from_email, to_email, template_subject, template_text):
    """
    Send an email with specified content.

    Arguments:
        context_data (dict): data to be passed to templates.
        from_email (str): sender's email.
        to_email (list): list of addresses to send an email to.
        template_subject (str): path to a subject template, e.g. 'ctms/email/subject.txt'
        template_text (str):  path to a body template, e.g. 'ctms/email/text.txt'
    """
    context = Context(context_data)

    subj_template = loader.get_template(template_subject)
    rendered_subj = subj_template.render(context)

    text_template = loader.get_template(template_text)
    rendered_text = text_template.render(context)

    send_mail(
        rendered_subj,
        rendered_text,
        from_email,
        to_email,
        fail_silently=True
    )


def suspending_receiver(signal, **decorator_kwargs):
    """
    Custom decorator to disable signals.

    Reference:
        https://devblog.kogan.com/blog/disable-signal-receivers-in-your-django-tests
    """

    def our_wrapper(func):
        @receiver(signal, **decorator_kwargs)
        @functools.wraps(func)
        def fake_receiver(sender, **kwargs):
            if settings.SUSPEND_SIGNALS:
                return
            return func(sender, **kwargs)

        return fake_receiver

    return our_wrapper


def get_onboarding_steps():
    """
    Get fields from somewhere, haven't decided yet

    Return list of steps to be done
    """
    return [
        onboarding.STEP_1,
        onboarding.STEP_2,
        onboarding.STEP_3,
        onboarding.STEP_4,
        onboarding.STEP_5,
        onboarding.STEP_6,
        onboarding.STEP_7,
        onboarding.STEP_8                    
    ]


def get_onboarding_percentage(user_id):
    if user_id:
        status = c_onboarding_status(use_secondary=True).find_one({onboarding.USER_ID: user_id}) or {}
        if status:
            steps = [status.get(key, False) for key in get_onboarding_steps()]
            return round(
                len(filter(lambda x: x, steps)) / float(len(steps)) * 100,
                0
            )
    return 0


def update_onboarding_step(step, user_id):
    find_crit = {onboarding.USER_ID: user_id}
    onboarding_data = c_onboarding_status(use_secondary=True).find_one(find_crit)
    if not onboarding_data or not onboarding_data.get(step):
        c_onboarding_status().update_one(find_crit, {'$set': {
            step: True
        }}, upsert=True)


ONBOARDING_STEPS_DEFAULT_TEMPLATE = {
    'title': '',
    'description': '',
    'html': ''
}

ONBOARDING_SETTINGS_DEFAULT = {
    onboarding.INTRODUCTION_COURSE_ID: settings.ONBOARDING_INTRODUCTION_COURSE_ID,
    onboarding.VIEW_INTRODUCTION: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.INTRODUCTION_INTRO: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_COURSE: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_COURSELET: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.CREATE_THREAD: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.INVITE_SOMEBODY: ONBOARDING_STEPS_DEFAULT_TEMPLATE,                    
    onboarding.PREVIEW_COURSELET: ONBOARDING_STEPS_DEFAULT_TEMPLATE,
    onboarding.NEXT_STEPS: ONBOARDING_STEPS_DEFAULT_TEMPLATE
}


# TODO: write unit tests
def get_onboarding_setting(setting_name):
    """
    Return settings for the certain `settings_name`
    If it does not exist take default settings and save it to the MongoDB
    Argument:
        setting_name (str): name of setting e.g. `create_course`
    Return:
        dict object with the data. See ONBOARDING_STEPS_DEFAULT_TEMPLATE
    """
    try:
        ONBOARDING_SETTINGS_DEFAULT[setting_name]
    except KeyError:
        return

    onboarding_setting = c_onboarding_settings(use_secondary=True).find_one({'name': setting_name})
    if not onboarding_setting:
        c_onboarding_settings().insert({'name': setting_name, 'data': ONBOARDING_SETTINGS_DEFAULT[setting_name]})
        return ONBOARDING_SETTINGS_DEFAULT[setting_name]
    return onboarding_setting['data']


# TODO: refactor this, settings for each step no need longer
def get_onboarding_status_with_settings(user_id):
    """
    Return combined data with the status by on-boarding steps (done: true/false)
    and settings for according status name
    Argument:
        user_id (int): user's id
    Return:
        dict with data
    Example:
    {
        "instructor_intro": {
            "done": true,
            "settings": {
                "html": "",
                "description": "",
                "title": ""
            }
        },
        "create_course": {
            "done": true,
            "settings": {
                "html": "",
                "description": "",
                "title": ""
            }
        },
        "create_courselet": {
            "done": false,
            "settings": {
                "html": "",
                "description": "",
                "title": ""
            }
        },
        "review_answers": {
            "done": true,
            "settings": {
                "html": "<p>Title</p>",
                "description": "Here is some description",
                "title": "Title"
            }
        },
        "invite_somebody": {
            "done": true,
            "settings": {
                "html": "",
                "description": "",
                "title": ""
            }
        },
        "create_thread": {
            "done": false,
            "settings": {
                "html": "",
                "description": "",
                "title": ""
            }
        }
    }
    """
    onboarding_status = c_onboarding_status().find_one({onboarding.USER_ID: user_id}, {'_id': 0, 'user_id': 0}) or {}
    data = {}

    for step in get_onboarding_steps():
        data[step] = {
            'done': onboarding_status.get(step, False)
        }
    return data





from django.core.management.base import BaseCommand

from ct.models import Course, Role, UnitLesson, Unit, Lesson, Response
from ctms.models import Invite
from chat.models import Chat, EnrollUnitCode
from accounts.models import Instructor
from core.common.utils import update_onboarding_step, get_onboarding_percentage
from core.common import onboarding
from django.conf import settings


class Command(BaseCommand):
    help = 'Onboarding preprocessing'

    def handle(self, *args, **options):
        for instructor in Instructor.objects.all():                    

            try:                    
                course = Course.objects.get(id=settings.ONBOARDING_INTRODUCTION_COURSE_ID)                    
            except Course.DoesNotExist:                    
                print("Onboarding course is not provided")                    
                return                    

            chat_exists = Chat.objects.filter(
                user=instructor.user,
                enroll_code__courseUnit__course=course,
                progress__gte=70
            ).exists()
            if chat_exists:
                update_onboarding_step(onboarding.STEP_2, instructor.user_id)

            # if instructor has created create_course

            if Course.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_3, instructor.user_id)

            # if instructor has created a create_courselet

            if Unit.objects.filter(addedBy=instructor.user).exists():
                update_onboarding_step(onboarding.STEP_4, instructor.user_id)

            # if instructor has created a create_thread

            if Lesson.objects.filter(addedBy=instructor.user).exists():                    
                update_onboarding_step(onboarding.STEP_5, instructor.user_id)

            # if he has created invite_somebody
            if Invite.objects.filter(instructor=instructor).exists():                    
                update_onboarding_step(onboarding.STEP_8, instructor.user_id)                    

            enroll_unit_code_exists = EnrollUnitCode.objects.filter(
                courseUnit__course__addedBy=instructor.user,
                isPreview=True,
                isLive=False,
                isTest=False
            ).exists()
            if enroll_unit_code_exists:
                update_onboarding_step(onboarding.STEP_6, instructor.user_id)

            print("Instructor {} passed onboarding at {}%".format(
                instructor.user.username, get_onboarding_percentage(instructor.user.id))
            )

import re
from uuid import uuid4

from django.db import models
from django.db.models.signals import post_save
from django.db.utils import IntegrityError
from django.dispatch import receiver
from django.contrib.auth.models import User
from django.contrib.sites.models import Site
from django.conf import settings
from django.core.mail import send_mail
from django.core.urlresolvers import reverse
from django.http.response import Http404
from django.template import loader, Context

from accounts.models import Instructor
from chat.models import EnrollUnitCode
from core.common import onboarding
from core.common.utils import update_onboarding_step
from ct.models import Course




STATUS_CHOICES = (
    ('pendind', 'pending'),
    ('joined', 'joined'),
)

TYPE_CHOICES = (
    ('student', 'student'),
    ('tester', 'tester')
)

def clean_email_name(email):
    email_name, domain = email.split('@', 1)
    email_name = email_name.replace('.', '')
    return email_name, domain

class InviteQuerySet(models.QuerySet):
    def my_invites(self, request):
        return self.filter(instructor=request.user.instructor)

    def testers(self):
        return self.filter(type='tester')

    def students(self):
        return self.filter(type='student')

    def shared_for_me(self, request):
        return self.filter(
            models.Q(user=request.user) | models.Q(email=request.user.email)
        )


class Invite(models.Model):
    instructor = models.ForeignKey(Instructor)
    user = models.ForeignKey(User, blank=True, null=True)
    email = models.EmailField()
    code = models.CharField('invite code', max_length=255)
    status = models.CharField('status', max_length=20, choices=STATUS_CHOICES, default='pending')
    type = models.CharField('invite type', max_length=50, choices=TYPE_CHOICES, default='tester')
    course = models.ForeignKey(Course)
    enroll_unit_code = models.ForeignKey(EnrollUnitCode, null=True)

    added = models.DateTimeField('added datetime', auto_now_add=True)

    objects = InviteQuerySet.as_manager()

    @staticmethod
    def search_user_by_email(email):
        return User.objects.filter(email=email).first()

    @classmethod
    def create_new(cls, commit, course, instructor, email, invite_type, enroll_unit_code):
        user = Invite.search_user_by_email(email)
        try:
            old_invite = Invite.get_by_user_or_404(
                user=user,
                type=invite_type,
                course=course,
                instructor=instructor,
                enroll_unit_code=enroll_unit_code
            )
            if old_invite:
                return old_invite
        except Http404:
            pass
        code = Invite(
            instructor=instructor,
            user=user,
            email=email,
            code=uuid4().hex,
            status='pending',
            type=invite_type,
            course=course,
            enroll_unit_code=enroll_unit_code
        )
        if commit:
            code.save()
        return code

    def get_invited_user_username(self):
        return self.email.split("@")[0] if self.email else ''

    class Meta:
        unique_together = ('instructor', 'email', 'type', 'course', 'enroll_unit_code')

    def save(self, force_insert=False, force_update=False, using=None,
             update_fields=None):
        user = Invite.search_user_by_email(self.email)
        self.user = user
        return super(Invite, self).save(force_insert, force_update, using, update_fields)

    def send_mail(self, request, view):
        try:
            # TODO: use `send_email` utility function here (see `core`)
            context = Context({
                'invite': self,
                'current_site': Site.objects.get_current(request)
            })
            subj_template = loader.get_template('ctms/email/invite_subject.txt')
            rendered_subj = subj_template.render(context)

            text_template = loader.get_template('ctms/email/invite_text.txt')
            rendered_text = text_template.render(context)
            send_mail(
                rendered_subj,
                rendered_text,
                settings.EMAIL_FROM,
                [self.email],
                fail_silently=False
            )
            return {
                'success': True,
                'message': 'Invitation successfully sent.',
                'invite': {
                    'status': self.status,
                }
            }
        except IntegrityError:
            return {
                'success': False,
                'message': 'You already have sent invite to user with {} email'.format(request.POST['email'])
            }

    def get_absolute_url(self):
        return reverse('ctms:tester_join_course', kwargs={'code': self.code})

    @staticmethod
    def get_by_user_or_404(user, **kwargs):
        '''
        Do a search for invite by passed parameters and user.
         NOTE: this function firstly try to get invite by passed kwargs,
         then check that Invite.email and user.email are equal,
         if they not - trying to check Invite.email and user.email
         !! excluding dots from email-name. !!
        :param user: request.user
        :param kwargs: params to search by
        :return: invite if found
        :raise: Http404 if not found
        '''
        if not user:
            raise Http404
        invites = Invite.objects.filter(
            **kwargs
        )
        my_invite = None

        for invite in invites:
            if invite and invite.email == user.email:
                my_invite = invite
                break
            user_email_name, user_domain = clean_email_name(user.email)
            invite_email, invite_domain = clean_email_name(invite.email)
            if invite_domain != user_domain:
                continue
            res = re.search(
                "^{}@{}$".format(r"\.?".join(user_email_name), user_domain),
                "{}@{}".format(invite_email, invite_domain)
            )
            if res and res.string:
                my_invite = invite
                break
        else:
            raise Http404()
        if my_invite:
            return my_invite
        else:
            raise Http404()

    def __unicode__(self):
        return "Code {}, User {}".format(self.code, self.email)


@receiver(post_save, sender=Invite)                    
def onboarding_invite_created(sender, instance, **kwargs):                    
    update_onboarding_step(onboarding.STEP_8, instance.instructor.user_id)                    

import asyncio
import click
import collections
import hashlib
import os
import sys
import threading
import traceback
import urllib.parse
from concurrent import futures
from pathlib import Path

from markupsafe import Markup
from jinja2 import ChoiceLoader, Environment, FileSystemLoader, PrefixLoader
from sanic import Sanic, response
from sanic.exceptions import InvalidUsage, NotFound

from .views.base import (
    DatasetteError,
    ureg
)
from .views.database import DatabaseDownload, DatabaseView
from .views.index import IndexView
from .views.special import JsonDataView
from .views.table import RowView, TableView

from .utils import (
    InterruptedError,
    Results,
    escape_css_string,
    escape_sqlite,
    get_plugins,
    module_from_path,
    sqlite3,
    sqlite_timelimit,
    to_css_class
)
from .inspect import inspect_hash, inspect_views, inspect_tables
from .plugins import pm, DEFAULT_PLUGINS
from .version import __version__

app_root = Path(__file__).parent.parent

connections = threading.local()
MEMORY = object()

ConfigOption = collections.namedtuple(
    "ConfigOption", ("name", "default", "help")
)
CONFIG_OPTIONS = (
    ConfigOption("default_page_size", 100, """
        Default page size for the table view
    """.strip()),
    ConfigOption("max_returned_rows", 1000, """
        Maximum rows that can be returned from a table or custom query
    """.strip()),
    ConfigOption("num_sql_threads", 3, """
        Number of threads in the thread pool for executing SQLite queries
    """.strip()),
    ConfigOption("sql_time_limit_ms", 1000, """
        Time limit for a SQL query in milliseconds
    """.strip()),
    ConfigOption("default_facet_size", 30, """
        Number of values to return for requested facets
    """.strip()),
    ConfigOption("facet_time_limit_ms", 200, """
        Time limit for calculating a requested facet
    """.strip()),
    ConfigOption("facet_suggest_time_limit_ms", 50, """
        Time limit for calculating a suggested facet
    """.strip()),
    ConfigOption("allow_facet", True, """
        Allow users to specify columns to facet using ?_facet= parameter
    """.strip()),
    ConfigOption("allow_download", True, """
        Allow users to download the original SQLite database files
    """.strip()),
    ConfigOption("suggest_facets", True, """
        Calculate and display suggested facets
    """.strip()),
    ConfigOption("allow_sql", True, """
        Allow arbitrary SQL queries via ?sql= parameter
    """.strip()),
    ConfigOption("default_cache_ttl", 365 * 24 * 60 * 60, """                    
        Default HTTP cache TTL (used in Cache-Control: max-age= header)
    """.strip()),
    ConfigOption("cache_size_kb", 0, """
        SQLite cache size in KB (0 == use SQLite default)
    """.strip()),
    ConfigOption("allow_csv_stream", True, """
        Allow .csv?_stream=1 to download all rows (ignoring max_returned_rows)
    """.strip()),
    ConfigOption("max_csv_mb", 100, """
        Maximum size allowed for CSV export in MB - set 0 to disable this limit
    """.strip()),
    ConfigOption("truncate_cells_html", 2048, """
        Truncate cells longer than this in HTML table view - set 0 to disable
    """.strip()),
    ConfigOption("force_https_urls", False, """
        Force URLs in API output to always use https:// protocol
    """.strip()),
)
DEFAULT_CONFIG = {
    option.name: option.default
    for option in CONFIG_OPTIONS
}


async def favicon(request):
    return response.text("")


class Datasette:

    def __init__(
        self,
        files,
        cache_headers=True,
        cors=False,
        inspect_data=None,
        metadata=None,
        sqlite_extensions=None,
        template_dir=None,
        plugins_dir=None,
        static_mounts=None,
        memory=False,
        config=None,
        version_note=None,
    ):
        self.files = files
        if not self.files:
            self.files = [MEMORY]
        elif memory:
            self.files = (MEMORY,) + self.files
        self.cache_headers = cache_headers
        self.cors = cors
        self._inspect = inspect_data
        self._metadata = metadata or {}
        self.sqlite_functions = []
        self.sqlite_extensions = sqlite_extensions or []
        self.template_dir = template_dir
        self.plugins_dir = plugins_dir
        self.static_mounts = static_mounts or []
        self._config = dict(DEFAULT_CONFIG, **(config or {}))
        self.version_note = version_note
        self.executor = futures.ThreadPoolExecutor(
            max_workers=self.config("num_sql_threads")
        )
        self.max_returned_rows = self.config("max_returned_rows")
        self.sql_time_limit_ms = self.config("sql_time_limit_ms")
        self.page_size = self.config("default_page_size")
        # Execute plugins in constructor, to ensure they are available
        # when the rest of `datasette inspect` executes
        if self.plugins_dir:
            for filename in os.listdir(self.plugins_dir):
                filepath = os.path.join(self.plugins_dir, filename)
                mod = module_from_path(filepath, name=filename)
                try:
                    pm.register(mod)
                except ValueError:
                    # Plugin already registered
                    pass

    def config(self, key):
        return self._config.get(key, None)

    def config_dict(self):
        # Returns a fully resolved config dictionary, useful for templates
        return {
            option.name: self.config(option.name)
            for option in CONFIG_OPTIONS
        }

    def metadata(self, key=None, database=None, table=None, fallback=True):
        """
        Looks up metadata, cascading backwards from specified level.
        Returns None if metadata value is not found.
        """
        assert not (database is None and table is not None), \
            "Cannot call metadata() with table= specified but not database="
        databases = self._metadata.get("databases") or {}
        search_list = []
        if database is not None:
            search_list.append(databases.get(database) or {})
        if table is not None:
            table_metadata = (
                (databases.get(database) or {}).get("tables") or {}
            ).get(table) or {}
            search_list.insert(0, table_metadata)
        search_list.append(self._metadata)
        if not fallback:
            # No fallback allowed, so just use the first one in the list
            search_list = search_list[:1]
        if key is not None:
            for item in search_list:
                if key in item:
                    return item[key]
            return None
        else:
            # Return the merged list
            m = {}
            for item in search_list:
                m.update(item)
            return m

    def plugin_config(
        self, plugin_name, database=None, table=None, fallback=True
    ):
        "Return config for plugin, falling back from specified database/table"
        plugins = self.metadata(
            "plugins", database=database, table=table, fallback=fallback
        )
        if plugins is None:
            return None
        return plugins.get(plugin_name)

    def app_css_hash(self):
        if not hasattr(self, "_app_css_hash"):
            self._app_css_hash = hashlib.sha1(
                open(
                    os.path.join(str(app_root), "datasette/static/app.css")
                ).read().encode(
                    "utf8"
                )
            ).hexdigest()[
                :6
            ]
        return self._app_css_hash

    def get_canned_queries(self, database_name):
        queries = self.metadata(
            "queries", database=database_name, fallback=False
        ) or {}
        names = queries.keys()
        return [
            self.get_canned_query(database_name, name) for name in names
        ]

    def get_canned_query(self, database_name, query_name):
        queries = self.metadata(
            "queries", database=database_name, fallback=False
        ) or {}
        query = queries.get(query_name)
        if query:
            if not isinstance(query, dict):
                query = {"sql": query}
            query["name"] = query_name
            return query

    async def get_table_definition(self, database_name, table, type_="table"):
        table_definition_rows = list(
            await self.execute(
                database_name,
                'select sql from sqlite_master where name = :n and type=:t',
                {"n": table, "t": type_},
            )
        )
        if not table_definition_rows:
            return None
        return table_definition_rows[0][0]

    def get_view_definition(self, database_name, view):
        return self.get_table_definition(database_name, view, 'view')

    def update_with_inherited_metadata(self, metadata):
        # Fills in source/license with defaults, if available
        metadata.update(
            {
                "source": metadata.get("source") or self.metadata("source"),
                "source_url": metadata.get("source_url")
                or self.metadata("source_url"),
                "license": metadata.get("license") or self.metadata("license"),
                "license_url": metadata.get("license_url")
                or self.metadata("license_url"),
                "about": metadata.get("about") or self.metadata("about"),
                "about_url": metadata.get("about_url")
                or self.metadata("about_url"),
            }
        )

    def prepare_connection(self, conn):
        conn.row_factory = sqlite3.Row
        conn.text_factory = lambda x: str(x, "utf-8", "replace")
        for name, num_args, func in self.sqlite_functions:
            conn.create_function(name, num_args, func)
        if self.sqlite_extensions:
            conn.enable_load_extension(True)
            for extension in self.sqlite_extensions:
                conn.execute("SELECT load_extension('{}')".format(extension))
        if self.config("cache_size_kb"):
            conn.execute('PRAGMA cache_size=-{}'.format(self.config("cache_size_kb")))
        pm.hook.prepare_connection(conn=conn)

    def table_exists(self, database, table):
        return table in self.inspect().get(database, {}).get("tables")

    def inspect(self):
        " Inspect the database and return a dictionary of table metadata "
        if self._inspect:
            return self._inspect

        self._inspect = {}
        for filename in self.files:
            if filename is MEMORY:
                self._inspect[":memory:"] = {
                    "hash": "000",
                    "file": ":memory:",
                    "size": 0,
                    "views": {},
                    "tables": {},
                }
            else:
                path = Path(filename)
                name = path.stem
                if name in self._inspect:
                    raise Exception("Multiple files with same stem %s" % name)
                try:
                    with sqlite3.connect(
                        "file:{}?immutable=1".format(path), uri=True
                    ) as conn:
                        self.prepare_connection(conn)
                        self._inspect[name] = {
                            "hash": inspect_hash(path),
                            "file": str(path),
                            "size": path.stat().st_size,
                            "views": inspect_views(conn),
                            "tables": inspect_tables(conn, (self.metadata("databases") or {}).get(name, {}))
                        }
                except sqlite3.OperationalError as e:
                    if (e.args[0] == 'no such module: VirtualSpatialIndex'):
                        raise click.UsageError(
                            "It looks like you're trying to load a SpatiaLite"
                            " database without first loading the SpatiaLite module."
                            "\n\nRead more: https://datasette.readthedocs.io/en/latest/spatialite.html"
                        )
                    else:
                        raise
        return self._inspect

    def register_custom_units(self):
        "Register any custom units defined in the metadata.json with Pint"
        for unit in self.metadata("custom_units") or []:
            ureg.define(unit)

    def versions(self):
        conn = sqlite3.connect(":memory:")
        self.prepare_connection(conn)
        sqlite_version = conn.execute("select sqlite_version()").fetchone()[0]
        sqlite_extensions = {}
        for extension, testsql, hasversion in (
            ("json1", "SELECT json('{}')", False),
            ("spatialite", "SELECT spatialite_version()", True),
        ):
            try:
                result = conn.execute(testsql)
                if hasversion:
                    sqlite_extensions[extension] = result.fetchone()[0]
                else:
                    sqlite_extensions[extension] = None
            except Exception as e:
                pass
        # Figure out supported FTS versions
        fts_versions = []
        for fts in ("FTS5", "FTS4", "FTS3"):
            try:
                conn.execute(
                    "CREATE VIRTUAL TABLE v{fts} USING {fts} (data)".format(fts=fts)
                )
                fts_versions.append(fts)
            except sqlite3.OperationalError:
                continue
        datasette_version = {"version": __version__}
        if self.version_note:
            datasette_version["note"] = self.version_note
        return {
            "python": {
                "version": ".".join(map(str, sys.version_info[:3])), "full": sys.version
            },
            "datasette": datasette_version,
            "sqlite": {
                "version": sqlite_version,
                "fts_versions": fts_versions,
                "extensions": sqlite_extensions,
                "compile_options": [
                    r[0] for r in conn.execute("pragma compile_options;").fetchall()
                ],
            },
        }

    def plugins(self, show_all=False):
        ps = list(get_plugins(pm))
        if not show_all:
            ps = [p for p in ps if p["name"] not in DEFAULT_PLUGINS]
        return [
            {
                "name": p["name"],
                "static": p["static_path"] is not None,
                "templates": p["templates_path"] is not None,
                "version": p.get("version"),
            }
            for p in ps
        ]

    async def execute(
        self,
        db_name,
        sql,
        params=None,
        truncate=False,
        custom_time_limit=None,
        page_size=None,
    ):
        """Executes sql against db_name in a thread"""
        page_size = page_size or self.page_size

        def sql_operation_in_thread():
            conn = getattr(connections, db_name, None)
            if not conn:
                info = self.inspect()[db_name]
                if info["file"] == ":memory:":
                    conn = sqlite3.connect(":memory:")
                else:
                    conn = sqlite3.connect(
                        "file:{}?immutable=1".format(info["file"]),
                        uri=True,
                        check_same_thread=False,
                    )
                self.prepare_connection(conn)
                setattr(connections, db_name, conn)

            time_limit_ms = self.sql_time_limit_ms
            if custom_time_limit and custom_time_limit < time_limit_ms:
                time_limit_ms = custom_time_limit

            with sqlite_timelimit(conn, time_limit_ms):
                try:
                    cursor = conn.cursor()
                    cursor.execute(sql, params or {})
                    max_returned_rows = self.max_returned_rows
                    if max_returned_rows == page_size:
                        max_returned_rows += 1
                    if max_returned_rows and truncate:
                        rows = cursor.fetchmany(max_returned_rows + 1)
                        truncated = len(rows) > max_returned_rows
                        rows = rows[:max_returned_rows]
                    else:
                        rows = cursor.fetchall()
                        truncated = False
                except sqlite3.OperationalError as e:
                    if e.args == ('interrupted',):
                        raise InterruptedError(e)
                    print(
                        "ERROR: conn={}, sql = {}, params = {}: {}".format(
                            conn, repr(sql), params, e
                        )
                    )
                    raise

            if truncate:
                return Results(rows, truncated, cursor.description)

            else:
                return Results(rows, False, cursor.description)

        return await asyncio.get_event_loop().run_in_executor(
            self.executor, sql_operation_in_thread
        )

    def app(self):
        app = Sanic(__name__)
        default_templates = str(app_root / "datasette" / "templates")
        template_paths = []
        if self.template_dir:
            template_paths.append(self.template_dir)
        template_paths.extend(
            [
                plugin["templates_path"]
                for plugin in get_plugins(pm)
                if plugin["templates_path"]
            ]
        )
        template_paths.append(default_templates)
        template_loader = ChoiceLoader(
            [
                FileSystemLoader(template_paths),
                # Support {% extends "default:table.html" %}:
                PrefixLoader(
                    {"default": FileSystemLoader(default_templates)}, delimiter=":"
                ),
            ]
        )
        self.jinja_env = Environment(loader=template_loader, autoescape=True)
        self.jinja_env.filters["escape_css_string"] = escape_css_string
        self.jinja_env.filters["quote_plus"] = lambda u: urllib.parse.quote_plus(u)
        self.jinja_env.filters["escape_sqlite"] = escape_sqlite
        self.jinja_env.filters["to_css_class"] = to_css_class
        pm.hook.prepare_jinja2_environment(env=self.jinja_env)
        app.add_route(IndexView.as_view(self), r"/<as_format:(\.jsono?)?$>")
        # TODO: /favicon.ico and /-/static/ deserve far-future cache expires
        app.add_route(favicon, "/favicon.ico")
        app.static("/-/static/", str(app_root / "datasette" / "static"))
        for path, dirname in self.static_mounts:
            app.static(path, dirname)
        # Mount any plugin static/ directories
        for plugin in get_plugins(pm):
            if plugin["static_path"]:
                modpath = "/-/static-plugins/{}/".format(plugin["name"])
                app.static(modpath, plugin["static_path"])
        app.add_route(
            JsonDataView.as_view(self, "inspect.json", self.inspect),
            r"/-/inspect<as_format:(\.json)?$>",
        )
        app.add_route(
            JsonDataView.as_view(self, "metadata.json", lambda: self._metadata),
            r"/-/metadata<as_format:(\.json)?$>",
        )
        app.add_route(
            JsonDataView.as_view(self, "versions.json", self.versions),
            r"/-/versions<as_format:(\.json)?$>",
        )
        app.add_route(
            JsonDataView.as_view(self, "plugins.json", self.plugins),
            r"/-/plugins<as_format:(\.json)?$>",
        )
        app.add_route(
            JsonDataView.as_view(self, "config.json", lambda: self._config),
            r"/-/config<as_format:(\.json)?$>",
        )
        app.add_route(
            DatabaseDownload.as_view(self), r"/<db_name:[^/]+?><as_db:(\.db)$>"
        )
        app.add_route(
            DatabaseView.as_view(self), r"/<db_name:[^/]+?><as_format:(\.jsono?|\.csv)?$>"
        )
        app.add_route(
            TableView.as_view(self),
            r"/<db_name:[^/]+>/<table_and_format:[^/]+?$>",
        )
        app.add_route(
            RowView.as_view(self),
            r"/<db_name:[^/]+>/<table:[^/]+?>/<pk_path:[^/]+?><as_format:(\.jsono?)?$>",
        )
        self.register_custom_units()
        # On 404 with a trailing slash redirect to path without that slash:
        @app.middleware("response")
        def redirect_on_404_with_trailing_slash(request, original_response):
            if original_response.status == 404 and request.path.endswith("/"):
                path = request.path.rstrip("/")
                if request.query_string:
                    path = "{}?{}".format(path, request.query_string)
                return response.redirect(path)

        @app.exception(Exception)
        def on_exception(request, exception):
            title = None
            help = None
            if isinstance(exception, NotFound):
                status = 404
                info = {}
                message = exception.args[0]
            elif isinstance(exception, InvalidUsage):
                status = 405
                info = {}
                message = exception.args[0]
            elif isinstance(exception, DatasetteError):
                status = exception.status
                info = exception.error_dict
                message = exception.message
                if exception.messagge_is_html:
                    message = Markup(message)
                title = exception.title
            else:
                status = 500
                info = {}
                message = str(exception)
                traceback.print_exc()
            templates = ["500.html"]
            if status != 500:
                templates = ["{}.html".format(status)] + templates
            info.update(
                {"ok": False, "error": message, "status": status, "title": title}
            )
            if request is not None and request.path.split("?")[0].endswith(".json"):
                return response.json(info, status=status)

            else:
                template = self.jinja_env.select_template(templates)
                return response.html(template.render(info), status=status)

        return app

from threading import Thread, Lock
import logging
import sys
import time
import hyperion.lib.util.config as config
from os import system
from subprocess import call
from psutil import Process, NoSuchProcess
is_py2 = sys.version[0] == '2'
if is_py2:
    import Queue as Queue
else:
    import queue as Queue
    

class ComponentMonitorJob(object):
    """Abstract class that represents a component monitoring job (local or remote)."""

    def __init__(self, pid, comp_name):
        """Initializes component monitoring job.

        :param pid: Process id of the component
        :type pid: int
        :param comp_name: Name of the component
        :type comp_name: str
        """
        self.pid = pid
        self.comp_name = comp_name

    def run_check(self):
        """You need to override this function in monitoring subclasses. It is called in the main monitoring thread.

        :return: True on a successful check, otherwise a CrashEvent is generated
        :rtype: bool or CrashEvent
        """


class LocalComponentMonitoringJob(ComponentMonitorJob):
    """Class that represents a local component monitoring job."""

    def __init__(self, pid, comp_name):
        """Creates a monitoring job for a local component.

        :param pid: Process id of the component
        :type pid: int
        :param comp_name: Name of the component
        :type comp_name: str
        """

        super(LocalComponentMonitoringJob, self).__init__(pid, comp_name)

    def run_check(self):
        """Runs a check if the pid exists and has not finished yet.

        :return: True if the component is running, otherwise returns a generated ``LocalCrashEvent``
        :rtype bool or LocalCrashEvent
        """
        try:
            proc = Process(self.pid)
            if proc.is_running():
                return True
        except NoSuchProcess:
            pass
        return CrashEvent(self.comp_name)

    def info(self):
        """Generate a status information for the job describing what is being monitored.

        :return: Information about this job
        :rtype: str
        """

        return "Running check for local component %s with pid %s" % (self.comp_name, self.pid)


class RemoteComponentMonitoringJob(ComponentMonitorJob):
    """Class that represents a remote component monitoring job."""

    def __init__(self, pid, comp_name, hostname, host_status):
        """Creates a remote component monitoring job.

        :param pid: Process id on the remote machine
        :type pid: int
        :param comp_name: Name of the monitored component
        :type comp_name: str
        :param hostname: Name of the host running the component
        :type hostname: str
        """

        super(RemoteComponentMonitoringJob, self).__init__(pid, comp_name)
        self.hostname = hostname
        self.host_status = host_status

    def run_check(self):
        """Runs a check if a remote process is still running.

        :return: True if the component is still running or the host is not reachable, otherwise a ``RemoteCrashEvent`` is generated.
        :rtype: bool or RemoteCrashEvent
        """

        if self.host_status.get(self.hostname):
            cmd = 'ssh -F %s %s "ps -p %s > /dev/null"' % (config.CUSTOM_SSH_CONFIG_PATH, self.hostname, self.pid)
            if call(cmd, shell=True) == 0:
                return True
            else:
                return RemoteCrashEvent(self.comp_name, self.hostname)
        # Return true because no information can be retrieved. The connection to the host has to be reestablished first.
        return True

    def info(self):
        """Generate a status information for the job describing what is being monitored.

        :return: Information about this job
        :rtype: str
        """

        return "Running check for remote component %s with pid %s on host %s" % (self.comp_name, self.pid,
                                                                                 self.hostname)


class HostMonitorJob(object):
    """Class representing a host monitoring job."""
    def __init__(self, pid, hostname, host_status, host_lock):
        """Create host monitoring job.

        :param pid: Process id of the ssh connection
        :type pid: int
        :param hostname: Name of the host connected to
        :type hostname: str
        :param host_status: Status of the used hosts
        :type host_status: dict
        :param host_lock: Lock that has to be acquired in order to write to the host status dictionary.
        :type host_lock: Lock
        """
        self.pid = pid
        self.hostname = hostname
        self.host_status = host_status
        self.host_lock = host_lock

    def run_check(self):
        try:
            proc = Process(self.pid)
            if proc.is_running() and system("exec >(ping %s -c 10 >/dev/null) </dev/null" % self.hostname) is 0:                    
                return True
        except NoSuchProcess:
            pass

        self.host_lock.acquire()
        self.host_status[self.hostname] = None
        self.host_lock.release()

        return DisconnectEvent(self.hostname)

    def info(self):
        return "Running ssh host check for %s with pid %s" % (self.hostname, self.pid)


class CrashEvent(object):
    """Superclass to model a component crash.

    Provides the name of the crashed component."""

    def __init__(self, comp_name):
        """Initializes the crash event assigning the component name

        :param comp_name: Name of the crashed component
        :type comp_name: str
        """

        self.comp_name = comp_name


class LocalCrashEvent(CrashEvent):
    """Crash event subclass for local component crashes.

    Provides the name of the crashed component and a short message.
    """

    def __init__(self, comp_name):
        """Creates a local crash event class with a component name and generates a short message.

        :param comp_name: Name of the crashed component
        :type comp_name: str
        """

        super(LocalCrashEvent, self).__init__(comp_name)
        self.message = 'Component %s crashed on localhost' % comp_name


class RemoteCrashEvent(CrashEvent):
    """Crash event subclass for remote component crashes.

    Provides the name of the crashed component along with the host it ran on and a short message.
    """

    def __init__(self, comp_name, hostname):
        """Creates a remote crash event with a component name and a host generating a short message.

        :param comp_name: Name of the crashed component
        :type comp_name: str
        :param hostname: Name of the host the component was running on
        :type hostname: str
        """

        super(RemoteCrashEvent, self).__init__(comp_name)
        self.hostname = hostname
        self.message = 'Component %s crashed on remote host %s' % (comp_name, hostname)


class DisconnectEvent(object):
    """Class representing a disconnect event for remote hosts."""

    def __init__(self, hostname):
        """Creates a disconnect event with a hostname and generates a short message."""
        self.hostname = hostname
        self.message = 'Lost connection to remote host %s' % hostname


class MonitoringThread(Thread):
    """This class is monitoring thread that extends the threading.Thread class."""

    def __init__(self, queue):
        """Initializes the monitoring thread with its input queue.

        :param queue: Input queue the monitor retrieves its jobs from
        :type queue: Queue.Queue
        """

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.debug("Initialized thread")
        super(MonitoringThread, self).__init__()
        self.job_queue = queue
        self.subscribed_queues = []
        self.end = False

    def kill(self):
        """Shuts down the thread by signalling the run function to end.

        :return: None
        """

        logger = logging.getLogger(__name__)
        logger.debug("Killing process monitoring thread")
        self.end = True

    def add_subscriber(self, queue):
        """Adds a subscriber to the list of queues to send notifications to.

        :param queue: Subscribing queue that will get notifications by this thread
        :type queue: Queue.Queue
        :return: None
        """

        logger = logging.getLogger(__name__)
        logger.debug("Added subscriber")
        self.subscribed_queues.append(queue)

    def run(self):
        """Starts the monitoring thread.

        :return: None
        """

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.debug("Started run funtion")
        while not self.end:

            comp_jobs = []
            jobs = []
            already_handleled = {}
            # Get all enqueued jobs for this iteration
            while not self.job_queue.empty():
                mon_job = self.job_queue.get()
                if isinstance(mon_job, HostMonitorJob):
                    jobs.append(mon_job)
                if isinstance(mon_job, ComponentMonitorJob) and mon_job.comp_name not in already_handleled:
                    comp_jobs.append(mon_job)
                    already_handleled[mon_job.comp_name] = True

            # Reorder job list to first check the hosts, then check the components because this makes sense
            jobs.extend(comp_jobs)
            for mon_job in jobs:
                logger.debug(mon_job.info())
                ret = mon_job.run_check()
                if ret is True:
                    logger.debug("S'all good man")
                    # If job is ok, put it back for the next iteration
                    self.job_queue.put(mon_job)
                else:
                    # If job is not ok, notify subscribers
                    logger.debug("Check failed, notifying subscribers")
                    for subscriber in self.subscribed_queues:
                        subscriber.put(ret)

            time.sleep(1)


#
# Copyright (c) 2016 NORDUnet A/S
# All rights reserved.
#
#   Redistribution and use in source and binary forms, with or
#   without modification, are permitted provided that the following
#   conditions are met:
#
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above
#        copyright notice, this list of conditions and the following
#        disclaimer in the documentation and/or other materials provided
#        with the distribution.
#     3. Neither the name of the NORDUnet nor the names of its
#        contributors may be used to endorse or promote products derived
#        from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#

from time import time
from saml2.ident import code
from flask import session, request, redirect, current_app
from eduid_common.authn.loa import get_loa
from eduid_webapp.authn.acs_registry import acs_action


@acs_action('login-action')
def login_action(session_info, user):
    """
    Upon successful login in the IdP, store login info in the session
    and redirect back to the app that asked for authn.

    :param session_info: the SAML session info
    :type session_info: dict

    :param user: the authenticated user
    :type user: eduid_userdb.User
    """
    current_app.logger.info("User {!r} logging in.".format(user))
    session['_saml2_session_name_id'] = code(session_info['name_id'])
    session['eduPersonPrincipalName'] = user.eppn
    session['user_eppn'] = user.eppn
    loa = get_loa(current_app.config.get('AVAILABLE_LOA'), session_info)
    session['eduPersonAssurance'] = loa
    session.persist()

    # redirect the user to the view where he came from
    relay_state = request.form.get('RelayState', '/')                    
    current_app.logger.debug('Redirecting to the RelayState: ' + relay_state)
    response = redirect(location=relay_state)
    session.set_cookie(response)
    current_app.logger.info('Redirecting user {!r} to {!r}'.format(user, relay_state))
    return response


@acs_action('change-password-action')
def chpass_action(session_info, user):
    """
    Upon successful reauthn in the IdP,
    set a timestamp in the session (key reauthn-for-chpass)
    and redirect back to the app that asked for reauthn.

    :param session_info: the SAML session info
    :type session_info: dict

    :param user: the authenticated user
    :type user: eduid_userdb.User
    """
    return _reauthn('reauthn-for-chpass', session_info, user)


@acs_action('terminate-account-action')
def term_account_action(session_info, user):
    """
    Upon successful reauthn in the IdP,
    set a timestamp in the session (key reauthn-for-termination)
    and redirect back to the app that asked for reauthn.

    :param session_info: the SAML session info
    :type session_info: dict

    :param user: the authenticated user
    :type user: eduid_userdb.User
    """
    return _reauthn('reauthn-for-termination', session_info, user)


def _reauthn(reason, session_info, user):

    current_app.logger.info("Reauthenticating user {!r} for {!r}.".format(user, reason))
    session['_saml2_session_name_id'] = code(session_info['name_id'])
    session[reason] = int(time())
    session.persist()

    # redirect the user to the view where he came from
    relay_state = request.form.get('RelayState', '/')                    
    current_app.logger.debug('Redirecting to the RelayState: ' + relay_state)
    return redirect(location=relay_state)

#
# Copyright (c) 2016 NORDUnet A/S
# All rights reserved.
#
#   Redistribution and use in source and binary forms, with or
#   without modification, are permitted provided that the following
#   conditions are met:
#
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above
#        copyright notice, this list of conditions and the following
#        disclaimer in the documentation and/or other materials provided
#        with the distribution.
#     3. Neither the name of the NORDUnet nor the names of its
#        contributors may be used to endorse or promote products derived
#        from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#

import os
import time
import json
import base64
from hashlib import sha256

from werkzeug.exceptions import NotFound
from werkzeug.http import dump_cookie
from flask import session
from flask import Blueprint
from saml2.s_utils import deflate_and_base64_encode

from eduid_userdb.user import User
from eduid_userdb.data_samples import NEW_COMPLETED_SIGNUP_USER_EXAMPLE
from eduid_common.api.testing import EduidAPITestCase
from eduid_common.authn.cache import OutstandingQueriesCache
from eduid_common.authn.utils import get_location, no_authn_views
from eduid_common.authn.eduid_saml2 import get_authn_request
from eduid_common.authn.tests.responses import (auth_response,
                                                logout_response,
                                                logout_request)
from eduid_webapp.authn.app import authn_init_app
from eduid_common.api.app import eduid_init_app


import logging
logger = logging.getLogger(__name__)

HERE = os.path.abspath(os.path.dirname(__file__))


class AuthnAPITestBase(EduidAPITestCase):

    def update_config(self, config):
        """
        Called from the parent class, so that we can update the configuration
        according to the needs of this test case.
        """
        saml_config = os.path.join(HERE, 'saml2_settings.py')
        config.update({
            'SAML2_LOGIN_REDIRECT_URL': '/',
            'SAML2_LOGOUT_REDIRECT_URL': '/logged-out',
            'SAML2_SETTINGS_MODULE': saml_config,
            'TOKEN_LOGIN_SHARED_KEY': 'shared_secret',
            'TOKEN_LOGIN_SUCCESS_REDIRECT_URL': 'http://test.localhost/success',
            'TOKEN_LOGIN_FAILURE_REDIRECT_URL': 'http://test.localhost/failure'                    
            })
        return config

    def load_app(self, config):
        """
        Called from the parent class, so we can provide the appropriate flask
        app for this test case.
        """
        return authn_init_app('test.localhost', config)

    def add_outstanding_query(self, came_from):
        """
        Add a SAML2 authentication query to the queries cache.
        To be used before accessing the assertion consumer service.

        :param came_from: url to redirect back the client
                          after finishing with the authn service.
        :type came_from: str

        :return: the session token corresponding to the query
        :rtype: str
        """
        with self.app.test_request_context('/login'):
            self.app.dispatch_request()
            oq_cache = OutstandingQueriesCache(session)
            oq_cache.set(session.token, came_from)
            session.persist()
            return session.token

    def login(self, eppn, came_from):
        """
        Add a SAML2 authentication query to the queries cache,
        build a cookie with a session id corresponding to the added query,
        build a SAML2 authn response for the added query,
        and send both to the assertion consumer service,
        so that the user is logged in (the session corresponding to the cookie
        has her eppn).
        This method returns the cookie that has to be sent with any
        subsequent request that needs to be athenticated.

        :param eppn: the eppn of the user to be logged in
        :type eppn: str
        :param came_from: url to redirect back the client
                          after finishing with the authn service.
        :type came_from: str

        :return: the cookie corresponding to the authn session
        :rtype: str
        """
        session_id = self.add_outstanding_query(came_from)
        cookie = self.dump_session_cookie(session_id)
        saml_response = auth_response(session_id, eppn)

        with self.app.test_request_context('/saml2-acs', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLResponse': base64.b64encode(saml_response),
                                                 'RelayState': came_from}):

            response1 = self.app.dispatch_request()
            cookie = response1.headers['Set-Cookie']
            return cookie

    def authn(self, url, force_authn=False):                    
        """
        Common code for the tests that need to send an authentication request.
        This checks that the client is redirected to the idp.

        :param url: the url of the desired authentication mode.
        :type url: str
        :param force_authn: whether to force reauthentication for an already
                            authenticated client
        :type force_authn: bool
        """
        with self.app.test_client() as c:
            resp = c.get(url)                    
            authn_req = get_location(get_authn_request(self.app.config,
                                                       session, '/', None,                    
                                                       force_authn=force_authn))
            idp_url = authn_req.split('?')[0]
            self.assertEqual(resp.status_code, 302)
            self.assertTrue(resp.location.startswith(idp_url))

    def acs(self, url, eppn, check_fn):                    
        """
        common code for the tests that need to access the assertion consumer service
        and then check the side effects of this access.

        :param url: the url of the desired authentication mode.
        :type url: str
        :param eppn: the eppn of the user to access the service
        :type eppn: str
        :param check_fn: the function that checks the side effects after accessing the acs
        :type check_fn: callable
        """
        came_from = '/camefrom/'                    
        with self.app.test_client() as c:
            resp = c.get(url)                    
            cookie = resp.headers['Set-Cookie']
            token = session._session.token
            authr = auth_response(token, eppn)

        with self.app.test_request_context('/saml2-acs', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLResponse': base64.b64encode(authr),
                                                 'RelayState': came_from}):

            oq_cache = OutstandingQueriesCache(session)
            oq_cache.set(token, came_from)

            resp = self.app.dispatch_request()

            self.assertEquals(resp.status_code, 302)
            self.assertEquals(resp.location, came_from)
            check_fn()

    def dump_session_cookie(self, session_id):
        """
        Get a cookie corresponding to an authenticated session.

        :param session_id: the token for the session
        :type session_id: str

        :return: the cookie
        """
        return dump_cookie(self.app.config.get('SESSION_COOKIE_NAME'), session_id,
                           max_age=float(self.app.config.get('PERMANENT_SESSION_LIFETIME')),
                           path=self.app.config.get('SESSION_COOKIE_PATH'),
                           domain=self.app.config.get('SESSION_COOKIE_DOMAIN'))


class AuthnAPITestCase(AuthnAPITestBase):
    """
    Tests to check the different modes of authentication.
    """

    def init_data(self):
        """
        Called from the parent class, so we can extend data initialized.
        """
        test_user = User(data=NEW_COMPLETED_SIGNUP_USER_EXAMPLE)  # eppn hubba-fooo
        self.app.central_userdb.save(test_user, check_sync=False)

    def test_login_authn(self):
        self.authn('/login')

    def test_chpass_authn(self):
        self.authn('/chpass', force_authn=True)

    def test_terminate_authn(self):
        self.authn('/terminate', force_authn=True)

    def test_login_assertion_consumer_service(self):
        eppn = 'hubba-bubba'

        def _check():
            eppn = 'hubba-bubba'
            self.assertEquals(session['eduPersonPrincipalName'], eppn)

        self.acs('/login', eppn, _check)

    def test_chpass_assertion_consumer_service(self):
        eppn = 'hubba-bubba'

        def _check():
            self.assertIn('reauthn-for-chpass', session)
            then = session['reauthn-for-chpass']
            now = int(time.time())
            self.assertTrue(now - then < 5)

        self.acs('/chpass', eppn, _check)

    def test_terminate_assertion_consumer_service(self):
        eppn = 'hubba-bubba'

        def _check():
            self.assertIn('reauthn-for-termination', session)
            then = session['reauthn-for-termination']
            now = int(time.time())
            self.assertTrue(now - then < 5)

        self.acs('/terminate', eppn, _check)

    def test_token_login_new_user(self):
        eppn = 'hubba-fooo'
        shared_key = self.app.config['TOKEN_LOGIN_SHARED_KEY']
        timestamp = '{:x}'.format(int(time.time()))
        nonce = os.urandom(16).encode('hex')
        token = sha256("{0}|{1}|{2}|{3}".format(shared_key, eppn, nonce, timestamp)).hexdigest()

        data = {
            'eppn': eppn,
            'token': token,
            'nonce': nonce,
            'ts': timestamp
        }

        with self.app.test_client() as c:
            resp = c.post('/token-login', data=data)
            self.assertEqual(resp.status_code, 302)
            self.assertTrue(resp.location.startswith(self.app.config['TOKEN_LOGIN_SUCCESS_REDIRECT_URL']))

    def test_token_login_old_user(self):
        eppn = 'hubba-bubba'
        shared_key = self.app.config['TOKEN_LOGIN_SHARED_KEY']
        timestamp = '{:x}'.format(int(time.time()))
        nonce = os.urandom(16).encode('hex')
        token = sha256("{0}|{1}|{2}|{3}".format(shared_key, eppn, nonce, timestamp)).hexdigest()

        data = {
            'eppn': eppn,
            'token': token,
            'nonce': nonce,
            'ts': timestamp
        }

        with self.app.test_client() as c:
            resp = c.post('/token-login', data=data)
            self.assertEqual(resp.status_code, 302)
            self.assertTrue(resp.location.startswith(self.app.config['TOKEN_LOGIN_FAILURE_REDIRECT_URL']))


class UnAuthnAPITestCase(EduidAPITestCase):

    def update_config(self, config):
        """
        Called from the parent class, so that we can update the configuration
        according to the needs of this test case.
        """
        saml_config = os.path.join(HERE, 'saml2_settings.py')
        config.update({
            'TOKEN_SERVICE_URL': 'http://login',
            'SAML2_SETTINGS_MODULE': saml_config,
            })
        return config

    def load_app(self, config):
        """
        Called from the parent class, so we can provide the appropriate flask
        app for this test case.
        """
        return eduid_init_app('testing', config)

    def test_no_cookie(self):
        with self.app.test_client() as c:
            resp = c.get('/')
            self.assertEqual(resp.status_code, 302)
            self.assertTrue(resp.location.startswith(self.app.config['TOKEN_SERVICE_URL']))

    def test_cookie(self):
        token = ('a7MPUEQQLAEEQEAQDGJOXKAMFM467EUW6HCETFI4VP5JCU3CDVJDQZSHMXAOSC'
                 'U25WPZA66NY5ZVAA4RPCVMHBQBJSVGYQPPLZNIBTP3Y')
        sessid = ('fb1f42420b0109020203325d750185673df252de388932a3957f522a6c43a'
                  'a47')
        self.redis_instance.conn.set(sessid, json.dumps({'v1': {'id': '0'}}))

        eppn = self.test_user_data['eduPersonPrincipalName']
        with self.session_cookie(self.browser, eppn) as c:
            self.assertRaises(NotFound, c.get, '/')


class NoAuthnAPITestCase(EduidAPITestCase):

    def setUp(self):
        super(NoAuthnAPITestCase, self).setUp()
        test_views = Blueprint('testing', __name__)

        @test_views.route('/test')
        def test():
            return 'OK'

        @test_views.route('/test3')
        def test3():
            return 'OK'

        self.app.register_blueprint(test_views)

    def update_config(self, config):
        """
        Called from the parent class, so that we can update the configuration
        according to the needs of this test case.
        """
        saml_config = os.path.join(HERE, 'saml2_settings.py')
        config.update({
            'TOKEN_SERVICE_URL': 'http://login',
            'SAML2_SETTINGS_MODULE': saml_config,
            'NO_AUTHN_URLS': ['^/test$'],
            })
        return config

    def load_app(self, config):
        """
        Called from the parent class, so we can provide the appropriate flask
        app for this test case.
        """
        return eduid_init_app('testing', config)

    def test_no_authn(self):
        with self.app.test_client() as c:
            resp = c.get('/test')
            self.assertEqual(resp.status_code, 200)

    def test_authn(self):
        with self.app.test_client() as c:
            resp = c.get('/test2')
            self.assertEqual(resp.status_code, 302)
            self.assertTrue(resp.location.startswith(self.app.config['TOKEN_SERVICE_URL']))

    def test_no_authn_util(self):
        no_authn_urls_before = [path for path in self.app.config['NO_AUTHN_URLS']]
        no_authn_path = '/test3'
        no_authn_views(self.app, [no_authn_path])
        self.assertEqual(no_authn_urls_before + ['^{!s}$'.format(no_authn_path)], self.app.config['NO_AUTHN_URLS'])

        with self.app.test_client() as c:
            resp = c.get('/test3')
            self.assertEqual(resp.status_code, 200)


class LogoutRequestTests(AuthnAPITestBase):

    def test_metadataview(self):
        with self.app.test_client() as c:
            response = c.get('/saml2-metadata')
            self.assertEqual(response.status, '200 OK')

    def test_logout_nologgedin(self):
        eppn = 'hubba-bubba'
        csrft = 'csrf token'
        with self.app.test_request_context('/logout', method='POST',
                                           data={'csrf': csrft}):
            session['_csrft_'] = csrft
            session['user_eppn'] = eppn
            session['eduPersonPrincipalName'] = eppn
            response = self.app.dispatch_request()
            self.assertEqual(response.status, '200 OK')
            self.assertIn(self.app.config['SAML2_LOGOUT_REDIRECT_URL'],
                          json.loads(response.data)['payload']['location'])

    def test_logout_loggedin(self):
        eppn = 'hubba-bubba'
        came_from = '/afterlogin/'
        cookie = self.login(eppn, came_from)

        csrft = 'csrf token'
        with self.app.test_request_context('/logout', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'csrf': csrft}):
            session['_csrft_'] = csrft
            response2 = self.app.dispatch_request()
            self.assertEqual(response2.status, '200 OK')
            self.assertIn('https://idp.example.com/simplesaml/saml2/idp/'
                          'SingleLogoutService.php',
                          json.loads(response2.data)['payload']['location'])

    def test_logout_service_startingSP(self):

        came_from = '/afterlogin/'
        session_id = self.add_outstanding_query(came_from)
        cookie = self.dump_session_cookie(session_id)

        with self.app.test_request_context('/saml2-ls', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLResponse': deflate_and_base64_encode(
                                            logout_response(session_id)
                                           ),
                                               'RelayState': 'testing-relay-state',                                        
                                           }):
            response = self.app.dispatch_request()

            self.assertEqual(response.status, '302 FOUND')
            self.assertIn('testing-relay-state', response.location)

    def test_logout_service_startingSP_already_logout(self):

        came_from = '/afterlogin/'
        session_id = self.add_outstanding_query(came_from)

        with self.app.test_request_context('/saml2-ls', method='POST',
                                           data={'SAMLResponse': deflate_and_base64_encode(
                                               logout_response(session_id)
                                           ),
                                               'RelayState': 'testing-relay-state',                                        
                                           }):
            response = self.app.dispatch_request()

            self.assertEqual(response.status, '302 FOUND')
            self.assertIn('testing-relay-state', response.location)

    def test_logout_service_startingIDP(self):

        eppn = 'hubba-bubba'
        came_from = '/afterlogin/'
        session_id = self.add_outstanding_query(came_from)
        cookie = self.dump_session_cookie(session_id)

        saml_response = auth_response(session_id, eppn)

        # Log in through IDP SAMLResponse
        with self.app.test_request_context('/saml2-acs', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLResponse': base64.b64encode(saml_response),
                                                 'RelayState': 'testing-relay-state',                                        
                                                 }):
            response = self.app.dispatch_request()

        with self.app.test_request_context('/saml2-ls', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLRequest': deflate_and_base64_encode(
                                               logout_request(session_id)
                                           ),
                                               'RelayState': 'testing-relay-state',                                        
                                           }):
            response = self.app.dispatch_request()

            self.assertEqual(response.status, '302 FOUND')
            self.assertIn('https://idp.example.com/simplesaml/saml2/idp/'
                          'SingleLogoutService.php?SAMLResponse=', response.location)

    def test_logout_service_startingIDP_no_subject_id(self):

        eppn = 'hubba-bubba'
        came_from = '/afterlogin/'
        session_id = self.add_outstanding_query(came_from)
        cookie = self.dump_session_cookie(session_id)

        saml_response = auth_response(session_id, eppn)

        # Log in through IDP SAMLResponse
        with self.app.test_request_context('/saml2-acs', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLResponse': base64.b64encode(saml_response),
                                                 'RelayState': 'testing-relay-state',                                        
                                                 }):
            response = self.app.dispatch_request()

        with self.app.test_request_context('/saml2-ls', method='POST',
                                           headers={'Cookie': cookie},
                                           data={'SAMLRequest': deflate_and_base64_encode(
                                               logout_request(session_id)
                                           ),
                                               'RelayState': 'testing-relay-state',                                        
                                           }):
            del session['_saml2_session_name_id']
            session.persist()
            response = self.app.dispatch_request()

            self.assertEqual(response.status, '302 FOUND')
            self.assertIn('testing-relay-state', response.location)

#
# Copyright (c) 2016 NORDUnet A/S
# All rights reserved.
#
#   Redistribution and use in source and binary forms, with or
#   without modification, are permitted provided that the following
#   conditions are met:
#
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above
#        copyright notice, this list of conditions and the following
#        disclaimer in the documentation and/or other materials provided
#        with the distribution.
#     3. Neither the name of the NORDUnet nor the names of its
#        contributors may be used to endorse or promote products derived
#        from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#

from saml2 import BINDING_HTTP_REDIRECT
from saml2.ident import decode
from saml2.client import Saml2Client
from saml2.response import LogoutResponse
from saml2.metadata import entity_descriptor
from werkzeug.exceptions import Forbidden
from flask import request, session, redirect, abort, make_response
from flask import current_app, Blueprint

from eduid_common.api.decorators import MarshalWith
from eduid_common.authn.utils import get_location
from eduid_common.authn.loa import get_loa
from eduid_common.authn.eduid_saml2 import get_authn_request, get_authn_response
from eduid_common.authn.eduid_saml2 import authenticate
from eduid_common.authn.cache import IdentityCache, StateCache
from eduid_webapp.authn.acs_registry import get_action, schedule_action
from eduid_webapp.authn.helpers import verify_auth_token                    
from eduid_webapp.authn.schemas import LogoutPayload, LogoutResponseSchema



authn_views = Blueprint('authn', __name__)


@authn_views.route('/login')
def login():
    """
    login view, redirects to SAML2 IdP
    """
    return _authn('login-action')


@authn_views.route('/chpass')
def chpass():
    """
    Reauthn view, sends a SAML2 reauthn request to the IdP.
    """
    return _authn('change-password-action', force_authn=True)


@authn_views.route('/terminate')
def terminate():
    """
    Reauthn view, sends a SAML2 reauthn request to the IdP.
    """
    return _authn('terminate-account-action', force_authn=True)


def _authn(action, force_authn=False):
    redirect_url = current_app.config.get('SAML2_LOGIN_REDIRECT_URL', '/')
    relay_state = request.args.get('next', redirect_url)                    
    idps = current_app.saml2_config.getattr('idp')
    assert len(idps) == 1
    idp = idps.keys()[0]
    idp = request.args.get('idp', idp)
    loa = request.args.get('required_loa', None)
    authn_request = get_authn_request(current_app.config, session,
                                      relay_state, idp, required_loa=loa,
                                      force_authn=force_authn)
    schedule_action(action)
    current_app.logger.info('Redirecting the user to the IdP for ' + action)
    return redirect(get_location(authn_request))


@authn_views.route('/saml2-acs', methods=['POST'])
def assertion_consumer_service():
    """
    Assertion consumer service, receives POSTs from SAML2 IdP's
    """

    if 'SAMLResponse' not in request.form:
        abort(400)

    xmlstr = request.form['SAMLResponse']
    session_info = get_authn_response(current_app.config, session, xmlstr)
    current_app.logger.debug('Trying to locate the user authenticated by the IdP')
    user = authenticate(current_app, session_info)

    if user is None:
        current_app.logger.error('Could not find the user identified by the IdP')
        raise Forbidden("Access not authorized")

    action = get_action()
    return action(session_info, user)


def _get_name_id(session):
    """
    Get the SAML2 NameID of the currently logged in user.
    :param session: The current session object
    :return: NameID
    :rtype: saml2.saml.NameID | None
    """
    try:
        return decode(session['_saml2_session_name_id'])
    except KeyError:
        return None


@authn_views.route('/logout', methods=['POST'])
@MarshalWith(LogoutResponseSchema)
def logout():
    """
    SAML Logout Request initiator.
    This view initiates the SAML2 Logout request
    using the pysaml2 library to create the LogoutRequest.
    """
    eppn = session.get('user_eppn')

    if eppn is None:
        current_app.logger.info('Session cookie has expired, no logout action needed')
        location = current_app.config.get('SAML2_LOGOUT_REDIRECT_URL')
        return LogoutPayload().dump({'location': location}).data

    user = current_app.central_userdb.get_user_by_eppn(eppn)

    current_app.logger.debug('Logout process started for user {!r}'.format(user))
    state = StateCache(session)
    identity = IdentityCache(session)

    client = Saml2Client(current_app.saml2_config,
                         state_cache=state,
                         identity_cache=identity)

    subject_id = _get_name_id(session)
    if subject_id is None:
        current_app.logger.warning(
            'The session does not contain '
            'the subject id for user {!r}'.format(user))
        location = current_app.config.get('SAML2_LOGOUT_REDIRECT_URL')

    else:
        logouts = client.global_logout(subject_id)
        loresponse = logouts.values()[0]
        # loresponse is a dict for REDIRECT binding, and LogoutResponse for SOAP binding
        if isinstance(loresponse, LogoutResponse):
            if loresponse.status_ok():
                current_app.logger.debug('Performing local logout for {!r}'.format(user))
                session.clear()
                location = current_app.config.get('SAML2_LOGOUT_REDIRECT_URL')
                location = request.form.get('RelayState', location)                    
                return LogoutPayload().dump({'location': location}).data
            else:
                abort(500)
        headers_tuple = loresponse[1]['headers']
        location = headers_tuple[0][1]
        current_app.logger.info('Redirecting to {!r} to continue the logout process '
                                'for user {!r}'.format(location, user))

    state.sync()
    return LogoutPayload().dump({'location': location}).data


@authn_views.route('/saml2-ls', methods=['POST'])
def logout_service():
    """SAML Logout Response endpoint
    The IdP will send the logout response to this view,
    which will process it with pysaml2 help and log the user
    out.
    Note that the IdP can request a logout even when
    we didn't initiate the process as a single logout
    request started by another SP.
    """
    current_app.logger.debug('Logout service started')

    state = StateCache(session)
    identity = IdentityCache(session)
    client = Saml2Client(current_app.saml2_config,
                         state_cache=state,
                         identity_cache=identity)

    logout_redirect_url = current_app.config.get('SAML2_LOGOUT_REDIRECT_URL')
    next_page = session.get('next', logout_redirect_url)
    next_page = request.args.get('next', next_page)
    next_page = request.form.get('RelayState', next_page)

    if 'SAMLResponse' in request.form: # we started the logout
        current_app.logger.debug('Receiving a logout response from the IdP')
        response = client.parse_logout_request_response(
            request.form['SAMLResponse'],
            BINDING_HTTP_REDIRECT
        )
        state.sync()
        if response and response.status_ok():
            session.clear()
            return redirect(next_page)
        else:
            current_app.logger.error('Unknown error during the logout')
            abort(400)

    # logout started by the IdP
    elif 'SAMLRequest' in request.form:
        current_app.logger.debug('Receiving a logout request from the IdP')
        subject_id = _get_name_id(session)
        if subject_id is None:
            current_app.logger.warning(
                'The session does not contain the subject id for user {0} '
                'Performing local logout'.format(
                    session['eduPersonPrincipalName']
                )
            )
            session.clear()
            return redirect(next_page)
        else:
            http_info = client.handle_logout_request(
                request.form['SAMLRequest'],
                subject_id,
                BINDING_HTTP_REDIRECT,
                relay_state=request.form['RelayState']
            )
            state.sync()
            location = get_location(http_info)
            session.clear()
            return redirect(location)
    current_app.logger.error('No SAMLResponse or SAMLRequest parameter found')
    abort(400)


@authn_views.route('/token-login', methods=['POST'])
def token_login():
    current_app.logger.debug('Starting token login')
    location_on_fail = current_app.config.get('TOKEN_LOGIN_FAILURE_REDIRECT_URL')
    location_on_success = current_app.config.get('TOKEN_LOGIN_SUCCESS_REDIRECT_URL')

    eppn = request.form.get('eppn')
    token = request.form.get('token')
    nonce = request.form.get('nonce')
    timestamp = request.form.get('ts')
    loa = get_loa(current_app.config.get('AVAILABLE_LOA'), None)  # With no session_info lowest loa will be returned

    if verify_auth_token(eppn=eppn, token=token, nonce=nonce, timestamp=timestamp):
        try:
            user = current_app.central_userdb.get_user_by_eppn(eppn)
            if user.locked_identity.count > 0:
                # This user has previously verified their account and is not new, this should not happen.
                current_app.logger.error('Not new user {} tried to log in using token login'.format(user))
                return redirect(location_on_fail)
            session['eduPersonPrincipalName'] = user.eppn
            session['user_eppn'] = user.eppn
            session['eduPersonAssurance'] = loa
            session.persist()

            response = redirect(location_on_success)
            session.set_cookie(response)
            current_app.logger.info('Successful token login, redirecting user {} to {}'.format(user,
                                                                                               location_on_success))
            return response
        except current_app.central_userdb.exceptions.UserDoesNotExist:
            current_app.logger.error('No user with eduPersonPrincipalName = {} found'.format(eppn))
        except current_app.central_userdb.exceptions.MultipleUsersReturned:
            current_app.logger.error("There are more than one user with eduPersonPrincipalName = {}".format(eppn))

    current_app.logger.info('Token login failed, redirecting user to {}'.format(location_on_fail))
    return redirect(location_on_fail)


@authn_views.route('/saml2-metadata')
def metadata():
    """
    Returns an XML with the SAML 2.0 metadata for this
    SP as configured in the saml2_settings.py file.
    """
    metadata = entity_descriptor(current_app.saml2_config)
    response = make_response(metadata.to_string(), 200)
    response.headers['Content-Type'] = "text/xml; charset=utf8"
    return response

# This attempts to execute a student's python function against any number of
# test cases.
# We attempt to catch common mistakes by static anlysis of student source code
# that fails to compile, and then further static analysis of an AST given a
# successful compile but unsuccessful result.
# We also attempt to (minimally) guard against malicious code by stripping
# the global environment and enforcing only a single function definition.
# This also includes disallowing the user to (easily) output over stdout, which
# might allow student code to effectively publish their own grade to the caller.
# Of course, this is not foolproof as os.write(1, 'str') is hard to guard
# against if the student code does manage to get access to __import__.

import argparse, ast, json, sys, keyword, math                    

# Constants.
global_whitelist = ['__doc__', '__package__']
# Mostly a copy of all __builtins__.__dict__'s keys.
# Normally present values that are removed are denoted by a comment
# NOTE: Keep this list in alphabetical order
# LAST UPDATED FOR VERSION 3.5.2
builtins_whitelist = [
  'abs',
  'all',
  'any',
  'ArithmeticError',
  'ascii',
  'AssertionError',
  'AttributeError',
  'BaseException',
  'bin',
  'BlockingIOError',
  'bool',
  'BrokenPipeError',
  'BufferError',
  '__build_class__',
  'bytearray',
  'bytes',
  'BytesWarning',
  'callable',
  'ChildProcessError',
  'chr',
  'classmethod',
  #'compile',    # Avoid new code creation.
  'complex',
  'ConnectionAbortedError',
  'ConnectionError',
  'ConnectionRefusedError',
  'ConnectionResetError',
  #'copyright',  # Extraneous constant from module site.
  #'credits',    # ibid module site.
  #'__debug__',  # No reason to use debug mode on student code.
  'delattr',
  'DeprecationWarning',
  'dict',
  'dir',
  'divmod',
  '__doc__',
  'Ellipsis',
  'enumerate',
  'EnvironmentError',
  'EOFError',
  #'eval',       # ibid code creation.
  'Exception',
  #'exec',       # ibid code creation.
  #'exit',       # ibid module site.
  'False',
  'FileExistsError',
  'FileNotFoundError',
  'filter',
  'float',
  'FloatingPointError',
  'format',
  'frozenset',
  'FutureWarning',
  'GeneratorExit',
  'getatter',
  'globals',
  'hasattr',
  'hash',
  #'help',       # ibid module site.
  'hex',
  'id',
  #'__import__', # ibid code creation.
  'ImportError',
  'ImportWarning',
  'IndentationError',
  'IndexError',
  'input',
  'int',
  'InterruptedError',
  'IOError',
  'IsADirectoryError',
  'isinstance',
  'issubclass',
  'iter',
  'KeyboardInterrupt',
  'KeyError',
  'len',
  #'license',    # ibid module site.
  'list',
  #'__loader__', # ibid code creation.
  'locals',
  'LookupError',
  'map',
  'max',
  'MemoryError',
  'memoryview',
  'min',
  '__name__',
  'NameError',
  'next',
  'None',
  'NotADirectoryError',
  'NotImplemented',
  'NotImplementedError',
  'object',
  'oct',
  #'open',      # Avoid file i/o.
  'ord',
  'OSError',
  'OverflowError',
  '__package__',
  'PendingDeprecationWarning',
  'PermissionError',
  'pow',
  'print',
  'ProcessLookupError',
  'property',
  #'quit',      # ibid module site.
  'range',
  'RecursionError',
  'ReferenceError',
  'repr',
  'ResourceWarning',
  'reversed',
  'round',
  'RuntimeError',
  'RuntimeWarning',
  'set',
  'setattr',
  'slice',
  'sorted',
  #'__spec__',  # ibid code creation.
  'staticmethod',
  'StopAsyncIteration',
  'StopIteration',
  'str',
  'sum',
  'super',
  'SyntaxError',
  'SyntaxWarning',
  'SystemExit',
  'TabError',
  'TimeoutError',
  'True',
  'tuple',
  'type',
  'TypeError',
  'UnboundLocalError',
  'UnicodeEncodeError',
  'UnicodeWarning',
  'UserWarning',
  'ValueError',
  'vars',
  'Warning',
  'ZeroDivisionError',
  'zip',
]

## OUTPUT FORMAT
# The output of this script will be written to stdout, and will take the form:
# {
#   'score': dd,
#   'deductions': [
#     { 'points': dd, 'reason': str }, ...
#   ]
# }

def output_json(points, deductions):
  # Write out the proper json output to stdout.
  score = points - sum(d['points'] for d in deductions)
  if score < 0: score = 0
  print(json.dumps({'score': score, 'deductions': deductions}))

def dock_points(deductions, points, reason):
  deductions.append({'points': points, 'reason': reason})

def fix_syntax_err(code, err):
  # Try to fix the syntax error found in the code. Returns fixed code or None.
  # TODO: Come up with some rules for fixing syntax errors.
  return None

def grade(code_obj, name, points, test_case_objs, vlevel = 0):
  # Grades the given implementation of name, code_obj, with a maximum score
  # of points on each test_case_obj. Returns a list of deductions.
  deductions = []  # Reasons we took off points.
  points_per_case = points // len(test_case_objs)

  # Instrument globals and locals. This is not leak-proof by anymeans, but
  # helps to limit the attack surface.
  instr_globals = {
    k: globals()[k]
    for k in global_whitelist
    if k in globals()
  }
  instr_globals['__name__'] = name  # Module shouldn't run with name as __main__
  instr_globals['__builtins__'] = {
    k: __builtins__.__dict__[k]
    for k in builtins_whitelist
    if k in __builtins__.__dict__
  }
  instr_locals = {}

  # TODO: instrument stdin, stdout, and stderr for these testcases.
  # TODO: if output is captured from stdout, consider comparing it against desired result

  # Run the function declaration from the student.
  try:
    exec(code_obj, instr_globals, instr_locals)                    
  except BaseException as e:
    if vlevel >= 1: print(repr(e), file=sys.stderr)
    # We'll consider any exception while defining the function to be a 0.
    dock_points(deductions, points, 'unable to execute function')
    return deductions

  for i, test_case_obj in enumerate(test_case_objs):
    try:
      result = eval(test_case_obj, instr_globals, instr_locals)                    
      if not result:
        dock_points(deductions, points_per_case, 'failed test case %d' % i)
    except BaseException as e:
      if vlevel >= 1: print(repr(e), file=sys.stderr)
      # We'll consider any exception while executing a test case to be wrong.
      dock_points(deductions, points_per_case, 'exception during test case %d' % i)                    

  return deductions


def main():
  ## INPUT ARGUMENTS
  parser = argparse.ArgumentParser(description="Grade student code against "
          "given test cases. Results will be written over stdout in JSON")
  parser.add_argument('-n', '--name', required=True,
          help="The name of the function the student was supposed to implement")
  parser.add_argument('-p', '--points', type=int, default=0,
          help="The number of points this question is worth. This argument is "
               "only used when -c is passed, and defaults to 0")
  parser.add_argument('-c', '--code',
          help="The student's code submission. Make sure to carefully escape "
               "this argument as a single string. If this argument is ommitted "
               "then this program just checks the validity of the test cases. "
               "The exit status indicates the validity of the cases")
  parser.add_argument('-t', '--test_case', required=True, action='append',
          help="The test cases to run the students code against. Each test case "
               "must take the form of of a function call without the function "
               "name followed by a comparison to a return value. For example "
               "``(1, 2) == 3'' or ``(1, 2, (3, 4), *[5, 6], last=8) == None''")
  parser.add_argument('-v', '--verbose',  action='count', default=0,
          help="Specifies verbositiy level. Each time this flag is specified, "
               "the count goes up by one. Level 1 or greater outputs additional "
               "information about exceptions that occur")


  # Process input arguments.
  args = parser.parse_args()
  vlevel = args.verbose

  # Ensure that name is a valid identifier (not a keyword).
  name = args.name
  if not name.isidentifier() or keyword.iskeyword(name):
    raise ValueError('Function name is not a valid identifier')

  test_case_objs = []
  # Handle test cases (make sure they are valid)
  for i, test_case in enumerate(args.test_case):
    # Prepend the function name to create a valid expression comparing the result
    # of calling the function with a value.
    test_case = name + test_case
    # Try parsing this into a single expression ast.
    try:
      expr = ast.parse(test_case, mode='eval')
    except BaseException as e:
      if vlevel >= 1: print(repr(e), file=sys.stderr)
      expr = None

    if not expr:
      raise ValueError('Failed to parse test case %d' % i)

    # Validate format of test case.
    # For now we will be pretty strict, we expect exactly:
    # One comparison expression:
    #   where left is a single function call.
    #   and there is only one comparator
    #     which must be a simple literal:
    #       Dict, Set, Num, Str, Bytes, NameConstant, List, Tuple.
    #     or simple operators applied to the above:
    #       BinOp, UnaryOp.
    valid = False
    if type(expr) == ast.Expression:
      comp = expr.body
      if type(comp) == ast.Compare and len(comp.ops) == len(comp.comparators) == 1:
        # We have a valid comparison between exactly two exprs.
        left = comp.left
        right = comp.comparators[0]

        # Validate left side of comparison.
        left_valid = False
        if type(left) == ast.Call:
          if type(left.func) == ast.Name and left.func.id == name:
            # We appear to be calling the right function, TODO: walk args.
            left_valid = True

        # Validate right side of comparison (only if left side was okay).
        if left_valid:
          # TODO: walk nested exprs as needed.
          if type(right) in [ast.Num, ast.Str, ast.Bytes, ast.NameConstant,
                             ast.Dict, ast.Set, ast.List, ast.Tuple,
                             ast.BinOp, ast.UnaryOp]:
            valid = True

    if not valid:
      raise ValueError('Invalid formatting for test case %d' % i)

    # Finally, we just have to try compiling the test case.
    try:
      obj = compile(expr, '<unknown>', 'eval')
    except BaseException as e:
      if vlevel >= 1: print(repr(e), file=sys.stderr)
      obj = None

    if not obj:
      raise ValueError('Cannot compile test case %d' % i)

    test_case_objs.append(obj)

  # Handle student code.
  code = args.code
  if not code:
    # We're just supposed to test the validity of the test cases when code is None.
    # TODO: Consider trying to evaluate the test cases to ensure that in addition to
    #       compiling, they actually evaluate without throwing exceptions.
    return

  # Bookkeeping for score.
  deductions = []

  # Try to construct an AST.
  tree = None
  while not tree:
    try:
      tree = ast.parse(code)
    except SyntaxError as se:
      fixed = fix_syntax_err(code, se)
      if not fixed:
        if vlevel >= 1: print(repr(se), file=sys.stderr)
        dock_points(deductions, args.points, 'syntax error')
        break  # Couldn't fix error.
      code = fixed
    except BaseException as e:
      if vlevel >= 1: print(repr(e), file=sys.stderr)
      dock_points(deductions, args.points, 'failed to parse code')
      break    # Unknown exception.

  if not tree:
    output_json(args.points, deductions)
    return

  # Validate the tree. Should be a single module containing a single function.
  valid = False
  if type(tree) == ast.Module and len(tree.body) == 1:
    fdef = tree.body[0]
    if type(fdef) in [ast.FunctionDef, ast.AsyncFunctionDef]:
      if fdef.name != name:
        fdef.name = name
        # TODO: Solidify point values.
        dock_points(deductions, 1, 'misnamed function')
      # TODO: Consider checking number of arguments and stuff.
      valid = True

  if not valid:
    dock_points(deductions, args.points, 'not just a single function definition')
    output_json(args.points, deductions)
    return

  # TODO: Consider doing more work on the AST to help catch common errors.
  # TODO: Consider multiple alterations to tree to fix common errors.

  # Attempt to compile current code tree.
  try:
    code_obj = compile(tree, '<unknown>', 'exec')
  except BaseException as e:
    if vlevel >= 1: print(repr(e), file=sys.stderr)
    code_obj = None

  # Currently no way to recover from failed compile if tree parsed okay.
  # Full marks off.
  if not code_obj:
    dock_points(deductions, args.points, 'failed to compile code')
    output_json(args.points, deductions)
    return

  # Actually grade the students submission!
  deductions += grade(code_obj, name, args.points, test_case_objs, vlevel)
  output_json(args.points, deductions)

if __name__ == '__main__':
  try:
    main()
  except Exception as e:
    sys.exit(str(e))

from gi.repository import Gio, Gdk, Gtk
from keepassgtk.logging_manager import LoggingManager
from keepassgtk.database_manager import DatabaseManager
from keepassgtk.create_database import CreateDatabase
from keepassgtk.container_page import ContainerPage
from keepassgtk.unlock_database import UnlockDatabase
import keepassgtk.config_manager
import os
from os.path import exists
import ntpath
import gi
gi.require_version('Gtk', '3.0')
gi.require_version('Gdk', '3.0')


class MainWindow(Gtk.ApplicationWindow):
    application = NotImplemented
    database_manager = NotImplemented
    container = NotImplemented
    override_dialog = NotImplemented
    quit_dialog = NotImplemented
    filechooser_creation_dialog = NotImplemented
    headerbar = NotImplemented
    first_start_grid = NotImplemented
    logging_manager = LoggingManager(True)
    opened_databases = []
    databases_to_save = []

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        keepassgtk.config_manager.configure()
        self.assemble_window()

    def assemble_window(self):
        self.set_default_size(800, 500)
        
        self.create_headerbar()
        self.first_start_screen()

        self.connect("delete-event", self.on_application_quit)

        self.custom_css()

    #
    # Headerbar
    #

    def create_headerbar(self):
        builder = Gtk.Builder()
        builder.add_from_resource("/run/terminal/KeepassGtk/main_window.ui")

        self.headerbar = builder.get_object("headerbar")

        file_open_button = builder.get_object("open_button")
        file_open_button.connect("clicked", self.open_filechooser, None)

        file_new_button = builder.get_object("new_button")
        file_new_button.connect("clicked", self.create_filechooser, None)

        self.set_titlebar(self.headerbar)

    def set_headerbar(self):
        self.set_titlebar(self.headerbar)

    def get_headerbar(self):
        return self.headerbar

    #
    # Styles
    #

    def custom_css(self):
        screen = Gdk.Screen.get_default()

        css_provider = Gtk.CssProvider()
        css_provider_resource = Gio.File.new_for_uri(
            "resource:///run/terminal/KeepassGtk/keepassgtk.css")
        css_provider.load_from_file(css_provider_resource)

        context = Gtk.StyleContext()
        context.add_provider_for_screen(
            screen, css_provider, Gtk.STYLE_PROVIDER_PRIORITY_USER)

    #
    # First Start Screen
    #

    def first_start_screen(self):
        if keepassgtk.config_manager.has_group("history") and keepassgtk.config_manager.get_string("history", "last-opened-db") != "" and exists(keepassgtk.config_manager.get_string("history", "last-opened-db")):
            self.logging_manager.log_debug(
                "Found last opened database entry (" +
                keepassgtk.config_manager.get_string(
                    "history", "last-opened-db") + ")")

            tab_title = ntpath.basename(keepassgtk.config_manager.get_string(
                "history", "last-opened-db"))
            self.start_database_opening_routine(                    
                tab_title,
                keepassgtk.config_manager.get_string(
                    "history", "last-opened-db"))
        else:
            self.logging_manager.log_debug(
                "No / Not valid last opened database entry found.")
            builder = Gtk.Builder()
            builder.add_from_resource(
                "/run/terminal/KeepassGtk/main_window.ui")

            self.first_start_grid = builder.get_object("first_start_grid")
            self.add(self.first_start_grid)

    #
    # Container Methods (Gtk Notebook holds tabs)
    #

    def create_container(self):
        if self.first_start_grid != NotImplemented:
            self.first_start_grid.destroy()

        self.container = Gtk.Notebook()

        self.container.set_border_width(0)
        self.container.set_scrollable(True)
        self.container.set_show_border(False)
        self.container.connect("switch-page", self.on_tab_switch)

        self.add(self.container)
        self.show_all()

    def destroy_container(self):
        self.container.destroy()

    #
    # Open Database Methods
    #

    def open_filechooser(self, widget, none):
        filechooser_opening_dialog = Gtk.FileChooserDialog(
            "Choose Keepass Database", self, Gtk.FileChooserAction.OPEN,
            (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL,
             Gtk.STOCK_OPEN, Gtk.ResponseType.OK))

        filter_text = Gtk.FileFilter()
        filter_text.set_name("Keepass 2 Database")
        filter_text.add_mime_type("application/x-keepass2")
        filechooser_opening_dialog.add_filter(filter_text)

        response = filechooser_opening_dialog.run()
        if response == Gtk.ResponseType.OK:
            self.logging_manager.log_debug(
                "File selected: " + filechooser_opening_dialog.get_filename())
            filechooser_opening_dialog.close()

            tab_title = self.create_tab_title_from_filepath(                    
                filechooser_opening_dialog.get_filename())
            self.start_database_opening_routine(                    
                tab_title, filechooser_opening_dialog.get_filename())                    
        elif response == Gtk.ResponseType.CANCEL:
            self.logging_manager.log_debug("File selection canceled")
            filechooser_opening_dialog.close()

    def start_database_opening_routine(self, tab_title, filepath):
        builder = Gtk.Builder()
        builder.add_from_resource(
            "/run/terminal/KeepassGtk/create_database.ui")
        headerbar = builder.get_object("headerbar")

        UnlockDatabase(self, self.create_tab(tab_title, headerbar), filepath)

    #
    # Create Database Methods
    #

    def create_filechooser(self, widget, none):
        self.filechooser_creation_dialog = Gtk.FileChooserDialog(
            "Create new Database", self, Gtk.FileChooserAction.SAVE,
            (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL,
             Gtk.STOCK_SAVE, Gtk.ResponseType.OK))
        self.filechooser_creation_dialog.set_current_name("Database.kdbx")
        self.filechooser_creation_dialog.set_modal(True)

        filter_text = Gtk.FileFilter()
        filter_text.set_name("Keepass 2 Database")
        filter_text.add_mime_type("application/x-keepass2")
        self.filechooser_creation_dialog.add_filter(filter_text)

        response = self.filechooser_creation_dialog.run()
        if response == Gtk.ResponseType.OK:
            self.does_file_exist()
        elif response == Gtk.ResponseType.CANCEL:
            self.filechooser_creation_dialog.close()

    def does_file_exist(self):
        if os.path.exists(self.filechooser_creation_dialog.get_filename()):
            builder = Gtk.Builder()
            builder.add_from_resource(
                "/run/terminal/KeepassGtk/override_dialog.ui")
            self.override_dialog = builder.get_object("override_dialog")

            self.override_dialog.set_destroy_with_parent(True)
            self.override_dialog.set_modal(True)
            self.override_dialog.set_transient_for(self.filechooser_creation_dialog)

            cancel_button = builder.get_object("cancel_button")
            override_button = builder.get_object("override_button")

            cancel_button.connect("clicked", self.on_cancel_button_clicked)
            override_button.connect("clicked", self.on_override_button_clicked)

            self.override_dialog.present()
        else:
            self.copy_database_file()

            tab_title = self.create_tab_title_from_filepath(self.filechooser_creation_dialog.get_current_name())                    
            self.start_database_creation_routine(tab_title)

    def copy_database_file(self):
        stock_database = Gio.File.new_for_uri(
            "resource:///run/terminal/KeepassGtk/database.kdbx")
        new_database = Gio.File.new_for_path(
            self.filechooser_creation_dialog.get_filename())

        stock_database.copy(new_database, Gio.FileCopyFlags.OVERWRITE)
        self.filechooser_creation_dialog.close()

    def start_database_creation_routine(self, tab_title):
        self.database_manager = DatabaseManager(
            self.filechooser_creation_dialog.get_filename(),
            "liufhre86ewoiwejmrcu8owe")
        builder = Gtk.Builder()
        builder.add_from_resource(
            "/run/terminal/KeepassGtk/create_database.ui")
        headerbar = builder.get_object("headerbar")
        CreateDatabase(
            self, self.create_tab(tab_title, headerbar),
            self.database_manager)

    #
    # Tab Manager
    #

    def create_tab(self, title, headerbar):
        if self.container == NotImplemented:
            self.create_container()

        page_instance = ContainerPage(headerbar)

        tab_hbox = Gtk.HBox(False, 0)
        tab_label = Gtk.Label(title)
        tab_hbox.pack_start(tab_label, False, False, False)

        icon = Gio.ThemedIcon(name="window-close-symbolic")
        close_image = Gtk.Image.new_from_gicon(icon, Gtk.IconSize.BUTTON)
        close_button = Gtk.Button()
        close_button.set_relief(Gtk.ReliefStyle.NONE)
        close_button.set_focus_on_click(False)
        close_button.connect("clicked", self.on_tab_close_button_clicked, page_instance)
        close_button.add(close_image)

        tab_hbox.pack_start(close_button, False, False, False)
        tab_hbox.show_all()

        self.container.append_page(page_instance, tab_hbox)
        self.container.set_current_page(self.container.page_num(page_instance))
        self.update_tab_bar_visibility()

        return page_instance

    def update_tab_bar_visibility(self):
        if self.container.get_n_pages() > 1:
            self.container.set_show_tabs(True)
        else:
            self.container.set_show_tabs(False)

    def create_tab_title_from_filepath(self, filepath):
        return ntpath.basename(filepath)

    def close_tab(self, child_widget):
        page_num = self.container.page_num(child_widget)
        self.container.remove_page(page_num)
        self.update_tab_bar_visibility()

    #
    # Events
    #

    def on_tab_close_button_clicked(self, sender, widget):
        page_num = self.container.page_num(widget)

        for db in self.opened_databases:
            if db.window.container.page_num(db.parent_widget) == page_num:
                self.opened_databases.remove(db)

        self.container.remove_page(page_num)
        self.update_tab_bar_visibility()

    def on_cancel_button_clicked(self, widget):
        self.override_dialog.destroy()
        self.filechooser_creation_dialog.destroy()

    def on_override_button_clicked(self, widget):
        self.copy_database_file()

        tab_title = self.create_tab_title_from_filepath(                    
            self.filechooser_creation_dialog.get_current_name())
        self.start_database_creation_routine(tab_title)

        self.override_dialog.destroy()

    def on_tab_switch(self, notebook, tab, pagenum):
        headerbar = tab.get_headerbar()
        self.set_titlebar(headerbar)

    def on_save_check_button_toggled(self, check_button, db):
        if check_button.get_active():
            self.databases_to_save.append(db)
        else:
            self.databases_to_save.remove(db)

    def on_back_button_clicked(self, button):
        self.databases_to_save.clear()
        self.quit_dialog.destroy()

    def on_quit_button_clicked(self, button):
        for db in self.databases_to_save:
            db.database_manager.save_database()

        self.quit_dialog.destroy()
        self.application.quit()

    #
    # Application Quit Dialog
    #

    def on_application_quit(self, window, event):
        unsaved_databases_list = []
        for db in self.opened_databases:
            if db.database_manager.changes is True:
                unsaved_databases_list.append(db)

        if unsaved_databases_list.__len__() > 0:
            builder = Gtk.Builder()
            builder.add_from_resource(
                "/run/terminal/KeepassGtk/quit_dialog.ui")
            self.quit_dialog = builder.get_object("quit_dialog")

            self.quit_dialog.set_destroy_with_parent(True)
            self.quit_dialog.set_modal(True)
            self.quit_dialog.set_transient_for(self)

            back_button = builder.get_object("back_button")
            quit_button = builder.get_object("quit_button")

            back_button.connect("clicked", self.on_back_button_clicked)
            quit_button.connect("clicked", self.on_quit_button_clicked)

            unsaved_databases_list_box = builder.get_object("unsaved_databases_list_box")
                
            for db in unsaved_databases_list:
                unsaved_database_row = Gtk.ListBoxRow()
                check_button = Gtk.CheckButton()
                check_button.set_label(db.database_manager.database_path)
                check_button.connect("toggled", self.on_save_check_button_toggled, db)
                unsaved_database_row.add(check_button)
                unsaved_database_row.show_all()
                unsaved_databases_list_box.add(unsaved_database_row)

            self.quit_dialog.present()

            return(True)         

from gi.repository import Gio, Gtk
from keepassgtk.database_manager import DatabaseManager
from keepassgtk.unlocked_database import UnlockedDatabase
import keepassgtk.config_manager
from keepassgtk.logging_manager import LoggingManager
import gi
gi.require_version('Gtk', '3.0')
import ntpath
import threading


class UnlockDatabase:
    builder = NotImplemented
    parent_widget = NotImplemented
    window = NotImplemented
    database_filepath = NotImplemented
    database_manager = NotImplemented
    unlock_database_stack_box = NotImplemented
    keyfile = NotImplemented
    composite_keyfile_path = NotImplemented
    logging_manager = LoggingManager(True)
    overlay = NotImplemented

    def __init__(self, window, widget, filepath):
        self.window = window
        self.parent_widget = widget
        self.database_filepath = filepath
        self.unlock_database()

    def unlock_database(self):
        self.builder = Gtk.Builder()
        self.builder.add_from_resource("/run/terminal/KeepassGtk/unlock_database.ui")

        self.set_headerbar()

        self.assemble_stack()
        self.connect_events()

    #
    # Headerbar
    #

    def set_headerbar(self):
        headerbar = self.builder.get_object("headerbar")
        headerbar.set_subtitle(self.database_filepath)
        self.window.set_titlebar(headerbar)
        self.parent_widget.set_headerbar(headerbar)
        back_button = self.builder.get_object("back_button")
        back_button.connect("clicked", self.on_headerbar_back_button_clicked)

    #
    # Stack
    #

    def assemble_stack(self):
        self.overlay = Gtk.Overlay()

        unlock_failed_overlay = self.builder.get_object("unlock_failed_overlay")
        self.overlay.add_overlay(unlock_failed_overlay)

        stack = Gtk.Stack()
        stack.set_transition_type(Gtk.StackTransitionType.CROSSFADE)

        self.unlock_database_stack_box = self.builder.get_object("unlock_database_stack_box")
        unlock_database_stack_switcher = self.builder.get_object("unlock_database_stack_switcher")
        unlock_database_stack_switcher.set_stack(stack)

        password_unlock_stack_page = self.builder.get_object("password_unlock_stack_page")
        keyfile_unlock_stack_page = self.builder.get_object("keyfile_unlock_stack_page")
        composite_unlock_stack_page = self.builder.get_object("composite_unlock_stack_page")

        stack.add_titled(password_unlock_stack_page, "password_unlock", "Password")
        stack.child_set_property(password_unlock_stack_page, "icon-name", "input-dialpad-symbolic")

        stack.add_titled(keyfile_unlock_stack_page, "keyfile_unlock", "Keyfile")
        stack.child_set_property(keyfile_unlock_stack_page, "icon-name", "mail-attachment-symbolic")

        stack.add_titled(composite_unlock_stack_page, "composite_unlock", "Composite")
        stack.child_set_property(composite_unlock_stack_page, "icon-name", "insert-link-symbolic")

        self.overlay.add(stack)
        self.unlock_database_stack_box.add(self.overlay)
        self.unlock_database_stack_box.show_all()

        self.parent_widget.add(self.unlock_database_stack_box)

    def connect_events(self):
        password_unlock_button = self.builder.get_object("password_unlock_button")
        password_unlock_button.connect("clicked", self.on_password_unlock_button_clicked)

        keyfile_unlock_button = self.builder.get_object("keyfile_unlock_button")
        keyfile_unlock_button.connect("clicked", self.on_keyfile_unlock_button_clicked)

        composite_unlock_button = self.builder.get_object("composite_unlock_button")
        composite_unlock_button.connect("clicked", self.on_composite_unlock_button_clicked)

        keyfile_unlock_select_button = self.builder.get_object("keyfile_unlock_select_button")
        keyfile_unlock_select_button.connect("clicked", self.on_keyfile_unlock_select_button_clicked)

        composite_unlock_select_button = self.builder.get_object("composite_unlock_select_button")
        composite_unlock_select_button.connect("clicked", self.on_composite_unlock_select_button_clicked)

        password_unlock_entry = self.builder.get_object("password_unlock_entry")
        password_unlock_entry.connect("activate", self.on_password_unlock_button_clicked)
        password_unlock_entry.connect("icon-press", self.on_password_unlock_entry_secondary_clicked)

    #
    # Events
    #

    def on_password_unlock_entry_secondary_clicked(self, widget, position, eventbutton):
        if widget.get_visibility():
            widget.set_invisible_char("")
            widget.set_visibility(False)
        else:
            widget.set_visibility(True)

    def on_headerbar_back_button_clicked(self, widget):
        self.window.set_headerbar()
        self.window.close_tab(self.parent_widget)

    def on_password_unlock_button_clicked(self, widget):
        password_unlock_entry = self.builder.get_object("password_unlock_entry")

        if password_unlock_entry.get_text() != "":                    
            try:
                self.database_manager = DatabaseManager(self.database_filepath, password_unlock_entry.get_text())
                self.open_database_page()
                self.logging_manager.log_debug("Opening of database was successfull")
            except(OSError):
                self.show_unlock_failed_revealer()

                password_unlock_entry.grab_focus()
                password_unlock_entry.get_style_context().add_class("error")
                self.clear_input_fields()
                self.logging_manager.log_debug("Could not open database, wrong password")

    def on_keyfile_unlock_select_button_clicked(self, widget):
        keyfile_chooser_dialog = Gtk.FileChooserDialog("Choose a keyfile", self.window, Gtk.FileChooserAction.OPEN, (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL, Gtk.STOCK_OPEN, Gtk.ResponseType.OK))
        filter_text = Gtk.FileFilter()
        filter_text.set_name("Keyfile")
        filter_text.add_mime_type("application/octet-stream")
        filter_text.add_mime_type("application/x-keepass2")
        filter_text.add_mime_type("text/plain")
        filter_text.add_mime_type("application/x-iwork-keynote-sffkey")
        keyfile_chooser_dialog.add_filter(filter_text)

        response = keyfile_chooser_dialog.run()
        if response == Gtk.ResponseType.OK:
            self.logging_manager.log_debug("File selected: " + keyfile_chooser_dialog.get_filename())
            keyfile_chooser_dialog.close()

            keyfile_unlock_select_button = self.builder.get_object("keyfile_unlock_select_button")
            keyfile_unlock_select_button.get_style_context().remove_class(Gtk.STYLE_CLASS_DESTRUCTIVE_ACTION)
            keyfile_unlock_select_button.get_style_context().add_class(Gtk.STYLE_CLASS_SUGGESTED_ACTION)
            keyfile_unlock_select_button.set_label(ntpath.basename(keyfile_chooser_dialog.get_filename()))

        elif response == Gtk.ResponseType.CANCEL:
            self.logging_manager.log_debug("File selection canceled")
            keyfile_chooser_dialog.close()

    def on_keyfile_unlock_button_clicked(self, widget):
        keyfile_unlock_select_button = self.builder.get_object("keyfile_unlock_select_button")
        keyfile_path = keyfile_unlock_select_button.get_label()

        try:
            self.database_manager = DatabaseManager(self.database_filepath, password=None, keyfile=keyfile_path)
            self.open_database_page()
            self.logging_manager.log_debug("Database successfully opened with keyfile")
        except(OSError, IndexError):
            self.show_unlock_failed_revealer()

            keyfile_unlock_select_button.get_style_context().add_class(Gtk.STYLE_CLASS_DESTRUCTIVE_ACTION)
            keyfile_unlock_select_button.set_label("Try again")

            self.logging_manager.log_debug("Invalid keyfile chosen")
            self.logging_manager.log_debug("Keyfile path: " + keyfile_path)

    def on_composite_unlock_select_button_clicked(self, widget):
        filechooser_opening_dialog = Gtk.FileChooserDialog(
            "Choose Keyfile", self.window, Gtk.FileChooserAction.OPEN,
            (Gtk.STOCK_CANCEL, Gtk.ResponseType.CANCEL, Gtk.STOCK_OPEN,
             Gtk.ResponseType.OK))
        composite_unlock_select_button = self.builder.get_object("composite_unlock_select_button")

        filter_text = Gtk.FileFilter()
        filter_text.set_name("Keyfile")
        filter_text.add_mime_type("application/octet-stream")
        filter_text.add_mime_type("application/x-keepass2")
        filter_text.add_mime_type("text/plain")
        filter_text.add_mime_type("application/x-iwork-keynote-sffkey")
        filechooser_opening_dialog.add_filter(filter_text)

        response = filechooser_opening_dialog.run()
        if response == Gtk.ResponseType.OK:
            self.logging_manager.log_debug("File selected: " + filechooser_opening_dialog.get_filename())
            filechooser_opening_dialog.close()
            file_path = filechooser_opening_dialog.get_filename()
            composite_unlock_select_button.set_label(ntpath.basename(file_path))
            self.composite_keyfile_path = file_path
        elif response == Gtk.ResponseType.CANCEL:
            self.logging_manager.log_debug("File selection cancelled")
            filechooser_opening_dialog.close()

    def on_composite_unlock_button_clicked(self, widget):
        composite_unlock_entry = self.builder.get_object("composite_unlock_entry")
        composite_unlock_select_button = self.builder.get_object("composite_unlock_select_button")

        if composite_unlock_entry.get_text() is not "":
            try:
                self.database_manager = DatabaseManager(self.database_filepath, composite_unlock_entry.get_text(), self.composite_keyfile_path)
                self.open_database_page()
                self.logging_manager.log_debug("Opening of database was successfull")
            except(OSError):
                self.show_unlock_failed_revealer()

                composite_unlock_entry.grab_focus()
                composite_unlock_entry.get_style_context().add_class("error")
                composite_unlock_select_button.get_style_context().remove_class("suggested-action")
                composite_unlock_select_button.get_style_context().add_class("destructive-action")
                self.clear_input_fields()

                self.logging_manager.log_debug("Could not open database, wrong password")
        else:
            composite_unlock_entry.get_style_context().add_class("error")

    #
    # Open Database
    #
    def open_database_page(self):
        self.clear_input_fields()
        keepassgtk.config_manager.create_config_entry_string("history", "last-opened-db", str(self.database_filepath))
        keepassgtk.config_manager.save_config()

        self.unlock_database_stack_box.destroy()
        UnlockedDatabase(self.window, self.parent_widget, self.database_manager)

    #
    # Helper Functions
    #

    def clear_input_fields(self):
        password_unlock_entry = self.builder.get_object("password_unlock_entry")
        composite_unlock_entry = self.builder.get_object("composite_unlock_entry")
        password_unlock_entry.set_text("")
        composite_unlock_entry.set_text("")

    def show_unlock_failed_revealer(self):
        unlock_failed_box = self.builder.get_object("unlock_failed_box")
        context = unlock_failed_box.get_style_context()
        context.add_class('NotifyRevealer')

        unlock_failed_revealer = self.builder.get_object("unlock_failed_revealer")
        unlock_failed_revealer.set_reveal_child(not unlock_failed_revealer.get_reveal_child())
        revealer_timer = threading.Timer(3.0, self.hide_unlock_failed_revealer)
        revealer_timer.start()

    def hide_unlock_failed_revealer(self):
        unlock_failed_revealer = self.builder.get_object("unlock_failed_revealer")
        unlock_failed_revealer.set_reveal_child(not unlock_failed_revealer.get_reveal_child())

from peewee import Database, SqliteDatabase


def can_import_apsw():
    # type: () -> bool
    return False  # for now
    try:
        import apsw
        return True
    except ImportError:
        return False


TexDBookDatabase = None  # type: Database

if can_import_apsw():
    from playhouse.apsw_ext import APSWDatabase
    
    TexDBookDatabase = APSWDatabase
else:
    TexDBookDatabase = SqliteDatabase

from django.http import HttpResponse, HttpResponseRedirect                    
from django.shortcuts import get_object_or_404, render                    
from django.views.generic import TemplateView, DetailView
from .forms import SearchForm
from lib.geoip import GeoIP
from lib.vt import VT
from lib.threatminer import ThreatMiner
import socket
from django.db.models import Q
from apps.threat.models import Event, Attribute
from apps.reputation.models import blacklist
from apps.twitter.models import tweet
from apps.exploit.models import Exploit

class IndexView(TemplateView):
    template_name = 'domain/index.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['search_form'] = SearchForm()
        return context

    def get(self, request, **kwargs):
        if request.GET.get('keyword'):
            domain = request.GET.get('keyword')
            return HttpResponseRedirect(domain)                    
        context = self.get_context_data()
        return self.render_to_response(context)

class DetailView(TemplateView):
    template_name = 'domain/detail.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['search_form'] = SearchForm()
        domain = self.kwargs['pk']
        try:
            context['geoip'] = GeoIP().lookup(domain)
        except Exception as e:
            print(e)
            pass
        try:
            context['ipaddress'] = socket.gethostbyname(domain)
        except Exception as e:
            pass

        vt = VT()
        context['vt_domain'] = vt.getDomainReport(domain)

        tm = ThreatMiner()
        context['tm_url'] = tm.getURIFromDomain(domain)
        context['tm_sample'] = tm.getSamplesFromDomain(domain)
        context['tm_report'] = tm.getReportFromDomain(domain)

        context['bls'] = blacklist.objects.filter(Q(domain=domain)|Q(url__contains=domain))
        count = context['bls'].count()
        if count > 0:
            context['bls_count'] = count
        context['events'] = Event.objects.filter(Q(info__icontains=domain)).order_by('-publish_timestamp')
        count = context['events'].count()
        if count > 0:
            context['events_count'] = count
        context['attributes'] = Attribute.objects.filter(Q(value__icontains=domain)).order_by('-timestamp')
        count = context['attributes'].count()
        if count > 0:
            context['attributes_count'] = count
        context['tws'] = tweet.objects.filter(Q(text__icontains=domain)).order_by('-datetime')
        count = context['tws'].count()
        if count > 0:
            context['tws_count'] = count
        context['exs'] = Exploit.objects.filter(Q(text__icontains=domain)).order_by('-datetime')
        count = context['exs'].count()
        if count > 0:
            context['exs_count'] = count

        return context


from django.http import HttpResponse, HttpResponseRedirect
from django.shortcuts import get_object_or_404, render                    
from django.views.generic import TemplateView, DetailView
from .forms import SearchForm
from lib.vt import VT
from lib.threatminer import ThreatMiner
from django.db.models import Q
from apps.threat.models import Event, Attribute
from apps.reputation.models import blacklist
from apps.twitter.models import tweet
from apps.exploit.models import Exploit

class IndexView(TemplateView):
    template_name = 'filehash/index.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['search_form'] = SearchForm()
        return context

    def get(self, request, **kwargs):
        if request.GET.get('keyword'):
            filehash = request.GET.get('keyword')
            return HttpResponseRedirect(filehash)                    
        context = self.get_context_data()
        return self.render_to_response(context)

class DetailView(TemplateView):
    template_name = 'filehash/detail.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['search_form'] = SearchForm()
        filehash = self.kwargs['pk']

        vt = VT()
        context['vt_hash'] = vt.getFileReport(filehash)
        context['vt_behavior'] = vt.getFileBehavior(filehash)

        tm = ThreatMiner()
        context['tm_meta'] = tm.getMetaFromSample(filehash)
        context['tm_http'] = tm.getHttpFromSample(filehash)
        context['tm_host'] = tm.getHostsFromSample(filehash)
        context['tm_av'] = tm.getAVFromSample(filehash)
        context['tm_report'] = tm.getReportFromSample(filehash)

        #context['bls'] = blacklist.objects.filter(Q(url__contains=filehash))
        #count = context['bls'].count()
        #if count > 0:
        #    context['bls_count'] = count
        context['events'] = Event.objects.filter(Q(info__icontains=filehash)).order_by('-publish_timestamp')
        count = context['events'].count()
        if count > 0:
            context['events_count'] = count
        context['attributes'] = Attribute.objects.filter(Q(value__icontains=filehash)).order_by('-timestamp')
        count = context['attributes'].count()
        if count > 0:
            context['attributes_count'] = count
        context['tws'] = tweet.objects.filter(Q(text__icontains=filehash)).order_by('-datetime')
        count = context['tws'].count()
        if count > 0:
            context['tws_count'] = count
        context['exs'] = Exploit.objects.filter(Q(text__icontains=filehash)).order_by('-datetime')
        count = context['exs'].count()
        if count > 0:
            context['exs_count'] = count

        return context

def getpcap(request, pk):
    response = HttpResponse(VT().getPcap(pk), content_type="application/vnd.tcpdump.pcap")
    response["Content-Disposition"] = "filename=%s.pcap" % pk
    return response


from django import forms

class SearchForm(forms.Form):
    keyword = forms.CharField(label='', max_length=100, required=True)                    
    keyword.widget.attrs['class'] = 'form-control mr-sm-2 my-2'
    keyword.widget.attrs['placeholder'] = 'Lookup IP Address'

from django.http import HttpResponse, HttpResponseRedirect                    
from django.shortcuts import get_object_or_404, render                    
from django.views.generic import TemplateView, DetailView
from .forms import SearchForm
from lib.geoip import GeoIP
from lib.vt import VT
from lib.threatminer import ThreatMiner
import socket
from django.db.models import Q
from apps.threat.models import Event, Attribute
from apps.reputation.models import blacklist
from apps.twitter.models import tweet
from apps.exploit.models import Exploit

class IndexView(TemplateView):
    template_name = 'ip/index.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['search_form'] = SearchForm()
        return context

    def get(self, request, **kwargs):
        if request.GET.get('keyword'):
            ip = request.GET.get('keyword')
            return HttpResponseRedirect(ip)                    
        context = self.get_context_data()
        return self.render_to_response(context)

class DetailView(TemplateView):
    template_name = 'ip/detail.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['search_form'] = SearchForm()
        ip = self.kwargs['pk']
        context['geoip'] = GeoIP().lookup(ip)
        try:
            context['domain'] = socket.gethostbyaddr(ip)[0]
        except Exception as e:
            pass

        vt = VT()
        context['vt_ip'] = vt.getIPReport(ip)

        tm = ThreatMiner()
        context['tm_url'] = tm.getURIFromIP(ip)
        context['tm_sample'] = tm.getSamplesFromIP(ip)
        context['tm_report'] = tm.getReportFromIP(ip)

        context['bls'] = blacklist.objects.filter(Q(ip=ip)|Q(url__contains=ip))
        count = context['bls'].count()
        if count > 0:
            context['bls_count'] = count
        context['events'] = Event.objects.filter(Q(info__icontains=ip)).order_by('-publish_timestamp')
        count = context['events'].count()
        if count > 0:
            context['events_count'] = count
        context['attributes'] = Attribute.objects.filter(Q(value__icontains=ip)).order_by('-timestamp')
        count = context['attributes'].count()
        if count > 0:
            context['attributes_count'] = count
        context['tws'] = tweet.objects.filter(Q(text__icontains=ip)).order_by('-datetime')
        count = context['tws'].count()
        if count > 0:
            context['tws_count'] = count
        context['exs'] = Exploit.objects.filter(Q(text__icontains=ip)).order_by('-datetime')
        count = context['exs'].count()
        if count > 0:
            context['exs_count'] = count

        return context


from django.http import HttpResponse, HttpResponseRedirect                    
from django.shortcuts import get_object_or_404, render                    
from django.views.generic import ListView, DetailView
from pure_pagination.mixins import PaginationMixin
from django.db.models import Q
from .models import Event, Attribute, Org, Tag, Object, ObjectReference
from .forms import EventSearchForm, AttributeSearchForm
from datetime import datetime, timezone, timedelta

class EventListView(PaginationMixin, ListView):
    model = Event
    template_name = 'threat/event_list.html'
    context_object_name = 'events'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['count'] = self.object_list.count()
        context['alltag'] = Tag.objects.order_by('id')
        taglist = self.request.GET.getlist('tag')
        context['tags'] = Tag.objects.filter(id__in=taglist)
        search_form = EventSearchForm(self.request.GET)
        context['search_form'] = search_form
        context['30_day_labels'] = self.thirty_day_labels()
        context['30_day_data'] = self.thirty_day_data()
        return context

    def get_queryset(self):
        query = Event.objects.order_by('-publish_timestamp')
        tag = self.request.GET.get('tag')
        if tag is not None:
            query = query.filter(tags__id=tag)
        org = self.request.GET.get('org')
        if org is not None:
            query = query.filter(orgc=org)
        level = self.request.GET.get('level')
        if level is not None:
            query = query.filter(threat_level_id=level)
        keyword = self.request.GET.get('keyword')
        if keyword is not None:
            query = query.filter(Q(info__icontains=keyword)).order_by('-publish_timestamp')
        return query

    def thirty_day_data(self):
        data = []
        today = datetime.now(timezone(timedelta(hours=+9), 'JST'))
        today = today.replace(hour=0, minute=0, second=0, microsecond=0)
        for day in range(30)[::-1]:
            from_date = today - timedelta(days=day)
            to_date = today - timedelta(days=day-1)
            count = self.object_list.filter(publish_timestamp__gte=from_date, publish_timestamp__lte=to_date).count()
            data.append(count)
        return data

    def thirty_day_labels(self):
        labels = []
        today = datetime.now(timezone(timedelta(hours=+9), 'JST'))
        today = today.replace(hour=0, minute=0, second=0, microsecond=0)
        for day in range(30)[::-1]:
            date = today - timedelta(days=day)
            label = date.strftime('%Y-%m-%d')
            labels.append(label)
        return labels

class EventDetailView(PaginationMixin, ListView):
    model = Attribute
    template_name = 'threat/event_detail.html'
    context_object_name = 'attributes'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        pk = self.kwargs['pk']
        event_obj = Event.objects.get(pk=pk)
        objects_obj = Object.objects.filter(event=pk)
        context = super().get_context_data(**kwargs)
        context['event'] = event_obj
        context['objects'] = objects_obj
        context['categories'] = event_obj.getUniqCategory()
        context['types'] = event_obj.getUniqType()
        context['count'] = self.object_list.count()
        return context

    def get_queryset(self):
        pk = self.kwargs['pk']
        query = Attribute.objects.filter(event=pk).order_by('id')
        category = self.request.GET.get('category')
        type = self.request.GET.get('type')
        if category is not None:
            query = query.filter(category=category)
        if type is not None:
            query = query.filter(type=type)
        return query

class AttributeListView(PaginationMixin, ListView):
    model = Attribute
    template_name = 'threat/attribute_list.html'
    context_object_name = 'attributes'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        attr = Attribute.objects.all()
        context = super().get_context_data(**kwargs)
        context['categories'] = attr.values_list('category', flat=True).order_by('category').distinct()
        context['types'] = attr.values_list('type', flat=True).order_by('type').distinct()
        context['count'] = self.object_list.count()
        search_form = AttributeSearchForm(self.request.GET)
        context['search_form'] = search_form
        #context['30_day_labels'] = self.thirty_day_labels()
        #context['30_day_data'] = self.thirty_day_data()
        return context

    def get_queryset(self):
        query = Attribute.objects.order_by('-timestamp')
        category = self.request.GET.get('category')
        type = self.request.GET.get('type')
        if category is not None:
            query = query.filter(category=category)
        if type is not None:
            query = query.filter(type=type)
        keyword = self.request.GET.get('keyword')
        if keyword is not None:
            query = query.filter(Q(value__icontains=keyword)).order_by('-timestamp')
        return query

    def thirty_day_data(self):
        data = []
        today = datetime.now(timezone(timedelta(hours=+9), 'JST'))
        today = today.replace(hour=0, minute=0, second=0, microsecond=0)
        for day in range(30)[::-1]:
            from_date = today - timedelta(days=day)
            to_date = today - timedelta(days=day-1)
            count = self.object_list.filter(timestamp__gte=from_date, timestamp__lte=to_date).count()
            data.append(count)
        return data

    def thirty_day_labels(self):
        labels = []
        today = datetime.now(timezone(timedelta(hours=+9), 'JST'))
        today = today.replace(hour=0, minute=0, second=0, microsecond=0)
        for day in range(30)[::-1]:
            date = today - timedelta(days=day)
            label = date.strftime('%Y-%m-%d')
            labels.append(label)
        return labels

class OrgListView(ListView):
    model = Org
    template_name = 'threat/org_list.html'
    context_object_name = 'orgs'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        count = self.object_list.count()
        context['count'] = count
        return context

    def get_queryset(self):
        query = Org.objects.order_by('id')
        return query

class TagListView(ListView):
    model = Tag
    template_name = 'threat/tag_list.html'
    context_object_name = 'tags'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        count = self.object_list.count()
        context['count'] = count
        return context

    def get_queryset(self):
        query = Tag.objects.order_by('id')
        return query


from django.http import HttpResponse, HttpResponseRedirect                    
from django.shortcuts import get_object_or_404, render, redirect
from django.views.generic import ListView, DetailView
from django.views.generic.edit import CreateView, UpdateView
from pure_pagination.mixins import PaginationMixin
from django.db.models import Q, Count
from .models import Hunt
from apps.threat.models import Event
from .forms import HuntForm
import csv
from io import StringIO, BytesIO
from codecs import BOM_UTF8
from pytz import timezone
from django.http import JsonResponse
from urllib.parse import urlparse
from http.client import HTTPConnection

class IndexView(PaginationMixin, ListView):
    model = Hunt
    template_name = 'threat_hunter/index.html'
    context_object_name = 'hunts'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        return context

    def get_queryset(self):
        query = Hunt.objects.order_by('id')
        query = query.annotate(count=Count('events'))
        return query

class EventListView(PaginationMixin, ListView):
    model = Event
    template_name = 'threat_hunter/event_list.html'
    context_object_name = 'events'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        return context

    def get_queryset(self, request, pk):
        pk = self.kwargs['pk']
        query = Event.objects.filter(Q(id__in=Hunt(id=pk).events.all())).order_by('-publish_timestamp')
        return query

    def get(self, request, pk):
        self.object_list = self.get_queryset(request, pk)
        context = self.get_context_data()
        return render(request, 'threat_hunter/event_list.html', context)

class HuntCreateView(CreateView):
    model = Hunt
    form_class = HuntForm
    template_name = 'threat_hunter/hunt_form.html'

    def get_success_url(self):
        self.object.run()
        return '/threat_hunter'
        
class HuntUpdateView(UpdateView):
    model = Hunt
    form_class = HuntForm
    template_name = 'threat_hunter/hunt_edit_form.html'

    def get_success_url(self):
        self.object.run()
        return '/threat_hunter'

def hunt_del(request, pk):
    hunt = get_object_or_404(Hunt, id=pk)
    hunt.delete()
    return redirect('threat_hunter:index')

def hunt_export(request, pk):
    stream = StringIO()
    writer = csv.writer(stream)
    header = ['#published', 'date', 'info', 'level', 'attribute_count', 'org']
    writer.writerow(header)
    for event in Event.objects.filter(id__in=Hunt(id=pk).events.all()).order_by('publish_timestamp'):
        dt = event.publish_timestamp.astimezone(timezone('Asia/Tokyo'))
        row = [dt, event.date, event.info, event.get_threat_level_id_display(), event.attribute_count, event.org.name]
        writer.writerow(row)
    b_stream = BytesIO(BOM_UTF8 + stream.getvalue().encode('utf8'))
    response = HttpResponse(b_stream.getvalue(), content_type="text/csv")
    response["Content-Disposition"] = "filename=hunter%s.csv" % pk
    return response

def hunt_switch_notice(request, pk):
    hunt = get_object_or_404(Hunt, id=pk)
    if hunt.notice == True:
        hunt.setNoticeFalse()
    else:
        hunt.setNoticeTrue()
    hunt.run()
    return redirect('threat_hunter:index')

def hunt_switch_enable(request, pk):
    hunt = get_object_or_404(Hunt, id=pk)
    if hunt.enable == True:
        hunt.setDisable()
    else:
        hunt.setEnable()
        hunt.run()
    return redirect('threat_hunter:index')


from django.http import HttpResponse, HttpResponseRedirect                    
from django.shortcuts import get_object_or_404, render                    
from django.views.generic import ListView, DetailView
from pure_pagination.mixins import PaginationMixin
from django.db.models import Q
from .models import tweet
from .forms import SearchForm
from django.http import JsonResponse
from urllib.parse import urlparse
from http.client import HTTPSConnection
from datetime import datetime, timezone, timedelta

class IndexView(PaginationMixin, ListView):
    template_name = 'twitter/index.html'
    context_object_name = 'tws'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        search_form = SearchForm(self.request.GET)
        context['search_form'] = search_form
        count = self.object_list.count()
        context['count'] = count
        context['30_day_labels'] = self.thirty_day_labels()
        context['30_day_data'] = self.thirty_day_data()
        return context

    def get_queryset(self):
        query = tweet.objects.order_by('-datetime')
        keyword = self.request.GET.get('keyword')
        if keyword is not None:
            query = query.filter(Q(text__icontains=keyword)).order_by('-datetime')
        return query

#    def post(self, request):
#        search_form = SearchForm(request.POST)
#        if not search_form.is_valid():
#            return HttpResponseRedirect('/')
#        self.object_list = self.get_queryset()
#        context = self.get_context_data()
#        context['search_form'] = search_form
#        return render(request, 'twitter/index.html', context)

    def thirty_day_data(self):
        data = []
        today = datetime.now(timezone(timedelta(hours=+9), 'JST'))
        today = today.replace(hour=0, minute=0, second=0, microsecond=0)
        for day in range(30)[::-1]:
            from_date = today - timedelta(days=day)
            to_date = today - timedelta(days=day-1)
            count = self.object_list.filter(datetime__gte=from_date, datetime__lte=to_date).count()
            data.append(count)
        return data

    def thirty_day_labels(self):
        labels = []
        today = datetime.now(timezone(timedelta(hours=+9), 'JST'))
        today = today.replace(hour=0, minute=0, second=0, microsecond=0)
        for day in range(30)[::-1]:
            date = today - timedelta(days=day)
            label = date.strftime('%Y-%m-%d')
            labels.append(label)
        return labels

def expand_url(request):
    url = request.GET.get('url', None)
    exurl = expand(url)
    while exurl != url:
        url = exurl
        exurl = expand(url)
    return JsonResponse({'url': exurl})

def expand(url):
    o = urlparse(url)
    con = HTTPSConnection(o.netloc)
    con.request('HEAD', o.path)
    res = con.getresponse()
    if res.getheader('location') == None:
        return url
    return res.getheader('location')

from django.http import HttpResponse, HttpResponseRedirect                    
from django.shortcuts import get_object_or_404, render, redirect
from django.views.generic import ListView, DetailView
from django.views.generic.edit import CreateView, UpdateView
from pure_pagination.mixins import PaginationMixin
from django.db.models import Q, Count
from .models import tweet, Hunt
from .forms import HuntForm
import csv
from io import StringIO, BytesIO
from codecs import BOM_UTF8
from pytz import timezone
from django.http import JsonResponse
from urllib.parse import urlparse
from http.client import HTTPSConnection

class IndexView(PaginationMixin, ListView):
    template_name = 'twitter_hunter/index.html'
    context_object_name = 'hts'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        return context

    def get_queryset(self, request):
        query = Hunt.objects.order_by('id')
        query = query.annotate(count=Count('tweet'))
        return query

    def get(self, request):
        self.object_list = self.get_queryset(request)
        context = self.get_context_data()
        return render(request, 'twitter_hunter/index.html', context)

class TweetsView(PaginationMixin, ListView):
    template_name = 'twitter_hunter/tweets.html'
    context_object_name = 'tws'
    paginate_by = 30

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        return context

    def get_queryset(self, request, pk):
        query = tweet.objects.filter(hunt_id=Hunt(id=pk)).order_by('-datetime')
        return query

    def get(self, request, pk):
        self.object_list = self.get_queryset(request, pk)
        context = self.get_context_data()
        return render(request, 'twitter_hunter/tweets.html', context)

#def hunt_add(request):
#    hunt = Hunt()
#    if request.method == 'POST':
#        form = HuntForm(request.POST, instance=hunt)
#        if form.is_valid():
#            hunt = form.save(commit=False)
#            hunt.save()
#            hunt.start()
#            return redirect('twitter_hunter:index')
#    else:
#        form = HuntForm(instance=hunt)
#    return render(request, 'twitter_hunter/hunt_edit.html', dict(form=form))

class HuntCreateView(CreateView):
    model = Hunt
    form_class = HuntForm
    template_name = 'twitter_hunter/hunt_form.html'

    def get_success_url(self):
        self.object.start()
        return '/twitter_hunter'

class HuntUpdateView(UpdateView):
    model = Hunt
    form_class = HuntForm
    template_name = 'twitter_hunter/hunt_edit_form.html'

    def get_success_url(self):
        self.object.restart()
        return '/twitter_hunter'

def hunt_del(request, pk):
    hunt = get_object_or_404(Hunt, id=pk)
    hunt.stop()
    hunt.delete()
    return redirect('twitter_hunter:index')

def hunt_export(request, pk):
    stream = StringIO()
    writer = csv.writer(stream)
    header = ['#datetime', 'user', 'screen_name', 'text']
    writer.writerow(header)
    for tw in tweet.objects.filter(hunt_id=Hunt(id=pk)).order_by('datetime'):
        dt = tw.datetime.astimezone(timezone('Asia/Tokyo'))
        row = [dt, tw.user, tw.screen_name, tw.text]
        writer.writerow(row)
    b_stream = BytesIO(BOM_UTF8 + stream.getvalue().encode('utf8'))
    response = HttpResponse(b_stream.getvalue(), content_type="text/csv")
    response["Content-Disposition"] = "filename=hunter%s.csv" % pk
    return response

def hunt_switch_notice(request, pk):
    hunt = get_object_or_404(Hunt, id=pk)
    hunt.stop()
    if hunt.notice == True:
        hunt.setNoticeFalse()
    else:
        hunt.setNoticeTrue()
    hunt.start()
    return redirect('twitter_hunter:index')

def hunt_switch_enable(request, pk):
    hunt = get_object_or_404(Hunt, id=pk)
    if hunt.enable == True:
        hunt.setDisable()
        hunt.stop()
    else:
        hunt.setEnable()
        hunt.start()
    return redirect('twitter_hunter:index')

def expand_url(request):
    url = request.GET.get('url', None)
    exurl = expand(url)
    while exurl != url:
        url = exurl
        exurl = expand(url)
    return JsonResponse({'url': exurl})

def expand(url):
    o = urlparse(url)
    con = HTTPSConnection(o.netloc)
    con.request('HEAD', o.path)
    res = con.getresponse()
    if res.getheader('location') == None:
        return url
    return res.getheader('location')


from django import forms

class SearchForm(forms.Form):
    keyword = forms.CharField(label='', max_length=100, required=True)                    
    keyword.widget.attrs['class'] = 'form-control mr-sm-2 my-2'
    keyword.widget.attrs['placeholder'] = 'Lookup URL'

import os
import subprocess


def test_serverextensions():
    """
    Validate serverextensions we want are installed
    """
    # jupyter-serverextension writes to stdout and stderr weirdly
    proc = subprocess.run([
        '/opt/tljh/user/bin/jupyter-serverextension',
        'list', '--sys-prefix'
    ], stderr=subprocess.PIPE)

    extensions = [
        'jupyterlab 0.35.3',                    
        'nbgitpuller 0.6.1',
        'nteract_on_jupyter 1.9.12',                    
        'nbresuse '
    ]

    for e in extensions:
        assert '{} \x1b[32mOK\x1b[0m'.format(e) in proc.stderr.decode()

def test_nbextensions():
    """
    Validate nbextensions we want are installed & enabled
    """
    # jupyter-nbextension writes to stdout and stderr weirdly
    proc = subprocess.run([
        '/opt/tljh/user/bin/jupyter-nbextension',
        'list', '--sys-prefix'
    ], stderr=subprocess.PIPE, stdout=subprocess.PIPE)

    extensions = [
        'nbresuse/main',
        # This is what ipywidgets nbextension is called
        'jupyter-js-widgets/extension'
    ]

    for e in extensions:
        assert '{} \x1b[32m enabled \x1b[0m'.format(e) in proc.stdout.decode()

    # Ensure we have 'OK' messages in our stdout, to make sure everything is importable
    assert proc.stderr.decode() == '      - Validating: \x1b[32mOK\x1b[0m\n' * len(extensions)


def test_labextensions():
    """
    Validate labextensions we want installed
    """
    # Currently we only install jupyterhub
    assert os.path.exists('/opt/tljh/user/bin/jupyter-labhub')

"""Installation logic for TLJH"""

import argparse
import itertools
import logging
import os
import secrets
import subprocess
import sys
import time
from urllib.error import HTTPError
from urllib.request import urlopen, URLError

import pluggy

from tljh import (
    apt,
    conda,
    hooks,
    migrator,
    systemd,
    traefik,
    user,
)
from .config import (
    CONFIG_DIR,
    CONFIG_FILE,
    HUB_ENV_PREFIX,
    INSTALL_PREFIX,
    STATE_DIR,
    USER_ENV_PREFIX,
)
from .yaml import yaml

HERE = os.path.abspath(os.path.dirname(__file__))


logger = logging.getLogger("tljh")

def ensure_node():
    """
    Ensure nodejs from nodesource is installed
    """
    key = b"""
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: GnuPG v1
Comment: GPGTools - https://gpgtools.org
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==
=CLGF
-----END PGP PUBLIC KEY BLOCK-----
    """.strip()
    apt.trust_gpg_key(key)
    apt.add_source('nodesource', 'https://deb.nodesource.com/node_10.x', 'main')
    apt.install_packages(['nodejs'])

def remove_chp():
    """
    Ensure CHP is not running
    """
    if os.path.exists("/etc/systemd/system/configurable-http-proxy.service"):
        if systemd.check_service_active('configurable-http-proxy.service'):
            try:
                systemd.stop_service('configurable-http-proxy.service')
            except subprocess.CalledProcessError:
                logger.info("Cannot stop configurable-http-proxy...")
        if systemd.check_service_enabled('configurable-http-proxy.service'):
            try:
                systemd.disable_service('configurable-http-proxy.service')
            except subprocess.CalledProcessError:
                logger.info("Cannot disable configurable-http-proxy...")
        try:
            systemd.uninstall_unit('configurable-http-proxy.service')
        except subprocess.CalledProcessError:
            logger.info("Cannot uninstall configurable-http-proxy...")


def ensure_jupyterhub_service(prefix):
    """
    Ensure JupyterHub Services are set up properly
    """

    os.makedirs(STATE_DIR, mode=0o700, exist_ok=True)

    remove_chp()
    systemd.reload_daemon()

    with open(os.path.join(HERE, 'systemd-units', 'jupyterhub.service')) as f:
        hub_unit_template = f.read()


    with open(os.path.join(HERE, 'systemd-units', 'traefik.service')) as f:
        traefik_unit_template = f.read()

    #Set up proxy / hub secret token if it is not already setup
    proxy_secret_path = os.path.join(STATE_DIR, 'traefik-api.secret')
    if not os.path.exists(proxy_secret_path):
        with open(proxy_secret_path, 'w') as f:
            f.write(secrets.token_hex(32))

    traefik.ensure_traefik_config(STATE_DIR)

    unit_params = dict(
        python_interpreter_path=sys.executable,
        jupyterhub_config_path=os.path.join(HERE, 'jupyterhub_config.py'),
        install_prefix=INSTALL_PREFIX,
    )
    systemd.install_unit('jupyterhub.service', hub_unit_template.format(**unit_params))
    systemd.install_unit('traefik.service', traefik_unit_template.format(**unit_params))
    systemd.reload_daemon()

    # If JupyterHub is running, we want to restart it.
    systemd.restart_service('jupyterhub')
    systemd.restart_service('traefik')

    # Mark JupyterHub & traefik to start at boot time
    systemd.enable_service('jupyterhub')
    systemd.enable_service('traefik')


def ensure_jupyterlab_extensions():
    """
    Install the JupyterLab extensions we want.
    """
    extensions = [
        '@jupyterlab/hub-extension',
        '@jupyter-widgets/jupyterlab-manager'
    ]
    subprocess.check_output([
        os.path.join(USER_ENV_PREFIX, 'bin/jupyter'),
        'labextension',
        'install'
    ] + extensions)


def ensure_jupyterhub_package(prefix):
    """
    Install JupyterHub into our conda environment if needed.

    We install all python packages from PyPI as much as possible in the
    hub environment. A lot of spawners & authenticators do not have conda-forge
    packages, but do have pip packages. Keeping all python packages in the
    hub environment be installed with pip prevents accidental mixing of python
    and conda packages!
    """
    conda.ensure_pip_packages(prefix, [
        'jupyterhub==0.9.4',                    
        'jupyterhub-dummyauthenticator==0.3.1',
        'jupyterhub-systemdspawner==0.11',
        'jupyterhub-firstuseauthenticator==0.12',
        'jupyterhub-nativeauthenticator==0.0.4',
        'jupyterhub-ldapauthenticator==1.2.2',
        'oauthenticator==0.8.0'                    
    ])
    traefik.ensure_traefik_binary(prefix)


def ensure_usergroups():
    """
    Sets up user groups & sudo rules
    """
    user.ensure_group('jupyterhub-admins')
    user.ensure_group('jupyterhub-users')

    logger.info("Granting passwordless sudo to JupyterHub admins...")
    with open('/etc/sudoers.d/jupyterhub-admins', 'w') as f:
        # JupyterHub admins should have full passwordless sudo access
        f.write('%jupyterhub-admins ALL = (ALL) NOPASSWD: ALL\n')
        # `sudo -E` should preserve the $PATH we set. This allows
        # admins in jupyter terminals to do `sudo -E pip install <package>`,
        # `pip` is in the $PATH we set in jupyterhub_config.py to include the user conda env.
        f.write('Defaults exempt_group = jupyterhub-admins\n')


def ensure_user_environment(user_requirements_txt_file):
    """
    Set up user conda environment with required packages
    """
    logger.info("Setting up user environment...")
    miniconda_version = '4.5.4'
    miniconda_installer_md5 = "a946ea1d0c4a642ddf0c3a26a18bb16d"

    if not conda.check_miniconda_version(USER_ENV_PREFIX, miniconda_version):
        logger.info('Downloading & setting up user environment...')
        with conda.download_miniconda_installer(miniconda_version, miniconda_installer_md5) as installer_path:
            conda.install_miniconda(installer_path, USER_ENV_PREFIX)

    # nbresuse needs psutil, which requires gcc
    apt.install_packages([
        'gcc'
    ])

    conda.ensure_conda_packages(USER_ENV_PREFIX, [
        # Conda's latest version is on conda much more so than on PyPI.
        'conda==4.5.8'
    ])

    conda.ensure_pip_packages(USER_ENV_PREFIX, [
        # JupyterHub + notebook package are base requirements for user environment
        'jupyterhub==0.9.4',                    
        'notebook==5.7.0',                    
        # Install additional notebook frontends!
        'jupyterlab==0.35.3',                    
        'nteract-on-jupyter==1.9.12',                    
        # nbgitpuller for easily pulling in Git repositories
        'nbgitpuller==0.6.1',
        # nbresuse to show people how much RAM they are using
        'nbresuse==0.3.0',
        # Most people consider ipywidgets to be part of the core notebook experience
        'ipywidgets==7.4.2',
        # Pin tornado
        'tornado<6.0'
    ])

    if user_requirements_txt_file:
        # FIXME: This currently fails hard, should fail soft and not abort installer
        conda.ensure_pip_requirements(USER_ENV_PREFIX, user_requirements_txt_file)


def ensure_admins(admins):
    """
    Setup given list of users as admins.
    """
    if not admins:
        return
    logger.info("Setting up admin users")
    config_path = CONFIG_FILE
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            config = yaml.load(f)
    else:
        config = {}

    config['users'] = config.get('users', {})
    config['users']['admin'] = list(admins)

    with open(config_path, 'w+') as f:
        yaml.dump(config, f)


def ensure_jupyterhub_running(times=20):
    """
    Ensure that JupyterHub is up and running

    Loops given number of times, waiting a second each.
    """

    for i in range(times):
        try:
            logger.info('Waiting for JupyterHub to come up ({}/{} tries)'.format(i + 1, times))
            urlopen('http://127.0.0.1')
            return
        except HTTPError as h:
            if h.code in [404, 502, 503]:
                # May be transient
                time.sleep(1)
                continue
            # Everything else should immediately abort
            raise
        except URLError as e:
            if isinstance(e.reason, ConnectionRefusedError):
                # Hub isn't up yet, sleep & loop
                time.sleep(1)
                continue
            # Everything else should immediately abort
            raise

    raise Exception("Installation failed: JupyterHub did not start in {}s".format(times))


def ensure_symlinks(prefix):
    """
    Ensure we symlink appropriate things into /usr/bin

    We add the user conda environment to PATH for notebook terminals,
    but not the hub venv. This means tljh-config is not actually accessible.

    We symlink to /usr/bin and not /usr/local/bin, since /usr/local/bin is
    not place, and works with sudo -E in sudo's search $PATH. We can work
    around this with sudo -E and extra entries in the sudoers file, but this
    is far more secure at the cost of upsetting some FHS purists.
    """
    tljh_config_src = os.path.join(prefix, 'bin', 'tljh-config')
    tljh_config_dest = '/usr/bin/tljh-config'
    if os.path.exists(tljh_config_dest):
        if os.path.realpath(tljh_config_dest) != tljh_config_src:
            #  tljh-config exists that isn't ours. We should *not* delete this file,
            # instead we throw an error and abort. Deleting files owned by other people
            # while running as root is dangerous, especially with symlinks involved.
            raise FileExistsError(f'/usr/bin/tljh-config exists but is not a symlink to {tljh_config_src}')
        else:
            # We have a working symlink, so do nothing
            return
    os.symlink(tljh_config_src, tljh_config_dest)


def setup_plugins(plugins=None):
    """
    Install plugins & setup a pluginmanager
    """
    # Install plugins
    if plugins:
        conda.ensure_pip_packages(HUB_ENV_PREFIX, plugins)

    # Set up plugin infrastructure
    pm = pluggy.PluginManager('tljh')
    pm.add_hookspecs(hooks)
    pm.load_setuptools_entrypoints('tljh')

    return pm


def run_plugin_actions(plugin_manager, plugins):
    """
    Run installer hooks defined in plugins
    """
    hook = plugin_manager.hook
    # Install apt packages
    apt_packages = list(set(itertools.chain(*hook.tljh_extra_apt_packages())))
    if apt_packages:
        logger.info('Installing {} apt packages collected from plugins: {}'.format(
            len(apt_packages), ' '.join(apt_packages)
        ))
        apt.install_packages(apt_packages)

    # Install conda packages
    conda_packages = list(set(itertools.chain(*hook.tljh_extra_user_conda_packages())))
    if conda_packages:
        logger.info('Installing {} conda packages collected from plugins: {}'.format(
            len(conda_packages), ' '.join(conda_packages)
        ))
        conda.ensure_conda_packages(USER_ENV_PREFIX, conda_packages)

    # Install pip packages
    pip_packages = list(set(itertools.chain(*hook.tljh_extra_user_pip_packages())))
    if pip_packages:
        logger.info('Installing {} pip packages collected from plugins: {}'.format(
            len(pip_packages), ' '.join(pip_packages)
        ))
        conda.ensure_pip_packages(USER_ENV_PREFIX, pip_packages)


def ensure_config_yaml(plugin_manager):
    """
    Ensure we have a config.yaml present
    """
    # ensure config dir exists and is private
    for path in [CONFIG_DIR, os.path.join(CONFIG_DIR, 'jupyterhub_config.d')]:
        os.makedirs(path, mode=0o700, exist_ok=True)

    migrator.migrate_config_files()

    if os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, 'r') as f:
            config = yaml.load(f)
    else:
        config = {}

    hook = plugin_manager.hook
    hook.tljh_config_post_install(config=config)

    with open(CONFIG_FILE, 'w+') as f:
        yaml.dump(config, f)


def main():
    from .log import init_logging
    init_logging()

    argparser = argparse.ArgumentParser()
    argparser.add_argument(
        '--admin',
        nargs='*',
        help='List of usernames set to be admin'
    )
    argparser.add_argument(
        '--user-requirements-txt-url',
        help='URL to a requirements.txt file that should be installed in the user enviornment'
    )
    argparser.add_argument(
        '--plugin',
        nargs='*',
        help='Plugin pip-specs to install'
    )

    args = argparser.parse_args()

    pm = setup_plugins(args.plugin)

    ensure_config_yaml(pm)
    ensure_admins(args.admin)
    ensure_usergroups()
    ensure_user_environment(args.user_requirements_txt_url)

    logger.info("Setting up JupyterHub...")
    ensure_node()
    ensure_jupyterhub_package(HUB_ENV_PREFIX)
    ensure_jupyterlab_extensions()
    ensure_jupyterhub_service(HUB_ENV_PREFIX)
    ensure_jupyterhub_running()
    ensure_symlinks(HUB_ENV_PREFIX)

    # Run installer plugins last
    run_plugin_actions(pm, args.plugin)

    logger.info("Done!")


if __name__ == '__main__':
    main()

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
from __future__ import unicode_literals

import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.six.moves.urllib.parse import unquote
from django.utils.translation import ugettext as _, ugettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(unquote(path))                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = ugettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
from __future__ import unicode_literals

import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.six.moves.urllib.parse import unquote
from django.utils.translation import ugettext as _, ugettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(unquote(path))                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = ugettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

"""
Views and functions for serving static files. These are only to be used
during development, and SHOULD NOT be used in a production setting.
"""
from __future__ import unicode_literals

import mimetypes
import os
import posixpath
import re
import stat

from django.http import (
    FileResponse, Http404, HttpResponse, HttpResponseNotModified,
    HttpResponseRedirect,                    
)
from django.template import Context, Engine, TemplateDoesNotExist, loader
from django.utils.http import http_date, parse_http_date
from django.utils.six.moves.urllib.parse import unquote
from django.utils.translation import ugettext as _, ugettext_lazy


def serve(request, path, document_root=None, show_indexes=False):
    """
    Serve static files below a given point in the directory structure.

    To use, put a URL pattern such as::

        from django.views.static import serve

        url(r'^(?P<path>.*)$', serve, {'document_root': '/path/to/my/files/'})

    in your URLconf. You must provide the ``document_root`` param. You may
    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index
    of the directory.  This index view will use the template hardcoded below,
    but if you'd like to override it, you can create a template called
    ``static/directory_index.html``.
    """
    path = posixpath.normpath(unquote(path))                    
    path = path.lstrip('/')                    
    newpath = ''                    
    for part in path.split('/'):                    
        if not part:                    
            # Strip empty path components.
            continue                    
        drive, part = os.path.splitdrive(part)                    
        head, part = os.path.split(part)                    
        if part in (os.curdir, os.pardir):                    
            # Strip '.' and '..' in path.
            continue                    
        newpath = os.path.join(newpath, part).replace('\\', '/')                    
    if newpath and path != newpath:                    
        return HttpResponseRedirect(newpath)                    
    fullpath = os.path.join(document_root, newpath)                    
    if os.path.isdir(fullpath):
        if show_indexes:
            return directory_index(newpath, fullpath)                    
        raise Http404(_("Directory indexes are not allowed here."))
    if not os.path.exists(fullpath):
        raise Http404(_('"%(path)s" does not exist') % {'path': fullpath})
    # Respect the If-Modified-Since header.
    statobj = os.stat(fullpath)
    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),
                              statobj.st_mtime, statobj.st_size):
        return HttpResponseNotModified()
    content_type, encoding = mimetypes.guess_type(fullpath)
    content_type = content_type or 'application/octet-stream'
    response = FileResponse(open(fullpath, 'rb'), content_type=content_type)
    response["Last-Modified"] = http_date(statobj.st_mtime)
    if stat.S_ISREG(statobj.st_mode):
        response["Content-Length"] = statobj.st_size
    if encoding:
        response["Content-Encoding"] = encoding
    return response


DEFAULT_DIRECTORY_INDEX_TEMPLATE = """
{% load i18n %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="Content-Language" content="en-us" />
    <meta name="robots" content="NONE,NOARCHIVE" />
    <title>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</title>
  </head>
  <body>
    <h1>{% blocktrans %}Index of {{ directory }}{% endblocktrans %}</h1>
    <ul>
      {% if directory != "/" %}
      <li><a href="../">../</a></li>
      {% endif %}
      {% for f in file_list %}
      <li><a href="{{ f|urlencode }}">{{ f }}</a></li>
      {% endfor %}
    </ul>
  </body>
</html>
"""
template_translatable = ugettext_lazy("Index of %(directory)s")


def directory_index(path, fullpath):
    try:
        t = loader.select_template([
            'static/directory_index.html',
            'static/directory_index',
        ])
    except TemplateDoesNotExist:
        t = Engine(libraries={'i18n': 'django.templatetags.i18n'}).from_string(DEFAULT_DIRECTORY_INDEX_TEMPLATE)
    files = []
    for f in os.listdir(fullpath):
        if not f.startswith('.'):
            if os.path.isdir(os.path.join(fullpath, f)):
                f += '/'
            files.append(f)
    c = Context({
        'directory': path + '/',
        'file_list': files,
    })
    return HttpResponse(t.render(c))


def was_modified_since(header=None, mtime=0, size=0):
    """
    Was something modified since the user last downloaded it?

    header
      This is the value of the If-Modified-Since header.  If this is None,
      I'll just return True.

    mtime
      This is the modification time of the item we're talking about.

    size
      This is the size of the item we're talking about.
    """
    try:
        if header is None:
            raise ValueError
        matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                           re.IGNORECASE)
        header_mtime = parse_http_date(matches.group(1))
        header_len = matches.group(3)
        if header_len and int(header_len) != size:
            raise ValueError
        if int(mtime) > header_mtime:
            raise ValueError
    except (AttributeError, ValueError, OverflowError):
        return True
    return False

from __future__ import absolute_import
from engineauth import models
from engineauth import utils
from engineauth.config import load_config
import re
from webob import Response
from webob import Request

class EngineAuthResponse(Response):

    def _save_session(self):
        session = self.request.session
        # Compare the hash that we set in load_session to the current one.
        # We only save the session and cookie if this value has changed.
        if self.request.session_hash == session.hash():
            return session
        session.put()
        # If we have a user_id we want to updated the
        # session to use the user_id as the key.
        if session.user_id is not None:
            session_id = session.key.id()
            if session_id != session.user_id:
                session = models.Session.upgrade_to_user_session(
                    session_id, session.user_id)
        self.set_cookie('_eauth', session.serialize())
        return self

    def _save_user(self):
        pass


class EngineAuthRequest(Request):

    ResponseClass = EngineAuthResponse

    def _load_session(self):
        value = self.cookies.get('_eauth')
        session = None
        if value:
            session = models.Session.get_by_value(value)
        if session is not None:
            # Create a hash for later comparison,
            # to determine if a put() is required
            session_hash = session.hash()
        else:
            session = models.Session.create()
            # set this to False to ensure a cookie
            # is saved later in the response.
            session_hash = '0'
        self.session = session
        self.session_hash = session_hash
        return self

    def _get_user_class(self):
        try:
            return utils.import_class(self._config['user_model'])
        except Exception:
            return models.User

    def _load_user(self):
        if self.session is not None and self.session.user_id:
            self.user = self._get_user_class().get_by_id(int(self.session.user_id))
            if self.user is None:
                # TODO: If the user_id from the session returns no user,
                # then remove it.
                pass
        else:
            self.user = None
        return self

    def _load_user_by_profile(self, profile):
        # if the user is logged in update that user with the profile details
        if self.user:
            self.user.add_profile(profile)
        # else get or create a user based on the profile
        else:
            self.user = self._get_user_class().get_or_create_by_profile(profile)
        # Add user to session
        self.session.user_id = self.user.get_id()
    load_user_by_profile = _load_user_by_profile

    def _add_message(self, message, level=None, key='_messages'):
        if not self.session.data.get(key):
            self.session.data[key] = []
        return self.session.data[key].append({
            'message': message, 'level': level})
    add_message = _add_message

    def _get_messages(self, key='_messages'):
        try:
            return self.session.data.pop(key)
        except KeyError:
            pass
    get_messages = _get_messages

    def _set_redirect_uri(self):                    
        next_uri = self.GET.get('next')                    
        if next_uri is not None:                    
            self.session.data['_redirect_uri'] = next_uri                    
    set_redirect_uri = _set_redirect_uri                    

    def _get_redirect_uri(self):
        try:
            return self.session.data.pop('_redirect_uri').encode('utf-8')
        except KeyError:
            return self._config['success_uri']
    get_redirect_uri = _get_redirect_uri

    def _set_globals(self, environ):
#        environ['ea.config'] = req.config
        environ['ea.session'] = self.session
        environ['ea.user'] = self.user


class AuthMiddleware(object):
    def __init__(self, app, config=None):
        self.app = app
        self._config = load_config(config)
        self._url_parse_re = re.compile(r'%s/([^\s/]+)/*(\S*)' %
                                        (self._config['base_uri']))

    def __call__(self, environ, start_response):
        # If the request is to the admin, return
        if environ['PATH_INFO'].startswith('/_ah/'):
            return self.app(environ, start_response)
        # load session
        req = EngineAuthRequest(environ)
        req._config = self._config
        req._load_session()
        req._load_user()
        req._set_redirect_uri()                    
        resp = None
        # If the requesting url is for engineauth load the strategy
        if environ['PATH_INFO'].startswith(self._config['base_uri']):
            # extract provider and additional params from the url
            provider, provider_params = self._url_parse_re.match(
                req.path_info).group(1, 2)
            if provider:
                req.provider = provider
                req.provider_params = provider_params
                # load the desired strategy class
                strategy_class = self._load_strategy(provider)
                resp = req.get_response(strategy_class(self.app, self._config))
                if resp.request is None:
                    # TODO: determine why this is necessary.
                    resp.request = req
        if resp is None:
            resp = req.get_response(self.app)
        # Save session, return response
        resp._save_session()
        return resp(environ, start_response)

    def _load_strategy(self, provider):
        try:
            strategy_location = self._config[
                                'provider.{0}'.format(provider)]['class_path']
            return utils.import_class(strategy_location)
        except Exception, e:
            raise(Exception, "You must provide a location for the {0} "\
                             "strategy. Add a 'location' key to the "\
                             "'provider.{0}' config dict".format(provider))


from engineauth.middleware import AuthMiddleware
from engineauth.middleware import EngineAuthRequest
from engineauth import models
import test_base
import webapp2

__author__ = 'kyle.finley@gmail.com (Kyle Finley)'


app = AuthMiddleware(webapp2.WSGIApplication())

class TestAuthMiddleware(test_base.BaseTestCase):
    def setUp(self):
        super(TestAuthMiddleware, self).setUp()

    #    def test_load_config(self):
    #        req = EngineAuthRequest.blank('/auth/google')                    
    #        resp = req.get_response(app)
    #        self.assertEqual(resp, '/auth')

    def test_load_strategy(self):
        from engineauth.strategies.google import GoogleStrategy

        strategy_class = app._load_strategy('google')
        self.assertEqual(strategy_class, GoogleStrategy)
        self.assertRaises(Exception, app._load_strategy, 'enron')
        from engineauth.strategies.appengine_openid import\
            AppEngineOpenIDStrategy
        strategy_class = app._load_strategy('appengine_openid')
        self.assertEqual(strategy_class, AppEngineOpenIDStrategy)

    def test_load_session_no_session(self):
        req = EngineAuthRequest.blank('/auth/google')                    
        # No Session
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 0)
        sess = req._load_session()
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 1)

    def test_laod_session_session_id_no_user_id(self):
        # Cookie session_id but no user_id
        s = models.Session.create()
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 1)
        req = EngineAuthRequest.blank('/auth/google')                    
        req.cookies['_eauth'] = s.serialize()
        req._load_session()
        self.assertTrue(req.session.session_id == s.session_id)
        # Assert No new session was created
        s_count2 = models.Session.query().count()
        self.assertTrue(s_count2 == 1)

    def test_laod_session_session_id_and_user_id(self):
        # Cookie session_id and user_id
        s = models.Session.create()
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 1)
        req = EngineAuthRequest.blank('/auth/google')                    
        req.cookies['_eauth'] = s.serialize()
        req._load_session()
        self.assertTrue(req.session.session_id == s.session_id)
        # Assert No new session was created
        s_count2 = models.Session.query().count()
        self.assertTrue(s_count2 == 1)


    def test_laod_session_cookie_and_no_session(self):
        # Cookie and not session
        s = models.Session.create()
        old_sid = s.session_id
        s_serialized = s.serialize()
        s.key.delete()
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 0)
        req = EngineAuthRequest.blank('/auth/google')                    
        req.cookies['_eauth'] = s_serialized
        req._load_session()
        # Assert that a new session was created
        self.assertTrue(req.session.session_id != old_sid)
        # Assert No new session was created
        s_count2 = models.Session.query().count()
        self.assertTrue(s_count2 == 1)

    def test_save_session(self):
        # Cookie session_id but no user_id
        s = models.Session.create()
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 1)

        req = EngineAuthRequest.blank('/auth/google')                    
        req.cookies['_eauth'] = s.serialize()
        resp = req.get_response(app)
        resp.request = req
        resp._save_session()

        self.assertTrue(resp.request.session.session_id == s.session_id)
        # Assert No new session was created
        s_count2 = models.Session.query().count()
        self.assertTrue(s_count2 == 1)

        # Add a user_id to session
        resp.request.session.user_id = '1'
        resp._save_session()
        # a new session should be created with the user_id as it's id
#        self.assertEqual(resp.request.session.key.id(), '1')
        s_count = models.Session.query().count()
        self.assertTrue(s_count == 1)
        s1 = models.Session.query().get()
        self.assertEqual(s1.key.id(), '1')

    def test__load_user(self):
        user = models.User.create_user('test:12345')
        req = EngineAuthRequest.blank('/auth/google')                    
        req._load_session()
        req.session.user_id = user.get_id()
        req._load_user()
        self.assertEqual(user, req.user)

    def test__load_user_by_profile(self):
        # No existing User no logged in User
        auth_id = 'test:12345'
        user_info = {
            'auth_id': auth_id,
            'info': {},
        }
        # create profile
        p = models.UserProfile.get_or_create(auth_id, user_info)
        req = EngineAuthRequest.blank('/auth/google')                    
        req._load_session()
        req._load_user()

        # User Count before
        user_count = models.User.query().count()
        self.assertEqual(user_count, 0)

        req.load_user_by_profile(p)

        # User Count after
        user_count = models.User.query().count()
        self.assertEqual(user_count, 1)

        user = models.User.query().get()
        self.assertTrue(p.key.id() in user.auth_ids)

        # Yes existing User no logged in User
        req = EngineAuthRequest.blank('/auth/google')                    
        req._load_session()
        req._load_user()

        req.load_user_by_profile(p)

        # Test to no new User was created
        user_count = models.User.query().count()
        self.assertEqual(user_count, 1)

        # Yes existing User yes logged in User new Profile
        auth_id = 'test:abc'
        user_info = {
            'auth_id': auth_id,
            'info': {},
            }
        # create profile
        p1 = models.UserProfile.get_or_create(auth_id, user_info)
        req.load_user_by_profile(p1)

        # Test to no new User was created
        user_count = models.User.query().count()
        self.assertEqual(user_count, 1)

    def test_add_message(self):
        req = EngineAuthRequest.blank('/auth/google')                    
        req._load_session()

        msgs = req.get_messages()
        self.assertEquals(msgs, None)

        req.add_message('TEST MESSAGE')
        msgs = req.get_messages()
        self.assertEquals(msgs, [{'level': None, 'message':'TEST MESSAGE' }])

        # Get again should be none.
        msgs = req.get_messages()
        self.assertEquals(msgs, None)

        # add message with level error
        req.add_message('TEST1', 'error')
        # add another message with level error
        req.add_message('TEST2', 'success')

        msgs = req.get_messages()
        self.assertEquals(msgs, [
                {'level': 'error', 'message':'TEST1' },
                {'level': 'success', 'message':'TEST2' },
        ])
        # Get again should be none.
        msgs = req.get_messages()
        self.assertEquals(msgs, None)

        # Test with different key.
        # add message with level error
        req.add_message('TEST1', 'error')
        # add another message with level error
        req.add_message('TEST2', 'success', '_mykey')

        msgs = req.get_messages()
        self.assertEquals(msgs, [
                {'level': 'error', 'message':'TEST1' },
        ])
        msgs_key = req.get_messages('_mykey')
        self.assertEquals(msgs_key, [
                {'level': 'success', 'message':'TEST2' },
        ])
        # Get again should be none.
        msgs = req.get_messages()
        self.assertEquals(msgs, None)
        msgs_key = req.get_messages()
        self.assertEquals(msgs_key, None)

    def test_set_redirect_uri(self):                    
        # test without next uri
        req = EngineAuthRequest.blank('/auth/google')                    
        req._load_session()
        req.set_redirect_uri()                    
        req._config = {'success_uri': '/callback'}                    
        redirect_uri = req.get_redirect_uri()                    
        self.assertEqual(redirect_uri, '/callback')                    

        # test with out next uri
        req = EngineAuthRequest.blank('/auth/google?next=/newcallback')                    
        req._load_session()
        req.set_redirect_uri()                    
        req._config = {'success_uri': '/callback'}                    
        redirect_uri = req.get_redirect_uri()                    
        self.assertEqual(redirect_uri, '/newcallback')                    

        req = EngineAuthRequest.blank('/auth/google?next=/newcallback&a=121&123=a')                    
        req._load_session()
        req.set_redirect_uri()                    
        req._config = {'success_uri': '/callback'}                    
        redirect_uri = req.get_redirect_uri()                    
        self.assertEqual(redirect_uri, '/newcallback')                    

# -*- coding: utf-8 -*-
from __future__ import absolute_import

from functools import partial

import cherrypy
import cephfs

from . import ApiController, RESTController, UiApiController, BaseController, \
              Endpoint, Task                    
from .. import logger
from ..security import Scope
from ..services.cephfs import CephFS
from ..services.cephx import CephX
from ..services.exception import serialize_dashboard_exception
from ..services.ganesha import Ganesha, GaneshaConf, NFSException
from ..services.rgw_client import RgwClient


# pylint: disable=not-callable
def NfsTask(name, metadata, wait_for):
    def composed_decorator(func):
        return Task("nfs/{}".format(name), metadata, wait_for,
                    partial(serialize_dashboard_exception,
                            include_http_status=True))(func)
    return composed_decorator


@ApiController('/nfs-ganesha/export', Scope.NFS_GANESHA)
class NFSGaneshaExports(RESTController):
    RESOURCE_ID = "cluster_id/export_id"

    def list(self):
        result = []
        for cluster_id in Ganesha.get_ganesha_clusters():
            result.extend(
                [export.to_dict()
                 for export in GaneshaConf.instance(cluster_id).list_exports()])
        return result

    @NfsTask('create', {'path': '{path}', 'fsal': '{fsal.name}',
                        'cluster_id': '{cluster_id}'}, 2.0)
    def create(self, path, cluster_id, daemons, pseudo, tag, access_type,
               squash, security_label, protocols, transports, fsal, clients,
               reload_daemons=True):
        if fsal['name'] not in Ganesha.fsals_available():
            raise NFSException("Cannot create this export. "
                               "FSAL '{}' cannot be managed by the dashboard."
                               .format(fsal['name']))

        ganesha_conf = GaneshaConf.instance(cluster_id)
        ex_id = ganesha_conf.create_export({
            'path': path,
            'pseudo': pseudo,
            'cluster_id': cluster_id,
            'daemons': daemons,
            'tag': tag,
            'access_type': access_type,
            'squash': squash,
            'security_label': security_label,
            'protocols': protocols,
            'transports': transports,
            'fsal': fsal,
            'clients': clients
        })
        if reload_daemons:
            ganesha_conf.reload_daemons(daemons)
        return ganesha_conf.get_export(ex_id).to_dict()

    def get(self, cluster_id, export_id):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)
        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)
        return ganesha_conf.get_export(export_id).to_dict()

    @NfsTask('edit', {'cluster_id': '{cluster_id}', 'export_id': '{export_id}'},
             2.0)
    def set(self, cluster_id, export_id, path, daemons, pseudo, tag, access_type,
            squash, security_label, protocols, transports, fsal, clients,
            reload_daemons=True):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)

        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)

        if fsal['name'] not in Ganesha.fsals_available():
            raise NFSException("Cannot make modifications to this export. "
                               "FSAL '{}' cannot be managed by the dashboard."
                               .format(fsal['name']))

        old_export = ganesha_conf.update_export({
            'export_id': export_id,
            'path': path,
            'cluster_id': cluster_id,
            'daemons': daemons,
            'pseudo': pseudo,
            'tag': tag,
            'access_type': access_type,
            'squash': squash,
            'security_label': security_label,
            'protocols': protocols,
            'transports': transports,
            'fsal': fsal,
            'clients': clients
        })
        daemons = list(daemons)
        for d_id in old_export.daemons:
            if d_id not in daemons:
                daemons.append(d_id)
        if reload_daemons:
            ganesha_conf.reload_daemons(daemons)
        return ganesha_conf.get_export(export_id).to_dict()

    @NfsTask('delete', {'cluster_id': '{cluster_id}',
                        'export_id': '{export_id}'}, 2.0)
    def delete(self, cluster_id, export_id, reload_daemons=True):
        export_id = int(export_id)
        ganesha_conf = GaneshaConf.instance(cluster_id)

        if not ganesha_conf.has_export(export_id):
            raise cherrypy.HTTPError(404)

        export = ganesha_conf.remove_export(export_id)
        if reload_daemons:
            ganesha_conf.reload_daemons(export.daemons)


@ApiController('/nfs-ganesha/daemon')
class NFSGaneshaService(RESTController):

    def list(self):
        status_dict = Ganesha.get_daemons_status()
        if status_dict:
            return [
                {
                    'daemon_id': daemon_id,
                    'cluster_id': cluster_id,
                    'status': status_dict[cluster_id][daemon_id]['status'],
                    'desc': status_dict[cluster_id][daemon_id]['desc']
                }
                for daemon_id in status_dict[cluster_id]
                for cluster_id in status_dict
            ]

        result = []
        for cluster_id in Ganesha.get_ganesha_clusters():
            result.extend(
                [{'daemon_id': daemon_id, 'cluster_id': cluster_id}
                 for daemon_id in GaneshaConf.instance(cluster_id).list_daemons()])
        return result


@UiApiController('/nfs-ganesha')
class NFSGaneshaUi(BaseController):
    @Endpoint('GET', '/cephx/clients')
    def cephx_clients(self):
        return [client for client in CephX.list_clients()]

    @Endpoint('GET', '/fsals')
    def fsals(self):
        return Ganesha.fsals_available()

    @Endpoint('GET', '/lsdir')
    def lsdir(self, root_dir=None, depth=1):
        if root_dir is None:
            root_dir = "/"
        depth = int(depth)
        if depth > 5:
            logger.warning("[NFS] Limiting depth to maximum value of 5: "
                           "input depth=%s", depth)
            depth = 5
        root_dir = '{}/'.format(root_dir) \
                   if not root_dir.endswith('/') else root_dir

        try:
            cfs = CephFS()
            paths = cfs.get_dir_list(root_dir, depth)
            paths = [p[:-1] for p in paths if p != root_dir]
            return {'paths': paths}
        except (cephfs.ObjectNotFound, cephfs.PermissionError):
            return {'paths': []}

    @Endpoint('GET', '/cephfs/filesystems')
    def filesystems(self):
        return CephFS.list_filesystems()

    @Endpoint('GET', '/rgw/buckets')
    def buckets(self, user_id=None):
        return RgwClient.instance(user_id).get_buckets()

    @Endpoint('GET', '/clusters')
    def clusters(self):
        return Ganesha.get_ganesha_clusters()


from django import forms
from django.contrib.auth import get_user_model, authenticate
from django.contrib.auth.forms import UserCreationForm
from django.utils.translation import gettext as _                    
import magic, mimetypes                    

from .models import ScreenDoorUser, Position, Applicant
from .uservisibletext import ErrorMessages, CreatePositionFormText, \
    CreateAccountFormText, StandardFormText, LoginFormText                    

# For creating a new position
class ImportApplicationsForm(forms.ModelForm):
    class Meta:
        model = Applicant
        fields = ('pdf', )

# For creating a new position
class CreatePositionForm(forms.ModelForm):
    text = CreatePositionFormText.upload_new_position
    description = CreatePositionFormText.please_select_either_filetype
    pdf_name = CreatePositionFormText.pdf
    url_name = CreatePositionFormText.url
    pdf_text = CreatePositionFormText.browse_for_pdf
    url_text = CreatePositionFormText.link_to_job_description
    upload_text = CreatePositionFormText.choose_a_file
    browse_text = CreatePositionFormText.browse
    submit_text = CreatePositionFormText.submit

    class Meta:
        model = Position
        fields = ('pdf', 'url_ref')
        widgets = {'url_ref': forms.TextInput(attrs={'disabled': 'disabled'})}


    def clean(self):
        pdf = self.cleaned_data.get('pdf')
        url = self.cleaned_data.get('url_ref')
        # Check for an empty form
        if not pdf and not url:
            msg = forms.ValidationError(ErrorMessages.empty_create_position_form)                    
            self.add_error('pdf', msg)
            return
        # Check for an overfilled form
        elif pdf and url:
            msg = forms.ValidationError(
                ErrorMessages.overfilled_create_position_form)
            self.add_error('pdf', msg)
            return

        # Verify if the pdf upload has an correct mimetype (i.e. a pdf file)
        if pdf:
            file_type = mimetypes.MimeTypes().types_map_inv[1][
                magic.from_buffer(self.cleaned_data['pdf'].read(), mime=True)
            ][0]
            if not (file_type == '.pdf'):
                msg = forms.ValidationError(
                    ErrorMessages.incorrect_mime_type)
                self.add_error('pdf', msg)

        # Verify if the url matches the job.gc.ca domain
        if url:
            ## Note: Below code is temporary, until url uploading is supported.
            msg = forms.ValidationError(
                     ErrorMessages.url_upload_not_supported_yet)                    
            self.add_error('url_ref', msg)


            ## Note: Desired code below.
            # if not "https://emploisfp-psjobs.cfp-psc.gc.ca" in url:
            #     msg = forms.ValidationError(
            #         ErrorMessages.invalid_url_domain)
            #     self.add_error('url_ref', msg)

        return self.cleaned_data


class ScreenDoorUserCreationForm(UserCreationForm):
    text = CreateAccountFormText.create_account
    email_text = CreateAccountFormText.email_address
    password_text = CreateAccountFormText.choose_password
    password_confirm_text = CreateAccountFormText.confirm_password
    email = forms.EmailField(
        label=StandardFormText.username_or_email_label, max_length=100)
    login_button_text = CreateAccountFormText.have_an_account_sign_in

    class Meta(UserCreationForm):
        model = ScreenDoorUser
        fields = ('email',)

    # Clean and validate fields. Password validation is handled by Django UserCreationForm
    def clean(self):
        email = self.cleaned_data.get('email')
        # Validate e-mail domain (canada.ca only)
        email_domain = email.split('@')[1].lower()
        if email_domain != "canada.ca":
            message = forms.ValidationError(
                format(ErrorMessages.invalid_email_domain % email_domain))
            self.add_error('email', message)
        # Validate if e-mail is unique in system
        elif get_user_model().objects.filter(username=email.lower()).exists():
            message = forms.ValidationError(
                format(ErrorMessages.user_already_exists % email))
            self.add_error('email', message)

        return self.cleaned_data


class LoginForm(forms.Form):
    login_text = LoginFormText.login
    create_account_text = StandardFormText.create_account
    email = forms.EmailField(
        label=StandardFormText.username_or_email_label, max_length=100)
    password = forms.CharField(
        label=LoginFormText.password, min_length=8, max_length=42, widget=forms.PasswordInput)

    def clean(self):
        # Entered e-mail is compared as lower to ensure login is not case-sensitive
        email = self.cleaned_data.get('email').lower()
        password = self.cleaned_data.get('password')
        user = authenticate(username=email, password=password)

        # Does user exist in system?
        if user is None:
            message = forms.ValidationError(ErrorMessages.invalid_un_or_pw)
            self.add_error('email', message)
        # Has user confirmed e-mail address
        elif user.email_confirmed is False:
            message = forms.ValidationError(ErrorMessages.unconfirmed_email)
            self.add_error('email', message)

        return self.cleaned_data

    def get_user(self):
        # Entered e-mail is compared as lower to ensure login is not case-sensitive
        email = self.cleaned_data.get('email').lower()
        password = self.cleaned_data.get('password')
        return authenticate(username=email, password=password)

from django.urls import path, include

from . import views


# Set application namespace
# app_name = 'screendoor'

urlpatterns = [
    path('', views.index, name='home'),
    path('register/', views.register_form, name='register'),
    path('login/', views.login_form, name='login'),
    path('logout/', views.logout_view, name='logout'),
    path('confirm/', views.login_form, name='confirm_account'),
    path('createnewposition/', views.import_position, name='importposition'),
    path('positions/', views.positions, name='positions'),
    path('position/', views.position, name='position'),                    
    path('importapplications/', views.import_applications,
         name='importapplications'),
]

from string import digits
from django.core.mail import send_mail
from django.shortcuts import render, redirect
from django.contrib.auth import get_user_model
from django.contrib.auth import login, logout
from django.contrib.auth.decorators import login_required

from .uservisibletext import InterfaceText, CreateAccountFormText, PositionText, PositionsViewText, LoginFormText
from .forms import ScreenDoorUserCreationForm, LoginForm, CreatePositionForm, ImportApplicationsForm, ImportApplicationsText
from .models import EmailAuthenticateToken, Position                    
from screendoor.parseposter import parse_upload
from screendoor.redactor import parse_applications


# Each view is responsible for doing one of two things: returning an HttpResponse object containing the content for
# the requested page, or raising an exception such as Http404.
# The @login_required decorator redirects unauthenticated sessions to 'settings.LOGIN_URL' or the specified URL


# Index currently redirects to the positions view if logged in
@login_required(login_url='login/', redirect_field_name=None)
def index(request):
    return redirect('positions')
    # Returns main page
    return render(request, 'index.html',
                  {'user': request.user, 'baseVisibleText': InterfaceText})


# Renders account registration form
def register_form(request):
    register_form = ScreenDoorUserCreationForm()
    if request.method == 'POST':
        # create a form instance and populate it with data from the request:
        register_form = ScreenDoorUserCreationForm(request.POST)
        # check whether form data is valid
        if register_form.is_valid():
            # Create user
            user = create_account(request)
            # Send confirmation e-mail
            send_user_email(request, user)
            # Redirects to...
            return render(request, 'registration/register.html',
                          {'register_form': register_form,
                           'account_created': format(CreateAccountFormText.account_created % user)})
    # Returns form page
    return render(request, 'registration/register.html',
                  {'register_form': register_form})


# Creates and returns user object from request data
def create_account(request):
    # Creates account and saves email, password, username to database
    user = get_user_model().objects.create_user(
        request.POST['email'].lower(), password=request.POST['password1'], email=request.POST['email'].lower())
    # Extrapolate first and last name from e-mail account (experimental)
    user.first_name = request.POST['email'].split('.')[0].title()
    user.last_name = request.POST['email'].split(
        '.')[1].split('@')[0].title().translate({ord(n): None for n in digits})
    # Set user as inactive until e-mail confirmation
    user.email_confirmed = False
    # Save updated user info to database
    user.save()
    return user


# Sends account confirmation e-mail to user
# Currently sends mock e-mail via console
def send_user_email(request, user):
    url = generate_confirmation_url(request, user)
    send_mail(
        'ScreenDoor: Please confirm e-mail address',
        'Please visit the following URL to confirm your account: ' + url,
        'screendoor@screendoor.ca',
        # Address: should be user.email
        [user.email],
        fail_silently=False,
    )


# Creates and returns a working account confirmation URL
def generate_confirmation_url(request, user):
    token = EmailAuthenticateToken()
    token.user = user
    token.create_key()
    token.save()
    # TODO: generate first part of URL programmatically not as hardcoded string
    return "http://localhost:8000/confirm?key=" + str(token.key)


# Clears any GET data, i.e. account confirmation token string from URL
def clear_get_data(request):
    # Clears any GET data
    request.GET._mutable = True
    request.GET['key'] = None
    request.GET._mutable = False


# Returns true if user authentication token is valid and userhas been validated and saved
def authenticate_user(account_key):
    # If authentication key is valid, activate user and delete authentication token
    if EmailAuthenticateToken.objects.filter(key=account_key).exists():
        token = EmailAuthenticateToken.objects.get(key=account_key)
        user = token.user
        user.email_confirmed = True
        user.save()
        token.delete()
        return True                    
    return False                    


# Displays form for user login and calls validation methods
def login_form(request):
    # If user is not logged in, display login form
    if not request.user.is_authenticated:
        form = LoginForm()
        # Has the user hit login button
        if request.method == 'POST':
            clear_get_data(request)
            # Instantiate form object
            form = LoginForm(request.POST)
            # Validates form and persists username data
            if form.is_valid():
                user = form.get_user()
                # Logs in and redirects user
                login(request, user)
                return redirect('home')
        if request.GET.get('key') is not None:
            # Check if authentication key is valid
            if (authenticate_user(request.GET.get('key'))):                    
                # Display account confirmation message
                return render(request, 'registration/login.html',
                              {'login_form': form,
                               'account_confirmed': format(LoginFormText.account_confirmed % user.email)})
            # Display validation error message
            return render(request, 'registration/login.html',
                          {'login_form': form, 'validation_error': LoginFormText.validation_error})
        # Display login page
        return render(request, 'registration/login.html',
                      {'login_form': form})
    # If the user is already logged in, redirect to home
    return redirect('home')


# Logs out user
@login_required(login_url='/login/', redirect_field_name=None)
def logout_view(request):
    logout(request)
    return redirect('login')


# Run parse upload script and return dictionary
def parse_position_return_dictionary(create_position_form):
    # don't commit partial positions with only pdf/url into db
    return parse_upload(create_position_form.save(commit=False))


# Adds position to user data
def save_position_to_user(request):
    request.user.positions.add(Position.objects.get(
        id=request.session['position_id']))


# Displays form allowing users to upload job posting PDF files and URLs
@login_required(login_url='/login/', redirect_field_name=None)
def import_position(request):
    if request.method == 'POST':
        create_position_form = CreatePositionForm(
            request.POST, request.FILES)
        # Is the form data valid
        if create_position_form.is_valid():
            dictionary = parse_position_return_dictionary(create_position_form)
            errors = dictionary.get('errors')
            if errors:
                create_position_form.add_error('pdf', errors)
            # Is the parsed data valid (any errors added)
            if create_position_form.is_valid():
                position = dictionary.get('position')
                # Persist position ID in session for saving and editing
                request.session['position_id'] = position.id
                # Successful render of a position
                return render(request, 'createposition/importposition.html',
                              {'position': position, 'form': create_position_form,
                               'baseVisibleText': InterfaceText,
                               'userVisibleText': PositionText})
            # Display errors
            return render(request, 'createposition/importposition.html',
                          {'form': create_position_form,
                           'baseVisibleText': InterfaceText,
                           'userVisibleText': PositionText})
        # User pressed save button on uploaded and parsed position
        if request.POST.get("save-position"):
            save_position_to_user(request)
            return redirect('home')
    # Default view for GET request
    create_position_form = CreatePositionForm()
    return render(request, 'createposition/importposition.html', {
        'form': CreatePositionForm, 'baseVisibleText': InterfaceText
    })


# Gets user's persisted positions sort method, or returns default
def get_positions_sort_method(request):
    try:
        return request.session['position_sort']
    except KeyError:
        return '-created'


# Changes positions sort method
def change_positions_sort_method(request, sort_by):
    if request.POST.get("sort-created"):
        return '-created'
    elif request.POST.get("sort-closed"):
        return '-date_closed'
    elif request.POST.get("sort-position"):
        return 'position_title'
    return sort_by


# Data and visible text to render with positions list view
def positions_list_data(request, sort_by):
    return {
        'baseVisibleText': InterfaceText, 'positionText': PositionText, 'userVisibleText': PositionsViewText, 'applicationsForm': ImportApplicationsForm, 'positions': request.user.positions.all().order_by(sort_by), 'sort': request.session['position_sort']
    }
  
  
# View of all positions associated with a user account
@login_required(login_url='/login/', redirect_field_name=None)
def positions(request):
    # Order of positions display
    sort_by = get_positions_sort_method(request)
    if request.method == 'POST':
        sort_by = change_positions_sort_method(request, sort_by)
        # User wants to view position detail
        if request.POST.get("position"):
            return position(request, Position.objects.get(                    
                id=request.POST.get("id")))
        # User wants to delete position
        elif request.POST.get("delete"):
            Position.objects.get(
                id=request.POST.get("id")).delete()
        # User wants to upload applications for a position
        elif request.POST.get("upload-applications"):
            upload_applications(request)
            return position(request, Position.objects.get(                    
                id=request.POST.get("id")))
    # Persists positions sorting
    request.session['position_sort'] = sort_by
    # Displays list of positions
    return render(request, 'positions.html', positions_list_data(request, sort_by))


# Data and visible text to render with positions
def position_detail_data(request, position):
    return {'baseVisibleText': InterfaceText, 'applicationsForm': ImportApplicationsForm, 'positionText': PositionText, 'userVisibleText': PositionsViewText, 'position': position}                    


# Position detail view
@login_required(login_url='/login/', redirect_field_name=None)
def position(request, position):                    
    return render(request, 'position.html', position_detail_data(request, position))


def upload_applications(request):
    position = Position.objects.get(
        id=request.POST.get("id"))
    # form = ImportApplicationsForm(request.POST, request.FILES)
    # applications = import_applications(request)
    # position.applications.add(applications)
    # position.save()


def import_applications(request):
    if request.method == 'POST':
        form = ImportApplicationsForm(request.POST, request.FILES)
        if form.is_valid():
            breakpoint()
            parse_applications()
            # Call application parser logic here##

            return render(request, 'importapplications/applications.html', {
                'form': form})

    form = ImportApplicationsForm()
    return render(request, 'importapplications/applications.html', {
        'form': form})

"""

View partials provide all the callisto-core front-end functionality.
Subclass these partials with your own views if you are implementing
callisto-core. Many of the view partials only provide a subset of the
functionality required for a full HTML view.

docs / reference:
    - https://docs.djangoproject.com/en/1.11/topics/class-based-views/
    - https://github.com/project-callisto/callisto-core/blob/master/callisto_core/wizard_builder/view_partials.py

view_partials should define:
    - forms
    - models
    - helper classes
    - access checks
    - redirect handlers

and should not define:
    - templates
    - url names

"""
import logging
import re

import ratelimit.mixins
from nacl.exceptions import CryptoError

from django.conf import settings
from django.core.exceptions import PermissionDenied
from django.http import HttpResponse
from django.shortcuts import redirect
from django.urls import reverse, reverse_lazy
from django.views import generic as views

from callisto_core.evaluation.view_partials import EvalDataMixin
from callisto_core.reporting import report_delivery
from callisto_core.wizard_builder import (
    data_helper,
    view_partials as wizard_builder_partials,
)

from . import forms, models, view_helpers

logger = logging.getLogger(__name__)


#######################
# secret key partials #
#######################


class _PassphrasePartial(views.base.TemplateView):
    storage_helper = view_helpers.ReportStorageHelper

    @property
    def storage(self):
        return self.storage_helper(self)


class _PassphraseClearingPartial(EvalDataMixin, _PassphrasePartial):
    def get(self, request, *args, **kwargs):
        self.storage.clear_passphrases()
        return super().get(request, *args, **kwargs)


class DashboardPartial(_PassphraseClearingPartial):
    EVAL_ACTION_TYPE = "DASHBOARD"


###################
# report partials #
###################


class ReportBasePartial(EvalDataMixin, wizard_builder_partials.WizardFormPartial):
    model = models.Report
    storage_helper = view_helpers.EncryptedReportStorageHelper
    EVAL_ACTION_TYPE = "VIEW"

    @property
    def site_id(self):
        # TODO: remove
        return self.request.site.id

    @property
    def decrypted_report(self):
        return self.report.decrypt_record(self.storage.passphrase)

    def get_form_kwargs(self):
        kwargs = super().get_form_kwargs()
        kwargs.update({"view": self})  # TODO: remove
        return kwargs


class ReportCreatePartial(ReportBasePartial, views.edit.CreateView):
    form_class = forms.ReportCreateForm
    EVAL_ACTION_TYPE = "CREATE"

    def get_success_url(self):
        return reverse(self.success_url, kwargs={"step": 0, "uuid": self.object.uuid})


class _ReportDetailPartial(ReportBasePartial, views.detail.DetailView):
    context_object_name = "report"
    slug_field = "uuid"
    slug_url_kwarg = "uuid"

    @property
    def report(self):
        # TODO: remove, use self.object
        return self.get_object()


class _ReportLimitedDetailPartial(
    _ReportDetailPartial, ratelimit.mixins.RatelimitMixin
):
    ratelimit_key = "user"
    ratelimit_rate = settings.DECRYPT_THROTTLE_RATE


class _ReportAccessPartial(_ReportLimitedDetailPartial):
    invalid_access_key_message = "Invalid key in access request"
    invalid_access_user_message = "Invalid user in access request"
    invalid_access_no_key_message = "No key in access request"
    form_class = forms.ReportAccessForm
    access_form_class = forms.ReportAccessForm

    @property
    def access_granted(self):
        self._check_report_owner()
        try:
            passphrase = self.request.POST["key"]
        except Exception:
            return False

        if passphrase:
            try:
                self.storage.report.decrypt_record(passphrase)
                return True
            except CryptoError:
                logger.warn(self.invalid_access_key_message)
                return False
        else:
            logger.info(self.invalid_access_no_key_message)
            return False

    @property
    def access_form_valid(self):
        form = self._get_access_form()
        if form.is_valid():
            form.save()
            return True
        else:
            return False

    def _passphrase_next_url(self, request):
        next_url = None
        if "next" in request.GET:
            if re.search(r"^/[\W/-]*", request.GET["next"]):
                next_url = request.GET["next"]                    
        return next_url

    def dispatch(self, request, *args, **kwargs):
        logger.debug(f"{self.__class__.__name__} access check")

        if (
            self.access_granted or self.access_form_valid
        ) and self._passphrase_next_url(request):
            return self._redirect_from_passphrase(request)
        elif self.access_granted or self.access_form_valid:
            return super().dispatch(request, *args, **kwargs)
        else:
            return self._render_access_form()

    def _get_access_form(self):
        form_kwargs = self.get_form_kwargs()
        form_kwargs.update({"instance": self.get_object()})
        return self.access_form_class(**form_kwargs)

    def _render_access_form(self):
        self.object = self.report
        self.template_name = self.access_template_name
        context = self.get_context_data(form=self._get_access_form())
        return self.render_to_response(context)

    def _redirect_from_passphrase(self, request):
        return redirect(self._passphrase_next_url(request))

    def _check_report_owner(self):
        if not self.report.owner == self.request.user:
            logger.warn(self.invalid_access_user_message)
            raise PermissionDenied


class _ReportUpdatePartial(_ReportAccessPartial, views.edit.UpdateView):
    back_url = None

    @property
    def report(self):
        # TODO: remove, use self.object
        return self.get_object()


###################
# wizard partials #
###################


class EncryptedWizardPartial(
    _ReportUpdatePartial, wizard_builder_partials.WizardPartial
):
    steps_helper = view_helpers.ReportStepsHelper
    EVAL_ACTION_TYPE = "EDIT"

    def dispatch(self, request, *args, **kwargs):
        self._dispatch_processing()
        return super().dispatch(request, *args, **kwargs)

    def _rendering_done_hook(self):
        self.eval_action("REVIEW")


###################
# report actions  #
###################


class _ReportActionPartial(_ReportUpdatePartial):
    success_url = reverse_lazy("dashboard")

    def form_valid(self, form):
        logger.debug(f"{self.__class__.__name__} form valid")
        output = super().form_valid(form)
        self.view_action()
        return output

    def form_invalid(self, form):
        return super().form_invalid(form)

    def view_action(self):
        pass


class ReportDeletePartial(_ReportActionPartial):
    EVAL_ACTION_TYPE = "DELETE"

    def view_action(self):
        self.report.delete()


class WizardPDFPartial(_ReportActionPartial):
    EVAL_ACTION_TYPE = "ACCESS_PDF"

    def form_valid(self, form):
        # remove the old PDF generator completely.
        # this should be generated via JS now.
        pass


class ViewPDFPartial(WizardPDFPartial):
    content_disposition = "inline"
    EVAL_ACTION_TYPE = "VIEW_PDF"


class DownloadPDFPartial(WizardPDFPartial):
    content_disposition = "attachment"
    EVAL_ACTION_TYPE = "DOWNLOAD_PDF"

import logging
import os
import urllib
import requests
from django.contrib.auth.decorators import login_required, permission_required
from django.contrib import messages
from django.conf import settings
from django.core.exceptions import PermissionDenied
from django.core.urlresolvers import reverse
from django.http import HttpResponse, HttpResponseRedirect, HttpResponsePermanentRedirect, HttpResponseForbidden, JsonResponse, FileResponse, HttpResponseServerError
from django.shortcuts import render, get_object_or_404
from django.views.decorators.http import require_http_methods
from .models import Person, Candidate, Keyword, CommitteeMember
from .widgets import ID_VAL_SEPARATOR


BDR_EMAIL = 'bdr@brown.edu'
logger = logging.getLogger('etd')


def login(request):
    if request.user.is_authenticated():
        next_url = request.GET.get('next', reverse('home'))                    
        return HttpResponseRedirect(next_url)
    else:
        logger.error('login() - got anonymous user: %s' % request.META)
        return HttpResponseServerError('Internet Server error. Please contact %s for assistance.' % BDR_EMAIL)


def redirect_to_home(request):
    return HttpResponsePermanentRedirect(reverse('home'))


def home(request):
    return render(request, 'etd_app/home.html')


def overview(request):
    return render(request, 'etd_app/overview.html')


def faq(request):
    return render(request, 'etd_app/faq.html')


def copyright(request):
    return render(request, 'etd_app/copyright.html')


def get_person_instance(request):
    person_instance = None
    try:
        person_instance = Person.objects.get(netid=request.user.username)
    except Person.DoesNotExist:
        if 'orcid' in request.POST:
            try:
                person_instance = Person.objects.get(orcid=request.POST['orcid'])
            except Person.DoesNotExist:
                pass
    return person_instance


def get_shib_info_from_request(request):
    info = {}
    info['last_name'] = request.META.get('Shibboleth-sn', '')
    info['first_name'] = request.META.get('Shibboleth-givenName', '')
    info['email'] = request.META.get('Shibboleth-mail', '')
    return info


def _get_candidate(candidate_id, request):
    candidate = Candidate.objects.get(id=candidate_id)
    if candidate.person.netid != request.user.username:
        raise PermissionDenied
    return candidate


@login_required
def register(request):
    from .forms import PersonForm, CandidateForm
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['netid'] = request.user.username
        person_form = PersonForm(post_data, instance=get_person_instance(request))
        candidate_form = CandidateForm(post_data)
        if person_form.is_valid() and candidate_form.is_valid():
            person = person_form.save()
            banner_id = request.META.get('Shibboleth-brownBannerID', '')
            if banner_id:
                person.bannerid = banner_id
                person.save()
            candidate = candidate_form.save(commit=False)
            candidate.person = person
            candidate.save()
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        shib_info = get_shib_info_from_request(request)
        person_instance = get_person_instance(request)
        degree_type = request.GET.get('type', '')
        if person_instance:
            person_form = PersonForm(instance=person_instance, degree_type=degree_type)
        else:
            person_form = PersonForm(initial=shib_info, degree_type=degree_type)
        candidate_form = CandidateForm(degree_type=degree_type)
    return render(request, 'etd_app/register.html', {'person_form': person_form, 'candidate_form': candidate_form, 'register': True})


@login_required
def candidate_profile(request, candidate_id):
    from .forms import PersonForm, CandidateForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['netid'] = request.user.username
        person_form = PersonForm(post_data, instance=candidate.person)
        candidate_form = CandidateForm(post_data, instance=candidate)
        if person_form.is_valid() and candidate_form.is_valid():
            person = person_form.save()
            banner_id = request.META.get('Shibboleth-brownBannerID', '')
            if banner_id:
                person.bannerid = banner_id
                person.save()
            candidate = candidate_form.save(commit=False)
            candidate.person = person
            candidate.save()
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        shib_info = get_shib_info_from_request(request)
        degree_type = request.GET.get('type', '')
        person_form = PersonForm(instance=candidate.person, degree_type=degree_type)
        candidate_form = CandidateForm(instance=candidate, degree_type=degree_type)
    return render(request, 'etd_app/register.html', {'person_form': person_form, 'candidate_form': candidate_form})


@login_required
def candidate_home(request, candidate_id=None):
    try:
        if candidate_id:
            candidate = _get_candidate(candidate_id=candidate_id, request=request)
        else:
            candidate = Candidate.objects.get(person__netid=request.user.username)
    except Candidate.DoesNotExist:
        type_ = request.GET.get('type', '')
        if type_:
            url = '%s?type=%s' % (reverse('register'), type_)
        else:
            url = reverse('register')
        return HttpResponseRedirect(url)
    except Candidate.MultipleObjectsReturned:
        candidate = Candidate.objects.filter(person__netid=request.user.username)[0]
    context_data = {'candidate': candidate}
    other_candidacies = Candidate.objects.filter(person__netid=request.user.username).exclude(id=candidate.id)
    if other_candidacies:
        context_data['other_candidacies'] = other_candidacies
    return render(request, 'etd_app/candidate.html', context_data)


@login_required
def candidate_upload(request, candidate_id):
    from .forms import UploadForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        form = UploadForm(request.POST, request.FILES)
        if form.is_valid():
            form.save_upload(candidate)
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        form = UploadForm()
    return render(request, 'etd_app/candidate_upload.html', {'candidate': candidate, 'form': form})


def _user_keywords_changed(thesis, user_request_keywords):
    db_keywords_info = {}
    for kw in thesis.keywords.all():
        db_keywords_info[str(kw.id)] = kw
    unsorted_user_keywords = []
    for kw in user_request_keywords:
        if kw in db_keywords_info:
            unsorted_user_keywords.append(db_keywords_info[kw].text)
        else:
            unsorted_user_keywords.append(kw)
    db_keywords = sorted([kw.text for kw in db_keywords_info.values()])
    user_keywords = sorted([kw.split(ID_VAL_SEPARATOR)[-1] for kw in unsorted_user_keywords])
    if user_keywords and (user_keywords != db_keywords):
        return True
    return False


@login_required
def candidate_metadata(request, candidate_id):
    from .forms import MetadataForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        post_data = request.POST.copy()
        post_data['candidate'] = candidate.id
        form = MetadataForm(post_data, instance=candidate.thesis)
        if form.is_valid():
            thesis = form.save()
            if thesis.abstract != form.cleaned_data['abstract']:
                messages.info(request, 'Your abstract contained invisible characters that we\'ve removed. Please make sure your abstract is correct in the information section below.')
            if thesis.title != form.cleaned_data['title']:
                messages.info(request, 'Your title contained invisible characters that we\'ve removed. Please make sure your title is correct in the information section below.')
            if _user_keywords_changed(thesis, request.POST.getlist('keywords', [])):
                messages.info(request, 'Your keywords contained invisible characters that we\'ve removed. Please make sure your keywords are correct in the information section below.')
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        form = MetadataForm(instance=candidate.thesis)
    context = {'candidate': candidate, 'form': form, 'ID_VAL_SEPARATOR': ID_VAL_SEPARATOR}
    return render(request, 'etd_app/candidate_metadata.html', context)


@login_required
def candidate_committee(request, candidate_id):
    from .forms import CommitteeMemberPersonForm, CommitteeMemberForm
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    if candidate.thesis.is_locked():
        return HttpResponseForbidden('Thesis has already been submitted and is locked.')
    if request.method == 'POST':
        person_form = CommitteeMemberPersonForm(request.POST)
        committee_member_form = CommitteeMemberForm(request.POST)
        if person_form.is_valid() and committee_member_form.is_valid():
            person = person_form.save()
            committee_member = committee_member_form.save(commit=False)
            committee_member.person = person
            committee_member.save()
            candidate.committee_members.add(committee_member)
            return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))
    else:
        person_form = CommitteeMemberPersonForm()
        committee_member_form = CommitteeMemberForm()
    context = {'candidate': candidate, 'person_form': person_form,
               'committee_member_form': committee_member_form}
    return render(request, 'etd_app/candidate_committee.html', context)


@login_required
@require_http_methods(['POST'])
def candidate_committee_remove(request, candidate_id, cm_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    cm = CommitteeMember.objects.get(id=cm_id)
    candidate.committee_members.remove(cm)
    return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))


@login_required
def candidate_preview_submission(request, candidate_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    return render(request, 'etd_app/candidate_preview.html', {'candidate': candidate})


@login_required
@require_http_methods(['POST'])
def candidate_submit(request, candidate_id):
    try:
        candidate = _get_candidate(candidate_id=candidate_id, request=request)
    except Candidate.DoesNotExist:
        return HttpResponseRedirect(reverse('register'))
    candidate.thesis.submit()
    return HttpResponseRedirect(reverse('candidate_home', kwargs={'candidate_id': candidate.id}))


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_home(request):
    return HttpResponseRedirect(reverse('review_candidates', kwargs={'status': 'all'}))


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_view_candidates(request, status):
    if 'sort_by' in request.GET:
        candidates = Candidate.get_candidates_by_status(status, sort_param=request.GET['sort_by'])
    else:
        candidates = Candidate.get_candidates_by_status(status)
    return render(request, 'etd_app/staff_view_candidates.html', {'candidates': candidates, 'status': status})


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def staff_approve(request, candidate_id):
    from .forms import GradschoolChecklistForm, FormatChecklistForm
    candidate = get_object_or_404(Candidate, id=candidate_id)
    if request.method == 'POST':
        form = GradschoolChecklistForm(request.POST)
        if form.is_valid():
            form.save_data(candidate)
            return HttpResponseRedirect(reverse('staff_home'))
    else:
        format_form = FormatChecklistForm(instance=candidate.thesis.format_checklist)
    context = {'candidate': candidate, 'format_form': format_form}
    return render(request, 'etd_app/staff_approve_candidate.html', context)


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
def view_abstract(request, candidate_id):
    candidate = get_object_or_404(Candidate, id=candidate_id)
    return render(request, 'etd_app/staff_view_abstract.html', {'candidate': candidate})


@login_required
@permission_required('etd_app.change_candidate', raise_exception=True)
@require_http_methods(['POST'])
def staff_format_post(request, candidate_id):
    from .forms import FormatChecklistForm
    candidate = get_object_or_404(Candidate, id=candidate_id)
    format_form = FormatChecklistForm(request.POST, instance=candidate.thesis.format_checklist)
    if format_form.is_valid():
        format_form.handle_post(request.POST, candidate)
        return HttpResponseRedirect(reverse('approve', kwargs={'candidate_id': candidate_id}))


@login_required
def view_file(request, candidate_id):
    candidate = get_object_or_404(Candidate, id=candidate_id)
    if candidate.person.netid != request.user.username:
        if not request.user.has_perm('etd_app.change_candidate'):
            return HttpResponseForbidden('You don\'t have permission to view this candidate\'s thesis.')
    if not candidate.thesis.current_file_name:
        return HttpResponse('Couldn\'t find a file: please email %s if there should be one.' % BDR_EMAIL)
    file_path = os.path.join(settings.MEDIA_ROOT, candidate.thesis.current_file_name)
    response = FileResponse(open(file_path, 'rb'), content_type='application/pdf')
    response['Content-Disposition'] = 'attachment; filename="%s"' % candidate.thesis.original_file_name
    return response


def _select2_list(search_results):
    select2_results = []
    for r in search_results:
        select2_results.append({'id': r.id, 'text': r.text})
    return select2_results


def _get_previously_used(model, term):
    keywords = Keyword.search(term=term, order='text')
    if len(keywords) > 0:
        return [{'text': 'Previously Used', 'children': _select2_list(keywords)}]
    else:
        return []


def _build_fast_url(term, index):
    url = '%s?query=%s&queryIndex=%s' % (settings.FAST_LOOKUP_BASE_URL, urllib.parse.quote(term), index)
    url = '%s&queryReturn=%s&suggest=autoSubject' % (url, urllib.parse.quote('idroot,auth,type,%s' % index))
    return url


def _fast_results_to_select2_list(fast_results, index):
    results = []
    fast_ids = []
    for item in fast_results:
        text = item['auth']
        if item['type'] != 'auth':
            text = '%s (%s)' % (text, item[index][0])
        if item['idroot'] not in fast_ids:
            results.append({'id': '%s%s%s' % (item['idroot'], ID_VAL_SEPARATOR, item['auth']), 'text': text})
            fast_ids.append(item['idroot'])
    return results


def _get_fast_results(term, index='suggestall'):
    error_response = [{'text': 'FAST results', 'children': [{'id': '', 'text': 'Error retrieving FAST results.'}]}]
    url = _build_fast_url(term, index)
    try:
        r = requests.get(url, timeout=2)
    except requests.exceptions.Timeout:
        logger.error('fast lookup timed out')
        return error_response
    except Exception:
        import traceback
        logger.error('fast lookup exception: %s' % traceback.format_exc())
        return error_response
    try:
        select2_results = _fast_results_to_select2_list(r.json()['response']['docs'], index)
        if select2_results:
            return [{'text': 'FAST results', 'children': select2_results}]
        else:
            return []
    except Exception as e:
        logger.error('fast data exception: %s' % e)
        logger.error('fast response: %s - %s' % (r.status_code, r.text))
        return error_response


@login_required
def autocomplete_keywords(request):
    term = request.GET['term']
    results = _get_previously_used(Keyword, term)
    results.extend(_get_fast_results(term))
    return JsonResponse({'err': 'nil', 'results': results})

# -*- coding: utf-8 -*-

"""Django models for the redirects app."""

import logging
import re

from django.db import models
from django.utils.translation import ugettext
from django.utils.translation import ugettext_lazy as _

from readthedocs.core.resolver import resolve_path
from readthedocs.projects.models import Project

from .managers import RedirectManager


log = logging.getLogger(__name__)

HTTP_STATUS_CHOICES = (
    (301, _('301 - Permanent Redirect')),
    (302, _('302 - Temporary Redirect')),
)

STATUS_CHOICES = (
    (True, _('Active')),
    (False, _('Inactive')),
)

TYPE_CHOICES = (
    ('prefix', _('Prefix Redirect')),
    ('page', _('Page Redirect')),
    ('exact', _('Exact Redirect')),
    ('sphinx_html', _('Sphinx HTMLDir -> HTML')),
    ('sphinx_htmldir', _('Sphinx HTML -> HTMLDir')),
    # ('advanced', _('Advanced')),
)

# FIXME: this help_text message should be dynamic since "Absolute path" doesn't
# make sense for "Prefix Redirects" since the from URL is considered after the
# ``/$lang/$version/`` part. Also, there is a feature for the "Exact
# Redirects" that should be mentioned here: the usage of ``$rest``
from_url_helptext = _(
    'Absolute path, excluding the domain. '
    'Example: <b>/docs/</b>  or <b>/install.html</b>',
)
to_url_helptext = _(
    'Absolute or relative URL. Example: '
    '<b>/tutorial/install.html</b>',
)
redirect_type_helptext = _('The type of redirect you wish to use.')


class Redirect(models.Model):

    """A HTTP redirect associated with a Project."""

    project = models.ForeignKey(
        Project,
        verbose_name=_('Project'),
        related_name='redirects',
    )

    redirect_type = models.CharField(
        _('Redirect Type'),
        max_length=255,
        choices=TYPE_CHOICES,
        help_text=redirect_type_helptext,
    )

    from_url = models.CharField(
        _('From URL'),
        max_length=255,
        db_index=True,
        help_text=from_url_helptext,
        blank=True,
    )

    to_url = models.CharField(
        _('To URL'),
        max_length=255,
        db_index=True,
        help_text=to_url_helptext,
        blank=True,
    )

    http_status = models.SmallIntegerField(
        _('HTTP Status'),
        choices=HTTP_STATUS_CHOICES,
        default=301,
    )
    status = models.BooleanField(choices=STATUS_CHOICES, default=True)

    create_dt = models.DateTimeField(auto_now_add=True)
    update_dt = models.DateTimeField(auto_now=True)

    objects = RedirectManager()

    class Meta:
        verbose_name = _('redirect')
        verbose_name_plural = _('redirects')
        ordering = ('-update_dt',)

    def __str__(self):
        redirect_text = '{type}: {from_to_url}'
        if self.redirect_type in ['prefix', 'page', 'exact']:
            return redirect_text.format(
                type=self.get_redirect_type_display(),
                from_to_url=self.get_from_to_url_display(),
            )
        return ugettext(
            'Redirect: {}'.format(
                self.get_redirect_type_display(),
            ),
        )

    def get_from_to_url_display(self):
        if self.redirect_type in ['prefix', 'page', 'exact']:
            from_url = self.from_url
            to_url = self.to_url
            if self.redirect_type == 'prefix':
                to_url = '/{lang}/{version}/'.format(
                    lang=self.project.language,
                    version=self.project.default_version,
                )
            return '{from_url} -> {to_url}'.format(
                from_url=from_url,
                to_url=to_url,
            )
        return ''

    def get_full_path(self, filename, language=None, version_slug=None):                    
        """
        Return a full path for a given filename.

        This will include version and language information. No protocol/domain
        is returned.
        """
        # Handle explicit http redirects
        if re.match('^https?://', filename):                    
            return filename

        return resolve_path(
            project=self.project,
            language=language,
            version_slug=version_slug,
            filename=filename,
        )

    def get_redirect_path(self, path, language=None, version_slug=None):
        method = getattr(
            self,
            'redirect_{type}'.format(
                type=self.redirect_type,
            ),
        )
        return method(path, language=language, version_slug=version_slug)

    def redirect_prefix(self, path, language=None, version_slug=None):
        if path.startswith(self.from_url):
            log.debug('Redirecting %s', self)
            cut_path = re.sub('^%s' % self.from_url, '', path)
            to = self.get_full_path(
                filename=cut_path,
                language=language,
                version_slug=version_slug,
            )
            return to

    def redirect_page(self, path, language=None, version_slug=None):
        if path == self.from_url:
            log.debug('Redirecting %s', self)
            to = self.get_full_path(
                filename=self.to_url.lstrip('/'),
                language=language,
                version_slug=version_slug,
            )
            return to

    def redirect_exact(self, path, language=None, version_slug=None):
        full_path = path
        if language and version_slug:
            # reconstruct the full path for an exact redirect
            full_path = self.get_full_path(path, language, version_slug)                    
        if full_path == self.from_url:
            log.debug('Redirecting %s', self)
            return self.to_url
        # Handle full sub-level redirects
        if '$rest' in self.from_url:
            match = self.from_url.split('$rest')[0]
            if full_path.startswith(match):
                cut_path = re.sub('^%s' % match, self.to_url, full_path)
                return cut_path

    def redirect_sphinx_html(self, path, language=None, version_slug=None):
        for ending in ['/', '/index.html']:
            if path.endswith(ending):
                log.debug('Redirecting %s', self)
                path = path[1:]  # Strip leading slash.
                to = re.sub(ending + '$', '.html', path)
                return self.get_full_path(
                    filename=to,
                    language=language,
                    version_slug=version_slug,
                )

    def redirect_sphinx_htmldir(self, path, language=None, version_slug=None):
        if path.endswith('.html'):
            log.debug('Redirecting %s', self)
            path = path[1:]  # Strip leading slash.
            to = re.sub('.html$', '/', path)
            return self.get_full_path(
                filename=to,
                language=language,
                version_slug=version_slug,
            )

#!/usr/bin/python
#
# Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


"""Deals with fetching tiles and composing them for the final image."""

import logging
import os
import StringIO
import tempfile
import urllib                    

import geom
import images
import PIL.Image as Image
import tilecalcs

logger = logging.getLogger("wms_maps")
_TILE_PIXEL_SIZE = 256
_NO_DATA_PIXELS = (0, 0, 0)
_OPAQUE_ALPHA = (255,)
_TRANSPARENT_ALPHA = (0,)
_ALPHA_THRESHOLD = 128
ALL_WHITE_PIXELS = (255, 255, 255)


def ProduceImage(layer_properties, user_log_rect, user_width, user_height):
  """High-level production of the image.

  Args:
      layer_properties: Object with details about the layer.
      user_log_rect: The user-requested projected, ie map coordinates,
        not lat/lon, limits of the desired region. Ie BBOX, pretty much.
      user_width: The user-requested width of the image.
      user_height: The user-requested height of the image.

  Returns:
      The image to be presented to the user.
  """
  proj = layer_properties.projection

  zoom_level = tilecalcs.CalcZoomLevel(user_log_rect.Extent(),
                                       proj.InternalLogOuterBounds().Extent(),
                                       geom.Pair(user_width, user_height))

  tilepixel_rect, rect_of_tiles = tilecalcs.CalcTileRects(
      proj, user_log_rect, zoom_level)

  logger.info("Done tile calcs")

  tiles_array = _FetchTiles(rect_of_tiles, zoom_level, layer_properties)

  im_whole_tiles_extent = geom.Pair(rect_of_tiles.Width() * _TILE_PIXEL_SIZE,
                                    rect_of_tiles.Height() * _TILE_PIXEL_SIZE)

  # Process transparency for map.
  # Presently "image/png" is the only picture format
  # which supports transparency.
  # If the picture format is "image/jpeg", then send
  # the image as it is, without processing it
  # for any transparency requirements.

  set_pixel_to_bgcolor = (layer_properties.image_format == "image/png" and
                          layer_properties.is_transparent == "FALSE")

  bgcolor = (layer_properties.bgcolor if set_pixel_to_bgcolor
             else _NO_DATA_PIXELS)
  alpha = _OPAQUE_ALPHA if set_pixel_to_bgcolor else _TRANSPARENT_ALPHA

  # Alpha channel is not required for jpeg formats.
  if layer_properties.image_format == "image/jpeg":
    mode = "RGB"
    color = bgcolor
  else:
    mode = "RGBA"
    color = bgcolor + alpha

  # If TRANSPARENT = TRUE, image format is "image/png",
  # then create a transparent image (alpha = 0) with a black background.

  # If TRANSPARENT = FALSE, image format is "image/png",
  # then create an opaque image (alpha = 255) with bgcolor background.

  # Will have unwanted margin but we'll crop it off later.
  im_whole_tiles = Image.new(mode, im_whole_tiles_extent.AsTuple(), color)

  logger.debug("Tiles rect (in tiles): %s %s",
               str(rect_of_tiles), str(rect_of_tiles.Extent()))
  logger.debug("im_whole_tiles pixel extent: %s",
               str(im_whole_tiles_extent))

  for row in range(rect_of_tiles.Height()):
    for column in range(rect_of_tiles.Width()):
      pos = (
          int(column * _TILE_PIXEL_SIZE),
          int(row * _TILE_PIXEL_SIZE),
          int((column + 1) * _TILE_PIXEL_SIZE),
          int((row + 1) * _TILE_PIXEL_SIZE)
          )
      im_tile = tiles_array.ImageAt(column, row)

      if set_pixel_to_bgcolor:
        im_tile = _SetTransPixelToBgcolor(im_tile, bgcolor)

      # It may be None.
      if im_tile:
        _PasteTile(im_whole_tiles, im_tile, pos)

  logger.debug("tilepixel_rect: %s", str(tilepixel_rect))

  # Relative to / within im_whole_tiles.
  # Round down to nearest 256.
  offset_within_tiled_image = geom.Pair(
      tilepixel_rect.x0 % _TILE_PIXEL_SIZE,
      tilepixel_rect.y0 % _TILE_PIXEL_SIZE
      )

  logger.debug("Offset within: %s", str(offset_within_tiled_image))

  within_tiled_image = geom.Rect.FromLowerLeftAndExtent(
      offset_within_tiled_image, tilepixel_rect.Extent())

  logger.debug("Cropping to: %s", str(within_tiled_image.AsTuple()))

  im_true = im_whole_tiles.crop(within_tiled_image.AsTuple())

  logger.debug("Stretching to requested: %s", str(
      (user_width, user_height)))

  # Stretch the final pixels to match the aspect ratio of WIDTH /
  # HEIGHT. This is per the spec; doing this lets the client compensate
  # for non-square pixels.
  im_user = im_true.resize((user_width, user_height), Image.ANTIALIAS)

  return im_user


def _FetchTiles(rect_of_tiles, zoom_level, layer_properties):
  """Fetches all the tiles for a given image.

  Args:
      rect_of_tiles: is ul - lr (lr is exclusive!) addresses of tiles at a given
        zoom_level.
      zoom_level: self-explanatory.
      layer_properties: Object with details about the layer.

  Returns:
      ImageArray of the tiles.

  FWIW fetching isn't a big part of the total time for our WMS (~0.3s),
  so we don't bother with threads.
  For 8 tiles, unthreaded was faster - ~0.017s vs ~0.029s;
    http://localhost/wms?LAYERS=1002&
    SERVICE=WMS&VERSION=1.3.0&REQUEST=GetMap&STYLES=&FORMAT=image%2Fjpeg&
    CRS=EPSG:3857&BBOX=-30000000.0,-30000000.0,30000000.0,30000000.0&
    WIDTH=400&HEIGHT=400
  For 16, threaded is faster:  0.108545780182s vs 0.0410861968994s
    http://localhost/wms?LAYERS=1002&SERVICE=WMS&
    VERSION=1.3.0&REQUEST=GetMap&STYLES=&FORMAT=image%2Fjpg&CRS=EPSG:3857&
    BBOX=-400000.0,-400000.0,400000.0,400000.0&WIDTH=800&HEIGHT=800
  """
  # <world_extent_in_tiles> is the total tiles vertically and
  # horizontally, so that we know to either wrap around east-west, or
  # fill in with black tiles (per the WMS spec) for north-south
  # out-of-bounds requests.

  logger.info("Fetching tiles")
  logger.debug("rect_of_tiles: %s", rect_of_tiles)

  world_extent_in_tiles = 2 ** zoom_level
  tiles_array = images.ImagesArray(
      rect_of_tiles.Width(), rect_of_tiles.Height())

  logger.debug("World extent in tiles: %s", str(world_extent_in_tiles))

  base_url = layer_properties.GetMapBaseUrl()

  # We don't fetch 'black', empty tiles. They are always whole tiles.
  for abs_tile_row in range(rect_of_tiles.y0, rect_of_tiles.y1):
    # rel_tile_row is the row it will appear in, in the tile image.
    # Ie, [0 - n-1]; top-down.
    # Tile pixel space and tiles are both 'graphics space', ie 0,0 is
    # upper-left corner, down to lower-right.

    rel_tile_row = abs_tile_row - rect_of_tiles.y0
    logger.debug("Row - abs: %d; rel:%d", abs_tile_row, rel_tile_row)

    if rel_tile_row < 0:
      logger.error("Tile row %d - must never be < 0", rel_tile_row)

    for abs_tile_col in range(rect_of_tiles.x0, rect_of_tiles.x1):
      rel_tile_col = (abs_tile_col - rect_of_tiles.x0)

      if abs_tile_row < 0 or world_extent_in_tiles <= abs_tile_row:
        logger.debug("[%d] %d, %d is black",
                     world_extent_in_tiles,
                     abs_tile_col,
                     abs_tile_row)

        # Python Imaging Library (PIL)'s pixels are black by default;
        # we just don't set them.
        tiles_array.AddImage(rel_tile_col, rel_tile_row, None)
      else:
        # If more than 360-worth, could wrap back onto an
        # already-written part of the image array. Though if it did
        # it'd write the same thing so, it's only inefficient, not an
        # error.
        world_wrapped_tile_col = abs_tile_col % world_extent_in_tiles
        tile_args = layer_properties.GetTileArgs(world_wrapped_tile_col,
                                                 abs_tile_row, zoom_level)
        tile_url = base_url + tile_args
        im_tile = _FetchMapTile(tile_url)
        if im_tile:
          if im_tile.size == (1, 1):
            # 1x1 tiles come (probably mostly) from vector layers. They
            # mean that the whole 256x256 tile should be filled with the
            # color & opacity of this pixel.
            im_tile = im_tile.resize((_TILE_PIXEL_SIZE, _TILE_PIXEL_SIZE))
          tiles_array.AddImage(rel_tile_col, rel_tile_row, im_tile)

  return tiles_array


def _SetTransPixelToBgcolor(tile, bgcolor):
  """Set the transparent pixels to bgcolor.

  Args:
     tile: Tile as sent from the server.
     bgcolor: BGCOLOR parameter as sent by the GIS client's.
     Default is 0xFFFFFF(white).
  Returns:
     The source tile with transparent pixels fill w/ BGCOLOR and made opaque.
  """
  logger.debug("Processing the transparency for tile")

  if not tile:
    # Server returned a 404 Error.
    # _FetchmapTile() would return tile = None, in such cases.
    return tile

  # Palette or (1, 1) size tiles have mode "P".
  if tile.getbands() == ("P",):
    # convert the P mode to RGBA mode
    rgba_tile = Image.new("RGBA", tile.size)
    rgba_tile.paste(tile)

    # transparent tiles need not be processed, as the grid image is
    # already filled with bgcolor and made opaque.

    # Non-transparent tiles should be returned as it is to be inserted
    # into the grid image.

    tile = (tile if rgba_tile.getpixel((0, 0))[-1] != _TRANSPARENT_ALPHA[0]
            else None)
    return tile

  # RGB mode for PNG tiles.
  # Return the tile as is.
  # This tile will have opaque alpha in the grid image.
  if tile.getbands() == ("R", "G", "B"):
    return tile

  pixdata = tile.load()
  for row in xrange(tile.size[0]):
    for col in xrange(tile.size[1]):
      # If pixel alpha < threshold, make it opaque and fill it with bgcolor.
      if pixdata[row, col][3] <= _ALPHA_THRESHOLD:
        pixdata[row, col] = bgcolor + _OPAQUE_ALPHA
      else:
        (red, green, blue, alpha) = pixdata[row, col]
        if alpha < _OPAQUE_ALPHA[0]:
          pixdata[row, col] = (red, green, blue) + _OPAQUE_ALPHA

  return tile


def _FetchMapTile(url):
  """Fetches and returns a tile, given an url.

  Args:
      url: the exact url of the tile to fetch.

  Returns:
      The tile bitmap.
  """
  try:
    fp = urllib.urlopen(url)                    
    f = StringIO.StringIO(fp.read())                    
    im_tile = Image.open(f)
    im_tile.load()
  except IOError, e:
    im_tile = None
    logger.error("Failed to fetch tile:%s", e)
  finally:                    
    if fp:                    
      fp.close()                    

  return im_tile


def _SaveImage(image, fname, image_spec):
  """For debugging; saves the named tile to /tmp.

  Args:
      image: the PIL tile image.
      fname: the name to give the image.
      image_spec: all details about type, extension etc.
  """
  try:
    _, t_path = tempfile.mkstemp(suffix="." + image_spec.file_extension,
                                 prefix=fname + "-")
    # image.info is necessary to get transparency.
    image.save(t_path, image_spec.pil_format, **image.info)
    os.chmod(t_path, 777)
  except IOError, e:
    logger.error("Failed to save:%s", str(e.args[0]))
    raise


def _PasteTile(im_dest, im_src, box):
  """Copy the image.

  Args:
      im_dest: Destination of the image to be copied.
      im_src: Source image to be copied.
      box: the dimentions of the image.
  """
  try:
    im_dest.paste(im_src, box)
  except ValueError, e:
    logger.error("Failed to paste:%s", str(e.args[0]))
    logger.debug("Size %s vs %s", str(im_src.size), str(im_dest.size))
    logger.debug("Mode %s vs %s", str(im_src.mode), str(im_dest.mode))
    raise


def main():
  map_url = ("http://localhost/ca_maps/query?request=ImageryMaps&"
             "channel=1002&version=1&x=1&y=0&z=1")
  im = _FetchMapTile(map_url)
  print im

if __name__ == "__main__":
  main()

#!/usr/bin/python
#
# Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Code and objects that know about the servers."""

import json
import logging
import re
from socket import gethostname
import urllib2                    
import urlparse

import wms.ogc.common.projections as projections

# Example 'serverDefs' from Maps/Portable. The parts we use are the same
# for GEMap server.

# var geeServerDefs = {
# isAuthenticated : false,
# layers :
# [
# {
# icon : "icons/773_l.png",
# id : 1004,
# initialState : true,
# isPng : false,
# label : "Imagery",
# lookAt : "none",
# opacity : 1,
# requestType : "ImageryMaps",
# version : 8
# }
# ,
# {
# icon : "icons/773_l.png",
# id : 1002,
# initialState : true,
# isPng : true,
# label : "SF info",
# lookAt : "none",
# opacity : 1,
# requestType : "VectorMapsRaster",
# version : 4
# }
# ]
# ,
# projection : "mercator",
# ...
# url : "http://localhost:9335/SearchServlet/MapsAdapter?\
#        service=GEPlacesPlugin&DbId=42"
# ...


_LAYER_ARG_NAMES = {
    "ImageryMaps": {
        "x": "x",
        "y": "y",
        "z": "z"},
    "VectorMapsRaster": {
        "x": "col",
        "y": "row",
        "z": "level"},
    "ImageryMapsMercator": {
        "x": "x",
        "y": "y",
        "z": "z"}
    }

_SERVER_DEF_URL = "query?request=Json&var=geeServerDefs&is2d=t"
_TILE_BASE_URL = "%s/query?request=%s"
_IMAGE_FMT = "&format=%s"
_CHANNEL_VERSION = "&channel=%s&version=%s"
_TILE_ARGS = "&%s=%d&%s=%d&%s=%d"

# TODO: Support for "glc" type database should be added.
_SUPPORTED_DB_TYPES = ("gemap", "gedb", "glm", "glb")

# Get logger
logger = logging.getLogger("wms_maps")


class WmsLayer(object):
  """Represents everything a client needs to deal with a server layer."""

  def __init__(
      self,
      target_url,
      name,
      layer_id,
      label,
      projection,
      request_type,
      db_type,
      version,
      tile_arg_names):
    self.target_url = target_url
    self.name = name
    self.layer_id = layer_id
    self.label = label
    self.projection = projection
    self.request_type = request_type
    self.db_type = db_type
    self.version = str(version)
    self.tile_arg_names = tile_arg_names

    # Add a variable to store the requested
    # image format for an image.
    # This would be of type "jpeg" or "png".
    # Make "jpeg" as default value.
    # This variable will be updated with the
    # user request format at a later stage.
    self.image_format = "image/jpeg"

  @staticmethod
  def Make(target_url, server_layer_def):
    """Make a WmsLayer object from a serverDefs layer.

    Args:
      target_url: The server's target url, after which we'll append '?query...'
      server_layer_def: JSON layer spec.
    Returns:
        A WmsLayer object.
    """

    # 'layer_ns' is namespace to distinguish layers of the same target path.
    target_path = urlparse.urlsplit(target_url).path[1:]
    layer_ns = "[%s]:%s" %(target_path, str(server_layer_def["id"]))

    if server_layer_def["projection"] == "mercator":
      projection = projections.Mercator()
    else:
      projection = projections.Flat()

    # Note: By default, the requestType is set to 'ImageryMaps' since the
    # requestType-property doesn't present in 3D Fusion Database.
    request_type = server_layer_def.get("requestType", "ImageryMaps")

    tile_arg_names = _LAYER_ARG_NAMES[request_type]

    # TODO: support multi-layered maps (contain glm_id in json).
    version_info = server_layer_def.get("version", None)

    layer = WmsLayer(
        target_url=target_url,
        name=layer_ns,
        layer_id=str(server_layer_def["id"]),
        label=server_layer_def["label"],
        projection=projection,
        request_type=request_type,
        db_type=server_layer_def["db_type"],
        version=version_info,
        tile_arg_names=tile_arg_names
        )

    return layer

  def GetMapBaseUrl(self):
    """Prepares the base URL for fetching tiles."""

    # Add 'requestType' parameter to the URL.
    base_url = _TILE_BASE_URL % (self.target_url, self.request_type)

    # Add 'format' parameter to the URL.
    base_url += _IMAGE_FMT % self.image_format

    if self.db_type == "gemap":
      # 'channel' and 'version' information is
      # required only for 'gemap' database types.
      base_url += _CHANNEL_VERSION % (self.layer_id, self.version)

    return base_url

  def GetTileArgs(self, x, y, z):
    """Prepares the URL for fetching tiles."""
    tile_args = _TILE_ARGS % (
        self.tile_arg_names["x"], x,
        self.tile_arg_names["y"], y,
        self.tile_arg_names["z"], z
        )

    return tile_args


def _GetServerVars(target_url):
  """Fetches the server definitions from the Maps server.

  Args:
      target_url: The url of the server with target path.
  Returns:
      The server definitions for specified target.
  """

  if target_url[-1] != "/":
    target_url += "/"

  logger.debug("Fetching server definitions over http")

  target_url = urlparse.urljoin(target_url, _SERVER_DEF_URL)

  logger.debug("Opening url: [%s]", target_url)                    

  try:                    
    fp = urllib2.urlopen(target_url)                    
    result = fp.read()                    
  except urllib2.HTTPError, e:                    
    logger.warning("Server definitions didn't return any results %s.", e)                    
    return {}                    

  fp.close()                    

  logger.debug("Server definitions data read, start regex")
  logger.debug("JSON vars: %s", result)

  # Clean up the JS -> JSON
  # leading line
  p = re.compile(r"var geeServerDefs =")
  result = p.sub("", result)

  # final line
  p = re.compile(r";\s*$")
  result = p.sub("", result)

  # Adds quotes to bare keywords, changing from JavaScript to
  # actual JSON. (\s* absorbs newlines, & all keys are on their own lines.)
  p = re.compile(r"([\[\{,])\s*(\w+)\s*:")
  result = p.sub(r'\g<1>"\g<2>":', result)

  return json.loads(result)


def _LayersFromServerVars(target_url):
  """Fetch layer information from ServerVars.

  Args:
    target_url: Server URL hosting the target database.
  Returns:
    layers_by_name: A dict of all the layers in a database.
  """
  layers_by_name = {}

  server_vars = _GetServerVars(target_url)

  # "server_vars" would be empty({}) if the target doesn't exist.
  # This kind of error would be handled even before reaching this point.
  # A check for server_vars being empty ({}) is not required here
  # for the same reason.

  if not server_vars.has_key("dbType"):
    # Old databases do not have the "dbType" parameter in geeServerDefs.
    # Detect type of db based on the projection field for old databases.
    # gedb has no projection specified,
    if server_vars.has_key("projection"):
      server_vars["dbType"] = "gemap"
    else:
      server_vars["dbType"] = "gedb"

  # No explicit projection, then it is gedb, default to 'flat'.
  if not server_vars.has_key("projection"):
    server_vars["projection"] = "flat"

  logger.debug("Servers projection: %s", server_vars["projection"])
  logger.debug("Server database type: %s", server_vars["dbType"])

  # Error out when db_type is not supported.
  if server_vars["dbType"] not in _SUPPORTED_DB_TYPES:
    logger.error("GEE WMS implementation doesn't support database"
                 "type '%s'", server_vars["dbType"])
    # In this scenario, return an empty({}) layers_by_name.
    return layers_by_name

  for server_layer_def in server_vars["layers"]:

    # TODO: Use layer projection for GetCapabilities.
    # This will allow the service to serve flat imagery as both 'flat'
    # and 'mercator' based projections.

    # propagate server's 'global' projection name to each layer.
    server_layer_def["projection"] = server_vars["projection"]

    # propagate server's 'global' database type to each layer.
    server_layer_def["db_type"] = server_vars["dbType"]

    layer = WmsLayer.Make(target_url, server_layer_def)
    layers_by_name[layer.name] = layer

    logger.debug("Found server layer: %s", layer.name)

  logger.debug("Layers processing done")

  return layers_by_name


class GEELayer(object):
  """Represents a Google Earth Enterprise Layer server."""

  def __init__(self):
    logger.debug("Initializing GEELayer")

  def GetLayers(self, server_url, target_path):
    """Returns WmsLayer representations of the server's layers.

    These contain metainfo, and the ability to fetch tiles -
    everything a code client needs to know about and use, to get
    tiles from a server.


    Args:
     server_url: URL of the server on which command to be executed.
     target_path: Target published point.
    Returns:
        The layers from the server definitions.
    """
    target_url = urlparse.urljoin(server_url, target_path)
    logger.debug("Fetching layer information for target url '%s'", target_url)

    layers_by_name = _LayersFromServerVars(target_url)

    for layer_name in layers_by_name.keys():
      # Ignore Vector layers  from 3d types.
      if layers_by_name[layer_name].db_type in ("gedb", "glb"):
        if layers_by_name[layer_name].label != "Imagery":
          # Delete the non-Imagery layer.
          layers_by_name.pop(layer_name)

    return layers_by_name


def main():
  obj = GEELayer()

  hostname = gethostname()
  target_path = "merc"

  server_url = "http://%s.xxx.xxx.com" % hostname
  results = obj.GetLayers(server_url, target_path)

  print results

if __name__ == "__main__":
  main()

import ckan.model as model
import ckan.plugins.toolkit as toolkit
import sqlalchemy
from ckan.lib.cli import CkanCommand
from ckan.model.package import Package
from ckanapi import LocalCKAN

_and_ = sqlalchemy.and_


class MigrateExtras(CkanCommand):
    """Migrates legacy field values that were added as free extras to datasets to their schema counterparts.
    """

    summary = __doc__.split('\n')[0]

    def __init__(self, name):

        super(MigrateExtras, self).__init__(name)

    def get_package_ids(self):
        session = model.Session
        package_ids = []

        packages = (
            session.query(
                Package
            )
        )

        for pkg in packages:
            package_ids.append(pkg.id)

        return package_ids

    def update_package(self, package_id, security_classification, data_driven_application, version, author_email, notes, update_frequency, resources):
        # https://github.com/ckan/ckanext-scheming/issues/158
        destination = LocalCKAN()
        destination.action.package_patch(id=package_id,
                                         security_classification=security_classification,
                                         data_driven_application=data_driven_application,
                                         version=version,
                                         author_email=author_email,
                                         notes=notes,
                                         update_frequency=update_frequency,
                                         resources=resources)

    def command(self):
        """

        :return:
        """
        self._load_config()

        context = {'session': model.Session}

        # Step 1: Get all the package IDs.
        package_ids = self.get_package_ids()

        for package_id in package_ids:
            # Set some defaults
            default_security_classification = "PUBLIC"
            default_data_driven_application = "NO"
            default_version = "1.0"
            default_author_email = "opendata@qld.gov.au"
            default_update_frequency = "annually"
            default_size = '1'  # 1 Byte
            resources = []

            pkg = toolkit.get_action('package_show')(context, {
                'id': package_id
            })

            if pkg['resources']:
                size = default_size

                for resource in pkg['resources']:
                    if 'size' in resource:
                        size = resource['size'] if resource['size'] is not None and resource[
                            'size'] != '0 bytes' else default_size

                    if 'name' in resource:
                        name = resource['name']

                    if 'description' in resource:
                        description = resource['description'] or name

                    update_resource = {
                        "id": resource['id'],
                        "size": size,
                        "name": name,
                        "description": description                    
                    }
                    resources.append(update_resource)

            # Go through the packages and check for presence of 'Security classification'
            # and 'Used in data-driven application' extras
            security_classification = default_security_classification
            data_driven_application = default_data_driven_application
            version = default_version
            author_email = default_author_email
            update_frequency = default_update_frequency

            if pkg.get('extras', None):

                for extra in pkg['extras']:
                    if extra['key'] == 'Security classification':
                        security_classification = extra['value'] or default_security_classification
                    elif extra['key'] in ['Used in data-driven application']:
                        data_driven_application = extra['value'] or default_data_driven_application

            if 'version' in pkg:
                version = pkg['version'] or default_version

            if 'author_email' in pkg:
                author_email = pkg['author_email'] or default_author_email

            if 'notes' in pkg:
                notes = pkg['notes'] or pkg['title']

            if 'update_frequency' in pkg:
                update_frequency = pkg['update_frequency'] or default_update_frequency

            self.update_package(package_id, security_classification, data_driven_application, version, author_email, notes, update_frequency, resources)                    

        return 'SUCCESS'


class DemotePublishers(CkanCommand):
    """Demotes any existing 'publisher-*' users from admin to editor in their respective organisations
    """

    summary = __doc__.split('\n')[0]

    def __init__(self, name):

        super(DemotePublishers, self).__init__(name)
        self.parser.add_option('-u', '--username_prefix', dest='username_prefix', help='Only demote usernames starting with this prefix', type=str, default='publisher-')

    def get_organizations(self):
        return toolkit.get_action('organization_list')(data_dict={'all_fields': True, 'include_users': True})

    def patch_organisation_users(self, org_id, users):
        toolkit.get_action('organization_patch')(data_dict={'id': org_id, 'users': users})

    def command(self):
        """

        :return:
        """
        self._load_config()

        username_prefix = self.options.username_prefix

        updates = 0

        for org in self.get_organizations():
            print('- - - - - - - - - - - - - - - - - - - - - - - - -')
            updates_required = False
            users = org.get('users', [])
            print('Processing organisation ID: %s | Name: %s' % (org['id'], org['name']))
            if users:
                for user in org['users']:
                    if user['name'].startswith(username_prefix) and user['capacity'] == 'admin':
                        print('- Setting capacity for user %s to "editor" in organisation %s' % (user['name'], org['name']))
                        user['capacity'] = 'editor'
                        updates_required = True
                        updates += 1
                if updates_required:
                    print('- Updating user capacities for organisation %s' % org['name'])
                    self.patch_organisation_users(org['id'], users)
                else:
                    print('- Nothing to update for organisation %s' % org['name'])

        print('- - - - - - - - - - - - - - - - - - - - - - - - -')

        return "COMPLETED. Total updates %s\n" % updates

import ckan.model as model
import ckan.plugins.toolkit as toolkit
import sqlalchemy
from ckan.lib.cli import CkanCommand
from ckan.model.package import Package
from ckanapi import LocalCKAN

_and_ = sqlalchemy.and_


class MigrateExtras(CkanCommand):
    """Migrates legacy field values that were added as free extras to datasets to their schema counterparts.
    """

    summary = __doc__.split('\n')[0]

    def __init__(self, name):

        super(MigrateExtras, self).__init__(name)

    def get_package_ids(self):
        session = model.Session
        package_ids = []

        packages = (
            session.query(
                Package
            )
        )

        for pkg in packages:
            package_ids.append(pkg.id)

        return package_ids

    def update_package(self, package_id, security_classification, data_driven_application, version, author_email, notes, update_frequency, resources):
        # https://github.com/ckan/ckanext-scheming/issues/158
        destination = LocalCKAN()
        destination.action.package_patch(id=package_id,
                                         security_classification=security_classification,
                                         data_driven_application=data_driven_application,
                                         version=version,
                                         author_email=author_email,
                                         notes=notes,
                                         update_frequency=update_frequency,
                                         resources=resources)

    def command(self):
        """

        :return:
        """
        self._load_config()

        context = {'session': model.Session}

        # Step 1: Get all the package IDs.
        package_ids = self.get_package_ids()

        for package_id in package_ids:
            # Set some defaults
            default_security_classification = "PUBLIC"
            default_data_driven_application = "NO"
            default_version = "1.0"
            default_author_email = "opendata@qld.gov.au"
            default_update_frequency = "annually"
            default_size = '1'  # 1 Byte
            resources = []

            pkg = toolkit.get_action('package_show')(context, {
                'id': package_id
            })

            if pkg['resources']:
                size = default_size

                for resource in pkg['resources']:
                    if 'size' in resource:
                        size = resource['size'] if resource['size'] is not None and resource[
                            'size'] != '0 bytes' else default_size

                    if 'name' in resource:
                        name = resource['name']

                    if 'description' in resource:
                        description = resource['description'] or name

                    update_resource = {
                        "id": resource['id'],
                        "size": size,
                        "name": name,
                        "description": description                    
                    }
                    resources.append(update_resource)

            # Go through the packages and check for presence of 'Security classification'
            # and 'Used in data-driven application' extras
            security_classification = default_security_classification
            data_driven_application = default_data_driven_application
            version = default_version
            author_email = default_author_email
            update_frequency = default_update_frequency

            if pkg.get('extras', None):

                for extra in pkg['extras']:
                    if extra['key'] == 'Security classification':
                        security_classification = extra['value'] or default_security_classification
                    elif extra['key'] in ['Used in data-driven application']:
                        data_driven_application = extra['value'] or default_data_driven_application

            if 'version' in pkg:
                version = pkg['version'] or default_version

            if 'author_email' in pkg:
                author_email = pkg['author_email'] or default_author_email

            if 'notes' in pkg:
                notes = pkg['notes'] or pkg['title']

            if 'update_frequency' in pkg:
                update_frequency = pkg['update_frequency'] or default_update_frequency

            self.update_package(package_id, security_classification, data_driven_application, version, author_email, notes, update_frequency, resources)                    

        return 'SUCCESS'


class DemotePublishers(CkanCommand):
    """Demotes any existing 'publisher-*' users from admin to editor in their respective organisations
    """

    summary = __doc__.split('\n')[0]

    def __init__(self, name):

        super(DemotePublishers, self).__init__(name)
        self.parser.add_option('-u', '--username_prefix', dest='username_prefix', help='Only demote usernames starting with this prefix', type=str, default='publisher-')

    def get_organizations(self):
        return toolkit.get_action('organization_list')(data_dict={'all_fields': True, 'include_users': True})

    def patch_organisation_users(self, org_id, users):
        toolkit.get_action('organization_patch')(data_dict={'id': org_id, 'users': users})

    def command(self):
        """

        :return:
        """
        self._load_config()

        username_prefix = self.options.username_prefix

        updates = 0

        for org in self.get_organizations():
            print('- - - - - - - - - - - - - - - - - - - - - - - - -')
            updates_required = False
            users = org.get('users', [])
            print('Processing organisation ID: %s | Name: %s' % (org['id'], org['name']))
            if users:
                for user in org['users']:
                    if user['name'].startswith(username_prefix) and user['capacity'] == 'admin':
                        print('- Setting capacity for user %s to "editor" in organisation %s' % (user['name'], org['name']))
                        user['capacity'] = 'editor'
                        updates_required = True
                        updates += 1
                if updates_required:
                    print('- Updating user capacities for organisation %s' % org['name'])
                    self.patch_organisation_users(org['id'], users)
                else:
                    print('- Nothing to update for organisation %s' % org['name'])

        print('- - - - - - - - - - - - - - - - - - - - - - - - -')

        return "COMPLETED. Total updates %s\n" % updates

import ckan.lib.base as base
import ckan.lib.helpers as helpers
import ckan.lib.mailer as mailer
import ckan.model as model
import ckan.plugins as plugins
import ckanext.datarequests.db as db
import ckanext.datarequests.validator as validator
import datetime
import logging
from pylons import config

import constants

c = plugins.toolkit.c
log = logging.getLogger(__name__)
tk = plugins.toolkit

# Avoid user_show lag
USERS_CACHE = {}


def _get_user(user_id):
    try:
        if user_id in USERS_CACHE:
            return USERS_CACHE[user_id]
        else:
            user = tk.get_action('user_show')({'ignore_auth': True}, {'id': user_id})
            USERS_CACHE[user_id] = user
            return user
    except Exception as e:
        log.warn(e)


def _get_organization(organization_id):
    try:
        organization_show = tk.get_action('organization_show')
        return organization_show({'ignore_auth': True}, {'id': organization_id})
    except Exception as e:
        log.warn(e)


def _get_package(package_id):
    try:
        package_show = tk.get_action('package_show')
        return package_show({'ignore_auth': True}, {'id': package_id})
    except Exception as e:
        log.warn(e)


def _dictize_datarequest(datarequest):
    # Transform time
    open_time = str(datarequest.open_time)
    # Close time can be None and the transformation is only needed when the
    # fields contains a valid date
    close_time = datarequest.close_time
    close_time = str(close_time) if close_time else close_time

    # Convert the data request into a dict
    data_dict = {
        'id': datarequest.id,
        'user_id': datarequest.user_id,
        'title': datarequest.title,
        'description': datarequest.description,
        'organization_id': datarequest.organization_id,
        'open_time': open_time,
        'accepted_dataset_id': datarequest.accepted_dataset_id,
        'close_time': close_time,
        'closed': datarequest.closed,
        'user': _get_user(datarequest.user_id),
        'organization': None,
        'accepted_dataset': None,
        'followers': 0,
        'dataset_url': helpers.url_for(controller='ckanext.datarequests.controllers.ui_controller:DataRequestsUI',
                                       action='show', id=datarequest.id, qualified=True)
    }

    if datarequest.organization_id:
        data_dict['organization'] = _get_organization(datarequest.organization_id)

    if datarequest.accepted_dataset_id:
        data_dict['accepted_dataset'] = _get_package(datarequest.accepted_dataset_id)

    data_dict['followers'] = db.DataRequestFollower.get_datarequest_followers_number(
        datarequest_id=datarequest.id)

    return data_dict


def _undictize_datarequest_basic(data_request, data_dict):
    data_request.title = data_dict['title']
    data_request.description = data_dict['description']
    organization = data_dict['organization_id']
    data_request.organization_id = organization if organization else None


def _send_mail(user_ids, action_type, datarequest):                    
    for user_id in user_ids:
        try:
            user_data = model.User.get(user_id)
            extra_vars = {
                'datarequest': datarequest,
                'user': user_data,
                'site_title': config.get('ckan.site_title'),
                'site_url': config.get('ckan.site_url')
            }

            subject = base.render_jinja2('emails/subjects/{0}.txt'.format(action_type), extra_vars)
            body = base.render_jinja2('emails/bodies/{0}.txt'.format(action_type), extra_vars)

            mailer.mail_user(user_data, subject, body)                    

        except Exception:
            logging.exception("Error sending notification to {0}".format(user_id))


def _get_admin_users_from_organasition(datarequest_dict):
    # Data QLD modification.
    users = set([user['id'] for user in datarequest_dict['organization']['users'] if user.get('capacity') == 'admin'])
    return users


# Copied from ckanext.datarequests.actions. Please keep up to date with any extension updates
@tk.chained_action
def create_datarequest(original_action, context, data_dict):
    """
    Action to create a new data request. The function checks the access rights
    of the user before creating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    not valid.

    Data QLD modification
    Will send email notification to users of assigned organisation with admin access

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request (optional).
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """

    model = context['model']
    session = context['session']

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CREATE_DATAREQUEST, context, data_dict)

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Store the data
    data_req = db.DataRequest()
    _undictize_datarequest_basic(data_req, data_dict)
    data_req.user_id = context['auth_user_obj'].id
    data_req.open_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization']:
        # Data QLD modification
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'new_datarequest_organisation', datarequest_dict], title=u'Data Request Created Email')                    

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def update_datarequest(original_action, context, data_dict):
    """
    Action to update a data request. The function checks the access rights of
    the user before updating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    invalid.

    Data QLD modification
    Will send email notification if organisation was changed to users of assigned organisation with admin access

    :param id: The ID of the data request to be updated
    :type id: string

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request.
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.UPDATE_DATAREQUEST, context, data_dict)

    # Get the initial data
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]

    # Avoid the validator to return an error when the user does not change the title
    context['avoid_existing_title_check'] = data_req.title == data_dict['title']

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Data QLD modification
    organisation_updated = data_req.organization_id != data_dict['organization_id']
    if organisation_updated:
        unassigned_organisation_id = data_req.organization_id

    # Set the data provided by the user in the data_red
    _undictize_datarequest_basic(data_req, data_dict)

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization'] and organisation_updated:
        # Data QLD modification
        # Email Admin users of the assigned organisation
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'new_datarequest_organisation', datarequest_dict], title=u'Data Request Assigned Email')                    
        # Email Admin users of unassigned organisation
        org_dict = {
            'organization': _get_organization(unassigned_organisation_id)
        }
        users = _get_admin_users_from_organasition(org_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'unassigned_datarequest_organisation', datarequest_dict], title=u'Data Request Unassigned Email')                    

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def close_datarequest(original_action, context, data_dict):
    """
    Action to close a data request. Access rights will be checked before
    closing the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    Data QLD modification
    Will send email notification to the data request creator

    :param id: The ID of the data request to be closed
    :type id: string

    :param accepted_dataset_id: The ID of the dataset accepted as solution
        for this data request
    :type accepted_dataset_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CLOSE_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    # Validate data
    validator.validate_datarequest_closing(context, data_dict)

    data_req = result[0]

    # Was the data request previously closed?
    if data_req.closed:
        raise tk.ValidationError([tk._('This Data Request is already closed')])

    data_req.closed = True
    data_req.accepted_dataset_id = data_dict.get('accepted_dataset_id', None)
    data_req.close_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    tk.enqueue_job(_send_mail, [users, 'close_datarequest_creator', datarequest_dict], title=u'Data Request Closed Send Email')                    

    return datarequest_dict


def open_datarequest(context, data_dict):
    """
    Action to open a data request. Access rights will be checked before
    opening the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    :param id: The ID of the data request to be closed
    :type id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

        # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.OPEN_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)

    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]
    data_req.closed = False
    data_req.accepted_dataset_id = None
    data_req.close_time = None

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    # Creator email
    tk.enqueue_job(_send_mail, [users, 'open_datarequest_creator', datarequest_dict], title=u'Data Request Opened Creator Email')                    
    if datarequest_dict['organization']:
        users = _get_admin_users_from_organasition(datarequest_dict)
        # Admins of organisation email
        tk.enqueue_job(_send_mail, [users, 'open_datarequest_organisation', datarequest_dict], title=u'Data Request Opened Admins Email')                    

    return datarequest_dict

import ckan.lib.base as base
import ckan.lib.helpers as helpers
import ckan.lib.mailer as mailer
import ckan.model as model
import ckan.plugins as plugins
import ckanext.datarequests.db as db
import ckanext.datarequests.validator as validator
import datetime
import logging
from pylons import config

import constants

c = plugins.toolkit.c
log = logging.getLogger(__name__)
tk = plugins.toolkit

# Avoid user_show lag
USERS_CACHE = {}


def _get_user(user_id):
    try:
        if user_id in USERS_CACHE:
            return USERS_CACHE[user_id]
        else:
            user = tk.get_action('user_show')({'ignore_auth': True}, {'id': user_id})
            USERS_CACHE[user_id] = user
            return user
    except Exception as e:
        log.warn(e)


def _get_organization(organization_id):
    try:
        organization_show = tk.get_action('organization_show')
        return organization_show({'ignore_auth': True}, {'id': organization_id})
    except Exception as e:
        log.warn(e)


def _get_package(package_id):
    try:
        package_show = tk.get_action('package_show')
        return package_show({'ignore_auth': True}, {'id': package_id})
    except Exception as e:
        log.warn(e)


def _dictize_datarequest(datarequest):
    # Transform time
    open_time = str(datarequest.open_time)
    # Close time can be None and the transformation is only needed when the
    # fields contains a valid date
    close_time = datarequest.close_time
    close_time = str(close_time) if close_time else close_time

    # Convert the data request into a dict
    data_dict = {
        'id': datarequest.id,
        'user_id': datarequest.user_id,
        'title': datarequest.title,
        'description': datarequest.description,
        'organization_id': datarequest.organization_id,
        'open_time': open_time,
        'accepted_dataset_id': datarequest.accepted_dataset_id,
        'close_time': close_time,
        'closed': datarequest.closed,
        'user': _get_user(datarequest.user_id),
        'organization': None,
        'accepted_dataset': None,
        'followers': 0,
        'dataset_url': helpers.url_for(controller='ckanext.datarequests.controllers.ui_controller:DataRequestsUI',
                                       action='show', id=datarequest.id, qualified=True)
    }

    if datarequest.organization_id:
        data_dict['organization'] = _get_organization(datarequest.organization_id)

    if datarequest.accepted_dataset_id:
        data_dict['accepted_dataset'] = _get_package(datarequest.accepted_dataset_id)

    data_dict['followers'] = db.DataRequestFollower.get_datarequest_followers_number(
        datarequest_id=datarequest.id)

    return data_dict


def _undictize_datarequest_basic(data_request, data_dict):
    data_request.title = data_dict['title']
    data_request.description = data_dict['description']
    organization = data_dict['organization_id']
    data_request.organization_id = organization if organization else None


def _send_mail(user_ids, action_type, datarequest):                    
    for user_id in user_ids:
        try:
            user_data = model.User.get(user_id)
            extra_vars = {
                'datarequest': datarequest,
                'user': user_data,
                'site_title': config.get('ckan.site_title'),
                'site_url': config.get('ckan.site_url')
            }

            subject = base.render_jinja2('emails/subjects/{0}.txt'.format(action_type), extra_vars)
            body = base.render_jinja2('emails/bodies/{0}.txt'.format(action_type), extra_vars)

            mailer.mail_user(user_data, subject, body)                    

        except Exception:
            logging.exception("Error sending notification to {0}".format(user_id))


def _get_admin_users_from_organasition(datarequest_dict):
    # Data QLD modification.
    users = set([user['id'] for user in datarequest_dict['organization']['users'] if user.get('capacity') == 'admin'])
    return users


# Copied from ckanext.datarequests.actions. Please keep up to date with any extension updates
@tk.chained_action
def create_datarequest(original_action, context, data_dict):
    """
    Action to create a new data request. The function checks the access rights
    of the user before creating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    not valid.

    Data QLD modification
    Will send email notification to users of assigned organisation with admin access

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request (optional).
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """

    model = context['model']
    session = context['session']

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CREATE_DATAREQUEST, context, data_dict)

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Store the data
    data_req = db.DataRequest()
    _undictize_datarequest_basic(data_req, data_dict)
    data_req.user_id = context['auth_user_obj'].id
    data_req.open_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization']:
        # Data QLD modification
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'new_datarequest_organisation', datarequest_dict], title=u'Data Request Created Email')                    

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def update_datarequest(original_action, context, data_dict):
    """
    Action to update a data request. The function checks the access rights of
    the user before updating the data request. If the user is not allowed
    a NotAuthorized exception will be risen.

    In addition, you should note that the parameters will be checked and an
    exception (ValidationError) will be risen if some of these parameters are
    invalid.

    Data QLD modification
    Will send email notification if organisation was changed to users of assigned organisation with admin access

    :param id: The ID of the data request to be updated
    :type id: string

    :param title: The title of the data request
    :type title: string

    :param description: A brief description for your data request
    :type description: string

    :param organiztion_id: The ID of the organization you want to asign the
        data request.
    :type organization_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict
    """

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.UPDATE_DATAREQUEST, context, data_dict)

    # Get the initial data
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]

    # Avoid the validator to return an error when the user does not change the title
    context['avoid_existing_title_check'] = data_req.title == data_dict['title']

    # Validate data
    validator.validate_datarequest(context, data_dict)

    # Data QLD modification
    organisation_updated = data_req.organization_id != data_dict['organization_id']
    if organisation_updated:
        unassigned_organisation_id = data_req.organization_id

    # Set the data provided by the user in the data_red
    _undictize_datarequest_basic(data_req, data_dict)

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    if datarequest_dict['organization'] and organisation_updated:
        # Data QLD modification
        # Email Admin users of the assigned organisation
        users = _get_admin_users_from_organasition(datarequest_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'new_datarequest_organisation', datarequest_dict], title=u'Data Request Assigned Email')                    
        # Email Admin users of unassigned organisation
        org_dict = {
            'organization': _get_organization(unassigned_organisation_id)
        }
        users = _get_admin_users_from_organasition(org_dict)
        users.discard(context['auth_user_obj'].id)
        tk.enqueue_job(_send_mail, [users, 'unassigned_datarequest_organisation', datarequest_dict], title=u'Data Request Unassigned Email')                    

    return datarequest_dict


#  Copied from ckanext.datarequests.actions. Please keep up to date with any action updates
@tk.chained_action
def close_datarequest(original_action, context, data_dict):
    """
    Action to close a data request. Access rights will be checked before
    closing the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    Data QLD modification
    Will send email notification to the data request creator

    :param id: The ID of the data request to be closed
    :type id: string

    :param accepted_dataset_id: The ID of the dataset accepted as solution
        for this data request
    :type accepted_dataset_id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

    # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.CLOSE_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)
    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    # Validate data
    validator.validate_datarequest_closing(context, data_dict)

    data_req = result[0]

    # Was the data request previously closed?
    if data_req.closed:
        raise tk.ValidationError([tk._('This Data Request is already closed')])

    data_req.closed = True
    data_req.accepted_dataset_id = data_dict.get('accepted_dataset_id', None)
    data_req.close_time = datetime.datetime.now()

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    tk.enqueue_job(_send_mail, [users, 'close_datarequest_creator', datarequest_dict], title=u'Data Request Closed Send Email')                    

    return datarequest_dict


def open_datarequest(context, data_dict):
    """
    Action to open a data request. Access rights will be checked before
    opening the data request. If the user is not allowed, a NotAuthorized
    exception will be risen.

    :param id: The ID of the data request to be closed
    :type id: string

    :returns: A dict with the data request (id, user_id, title, description,
        organization_id, open_time, accepted_dataset, close_time, closed,
        followers)
    :rtype: dict

    """

    model = context['model']
    session = context['session']
    datarequest_id = data_dict.get('id', '')

    # Check id
    if not datarequest_id:
        raise tk.ValidationError(tk._('Data Request ID has not been included'))

        # Init the data base
    db.init_db(model)

    # Check access
    tk.check_access(constants.OPEN_DATAREQUEST, context, data_dict)

    # Get the data request
    result = db.DataRequest.get(id=datarequest_id)

    if not result:
        raise tk.ObjectNotFound(tk._('Data Request %s not found in the data base') % datarequest_id)

    data_req = result[0]
    data_req.closed = False
    data_req.accepted_dataset_id = None
    data_req.close_time = None

    session.add(data_req)
    session.commit()

    datarequest_dict = _dictize_datarequest(data_req)

    # Mailing
    users = [data_req.user_id]
    # Creator email
    tk.enqueue_job(_send_mail, [users, 'open_datarequest_creator', datarequest_dict], title=u'Data Request Opened Creator Email')                    
    if datarequest_dict['organization']:
        users = _get_admin_users_from_organasition(datarequest_dict)
        # Admins of organisation email
        tk.enqueue_job(_send_mail, [users, 'open_datarequest_organisation', datarequest_dict], title=u'Data Request Opened Admins Email')                    

    return datarequest_dict

import os
import queue
import subprocess
import sys
import traceback

from PyQt5.QtCore import pyqtSlot
from PyQt5.QtGui import QTextCursor
from PyQt5.QtWidgets import QVBoxLayout, QMainWindow, QWidget, QTextEdit, QInputDialog, QMessageBox, QApplication

from matisse import Matisse
from .handled_decorators import handled_function, handled_slot
from .logging_stream import LoggingStream
from .status_monitor import StatusMonitor
from .threading import ExitFlag, LoggingThread


class ControlApplication(QApplication):
    EXIT_CODE_RESTART = 42  # Answer to the Ultimate Question of Life, the Universe, and Everything

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Non-handled functions only here
        self.setup_logging()
        self.setup_window()
        self.setup_menus()
        self.setup_action_listeners()
        # Set up the log window first to display log output
        self.setup_log_window()

        # Handled functions can go here
        self.setup_matisse()
        self.setup_widgets()

        # Other setup
        self.aboutToQuit.connect(self.clean_up)

        container = QWidget()
        container.setLayout(self.layout)
        self.window.setCentralWidget(container)
        self.window.show()

    def setup_logging(self):
        self.log_area = QTextEdit()
        self.log_area.setReadOnly(True)

        # Create the queue that holds all log messages and the input stream that writes them
        self.log_queue = queue.Queue()
        self.log_stream = LoggingStream(self.log_queue)
        # Create a thread to manage receiving log messages
        # TODO: Subclass QTextEdit and keep the logging thread there
        self.log_thread = LoggingThread(self.log_queue, parent=self)
        self.log_thread.message_received.connect(self.log)
        self.log_thread.start()

    def setup_window(self):
        self.window = window = QMainWindow()
        self.layout = QVBoxLayout()
        window.setWindowTitle('Matisse Controller')
        window.resize(600, 200)

    def setup_menus(self):
        menu_bar = self.window.menuBar()

        console_menu = menu_bar.addMenu('Console')
        self.clear_log_area_action = console_menu.addAction('Clear Log')
        self.open_idle_action = console_menu.addAction('Open Python Shell...')
        self.restart_action = console_menu.addAction('Restart')

        set_menu = menu_bar.addMenu('Set')
        self.set_wavelength_action = set_menu.addAction('Wavelength')
        self.set_bifi_approx_wavelength_action = set_menu.addAction('BiFi Approx. Wavelength')
        self.set_bifi_motor_pos_action = set_menu.addAction('BiFi Motor Position')
        self.set_thin_eta_motor_pos_action = set_menu.addAction('Thin Etalon Motor Position')

        scan_menu = menu_bar.addMenu('Scan')
        self.bifi_scan_action = scan_menu.addAction('Birefringent Filter')
        self.thin_eta_scan_action = scan_menu.addAction('Thin Etalon')

        lock_menu = menu_bar.addMenu('Lock')
        self.lock_all_action = lock_menu.addAction('Lock All')
        self.lock_all_action.setCheckable(True)
        self.lock_slow_piezo_action = lock_menu.addAction('Lock Slow Piezo')
        self.lock_slow_piezo_action.setCheckable(True)
        self.lock_thin_etalon_action = lock_menu.addAction('Lock Thin Etalon')
        self.lock_thin_etalon_action.setCheckable(True)
        self.lock_piezo_etalon_action = lock_menu.addAction('Lock Piezo Etalon')
        self.lock_piezo_etalon_action.setCheckable(True)
        self.lock_fast_piezo_action = lock_menu.addAction('Lock Fast Piezo')
        self.lock_fast_piezo_action.setCheckable(True)

        tools_menu = menu_bar.addMenu('Tools')

        self.lock_actions = [self.lock_slow_piezo_action, self.lock_thin_etalon_action, self.lock_piezo_etalon_action,
                             self.lock_fast_piezo_action]

    def setup_action_listeners(self):
        # Console
        self.clear_log_area_action.triggered.connect(self.clear_log_area)
        self.open_idle_action.triggered.connect(self.open_idle)
        self.restart_action.triggered.connect(self.restart)

        # Set
        self.set_wavelength_action.triggered.connect(self.set_wavelength_dialog)
        self.set_bifi_approx_wavelength_action.triggered.connect(self.set_bifi_approx_wavelength_dialog)
        self.set_bifi_motor_pos_action.triggered.connect(self.set_bifi_motor_pos_dialog)
        self.set_thin_eta_motor_pos_action.triggered.connect(self.set_thin_eta_motor_pos_dialog)

        # Scan
        self.bifi_scan_action.triggered.connect(self.start_bifi_scan)
        self.thin_eta_scan_action.triggered.connect(self.start_thin_etalon_scan)

        # Lock
        self.lock_all_action.triggered.connect(self.toggle_lock_all)
        self.lock_slow_piezo_action.triggered.connect(self.toggle_slow_piezo_lock)
        self.lock_thin_etalon_action.triggered.connect(self.toggle_thin_etalon_lock)
        self.lock_piezo_etalon_action.triggered.connect(self.toggle_piezo_etalon_lock)
        self.lock_fast_piezo_action.triggered.connect(self.toggle_fast_piezo_lock)

        # Tools

    def setup_log_window(self):
        self.layout.addWidget(self.log_area)

    @handled_function
    def setup_widgets(self):
        self.status_monitor_queue = queue.Queue(maxsize=1)
        self.status_monitor = StatusMonitor(self.matisse, self.status_monitor_queue)
        self.layout.addWidget(self.status_monitor)

    @handled_function
    def setup_matisse(self):
        try:
            self.matisse: Matisse = Matisse(device_id=sys.argv[1], wavemeter_port=sys.argv[2])
        except Exception as err:
            self.matisse: Matisse = None
            raise err

    @pyqtSlot()
    def clean_up(self):
        self.status_monitor_queue.put(ExitFlag())
        self.status_monitor.update_thread.wait()
        self.log_queue.put(ExitFlag())
        self.log_thread.wait()

    @pyqtSlot(str)
    def log(self, message):
        self.log_area.moveCursor(QTextCursor.End)
        self.log_area.insertPlainText(message)

    def error_dialog(self):
        stack = list(traceback.format_exception(*sys.exc_info()))
        # Pick length of longest line in stack, with a cutoff at 185
        desired_width = min(max([len(line) for line in stack]), 185)
        description = stack.pop()
        print(description, end='')
        # Remove entries for handled_function decorator, for clarity
        stack = filter(lambda item: os.path.join('gui', 'handled_decorators.py') not in item, stack)
        dialog = QMessageBox(icon=QMessageBox.Critical)
        dialog.setWindowTitle('Error')
        # Adding the underscores is a hack to resize the QMessageBox because it's not normally resizable.
        # This looks good in Windows, haven't tested other platforms. Sorry :(
        dialog.setText(f"{description + '_' * desired_width}\n\n{''.join(stack)}")
        dialog.exec()

    @handled_slot(bool)
    def clear_log_area(self, checked):
        self.log_area.clear()

    @handled_slot(bool)
    def open_idle(self, checked):
        print('Opening IDLE.')
        subprocess.Popen('python -m idlelib -t "Matisse Controller - Python Shell" -c "from matisse import Matisse; ' +
                         'matisse = Matisse(); print(\'Access the Matisse using \\\'matisse.[method]\\\'\')"')                    

    @handled_slot(bool)
    def restart(self, checked):
        self.exit(self.EXIT_CODE_RESTART)

    @handled_slot(bool)
    def set_wavelength_dialog(self, checked):
        target_wavelength, success = QInputDialog.getDouble(self.window,
                                                            title='Set Wavelength',
                                                            label='Wavelength (nm): ',
                                                            value=self.matisse.target_wavelength)
        if success:
            print(f"Setting wavelength to {target_wavelength} nm...")
            self.matisse.set_wavelength(target_wavelength)

    @handled_slot(bool)
    def set_bifi_approx_wavelength_dialog(self, checked):
        target_wavelength, success = QInputDialog.getDouble(self.window,
                                                            title='Set Approx. Wavelength',
                                                            label='Wavelength (nm): ',
                                                            value=self.matisse.query('MOTBI:WL?', numeric_result=True))
        if success:
            print(f"Setting BiFi approximate wavelength to {target_wavelength} nm...")
            self.matisse.set_bifi_wavelength(target_wavelength)

    @handled_slot(bool)
    def set_bifi_motor_pos_dialog(self, checked):
        target_pos, success = QInputDialog.getInt(self.window,
                                                  title='Set BiFi Motor Position',
                                                  label='Absolute Position:',
                                                  value=self.matisse.query('MOTBI:POS?', numeric_result=True))
        if success:
            print(f"Setting BiFi motor position to {target_pos}.")
            self.matisse.set_bifi_motor_pos(target_pos)

    @handled_slot(bool)
    def set_thin_eta_motor_pos_dialog(self, checked):
        target_pos, success = QInputDialog.getInt(self.window,
                                                  title='Set Thin Etalon Motor Position',
                                                  label='Absolute Position:',
                                                  value=self.matisse.query('MOTTE:POS?', numeric_result=True))
        if success:
            print(f"Setting thin etalon motor position to {target_pos}.")
            self.matisse.set_thin_etalon_motor_pos(target_pos)

    @handled_slot(bool)
    def start_bifi_scan(self, checked):
        print('Starting BiFi scan...')
        self.matisse.birefringent_filter_scan()

    @handled_slot(bool)
    def start_thin_etalon_scan(self, checked):
        print('Starting thin etalon scan...')
        self.matisse.thin_etalon_scan()

    @handled_slot(bool)
    def toggle_lock_all(self, checked):
        if checked:
            for action in self.lock_actions:
                if not action.isChecked():
                    action.trigger()
            if all([action.isChecked() for action in self.lock_actions]):
                [action.setEnabled(False) for action in self.lock_actions]
            else:
                self.lock_all_action.setChecked(False)
                print("Couldn't lock all laser components.")
        else:
            for action in reversed(self.lock_actions):
                action.trigger()
                action.setEnabled(True)

    @handled_slot(bool)
    def toggle_slow_piezo_lock(self, checked):
        print(f"{'Locking' if checked else 'Unlocking'} slow piezo.")
        self.lock_slow_piezo_action.setChecked(not checked)
        self.matisse.set_slow_piezo_lock(checked)
        self.lock_slow_piezo_action.setChecked(checked)

    @handled_slot(bool)
    def toggle_thin_etalon_lock(self, checked):
        print(f"{'Locking' if checked else 'Unlocking'} thin etalon.")
        self.lock_thin_etalon_action.setChecked(not checked)
        self.matisse.set_thin_etalon_lock(checked)
        self.lock_thin_etalon_action.setChecked(checked)

    @handled_slot(bool)
    def toggle_piezo_etalon_lock(self, checked):
        print(f"{'Locking' if checked else 'Unlocking'} piezo etalon.")
        self.lock_piezo_etalon_action.setChecked(not checked)
        self.matisse.set_piezo_etalon_lock(checked)
        self.lock_piezo_etalon_action.setChecked(checked)

    @handled_slot(bool)
    def toggle_fast_piezo_lock(self, checked):
        print(f"{'Locking' if checked else 'Unlocking'} fast piezo.")
        self.lock_fast_piezo_action.setChecked(not checked)
        self.matisse.set_piezo_etalon_lock(checked)
        self.lock_fast_piezo_action.setChecked(checked)

import sys
from contextlib import redirect_stdout                    

from gui import ControlApplication

# TODO: Assert that the user has provided these values
sys.argv.append('USB0::0x17E7::0x0102::07-40-01::INSTR')
sys.argv.append('COM5')
print(sys.argv)

exit_code = ControlApplication.EXIT_CODE_RESTART
while exit_code == ControlApplication.EXIT_CODE_RESTART:
    gui = ControlApplication([])
    with redirect_stdout(gui.log_stream):                    
        exit_code = gui.exec()                    
    del gui

# -*- coding: utf-8 -*-
# Copyright 2018 Fundament IT
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).
{
    'name': 'FIT BCNL Events',
    'category': 'Website',
    'version': '10.0.0.0.1',                    
    'author': 'Fundament IT',
    'website': 'https://fundament.it/',
    'licence': 'AGPL-3',
    'depends': ['website_event'],
    'summary':"""""",
    'description': """
Extension for the default Events module; used for BCNL, .
    """,
    'data': [
        'data/fit_actions.xml',
        'data/fit_event_views.xml',
        'data/fit_product_views.xml',
        'data/fit_res_partner_view.xml',
        'report/fit_report_subscription_view.xml',
        'security/user_groups.xml',
        'views/fit_event_views.xml',
        'views/fit_subscription_templates.xml',
        'views/fit_website_event_sale_templates.xml',
        'views/fit_website_event_templates.xml',
        'views/fit_website_templates.xml',
    ],
    'installable': True,
}

# -*- coding: utf-8 -*-
# Copyright 2018 Fundament IT
# License AGPL-3.0 or later (http://www.gnu.org/licenses/agpl).

import logging

from odoo import fields, http, _
from odoo.exceptions import ValidationError, UserError

_logger = logging.getLogger(__name__)


class WebsiteEventController(http.Controller):

    @http.route(['/fit_subscribe_controller/subscribe'], type='http', auth="public", website=True)
    def event_register(self, event_id, event_is_participating, **post):
        event_id = int(event_id)
        event_is_participating = event_is_participating
        event = http.request.env['event.event'].sudo().browse(event_id)
        subscription_update_counter = 0
        partner = http.request.env.user.partner_id
        partner_id = int(partner.id)
        if event_is_participating:
            for registration in event.registration_ids:
                for partner in registration.partner_id:
                    if partner.id == partner_id:
                        _logger.info('Found existing registration, set state to cancelled.')
                        #registration.unlink()
                        registration.state = 'cancel'
                        subscription_update_counter += 1
                        self._update_counter_subscription(event, partner, subscription_update_counter)
        else:
            #_logger.info('Search existing registration')
            existing_registration = http.request.env['event.registration'].sudo().search([('partner_id', '=', partner_id),
                                                                                          ('event_id', '=', event.id)])
            try:
                if existing_registration:
                    if event.seats_available > 0 and event.seats_availability == u'limited':
                        _logger.info('Found existing registration, set state to open (confirmed)')
                        existing_registration.state = 'open'
                        subscription_update_counter -= 1
                        self._update_counter_subscription(event, partner, subscription_update_counter)
                    else:
                        _logger.info('Found existing registration, no seats available')
                else:
                    if event.seats_available > 0 and event.seats_availability == u'limited':
                        _logger.info('No registration found, create new one')
                        http.request.env['event.registration'].sudo().create(
                            {
                                'partner_id': partner_id,
                                'event_id': event_id,
                                'name': partner.name if partner.name else '',
                                'phone': partner.mobile if partner.mobile else '',
                                'email': partner.email if partner.email else '',
                            }
                        )
                        subscription_update_counter -= 1
                        self._update_counter_subscription(event, partner, subscription_update_counter)
                    else:
                        _logger.info('No seats available')
            except ValidationError as e:
                _logger.error('Unable to register: '+str(e))

        referer = str(http.request.httprequest.headers.environ['HTTP_REFERER'])
        redirect = str('/'+referer.split('/')[-1])                    
        return http.request.redirect(redirect)

    def _update_counter_subscription(self, event, partner, subscription_update_counter):
        event_cat = str(event.event_type_id.name).lower()
        ai_monthly = http.request.env['fit.subscription'].sudo().search([('subscription_type', '=', 'ai_montly'),
                                                                        ('subscription_partner', '=', partner.id)])

        cf_monthly = http.request.env['fit.subscription'].sudo().search([('subscription_type', '=', 'cf_montly'),
                                                                        ('subscription_partner', '=', partner.id)])

        bc_monthly = http.request.env['fit.subscription'].sudo().search([('subscription_type', '=', 'bc_montly'),
                                                                        ('subscription_partner', '=', partner.id)])
        bc_tickets = http.request.env['fit.subscription'].sudo().search([('subscription_type', '=', 'bc_tickets'),
                                                                        ('subscription_partner', '=', partner.id)])
        bz_tickets = http.request.env['fit.subscription'].sudo().search([('subscription_type', '=', 'bz_tickets'),
                                                                        ('subscription_partner', '=', partner.id)])

        # If user has active all-in subscription then skip furter processing
        if ai_monthly.subscription_is_active:
            return;                    

        if event_cat == 'bokszaktraining':
            if bz_tickets:
                bz_tickets.subscription_counter += subscription_update_counter

        if event_cat == 'bootcamp':
            if bc_monthly and bc_monthly.subscription_is_active:
                return
            if cf_monthly and cf_monthly.subscription_is_active:
                return
            if bc_tickets:
                bc_tickets.subscription_counter += subscription_update_counter

import logging
from datetime import datetime

from dateutil.relativedelta import relativedelta

from odoo import fields, models, api

_logger = logging.getLogger(__name__)


class FitEvent(models.Model):
    _name = 'event.event'
    _inherit = ['event.event']

    fit_is_participating = fields.Boolean("Is Participating", compute="_fit_compute_is_participating")
    website_published = fields.Boolean(default=True)
    fit_day_of_week = fields.Char(string='Dag', default='')
    fit_repetition_enabled = fields.Boolean(string='Herhalen?', default=False)
    fit_repetition = fields.Selection([('daily', 'Dagelijks'),
                                       ('weekly', 'Wekelijks'),
                                       ('monthly', 'Maandelijks')], string="Schema herhaling")

    def _fit_compute_is_participating(self):
        # we don't allow public user to see participating label
        if self.env.user != self.env.ref('base.public_user'):
            email = self.env.user.partner_id.email
            for event in self:
                domain = ['&', '|', ('email', '=', email), ('partner_id', '=', self.env.user.partner_id.id), ('event_id', '=', event.id),
                          ('state', '=', 'open')]
                count = self.env['event.registration'].search_count(domain)
                if count > 0:
                    event.fit_is_participating = True
                else:
                    event.fit_is_participating = False

    @api.onchange('date_begin')
    def update_day_of_week(self):
        start_date = self.date_begin_located
        if start_date:
            self.fit_day_of_week = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S').strftime('%a')

    def get_attendee_list(self):
        attendee_list = str('')
        counter = 1
        reg_ids = self.sudo().registration_ids
        reg_ids = sorted(reg_ids, key=lambda x: x.date_open, reverse=False)
        for registration in reg_ids:
            if registration.state == 'open':
                if counter == 1:
                    attendee_list += registration.partner_id.sudo().name
                else:
                    attendee_list += ', ' + registration.partner_id.sudo().name
                counter += 1
        return attendee_list

    def start_automatic_event_creation(self):
        repeating_event_ids = self.env['event.event'].search([('fit_repetition_enabled', '=', True)])
        for repeating_event in repeating_event_ids:
            _logger.info('Found repeating event: ' + repeating_event.name)
            if repeating_event.fit_repetition == 'daily':
                self._handle_daily_event_repetition(repeating_event)
            if repeating_event.fit_repetition == 'weekly':
                self._handle_weekly_event_repetition(repeating_event)
            if repeating_event.fit_repetition == 'monthly':
                self._handle_montly_event_repetition(repeating_event)

    def _handle_daily_event_repetition(self, old_repeating_event):
        _logger.info('Handling daily repeating event')
        end_date = datetime.strptime(old_repeating_event.date_end, '%Y-%m-%d %H:%M:00')                    
        present = datetime.now()
        if present >= end_date:
            new_start_date = datetime.strptime(old_repeating_event.date_begin, '%Y-%m-%d %H:%M:00') + relativedelta(days=+1)                    
            new_end_date = end_date + relativedelta(days=+1)
            if self._event_does_not_exist(old_repeating_event, new_end_date):
                self._create_new_event(old_repeating_event, new_start_date, new_end_date)

    def _handle_weekly_event_repetition(self, old_repeating_event):
        _logger.info('Handling weekly repeating event')
        end_date = datetime.strptime(old_repeating_event.date_end, '%Y-%m-%d %H:%M:00')                    
        present = datetime.now()
        if present >= end_date:
            new_start_date = datetime.strptime(old_repeating_event.date_begin, '%Y-%m-%d %H:%M:00') + relativedelta(days=+7)                    
            new_end_date = end_date + relativedelta(days=+7)
            if self._event_does_not_exist(old_repeating_event, new_end_date):
                self._create_new_event(old_repeating_event, new_start_date, new_end_date)

    def _handle_monthly_event_repetition(self, old_repeating_event):
        _logger.info('Handling monthly repeating event')
        end_date = datetime.strptime(old_repeating_event.date_end, '%Y-%m-%d %H:%M:00')                    
        present = datetime.now()
        if present >= end_date:
            new_start_date = datetime.strptime(old_repeating_event.date_begin, '%Y-%m-%d %H:%M:00') + relativedelta(months=+1)                    
            new_end_date = end_date + relativedelta(months=+1)
            if self._event_does_not_exist(old_repeating_event, new_end_date):
                self._create_new_event(old_repeating_event, new_start_date, new_end_date)

    def _event_does_not_exist(self, old_repeating_event, new_end_date):
        _logger.info('Checking new event existence: ' + old_repeating_event.name + ', date: ' + str(new_end_date))
        old_event_cat = old_repeating_event.event_type_id.id
        existing_event = self.env['event.event'].search([('event_type_id', '=', old_event_cat), ('date_end', '=', str(new_end_date))])
        if existing_event:
            return False
        else:
            return True

    def _create_new_event(self, old_repeating_event, new_start_date, new_end_date):
        _logger.info('Start creation new repeating event')
        new_repeating_event = old_repeating_event.copy(default={'website_published': True})
        new_repeating_event.date_end = new_end_date
        new_repeating_event.date_begin = new_start_date

        # 'date_begin': str(new_start_date), 'date_end_': str(new_end_date),
        old_repeating_event.fit_repetition_enabled = False
        old_repeating_event.fit_repetition = ''

import logging
from datetime import datetime

from dateutil.relativedelta import relativedelta

from odoo import fields, models

_logger = logging.getLogger(__name__)


class Partner(models.Model):
    _name = 'res.partner'
    _inherit = ['res.partner']

    fit_subscriptions = fields.One2many(comodel_name='fit.subscription', inverse_name='subscription_partner', string='Inschrijving',
                                        store='True')
    fit_subscription_count = fields.Integer('# Inschrijvingen', compute='_compute_total_scubscriptions')

    def _compute_total_scubscriptions(self):
        counter = 0
        for subscription in self.fit_subscriptions:
            counter += 1
        self.fit_subscription_count = counter

    def can_subscribe(self, event):
        can_subscribe = False
        event_type = str(event.event_type_id.name).lower()
        event_start = datetime.strptime(event.date_begin, '%Y-%m-%d %H:%M:%S')
        if event_type == 'open' and len(self.fit_subscriptions) > 0:                    
            _logger.info('Can subscribe for open event id: %s, name: %s', event.event_type_id.name, event.name)                    
            return True                    
        if event_start < datetime.now():
            return False
        if (event_start + relativedelta(hours=-24)) > datetime.now() and event_type == 'crosstraining':
            return False
        for subscription in self.fit_subscriptions:
            if subscription._can_subscribe(event.event_type_id):
                _logger.info('Can subscribe for event id: %s, name: %s', event.event_type_id.name, event.name)
                can_subscribe = True
        return can_subscribe

    def can_unsubscribe(self, event):
        event_start = datetime.strptime(event.date_begin_located, '%Y-%m-%d %H:%M:%S')
        if event_start < datetime.now():
            return False
        return True                    

from django.shortcuts import render                    

from .models import Post

# Create your views here.
def home(request):
    posts = Post.objects.order_by('pub_date')                    
    return render(request, 'posts/home.html', {'posts':posts})

def post_details(request, post_id):
    return render(request, 'posts/posts_detail.html', {'post_id':post_id})                    

from django.shortcuts import render, get_object_or_404, reverse, redirect, HttpResponse
from django.urls import reverse_lazy
from django.views import View
from django.views.generic import CreateView, ListView, UpdateView, DeleteView
from django.contrib.auth.mixins import LoginRequiredMixin
from .forms import ShortUrlForm, JustURLForm, CategoryModelForm, ManyURLSForm, JustULRUpdateForm, \
    CategoryUpdateModelForm, CounterCountingForm
from .models import JustURL, Category, ClickTracking
from .utils import create_short_url, token_generator, generate_csv, get_client_ip, check_input_url
import re


class HomeView(View):
    def get(self, request, *args, **kwargs):
        form = ShortUrlForm()
        return render(request, 'home.html', {'form': form})

    def post(self, request, *args, **kwargs):
        form = ShortUrlForm(request.POST or None)
        if form.is_valid():
            url = form.cleaned_data['input_url']
            category = form.cleaned_data['category']
            created = JustURL.objects.create(input_url=url, category=category)
            short_url = create_short_url(created)
            created.short_url = f'{request.get_host()}/{short_url}'
            created.save()
            if request.user.is_superuser:
                return redirect(reverse('url-detail-view', kwargs={'pk': created.pk}))
            return redirect(reverse('success-url-view', kwargs={'pk': created.pk}))
        return render(request, 'home.html', {'form': form})


class SuccessUrlView(View):
    def get(self, request, pk, *args, **kwargs):
        object = JustURL.objects.get(pk=pk)
        form = CounterCountingForm()
        return render(request, 'success-url-view.html', {'object': object,
                                                         'form': form})

    def post(self, request, pk, *args, **kwargs):
        object = JustURL.objects.get(pk=pk)
        form = CounterCountingForm(request.POST or None)
        if form.is_valid():
            object.count += 1                    
            ip = get_client_ip(request)
            client_agent = request.META['HTTP_USER_AGENT']
            clicktracker = ClickTracking.objects.create(
                client_ip=ip,
                user_agent=client_agent,
            )
            clicktracker.url.add(object)
            clicktracker.save()
            object.save()                    
            return link_redirect(request, pk)                    
        return redirect('home-view')


class URLDetailView(LoginRequiredMixin, View):
    def get(self, request, pk, *args, **kwargs):
        form = CounterCountingForm()
        object = JustURL.objects.get(pk=pk)
        return render(request, 'url-detail-view.html', {'object': object,
                                                        'form': form})

    def post(self, request, pk, *args, **kwargs):
        object = JustURL.objects.get(pk=pk)
        form = CounterCountingForm(request.POST or None)
        if form.is_valid():
            object.count += 1                    
            ip = get_client_ip(request)
            client_agent = request.META['HTTP_USER_AGENT']
            clicktracker = ClickTracking.objects.create(
                client_ip=ip,
                user_agent=client_agent,
            )
            clicktracker.url.add(object)
            clicktracker.save()
            object.save()                    
            return link_redirect(request, pk)                    
        return render(request, 'url-detail-view.html', {'object': object,
                                                        'form': form})


class URLUpdateView(LoginRequiredMixin, UpdateView):
    queryset = JustURL.objects.all()
    form_class = JustULRUpdateForm
    template_name = 'url-update-view.html'


class URLDeleteView(LoginRequiredMixin, DeleteView):
    model = JustURL
    template_name = 'url-delete-view.html'
    success_url = reverse_lazy('home-view')


class CustomShortURLCreateView(View):
    def get(self, request, *args, **kwargs):
        form = JustURLForm()
        return render(request, 'custom-short-url.html', {'form': form})

    def post(self, request, *args, **kwargs):
        form = JustURLForm(request.POST or None)
        if form.is_valid():
            url = form.cleaned_data['input_url']
            short_url = form.cleaned_data['short_url']
            category = form.cleaned_data['category']
            if JustURL.objects.filter(short_url__contains=short_url).exists():
                message = 'Token is already in use'
                return render(request, 'custom-short-url.html', {'form': JustURLForm,
                                                                 'message': message})
            created = JustURL.objects.create(input_url=url, short_url=f'{request.get_host()}/{short_url}',
                                             category=category)
            created.save()
            if request.user.is_superuser:
                return redirect(reverse('url-detail-view', kwargs={'pk': created.pk}))
            return redirect(reverse('success-url-view', kwargs={'pk': created.pk}))
        return render(request, 'home.html', {'form': form})


class ShortManyURLSView(View):
    def get(self, request, *args, **kwargs):
        form = ManyURLSForm()
        return render(request, 'short-many-urls.html', {'form': form})

    def post(self, request, *args, **kwargs):
        form = ManyURLSForm(request.POST or None)
        if form.is_valid():
            urls = form.cleaned_data['input_url']
            urls_list = re.findall(r"[\w.']+", urls)
            data_list = []
            for url in urls_list:
                result = check_input_url(url)
                instance = JustURL.objects.create(input_url=result,
                                                  short_url=f'{request.get_host()}/{token_generator()}')
                instance.save()
                data = [instance.input_url, instance.short_url]
                data_list.append(data)

            response = HttpResponse(content_type='text/csv')
            response['Content-Disposition'] = 'attachment; filename="many_urls.csv"'
            return generate_csv(data_list, response)
        return redirect('home-view')


class CategoryCreateView(LoginRequiredMixin, CreateView):
    template_name = 'category-create-view.html'
    form_class = CategoryModelForm


class CategoryListView(LoginRequiredMixin, ListView):
    queryset = Category.objects.all().order_by('name')
    template_name = 'category-list-view.html'
    paginate_by = 15

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        quantity = 0
        urls_without_category = JustURL.objects.filter(category=None).count()
        print(urls_without_category)
        queryset = Category.objects.all()
        for cat in queryset:
            quantity += cat.justurl_set.all().count()
        context['number_of_links'] = quantity
        context['urls_without_category'] = urls_without_category
        return context


class CategoryDetailView(LoginRequiredMixin, View):
    def get(self, request, pk, *args, **kwargs):
        object = Category.objects.get(pk=pk)
        visits = sum(link.count for link in object.justurl_set.all())
        return render(request, 'category-detail-view.html', {'object': object,
                                                             'visits': visits})


class CategoryUpdateView(LoginRequiredMixin, UpdateView):
    queryset = Category.objects.all()
    form_class = CategoryUpdateModelForm
    template_name = 'category-update-view.html'
    success_url = reverse_lazy('category-list-view')


class CategoryDeleteView(LoginRequiredMixin, DeleteView):
    model = Category
    template_name = 'category-delete-view.html'
    success_url = reverse_lazy('category-list-view')


class ClickTrackingDetailView(LoginRequiredMixin, View):
    def get(self, request, pk, *args, **kwargs):
        object = get_object_or_404(JustURL, pk=pk)
        reports = object.clicktracking_set.all().order_by('timestamp')
        return render(request, 'clicktracking-detail-view.html', {'object': object,
                                                                  'reports': reports})


def link_redirect(request, pk):                    
    instance = get_object_or_404(JustURL, pk=pk)                    
    return redirect(instance.input_url)

from django.contrib import admin
from django.urls import re_path
from Shortener_App.views import (
    HomeView,
    SuccessUrlView,
    CustomShortURLCreateView,
    ShortManyURLSView,
    URLDetailView,
    URLUpdateView,
    URLDeleteView,
    CategoryCreateView,
    CategoryListView,
    CategoryDetailView,
    CategoryUpdateView,
    CategoryDeleteView,
    ClickTrackingDetailView,
    link_redirect
)

urlpatterns = [
    re_path(r'admin/', admin.site.urls),
    #  urls
    re_path(r'^$', HomeView.as_view(), name='home-view'),
    re_path(r'^success/(?P<pk>(\d)+)/$', SuccessUrlView.as_view(), name='success-url-view'),
    re_path(r'^add-custom/$', CustomShortURLCreateView.as_view(), name='add-custom-url'),
    re_path(r'^add-many/$', ShortManyURLSView.as_view(), name='add-many-urls'),
    re_path(r'^detail/(?P<pk>(\d)+)/$', URLDetailView.as_view(), name='url-detail-view'),
    re_path(r'^update/(?P<pk>(\d)+)/$', URLUpdateView.as_view(), name='url-update-view'),
    re_path(r'^delete/(?P<pk>(\d)+)/$', URLDeleteView.as_view(), name='url-delete-view'),
    #  categories
    re_path(r'^category/add/$', CategoryCreateView.as_view(), name='category-create-view'),
    re_path(r'^categories/$', CategoryListView.as_view(), name='category-list-view'),
    re_path(r'^detail/category/(?P<pk>(\d)+)/$', CategoryDetailView.as_view(), name='category-detail-view'),
    re_path(r'^update/category/(?P<pk>(\d)+)/$', CategoryUpdateView.as_view(), name='category-update-view'),
    re_path(r'^delete/category/(?P<pk>(\d)+)/$', CategoryDeleteView.as_view(), name='category-delete-view'),
    #  click tracking
    re_path(r'^(?P<pk>(\d)+)/reports/$', ClickTrackingDetailView.as_view(), name='clicktracking-detail-view'),
    #  redirecting
    re_path(r'^(?P<pk>(\d)+)/$', link_redirect, name='url-redirect-view'),                    
]

from threading import Thread, Lock
import logging
import sys
import time
import hyperion.lib.util.config as config
from os import system
from subprocess import call
from psutil import Process, NoSuchProcess
is_py2 = sys.version[0] == '2'
if is_py2:
    import Queue as Queue
else:
    import queue as Queue
    

class ComponentMonitorJob(object):
    """Abstract class that represents a component monitoring job (local or remote)."""

    def __init__(self, pid, comp_name):
        """Initializes component monitoring job.

        :param pid: Process id of the component
        :type pid: int
        :param comp_name: Name of the component
        :type comp_name: str
        """
        self.pid = pid
        self.comp_name = comp_name

    def run_check(self):
        """You need to override this function in monitoring subclasses. It is called in the main monitoring thread.

        :return: True on a successful check, otherwise a CrashEvent is generated
        :rtype: bool or CrashEvent
        """


class LocalComponentMonitoringJob(ComponentMonitorJob):
    """Class that represents a local component monitoring job."""

    def __init__(self, pid, comp_name):
        """Creates a monitoring job for a local component.

        :param pid: Process id of the component
        :type pid: int
        :param comp_name: Name of the component
        :type comp_name: str
        """

        super(LocalComponentMonitoringJob, self).__init__(pid, comp_name)

    def run_check(self):
        """Runs a check if the pid exists and has not finished yet.

        :return: True if the component is running, otherwise returns a generated ``LocalCrashEvent``
        :rtype bool or LocalCrashEvent
        """
        try:
            proc = Process(self.pid)
            if proc.is_running():
                return True
        except NoSuchProcess:
            pass
        return CrashEvent(self.comp_name)

    def info(self):
        """Generate a status information for the job describing what is being monitored.

        :return: Information about this job
        :rtype: str
        """

        return "Running check for local component %s with pid %s" % (self.comp_name, self.pid)


class RemoteComponentMonitoringJob(ComponentMonitorJob):
    """Class that represents a remote component monitoring job."""

    def __init__(self, pid, comp_name, hostname, host_status):
        """Creates a remote component monitoring job.

        :param pid: Process id on the remote machine
        :type pid: int
        :param comp_name: Name of the monitored component
        :type comp_name: str
        :param hostname: Name of the host running the component
        :type hostname: str
        """

        super(RemoteComponentMonitoringJob, self).__init__(pid, comp_name)
        self.hostname = hostname
        self.host_status = host_status

    def run_check(self):
        """Runs a check if a remote process is still running.

        :return: True if the component is still running or the host is not reachable, otherwise a ``RemoteCrashEvent`` is generated.
        :rtype: bool or RemoteCrashEvent
        """

        if self.host_status.get(self.hostname):
            cmd = 'ssh -F %s %s "ps -p %s > /dev/null"' % (config.CUSTOM_SSH_CONFIG_PATH, self.hostname, self.pid)
            if call(cmd, shell=True) == 0:
                return True
            else:
                return RemoteCrashEvent(self.comp_name, self.hostname)
        # Return true because no information can be retrieved. The connection to the host has to be reestablished first.
        return True

    def info(self):
        """Generate a status information for the job describing what is being monitored.

        :return: Information about this job
        :rtype: str
        """

        return "Running check for remote component %s with pid %s on host %s" % (self.comp_name, self.pid,
                                                                                 self.hostname)


class HostMonitorJob(object):
    """Class representing a host monitoring job."""
    def __init__(self, pid, hostname, host_status, host_lock):
        """Create host monitoring job.

        :param pid: Process id of the ssh connection
        :type pid: int
        :param hostname: Name of the host connected to
        :type hostname: str
        :param host_status: Status of the used hosts
        :type host_status: dict
        :param host_lock: Lock that has to be acquired in order to write to the host status dictionary.
        :type host_lock: Lock
        """
        self.pid = pid
        self.hostname = hostname
        self.host_status = host_status
        self.host_lock = host_lock

    def run_check(self):
        try:
            proc = Process(self.pid)
            if proc.is_running() and system("exec >(ping %s -c 10 >/dev/null) </dev/null" % self.hostname) is 0:                    
                return True
        except NoSuchProcess:
            pass

        self.host_lock.acquire()
        self.host_status[self.hostname] = None
        self.host_lock.release()

        return DisconnectEvent(self.hostname)

    def info(self):
        return "Running ssh host check for %s with pid %s" % (self.hostname, self.pid)


class CrashEvent(object):
    """Superclass to model a component crash.

    Provides the name of the crashed component."""

    def __init__(self, comp_name):
        """Initializes the crash event assigning the component name

        :param comp_name: Name of the crashed component
        :type comp_name: str
        """

        self.comp_name = comp_name


class LocalCrashEvent(CrashEvent):
    """Crash event subclass for local component crashes.

    Provides the name of the crashed component and a short message.
    """

    def __init__(self, comp_name):
        """Creates a local crash event class with a component name and generates a short message.

        :param comp_name: Name of the crashed component
        :type comp_name: str
        """

        super(LocalCrashEvent, self).__init__(comp_name)
        self.message = 'Component %s crashed on localhost' % comp_name


class RemoteCrashEvent(CrashEvent):
    """Crash event subclass for remote component crashes.

    Provides the name of the crashed component along with the host it ran on and a short message.
    """

    def __init__(self, comp_name, hostname):
        """Creates a remote crash event with a component name and a host generating a short message.

        :param comp_name: Name of the crashed component
        :type comp_name: str
        :param hostname: Name of the host the component was running on
        :type hostname: str
        """

        super(RemoteCrashEvent, self).__init__(comp_name)
        self.hostname = hostname
        self.message = 'Component %s crashed on remote host %s' % (comp_name, hostname)


class DisconnectEvent(object):
    """Class representing a disconnect event for remote hosts."""

    def __init__(self, hostname):
        """Creates a disconnect event with a hostname and generates a short message."""
        self.hostname = hostname
        self.message = 'Lost connection to remote host %s' % hostname


class MonitoringThread(Thread):
    """This class is monitoring thread that extends the threading.Thread class."""

    def __init__(self, queue):
        """Initializes the monitoring thread with its input queue.

        :param queue: Input queue the monitor retrieves its jobs from
        :type queue: Queue.Queue
        """

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.debug("Initialized thread")
        super(MonitoringThread, self).__init__()
        self.job_queue = queue
        self.subscribed_queues = []
        self.end = False

    def kill(self):
        """Shuts down the thread by signalling the run function to end.

        :return: None
        """

        logger = logging.getLogger(__name__)
        logger.debug("Killing process monitoring thread")
        self.end = True

    def add_subscriber(self, queue):
        """Adds a subscriber to the list of queues to send notifications to.

        :param queue: Subscribing queue that will get notifications by this thread
        :type queue: Queue.Queue
        :return: None
        """

        logger = logging.getLogger(__name__)
        logger.debug("Added subscriber")
        self.subscribed_queues.append(queue)

    def run(self):
        """Starts the monitoring thread.

        :return: None
        """

        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        logger.debug("Started run funtion")
        while not self.end:

            comp_jobs = []
            jobs = []
            already_handleled = {}
            # Get all enqueued jobs for this iteration
            while not self.job_queue.empty():
                mon_job = self.job_queue.get()
                if isinstance(mon_job, HostMonitorJob):
                    jobs.append(mon_job)
                if isinstance(mon_job, ComponentMonitorJob) and mon_job.comp_name not in already_handleled:
                    comp_jobs.append(mon_job)
                    already_handleled[mon_job.comp_name] = True

            # Reorder job list to first check the hosts, then check the components because this makes sense
            jobs.extend(comp_jobs)
            for mon_job in jobs:
                logger.debug(mon_job.info())
                ret = mon_job.run_check()
                if ret is True:
                    logger.debug("S'all good man")
                    # If job is ok, put it back for the next iteration
                    self.job_queue.put(mon_job)
                else:
                    # If job is not ok, notify subscribers
                    logger.debug("Check failed, notifying subscribers")
                    for subscriber in self.subscribed_queues:
                        subscriber.put(ret)

            time.sleep(1)

# -*- coding: utf-8 -*-
import re

from django import forms
from django.contrib.contenttypes.models import ContentType
from django.utils.translation import ugettext_lazy as _

from wiki.models import Article
from wiki.models import ChangeSet
from wiki.templatetags.wiki_extras import WIKI_WORD_RE

wikiword_pattern = re.compile('^' + WIKI_WORD_RE + '$')


class ArticleForm(forms.ModelForm):

    summary = forms.CharField(widget=forms.Textarea)

    comment = forms.CharField(required=False)
    user_ip = forms.CharField(widget=forms.HiddenInput)

    content_type = forms.ModelChoiceField(
        queryset=ContentType.objects.all(),
        required=False,
        widget=forms.HiddenInput)
    object_id = forms.IntegerField(required=False,
                                   widget=forms.HiddenInput)

    action = forms.CharField(widget=forms.HiddenInput)

    class Meta:
        model = Article
        exclude = ('creator', 'creator_ip',
                   'group', 'created_at', 'last_update')

    def clean_title(self):
        """Check for some errors regarding the title:                    
            1. Check for bad characters                    
            2. Check for reserved titles                    

            Checking for existing articles is done by Django on Database level                    
            """                    
        title = self.cleaned_data['title']
        if not wikiword_pattern.match(title):
            raise forms.ValidationError(_('The title contain bad characters.'))                    

        cs = ChangeSet.objects.filter(old_title=title).count()                    
        if cs > 0:                    
            raise forms.ValidationError(
                _('The title %(title)s is reserved for redirects or old links.'), params={'title': title},)                    
        # No errors
        return title

    def clean(self):
        super(ArticleForm, self).clean()
        kw = {}

        if self.cleaned_data['action'] == 'create':
            try:
                kw['title'] = self.cleaned_data['title']
                kw['content_type'] = self.cleaned_data['content_type']
                kw['object_id'] = self.cleaned_data['object_id']
            except KeyError:
                pass  # some error in this fields

        return self.cleaned_data

    def cache_old_content(self):
        if self.instance.id is None:
            self.old_title = self.old_content = self.old_markup = ''
            self.is_new = True
        else:
            self.old_title = self.instance.title
            self.old_content = self.instance.content
            self.old_markup = self.instance.markup
            self.is_new = False

    def save(self, *args, **kwargs):
        # 0 - Extra data
        editor_ip = self.cleaned_data['user_ip']
        comment = self.cleaned_data['comment']

        # 2 - Save the Article
        article = super(ArticleForm, self).save(*args, **kwargs)

        # 3 - Set creator and group
        editor = getattr(self, 'editor', None)
        group = getattr(self, 'group', None)
        if self.is_new:
            article.creator_ip = editor_ip
            if editor is not None:
                article.creator = editor
                article.group = group
            article.save(*args, **kwargs)

        # 4 - Create new revision
        changeset = article.new_revision(
            self.old_content, self.old_title, self.old_markup,
            comment, editor_ip, editor)

        return article, changeset

# -*- coding: utf-8 -*-

from datetime import datetime

from django.conf import settings
from django.core.cache import cache
from django.template import RequestContext
from django.core.urlresolvers import reverse
from django.http import (Http404, HttpResponseRedirect,
                         HttpResponseNotAllowed, HttpResponse, HttpResponseForbidden)
from django.shortcuts import get_object_or_404, render_to_response, redirect
from django.contrib.contenttypes.models import ContentType
from django.contrib import messages
from django.core.exceptions import ObjectDoesNotExist                    
from wiki.forms import ArticleForm
from wiki.models import Article, ChangeSet, dmp

from wiki.utils import get_ct
from django.contrib.auth.decorators import login_required

from wl_utils import get_real_ip
import re

# Settings
#  lock duration in minutes
try:
    WIKI_LOCK_DURATION = settings.WIKI_LOCK_DURATION
except AttributeError:
    WIKI_LOCK_DURATION = 15

try:
    from notification import models as notification
except ImportError:
    notification = None

# default querysets
ALL_ARTICLES = Article.objects.all()
ALL_CHANGES = ChangeSet.objects.all()


def get_articles_by_group(article_qs, group_slug=None,
                          group_slug_field=None, group_qs=None):
    group = None
    if group_slug is not None:
        group = get_object_or_404(group_qs,
                                  **{group_slug_field: group_slug})
        article_qs = article_qs.filter(content_type=get_ct(group),
                                       object_id=group.id)
    return article_qs, group


def get_articles_for_object(object, article_qs=None):
    if article_qs is None:
        article_qs = ALL_ARTICLES
    return article_qs.filter(content_type=get_ct(object),
                             object_id=object.id)


def get_url(urlname, group=None, args=None, kw=None):
    if group is None:
        return reverse(urlname, args=args)
    else:
        app = group._meta.app_label
        urlconf = '.'.join([app, 'urls'])
        url = reverse(urlname, urlconf, kwargs=kw)
        return ''.join(['/', app, url])  # @@@ harcoded: /app/.../

# NOCOMM Franku: This Class is currently not used
# If we want this it has to be checked for the changes
# related to django 1.8.
# A javascript alert box is maybe a better solution


class ArticleEditLock(object):
    """A soft lock to edting an article."""

    def __init__(self, title, request, message_template=None):
        self.title = title
        self.user_ip = get_real_ip(request)
        self.created_at = datetime.now()

        if message_template is None:
            message_template = ('Possible edit conflict:'
                                ' another user started editing this article at %s')

        self.message_template = message_template

        cache.set(title, self, WIKI_LOCK_DURATION * 60)

    def create_message(self, request):
        """Send a message to the user if there is another user editing this
        article."""
        if not self.is_mine(request):
            user = request.user
            user.message_set.create(
                message=self.message_template % self.created_at)

    def is_mine(self, request):
        return self.user_ip == get_real_ip(request)


def has_read_perm(user, group, is_member, is_private):
    """ Return True if the user has permission to *read*
    Articles, False otherwise.
    """
    if (group is None) or (is_member is None) or is_member(user, group):
        return True
    if (is_private is not None) and is_private(group):
        return False
    return True


def has_write_perm(user, group, is_member):
    """Return True if the user have permission to edit Articles, False
    otherwise."""
    if (group is None) or (is_member is None) or is_member(user, group):
        return True
    return False


def article_list(request,
                 group_slug=None, group_slug_field=None, group_qs=None,
                 article_qs=ALL_ARTICLES,
                 ArticleClass=Article,
                 template_name='index.html',
                 template_dir='wiki',
                 extra_context=None,
                 is_member=None,
                 is_private=None,
                 *args, **kw):
    if request.method == 'GET':
        articles, group = get_articles_by_group(
            article_qs, group_slug,
            group_slug_field, group_qs)

        allow_read = has_read_perm(request.user, group, is_member, is_private)
        allow_write = has_write_perm(request.user, group, is_member)

        if not allow_read:
            return HttpResponseForbidden()

        articles = articles.order_by('title')

        template_params = {'articles': articles,
                           'allow_write': allow_write}

        if group_slug is not None:
            template_params['group'] = group
            new_article = ArticleClass(title='NewArticle',
                                       content_type=get_ct(group),
                                       object_id=group.id)
        else:
            new_article = ArticleClass(title='NewArticle')
        template_params['new_article'] = new_article
        if extra_context is not None:
            template_params.update(extra_context)

        return render_to_response('/'.join([template_dir, template_name]),
                                  template_params,
                                  context_instance=RequestContext(request))
    return HttpResponseNotAllowed(['GET'])


def view_article(request, title, revision=None,
                 ArticleClass=Article,  # to create an unsaved instance
                 group_slug=None, group_slug_field=None, group_qs=None,
                 article_qs=ALL_ARTICLES,
                 template_name='view.html',
                 template_dir='wiki',
                 extra_context=None,
                 is_member=None,
                 is_private=None,
                 *args, **kw):

    if request.method == 'GET':
        article_args = {'title': title}
        if group_slug is not None:
            group = get_object_or_404(
                group_qs, **{group_slug_field: group_slug})
            article_args.update({'content_type': get_ct(group),
                                 'object_id': group.id})
            allow_read = has_read_perm(request.user, group, is_member,
                                       is_private)
            allow_write = has_write_perm(request.user, group, is_member)
        else:
            allow_read = allow_write = True

        if not allow_read:
            return HttpResponseForbidden()

        is_observing = False
        redirected_from = None
        try:
            article = article_qs.get(**article_args)
            if notification is not None:
                is_observing = notification.is_observing(article, request.user)
        except ArticleClass.DoesNotExist:
            try:
                # try to find an article that once had this title
                article = ChangeSet.objects.filter(
                    old_title=title).order_by('-revision')[0].article
                redirected_from = title
                # if article is not None:
                #    return redirect(article, permanent=True)
            except IndexError:
                article = ArticleClass(**article_args)

        if revision is not None:
            changeset = get_object_or_404(
                article.changeset_set, revision=revision)
            article.content = changeset.get_content()

        template_params = {'article': article,
                           'revision': revision,
                           'redirected_from': redirected_from,
                           'allow_write': allow_write}

        if notification is not None:
            template_params.update({'is_observing': is_observing,
                                    'can_observe': True})

        if group_slug is not None:
            template_params['group'] = group
        if extra_context is not None:
            template_params.update(extra_context)

        return render_to_response('/'.join([template_dir, template_name]),
                                  template_params,
                                  context_instance=RequestContext(request))
    return HttpResponseNotAllowed(['GET'])


@login_required
def edit_article(request, title,
                 group_slug=None, group_slug_field=None, group_qs=None,
                 article_qs=ALL_ARTICLES,
                 ArticleClass=Article,  # to get the DoesNotExist exception
                 ArticleFormClass=ArticleForm,
                 template_name='edit.html',
                 template_dir='wiki',
                 extra_context=None,
                 check_membership=False,
                 is_member=None,
                 is_private=None,
                 *args, **kw):

    group = None
    article_args = {'title': title}
    if group_slug is not None:
        group = get_object_or_404(group_qs, **{group_slug_field: group_slug})
        group_ct = get_ct(group)
        article_args.update({'content_type': group_ct,
                             'object_id': group.id})
        allow_read = has_read_perm(request.user, group, is_member,
                                   is_private)
        allow_write = has_write_perm(request.user, group, is_member)
    else:
        allow_read = allow_write = True

    if not allow_write:
        return HttpResponseForbidden()

    try:
        article = article_qs.get(**article_args)
    except ArticleClass.DoesNotExist:
        article = None                    

    if request.method == 'POST':

        form = ArticleFormClass(request.POST, instance=article)
        
        form.cache_old_content()
        if form.is_valid():

            if request.user.is_authenticated():
                form.editor = request.user

            if ((article is None) and (group_slug is not None)):
                form.group = group

            new_article, changeset = form.save()

            return redirect(new_article)

    elif request.method == 'GET':
        user_ip = get_real_ip(request)

        # NOCOMM FrankU: Never worked IMHO
        # lock = cache.get(title, None)
        # if lock is None:
        #     lock = ArticleEditLock(title, request)
        # lock.create_message(request)

        initial = {'user_ip': user_ip}
        if group_slug is not None:
            initial.update({'content_type': group_ct.id,
                            'object_id': group.id})

        if article is None:
            initial.update({'title': title,
                            'action': 'create'})
            form = ArticleFormClass(initial=initial)
        else:
            initial['action'] = 'edit'
            form = ArticleFormClass(instance=article,
                                    initial=initial)
    if not article:
        template_params = {'form': form, 'new_article': True}
    else:
        template_params = {'form': form, 'new_article': False,
                           'content_type': ContentType.objects.get_for_model(Article).pk, 'object_id': article.pk,
                           'images': article.all_images(),
                           'article': article,
                           }

    if group_slug is not None:
        template_params['group'] = group
    if extra_context is not None:
        template_params.update(extra_context)

    return render_to_response('/'.join([template_dir, template_name]),
                              template_params,
                              context_instance=RequestContext(request))


def view_changeset(request, title, revision,
                   revision_from=None,
                   group_slug=None, group_slug_field=None, group_qs=None,
                   article_qs=ALL_ARTICLES,
                   changes_qs=ALL_CHANGES,
                   template_name='changeset.html',
                   template_dir='wiki',
                   extra_context=None,
                   is_member=None,
                   is_private=None,
                   *args, **kw):

    if request.method == 'GET':
        article_args = {'article__title': title}
        if group_slug is not None:
            group = get_object_or_404(
                group_qs, **{group_slug_field: group_slug})
            article_args.update({'article__content_type': get_ct(group),
                                 'article__object_id': group.id})
        changeset = get_object_or_404(
            changes_qs,
            revision=int(revision),
            **article_args)

        article_args = {'title': title}
        if group_slug is not None:
            group = get_object_or_404(
                group_qs, **{group_slug_field: group_slug})
            article_args.update({'content_type': get_ct(group),
                                 'object_id': group.id})
            allow_read = has_read_perm(request.user, group, is_member,
                                       is_private)
            allow_write = has_write_perm(request.user, group, is_member)
        else:
            allow_read = allow_write = True

        if not allow_read:
            return HttpResponseForbidden()

        article = article_qs.get(**article_args)

        if revision_from is None:
            revision_from = int(revision) - 1

        from_value = None
        if int(revision) is not int(revision_from) + 1:
            from_value = revision_from

        template_params = {'article': article,
                           'article_title': article.title,
                           'changeset': changeset,
                           'differences': changeset.compare_to(revision_from),
                           'from': from_value,
                           'to': revision,
                           'allow_write': allow_write}

        if group_slug is not None:
            template_params['group'] = group
        if extra_context is not None:
            template_params.update(extra_context)

        return render_to_response('/'.join([template_dir, template_name]),
                                  template_params,
                                  context_instance=RequestContext(request))
    return HttpResponseNotAllowed(['GET'])


def article_history(request, title,
                    group_slug=None, group_slug_field=None, group_qs=None,
                    article_qs=ALL_ARTICLES,
                    template_name='history.html',
                    template_dir='wiki',
                    extra_context=None,
                    is_member=None,
                    is_private=None,
                    *args, **kw):

    if request.method == 'GET':

        article_args = {'title': title}
        if group_slug is not None:
            group = get_object_or_404(
                group_qs, **{group_slug_field: group_slug})
            article_args.update({'content_type': get_ct(group),
                                 'object_id': group.id})
            allow_read = has_read_perm(request.user, group, is_member,
                                       is_private)
            allow_write = has_write_perm(request.user, group, is_member)
        else:
            allow_read = allow_write = True

        if not allow_read:
            return HttpResponseForbidden()

        article = get_object_or_404(article_qs, **article_args)
        # changes = article.changeset_set.filter(
        #    reverted=False).order_by('-revision')
        changes = article.changeset_set.all().order_by('-revision')

        template_params = {'article': article,
                           'changes': changes,
                           'allow_write': allow_write}
        if group_slug is not None:
            template_params['group'] = group
        if extra_context is not None:
            template_params.update(extra_context)

        return render_to_response('/'.join([template_dir, template_name]),
                                  template_params,
                                  context_instance=RequestContext(request))

    return HttpResponseNotAllowed(['GET'])


@login_required
def revert_to_revision(request, title,
                       group_slug=None, group_slug_field=None, group_qs=None,
                       article_qs=ALL_ARTICLES,
                       extra_context=None,
                       is_member=None,
                       is_private=None,
                       *args, **kw):

    if request.method == 'POST':

        revision = int(request.POST['revision'])

        article_args = {'title': title}

        group = None
        if group_slug is not None:
            group = get_object_or_404(
                group_qs, **{group_slug_field: group_slug})
            article_args.update({'content_type': get_ct(group),
                                 'object_id': group.id})
            allow_read = has_read_perm(request.user, group, is_member,
                                       is_private)
            allow_write = has_write_perm(request.user, group, is_member)
        else:
            allow_read = allow_write = True

        if not (allow_read or allow_write):
            return HttpResponseForbidden()

        article = get_object_or_404(article_qs, **article_args)

        
        # Check whether there is another Article with the same name to which this article
        # want's to be reverted to. If so: prevent it and show a message.
        old_title = article.changeset_set.filter(
            revision=revision+1).get().old_title
        try:
            art = Article.objects.exclude(pk=article.pk).get(title=old_title)
        except ObjectDoesNotExist:                    
            # No existing article found -> reverting possible
            if request.user.is_authenticated():
                article.revert_to(revision, get_real_ip(request), request.user)
            else:
                article.revert_to(revision, get_real_ip(request))
            return redirect(article)
        # An article with this name exists
        messages.error(
            request, 'Reverting not possible because an article with name \'%s\' already exists' % old_title)
        return redirect(article)

    return HttpResponseNotAllowed(['POST'])


def history(request,
            group_slug=None, group_slug_field=None, group_qs=None,
            article_qs=ALL_ARTICLES, changes_qs=ALL_CHANGES,
            template_name='recentchanges.html',
            template_dir='wiki',
            extra_context=None,
            *args, **kw):

    if request.method == 'GET':
        if group_slug is not None:
            group = get_object_or_404(group_qs,
                                      **{group_slug_field: group_slug})
            changes_qs = changes_qs.filter(article__content_type=get_ct(group),
                                           article__object_id=group.id)
            allow_read = has_read_perm(request.user, group, is_member,
                                       is_private)
            allow_write = has_write_perm(request.user, group, is_member)
        else:
            allow_read = allow_write = True

        if not allow_read:
            return HttpResponseForbidden()

        template_params = {'changes': changes_qs.order_by('-modified'),
                           'allow_write': allow_write}
        if group_slug is not None:
            template_params['group'] = group_slug

        if extra_context is not None:
            template_params.update(extra_context)

        return render_to_response('/'.join([template_dir, template_name]),
                                  template_params,
                                  context_instance=RequestContext(request))
    return HttpResponseNotAllowed(['GET'])


@login_required
def observe_article(request, title,
                    group_slug=None, group_slug_field=None, group_qs=None,
                    article_qs=ALL_ARTICLES,
                    template_name='recentchanges.html',
                    template_dir='wiki',
                    extra_context=None,
                    is_member=None,
                    is_private=None,
                    *args, **kw):
    article_args = {'title': title}
    group = None
    if group_slug is not None:
        group = get_object_or_404(group_qs, **{group_slug_field: group_slug})
        article_args.update({'content_type': get_ct(group),
                             'object_id': group.id})
        allow_read = has_read_perm(request.user, group, is_member,
                                   is_private)
    else:
        allow_read = True

    if not allow_read:
        return HttpResponseForbidden()

    article = get_object_or_404(article_qs, **article_args)

    if not notification.is_observing(article, request.user):
        notification.observe(article, request.user,
                             'wiki_observed_article_changed')

    return redirect(article)

    return HttpResponseNotAllowed(['POST'])


@login_required
def stop_observing_article(request, title,
                           group_slug=None, group_slug_field=None, group_qs=None,
                           article_qs=ALL_ARTICLES,
                           template_name='recentchanges.html',
                           template_dir='wiki',
                           extra_context=None,
                           is_member=None,
                           is_private=None,
                           *args, **kw):
    article_args = {'title': title}
    group = None
    if group_slug is not None:
        group = get_object_or_404(group_qs, **{group_slug_field: group_slug})
        article_args.update({'content_type': get_ct(group),
                             'object_id': group.id})
        allow_read = has_read_perm(request.user, group, is_member,
                                   is_private)
    else:
        allow_read = True

    if not allow_read:
        return HttpResponseForbidden()

    article = get_object_or_404(article_qs, **article_args)

    if notification.is_observing(article, request.user):
        notification.stop_observing(article, request.user)

    return redirect(article)


def article_preview(request):
    """This is a AJAX function that previews the body of the article as it is
    currently displayed.

    This function is actually pretty simple, it just runs the function
    through the view template and returns it to the caller

    """
    rv = do_wl_markdown(request.POST['body'], 'bleachit')
    return HttpResponse(rv, content_type='text/html')


def article_diff(request):
    """This is a AJAX function that diffs the body of the article as it is
    currently displayed with the current version of the article."""
    current_article = get_object_or_404(
        Article, pk=int(request.POST['article']))
    content = request.POST['body']

    diffs = dmp.diff_main(current_article.content, content)
    dmp.diff_cleanupSemantic(diffs)

    return HttpResponse(dmp.diff_prettyHtml(diffs), content_type='text/html')


def backlinks(request, title):
    """Simple text search for links in other wiki articles pointing to the
    current article.

    If we convert WikiWords to markdown wikilinks syntax, this view
    should be changed to use '[[title]]' for searching.

    """

    # Find old title(s) of this article
    this_article = Article.objects.get(title=title)
    changesets = this_article.changeset_set.all()
    old_titles = []
    for cs in changesets:
        if cs.old_title and cs.old_title != title and cs.old_title not in old_titles:
            old_titles.append(cs.old_title)

    # Differentiate between WikiWords and other
    m = re.match(r"(!?)(\b[A-Z][a-z]+[A-Z]\w+\b)", title)
    if m:
        # title is a 'WikiWord' -> This catches also 'MingW' but we have no such title
        search_title = re.compile(r"%s" % title)
    else:
        # Others must be written like links: '[Wiki Page](/wiki/Wiki Page)'
        search_title = re.compile(r"\/%s\)" % title)
    
    # Search for current and previous titles
    found_old_links = []
    found_links = []
    articles_all = Article.objects.all().exclude(title=title)
    for article in articles_all:
        match = search_title.search(article.content)
        if match:
            found_links.append({'title': article.title})
        
        for old_title in old_titles:
            if old_title in article.content:
                found_old_links.append({'old_title': old_title, 'title': article.title })

    context = {'found_links': found_links,
               'found_old_links': found_old_links,
               'name': title}
    return render_to_response('wiki/backlinks.html',
                              context,
                              context_instance=RequestContext(request))

